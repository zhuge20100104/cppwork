{"cells":[{"cell_type":"code","execution_count":0,"id":"20210512-075443_489219442","metadata":{},"outputs":[],"source":["\ncpx_df = spark.read.parquet('s3://aardvark-prod-dca-data/oss/CAVIAR_KEYWORD_METRICS/version=1.1.0/range_type=DAY/date=2021-04-01/')\ncpx_df.printSchema()"]},{"cell_type":"code","execution_count":0,"id":"20210517-010816_473229651","metadata":{},"outputs":[],"source":["%%sh\naws s3 ls s3://aardvark-prod-dca-data/oss/CAVIAR_KEYWORD_METRICS/version=1.1.0/range_type=DAY/date=2021-04-01/\n"]},{"cell_type":"code","execution_count":0,"id":"20190520-023649_1821429393","metadata":{},"outputs":[],"source":["%%sh\n# unified data\naws s3 ls s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.product-download-channel.v1/fact/granularity_code=daily/\n## market_code  apple-store google-play\n\n"]},{"cell_type":"code","execution_count":0,"id":"20190718-023642_1724822828","metadata":{},"outputs":[],"source":["\nfrom pyspark.storagelevel import StorageLevel\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import BooleanType\n\nraw_df = spark.read.parquet(\"s3://aardvark-prod-dca-data/fact/DOWNLOAD_CHANNEL_KPI/version=1.0.0/date=2021-02-19/\")\n\nraw_df.persist(StorageLevel.MEMORY_AND_DISK)\n\nraw_df.createOrReplaceTempView(\"raw_df\")\n\n# raw_df.printSchema()\nraw_df.show(10, False)\n\n## 加入 None 列扩充\nraw_df_inter = (raw_df.withColumn(\"est_organic_featured_share\", when(col('metric_name') == 'predicted_featured_percent', col('metric_value')).otherwise(lit(None)))\n                .withColumn(\"est_organic_search_share\", when(col('metric_name') == 'predicted_true_organic_percent', col('metric_value')).otherwise(lit(None)))\n                .withColumn(\"est_paid_in_app_ads_share\", when(col('metric_name') == 'predicted_paid_in_app_ads_percent', col('metric_value')).otherwise(lit(None)))\n                .withColumn(\"est_paid_search_share\", when(col('metric_name') == 'predicted_paid_search_percent', col('metric_value')).otherwise(lit(None)))\n                )\n\n## 分别选出不为空的 est_organic_featured_share, est_organic_search_share, est_paid_in_app_ads_share和est_paid_search_share值\ndf1 = raw_df_inter.filter(\"est_organic_featured_share is not null\").select(\"app_id\", \"country_code\", \"platform\", \"device_type\",\"est_organic_featured_share\").distinct()\ndf2 = raw_df_inter.filter(\"est_organic_search_share is not null\").select(\"app_id\", \"country_code\", \"platform\", \"device_type\", \"est_organic_search_share\").distinct()\ndf3 = raw_df_inter.filter(\"est_paid_in_app_ads_share is not null\").select(\"app_id\", \"country_code\", \"platform\", \"device_type\", \"est_paid_in_app_ads_share\").distinct()\ndf4 = raw_df_inter.filter(\"est_paid_search_share is not null\").select(\"app_id\", \"country_code\", \"platform\", \"device_type\", \"est_paid_search_share\").distinct()\n\n## 4个df inner join得结果\nres_df = df1.join(df2, [\"app_id\", \"country_code\", \"platform\", \"device_type\"]).join(df3, [\"app_id\", \"country_code\", \"platform\",  \"device_type\"]).join(df4, [\"app_id\", \"country_code\", \"platform\",  \"device_type\"])\n\nres_df.persist(StorageLevel.MEMORY_AND_DISK)\n\nunfied_df = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.product-download-channel.v1/fact/granularity_code=daily/date=2021-02-19/\")\n\nunfied_df.persist(StorageLevel.MEMORY_AND_DISK)\n\nunfied_df.createOrReplaceTempView(\"unfied_df\")\n\nres_df1 = res_df.withColumnRenamed(\"est_organic_featured_share\", \"est_organic_featured_share_src\") \\\n    .withColumnRenamed(\"est_organic_search_share\", \"est_organic_search_share_src\") \\\n    .withColumnRenamed(\"est_paid_in_app_ads_share\", \"est_paid_in_app_ads_share_src\") \\\n    .withColumnRenamed(\"est_paid_search_share\", \"est_paid_search_share_src\") \\\n    .withColumnRenamed(\"app_id\", \"product_key\") \\\n    .withColumn(\"device_key\", when(col('device_type') == '0', lit(7)).otherwise(col('device_type')))\n    \nfinal_df = res_df1.join(unfied_df, [\"product_key\", \"country_code\", \"device_key\"])\n\n@udf(returnType=BooleanType())\ndef cal_diff(est_organic_featured_share_src, est_organic_search_share_src, est_paid_in_app_ads_share_src, est_paid_search_share_src, est_organic_featured_share, est_organic_search_share, est_paid_in_app_ads_share, est_paid_search_share):\n    if est_organic_featured_share_src ==  est_organic_featured_share and est_organic_search_share_src == est_organic_search_share and est_paid_in_app_ads_share_src == est_paid_in_app_ads_share and  est_paid_search_share_src ==  est_paid_search_share:\n        return True\n    return False\n\ndiff_df = final_df.withColumn(\"is_same_metric\", cal_diff(col(\"est_organic_featured_share_src\"), col(\"est_organic_search_share_src\"), col(\"est_paid_in_app_ads_share_src\"), col(\"est_paid_search_share_src\"), col(\"est_organic_featured_share\"), col(\"est_organic_search_share\"), col(\"est_paid_in_app_ads_share\"), col(\"est_paid_search_share\")))\n\ndiff_df.select(\"is_same_metric\").filter(col(\"is_same_metric\")==False).count()\n        \n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20210512-080155_490144583","metadata":{},"outputs":[],"source":["\nfrom pyspark.storagelevel import StorageLevel\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import BooleanType\n\ndate_ = '2021-02-19'\n\nunfied_df = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.product-download-channel.v1/fact/granularity_code=daily/date={}/\".format(date_))\n\n# snowflake production\nsfOptions = {\n  \"sfURL\" : \"appannie_aa_int_prod.us-east-1.snowflakecomputing.com\",\n  \"sfUser\" : \"app_bdp_data_validation_qa\",\n  \"sfPassword\" : \"0HN#s@Wa5$1R8jVj\",\n  \"sfDatabase\" : \"AA_INTELLIGENCE_PRODUCTION\",\n  \"sfSchema\" : \"ADL_STORE_PAID\",\n  \"sfWarehouse\" : \"wh_dod_read7\"\n}\nSNOWFLAKE_SOURCE_NAME = \"net.snowflake.spark.snowflake\"\ndb_df = spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n  .options(**sfOptions) \\\n  .option(\"query\",  \"select * from FACT_STORE_PRODUCT_DOWNLOAD_CHANNEL_V1_CLUSTER_BY_DATE where date='{}'\".format(date_)) \\\n  .load()\n\nres_df = db_df.join(unfied_df, ['product_key', 'country_code', 'device_key'], 'left')\n\nres_df.persist(StorageLevel.MEMORY_AND_DISK)\nres_df.createOrReplaceTempView(\"res_df\")\ncaled_df = spark.sql(\"select  country_code,est_download, EST_DOWNLOAD*est_organic_search_share as   est_organic_search_download1, est_organic_search_download, EST_DOWNLOAD*est_organic_featured_share as   est_organic_featured_download1, est_organic_featured_download,  EST_DOWNLOAD*est_paid_in_app_ads_share as  est_paid_in_app_ads_download1,     est_paid_in_app_ads_download,  EST_DOWNLOAD*est_paid_search_share as est_paid_search_download1, est_paid_search_download from res_df\")\n\n@udf(returnType=BooleanType())\ndef cal_right(est_download,est_organic_featured_share_src, est_organic_search_share_src, est_paid_in_app_ads_share_src, est_paid_search_share_src, est_organic_featured_share, est_organic_search_share, est_paid_in_app_ads_share, est_paid_search_share):\n    \n    if  est_organic_search_share_src is None:\n        if est_download ==  est_organic_search_share:\n            return True\n        else:\n            return False\n    \n    res = (\n        ((int(est_organic_featured_share_src) ==  est_organic_featured_share)  or (int(est_organic_featured_share_src+1) ==  est_organic_featured_share))\n            and ((int(est_organic_search_share_src) == est_organic_search_share) or (int(est_organic_search_share_src+1) == est_organic_search_share))\n            and ((int(est_paid_in_app_ads_share_src) == est_paid_in_app_ads_share) or (int(est_paid_in_app_ads_share_src+1) == est_paid_in_app_ads_share))\n            and ((int(est_paid_search_share_src) ==  est_paid_search_share)  or  (int(est_paid_search_share_src+1) ==  est_paid_search_share))\n            )\n\n    return res\n    \nnew_df = caled_df.withColumn(\"cal_right\", cal_right(col(\"est_download\"), col('est_organic_featured_download1'), col('est_organic_search_download1'), col('est_paid_in_app_ads_download1'), col('est_paid_search_download1'), col('est_organic_featured_download'), col('est_organic_search_download'), col('est_paid_in_app_ads_download'), col('est_paid_search_download')))\n\nnew_df.select(\"cal_right\").filter(col(\"cal_right\")==False).count()\n"]},{"cell_type":"code","execution_count":0,"id":"20210525-072741_1961383870","metadata":{},"outputs":[],"source":["\n\nfrom pyspark.storagelevel import StorageLevel\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import BooleanType\n\ndef print_count(date_):\n    unfied_df = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.product-download-channel.v1/fact/granularity_code=daily/date={}/\".format(date_))\n\n    # snowflake production\n    sfOptions = {\n    \"sfURL\" : \"appannie_aa_int_prod.us-east-1.snowflakecomputing.com\",\n    \"sfUser\" : \"app_bdp_data_validation_qa\",\n    \"sfPassword\" : \"0HN#s@Wa5$1R8jVj\",\n    \"sfDatabase\" : \"AA_INTELLIGENCE_PRODUCTION\",\n    \"sfSchema\" : \"ADL_STORE_PAID\",\n    \"sfWarehouse\" : \"wh_dod_read7\"\n    }\n    SNOWFLAKE_SOURCE_NAME = \"net.snowflake.spark.snowflake\"\n    db_df = spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n    .options(**sfOptions) \\\n    .option(\"query\",  \"select * from FACT_STORE_PRODUCT_DOWNLOAD_CHANNEL_V1_CLUSTER_BY_DATE where date='{}'\".format(date_)) \\\n    .load()\n    \n    print(unfied_df.select(\"product_key\").distinct().count())\n    print(db_df.select(\"product_key\").distinct().count())\n    \n\ndef get_date_range_count(prefix, start, end):\n    for i in range(start, end+1):\n        date_ = prefix + str(i)\n        print(\"Date: \" + date_)\n        print_count(date_)\n        print(\"\\n\")\n       \n        \nprefix = '2021-02-'\nget_date_range_count(prefix, 19, 28)\n\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20210525-074120_1580078489","metadata":{},"outputs":[],"source":["\nfrom pyspark.storagelevel import StorageLevel\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import BooleanType\n\ndate_ = '2021-02-19'\n\nunfied_df = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.product-download-channel.v1/fact/granularity_code=daily/date={}/\".format(date_))\nunfied_df.show(10, False)"]},{"cell_type":"code","execution_count":0,"id":"20210525-062128_1620870591","metadata":{},"outputs":[],"source":["%%sh\n\naws s3 ls s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.product-download-channel.v1/fact/granularity_code=daily/\n\n"]},{"cell_type":"code","execution_count":0,"id":"20190520-023708_1659875458","metadata":{},"outputs":[],"source":["\n## snowflake testing\nsfOptions = {\n  \"sfURL\" : \"appannie.us-east-1.snowflakecomputing.com\",\n  \"sfUser\" : \"fzhu\",\n  \"sfPassword\" : \"Lily870104\",\n  \"sfDatabase\" : \"ONE_SERVICE_TEST_DB_AABJFZHU\",\n  \"sfSchema\" : \"ADL_STORE_PAID\",\n  \"sfWarehouse\" : \"DEMO_WH\"\n}\nSNOWFLAKE_SOURCE_NAME = \"net.snowflake.spark.snowflake\"\ndf = spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n  .options(**sfOptions) \\\n  .option(\"query\",  \"select * from FACT_STORE_MARKET_DOWNLOAD_REVENUE_V1 limit 10\") \\\n  .load()\ndf.show()\n"]},{"cell_type":"code","execution_count":0,"id":"20191227-101546_278685021","metadata":{},"outputs":[],"source":["\n\n# snowflake production\nsfOptions = {\n  \"sfURL\" : \"appannie_aa_int_prod.us-east-1.snowflakecomputing.com\",\n  \"sfUser\" : \"app_bdp_data_validation_qa\",\n  \"sfPassword\" : \"0HN#s@Wa5$1R8jVj\",\n  \"sfDatabase\" : \"AA_INTELLIGENCE_PRODUCTION\",\n  \"sfSchema\" : \"ADL_ASO_PAID\",\n  \"sfWarehouse\" : \"wh_dod_read7\"\n}\nSNOWFLAKE_SOURCE_NAME = \"net.snowflake.spark.snowflake\"\ndf = spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n  .options(**sfOptions) \\\n  .option(\"query\",  \"select * from FACT_ASO_KEYWORD_CPX_V1_CLUSTER_BY_DATE limit 10\") \\\n  .load()\ndf.show()"]},{"cell_type":"code","execution_count":0,"id":"20191227-101544_676669949","metadata":{},"outputs":[],"source":["%%sh\n\nfind / -name \"site-packages\"\n"]},{"cell_type":"code","execution_count":0,"id":"20210522-073134_208068870","metadata":{},"outputs":[],"source":["\n\nimport sys\nsys.path.append(\"/mnt/application_name=bdp_fredric_test/application_code/version=latest/code/bdp_resources/python/\")\nimport vector_add\n\nc = vector_add.CT(range(1, 2000000))\nres = c.vector_add()\n\nres\n\n\n\n\n\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}