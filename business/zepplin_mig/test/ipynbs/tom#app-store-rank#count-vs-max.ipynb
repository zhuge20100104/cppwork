{"cells":[{"cell_type":"code","execution_count":0,"id":"20191115-014610_727182683","metadata":{},"outputs":[],"source":["\n\n# Copyright (c) 2019 App Annie Inc. All rights reserved.\n\n\"\"\"\nDescription:\nTest cases for ios app store rank\n\"\"\"\nimport datetime\nimport random\nimport unittest\n\nimport zlib\n\nfrom aaintdatapipeline.application.app_qa.data_validation_v1.pysparktest import PySparkTest\nfrom aaintdatapipeline.application.app_qa.common.utils import get_date_list\nfrom aaintdatapipeline.application.app_qa.data_validation_v1.constants import IOS_PHONE, IOS_TABLET\n\nfrom aaintdatapipeline.application.app_qa.data_validation_v1.utils import (\n    get_random_ios_feed_id, get_random_date, get_unified_data_path,\n    get_ios_device_code_from_feed_id, get_ios_unified_category_id, get_ios_feed_name_from_id, check_parquet_exist,\n    get_app_store_logic_path, datetime_to_string, get_ios_country_id_from_code, rank_bucket)\nfrom aaintdatapipeline.core.fs.device import unified_bucket\n\n# constant\nfrom aaintdatapipeline.core.fs.router import UnifiedRouter\nfrom aaintdatapipeline.core.log import logger\nfrom aaintdatapipeline.core.urn import Urn\n\nMAC = \"tv-os-tv\"\nAPP_STORE_RANK_URN = Urn(\n    namespace='app-tech.store.app-rank.v2',\n    data_type='fact'\n)\n\nFEED_ID_MAPPING_TO_COLUMN_NAME_TV = {\n    0: \"free_app_download\",\n    1: \"paid_app_download\",\n    2: \"revenue\"\n}\n\nFEED_ID_TO_NAME_TV = {\n    0: \"free_download\",\n    1: \"paid_download\",\n    2: \"revenue\"\n}\nCATEGORY_MAPPING = {\n    \"tv-os-tv\": {\n        36: 300000,\n        360: 300001,\n        6004: 300002,\n        6009: 300003,\n        6012: 300004,\n        6013: 300005,\n        6014: 300006,\n        6016: 300007,\n        6017: 300008\n    }\n}\n\n\n# utils\ndef get_tv_feed_name_from_id(key):\n    return FEED_ID_TO_NAME_TV.get(int(key), \"Can't find tv feed name mapping from feed_id:{}.\".format(key))\n\n\ndef get_tv_unified_category_id(key):\n    return CATEGORY_MAPPING['tv-os-tv'].get(int(key),\n                                              \"Can't find ios unified category id mapping from category_id:{}.\".format(key))\n\n\ndef get_app_store_rank_tv_raw_df(date, country_code):\n    \"\"\"\n    :return: raw_data_frame\n    :rtype: list_of_dic\n    raw_data:\n    _________________________________________________________________________________\n    |    date    |   country_id   |  category_id  |   feed_id   |   rank (app_id)   |\n    |------------|----------------|---------------|-------------|-------------------|\n    | 2019-04-27 | 143441(bigint) |   6016 (int)  |   0 (int)   | 376510438(bigint) |\n    ---------------------------------------------------------------------------------\n    unified_data:\n    _____________________________________________________________________________________\n    |  country_code  |   category_id   |       app_id       | feed_name (free_download) |\n    |----------------|-----------------|--------------------|---------------------------|\n    |      'US'      | 100026 (bigint) | 376510438 (bigint) |    25 (int) (app_rank)    |\n    -------------------------------------------------------------------------------------\n    \"\"\"\n    path = \"country-ranks/{_date}/23/{_country_code}\".format(_date=date, _country_code=country_code)\n    bucket = rank_bucket(\"prod_appannie_appletv\")\n    raw_tv_df = []\n    for key in bucket.list(path):\n        if 'md5' in key or 'SUCCESS' in key:\n            continue\n        raw_data = zlib.decompress(bucket.get(key))\n        for _data in raw_data.splitlines():\n            data = _data.split(\",\")\n            if len(data) == 5:\n                data_dic = {\n                    'date': data[0],\n                    'country_code': data[1],\n                    'category_id': data[2],\n                    'feed_id': data[3],\n                    'rank':  [name.split(\"-\")[1] for name in data[4].split(\" \")]\n                }\n                raw_tv_df.append(data_dic)\n            else:\n                logger.log(\"Error: The length of raw data is wrong, length is {}.\".format(len(data)))\n    return raw_tv_df\n\n\n# cases\nclass TestTVRank(PySparkTest):\n    start_date = '2019-11-12'\n    end_date = '2019-11-12' # datetime_to_string(datetime.date.today() + datetime.timedelta(-2))\n    date = get_random_date(start_date, end_date)\n    country_code = 'US'\n    test_times = 10000\n\n    def setup_spark(self, spark):\n        self.spark = spark\n\n    def setUp(self):\n        super(TestTVRank, self).setUp()\n        self.prepare_data()\n\n    def prepare_data(self):\n        self.raw_data = get_app_store_rank_tv_raw_df(self.date, self.country_code)\n        self.unified_data = {\n            MAC: self.spark.read.parquet(get_unified_data_path(APP_STORE_RANK_URN, self.date, MAC)),\n        }\n\n    def test_tv_rank_completeness(self):\n        if self.raw_data:\n            for _ in range(self.test_times):\n                raw_index = random.randint(0, len(self.raw_data) - 1)\n                raw_sample = self.raw_data[raw_index]\n                unified_device_code = MAC\n                unified_category_id = get_tv_unified_category_id(raw_sample['category_id'])\n                unified_column_name = get_tv_feed_name_from_id(raw_sample['feed_id'])\n                raw_count = len(raw_sample['rank']) if raw_sample['rank'][0] else 0\n                unified_count = self.unified_data[unified_device_code].filter(\n                    \"country_code='{}' and category_id={} and {} is not null\".format(\n                        self.country_code, unified_category_id, unified_column_name)).count()\n                msg = \"{}; {}; raw index = {}; raw count = {}; unified count = {}.\".format(\n                    raw_sample, self.unified_data, raw_index, raw_count, unified_count)\n                print(msg)\n                self.assertEqual(raw_count, unified_count, msg)\n        else:\n            self.check_no_unified_data()\n\n    def test_tv_rank_accuracy(self):\n        if self.raw_data:\n            for _ in range(self.test_times):\n                raw_index = random.randint(0, len(self.raw_data) - 1)\n                print raw_index\n                raw_sample = self.raw_data[raw_index]\n                unified_device_code = MAC\n                unified_category_id = get_tv_unified_category_id(raw_sample['category_id'])\n                unified_column_name = get_tv_feed_name_from_id(raw_sample['feed_id'])\n                _unified_data = self.unified_data[unified_device_code].filter(\n                    \"country_code='{}' and category_id={}\".format(self.country_code, unified_category_id)\n                )\n                for _ in range(5):\n                    # get raw data rank sample\n                    raw_rank = random.randint(0, len(raw_sample['rank']) - 1)\n                    print raw_rank\n                    # get unified_app_id\n                    unified_app_id = long(raw_sample['rank'][raw_rank])\n                    # get unified data rank\n                    unified_rank = int(_unified_data.filter(\"app_id={}\".format(\n                        unified_app_id)).collect()[0][unified_column_name])\n                    expect_raw_rank = raw_rank + 1\n                    msg = \"{}; {}; {}; {}; app_id = {}; raw index = {}; raw rank = {}; unified rank = {}.\".format(\n                            self.date, unified_device_code, self.country_code, unified_category_id, unified_app_id,\n                            raw_index, expect_raw_rank, unified_rank)\n                    print(msg)\n                    self.assertEqual(expect_raw_rank, unified_rank, msg)\n            else:\n                self.check_no_unified_data()\n\n    def check_no_unified_data(self):\n        self.assertEqual(\n            self.unified_data[MAC].filter(\"country_code='{}'\".format(self.country_code)).count(), 0,\n            msg=\"Raw data is null, while unified data is not null at {} in {} on {}.\".format(\n                self.date, self.country_code, MAC))\n\nabc = TestTVRank(\"test_tv_rank_accuracy\")\nabc.setup_spark(spark)\nabc.setUp()\n# abc.test_tv_rank_completeness()\nabc.test_tv_rank_accuracy()\nprint 'pass'\n\n# def main(spark, params):\n#     assert spark, params\n#     suite = unittest.TestSuite()\n#     suite.addTest(TestMACRank('test_tv_rank_completeness'))\n#     log_file = \"/tmp/test.log\"\n#     with open(log_file, \"w\") as f:\n#         runner = unittest.TextTestRunner(f)\n#         runner.run(suite)\n\n"]},{"cell_type":"code","execution_count":0,"id":"20191115-014625_1962552338","metadata":{},"outputs":[],"source":["\n\nimport psycopg2\nimport datetime\nimport pandas as pd\n\ncitus_dsn_ = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=\"aa_citus_db\",\n        user=\"citus_bdp_usage_qa\",\n        host=\"10.2.10.132\",\n        password=\"dNzWtSV3pKTx\",\n        port=5432\n    )\n)\n\ndef query(dsn, sql):\n    with psycopg2.connect(dsn) as conn:\n        conn.autocommit = True\n        with conn.cursor() as cur:\n            cur.execute(sql)\n            result = cur.fetchall()\n            conn.commit()\n    return result\n\ndef get_date_list(begin_date, end_date, freq):\n    date_list = [x.strftime('%Y-%m-%d') for x in list(pd.date_range(start=begin_date, end=end_date, freq=freq))]\n    return date_list\n\nbegin_date = datetime.datetime.strptime(\"2019-01-01\", '%Y-%m-%d')\nend_date = datetime.datetime.strptime(\"2019-11-17\", '%Y-%m-%d')\nDATE_LIST = get_date_list(begin_date, end_date, \"D\")\n\n\nmetrics = [\"free_download\"] #  \"new_paid_download\", \"revenue\", \"paid_download\", \"new_free_download\"\n\n# print \"%table \\tdate\\tcount\"\nprint \"%table {}\\t{}\".format(\"date\", \"count\")\n\nfor date_str in DATE_LIST:\n    date_count = {}\n    for metric in metrics:\n        sql = 'SELECT date, device_code, country_code, category_id, count({metric}),max({metric}) FROM store.store_app_rank_fact_v1  WHERE date = \\'{date_str}\\' AND ( granularity = \\'hourly\\' ) AND ( hour = 23 ) AND ({metric} is not null)  GROUP BY country_code, date, device_code, country_code, category_id ORDER BY date ASC'.format(\n            metric=metric, date_str=date_str)\n\n        test_result = query(citus_dsn_, sql)\n        date_count[metric] = 0\n        for result in test_result:\n            date, device_code, country_code, category_id, count, max = result\n            if count != 0 and count != max:\n                date_count[metric] += 1\n                # print \",\".join([date.strftime(\"%Y-%m-%d\"), device_code, country_code, str(category_id), metric, str(count),str(max)])\n    total_count = sum([date_count[key] for key in date_count])\n    print \"\\t\".join([date_str, str(total_count)])\n\nprint \"end\""]},{"cell_type":"code","execution_count":0,"id":"20191119-074714_1238233070","metadata":{},"outputs":[],"source":["\n\nimport psycopg2\nimport datetime\nimport pandas as pd\n\ncitus_dsn_ = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=\"aa_citus_db\",\n        user=\"citus_bdp_usage_qa\",\n        host=\"10.2.10.132\",\n        password=\"dNzWtSV3pKTx\",\n        port=5432\n    )\n)\n\ndef query(dsn, sql):\n    with psycopg2.connect(dsn) as conn:\n        conn.autocommit = True\n        with conn.cursor() as cur:\n            cur.execute(sql)\n            result = cur.fetchall()\n            conn.commit()\n    return result\n\ndef get_date_list(begin_date, end_date, freq):\n    date_list = [x.strftime('%Y-%m-%d') for x in list(pd.date_range(start=begin_date, end=end_date, freq=freq))]\n    return date_list\n\nbegin_date = datetime.datetime.strptime(\"2014-10-15\", '%Y-%m-%d')\nend_date = datetime.datetime.strptime(\"2014-12-17\", '%Y-%m-%d')\nDATE_LIST = get_date_list(begin_date, end_date, \"D\")\n\n\n\nmetrics = [\"free_download\", \"new_paid_download\", \"revenue\", \"paid_download\", \"new_free_download\"]\ndevice_list = [\"ios-phone\",\"ios-tablet\",\"android-all\",\"tv-os-tv\",\"mac-os-mac\"]\nprint \"%table {}\\t{}\\t{}\".format(\"date\",\"device\",\"count\")\n\nDATE_LIST = [\"2014-02-09\", \"2014-02-13\", \"2014-02-14\", \"2014-03-04\", \"2014-03-06\", \"2014-03-09\", \"2014-03-11\", \"2014-03-12\", \"2014-03-18\", \"2014-03-19\", \"2014-04-02\", \"2014-04-10\", \"2014-05-01\", \"2014-05-31\", \"2014-06-01\", \"2014-06-02\", \"2014-06-03\", \"2014-06-04\", \"2014-06-05\", \"2014-06-06\", \"2014-06-07\", \"2014-06-08\", \"2014-06-09\", \"2014-06-10\", \"2014-06-11\", \"2014-06-17\", \"2014-06-18\", \"2014-06-19\", \"2014-06-20\", \"2014-07-31\", \"2014-08-01\", \"2014-08-02\", \"2014-08-03\", \"2014-08-04\", \"2014-08-06\", \"2014-08-07\", \"2014-08-08\", \"2014-08-09\", \"2014-08-10\", \"2014-08-11\", \"2014-08-12\", \"2014-08-13\", \"2014-08-21\", \"2014-08-28\", \"2014-09-09\", \"2014-09-12\", \"2014-10-02\", \"2014-10-05\", \"2014-10-14\", \"2014-10-16\", \"2014-10-17\", \"2014-10-18\", \"2014-10-19\", \"2014-10-20\", \"2014-10-23\", \"2014-10-24\", \"2014-10-25\", \"2014-10-26\", \"2014-10-27\", \"2014-10-28\", \"2014-10-29\", \"2014-10-30\", \"2014-10-31\", \"2014-11-01\", \"2014-11-02\", \"2014-11-03\", \"2014-11-04\", \"2014-11-05\", \"2014-11-06\", \"2014-11-07\", \"2014-11-08\", \"2014-11-09\", \"2014-11-10\", \"2014-11-11\", \"2014-11-12\", \"2014-11-13\", \"2014-11-14\", \"2014-11-15\", \"2014-11-16\", \"2014-11-17\", \"2014-11-18\", \"2014-11-19\", \"2014-11-20\", \"2014-11-21\", \"2014-11-22\", \"2014-11-23\", \"2014-11-24\", \"2014-11-25\", \"2014-11-26\", \"2014-11-27\", \"2014-11-28\", \"2014-11-29\", \"2014-11-30\", \"2014-12-01\", \"2014-12-02\", \"2014-12-03\", \"2014-12-04\", \"2014-12-05\", \"2014-12-06\", \"2014-12-07\", \"2014-12-08\", \"2014-12-09\", \"2014-12-10\", \"2014-12-11\", \"2014-12-12\", \"2014-12-13\", \"2014-12-14\", \"2014-12-15\", \"2014-12-16\", \"2014-12-27\", \"2014-12-28\", \"2015-01-06\", \"2015-01-07\", \"2015-01-14\", \"2015-01-15\", \"2015-02-05\", \"2015-02-24\", \"2015-02-25\", \"2015-03-05\", \"2015-03-06\", \"2015-03-09\", \"2015-03-11\", \"2015-03-16\", \"2015-03-20\", \"2015-03-25\", \"2015-03-26\", \"2015-04-03\", \"2015-04-04\", \"2015-04-05\", \"2015-04-08\", \"2015-04-12\", \"2015-04-13\", \"2015-04-16\", \"2015-04-17\", \"2015-04-18\", \"2015-04-19\", \"2015-04-21\", \"2015-04-22\", \"2015-05-04\", \"2015-05-06\", \"2015-05-15\", \"2015-05-26\", \"2015-06-02\", \"2015-06-16\", \"2015-06-17\", \"2015-06-24\", \"2016-04-19\", \"2016-04-24\", \"2016-05-29\", \"2016-10-04\", \"2016-10-11\", \"2016-10-19\", \"2016-11-30\", \"2019-06-10\", \"2019-06-26\", \"2019-07-01\", \"2019-07-05\", \"2019-07-22\", \"2019-07-24\", \"2019-07-29\", \"2019-08-23\", \"2019-08-24\", \"2019-09-05\", \"2019-09-06\", \"2019-09-07\", \"2019-09-08\", \"2019-09-09\", \"2019-09-10\", \"2019-09-11\", \"2019-09-12\", \"2019-09-13\", \"2019-09-14\", \"2019-09-15\", \"2019-09-16\", \"2019-09-17\", \"2019-09-18\", \"2019-09-19\", \"2019-09-22\", \"2019-09-23\", \"2019-09-24\", \"2019-09-25\", \"2019-09-26\", \"2019-09-27\", \"2019-09-28\", \"2019-09-29\", \"2019-09-30\", \"2019-10-01\", \"2019-10-02\", \"2019-10-03\", \"2019-10-04\", \"2019-10-05\", \"2019-10-06\", \"2019-10-07\", \"2019-10-09\", \"2019-10-10\", \"2019-10-11\", \"2019-10-12\", \"2019-10-13\", \"2019-10-16\", \"2019-10-19\", \"2019-10-22\", \"2019-10-23\", \"2019-10-24\", \"2019-10-25\", \"2019-10-26\", \"2019-10-27\", \"2019-10-28\", \"2019-10-29\", \"2019-10-30\", \"2019-10-31\", \"2019-11-01\", \"2019-11-02\", \"2019-11-03\"]\n\nfor date_str in DATE_LIST:\n    date_count = {\"ios-phone\":0,\"ios-tablet\":0,\"android-all\":0,\"tv-os-tv\":0,\"mac-os-mac\":0 }\n    for metric in metrics:\n        sql = 'SELECT date, device_code, country_code, category_id, count({metric}),max({metric}) FROM store.store_app_rank_fact_v1  WHERE date = \\'{date_str}\\' AND ( granularity = \\'hourly\\' ) AND ( hour = 23 ) AND ({metric} is not null)  GROUP BY country_code, date, device_code, country_code, category_id ORDER BY date ASC'.format(\n            metric=metric, date_str=date_str)\n\n        test_result = query(citus_dsn_, sql)\n        for result in test_result:\n            date, device_code, country_code, category_id, count, max = result\n            if count != 0 and count != max:\n                date_count[device_code] += 1\n                # print \",\".join([date.strftime(\"%Y-%m-%d\"), device_code, country_code, str(category_id), metric, str(count),str(max)])\n    for key in device_list:\n        print \"\\t\".join([date_str, key, str(date_count[key])])\n\nprint \"end\""]},{"cell_type":"code","execution_count":0,"id":"20191119-033810_1017320824","metadata":{},"outputs":[],"source":["\nfrom aaintdatapipeline.core.conf import Conf\nfrom aaintdatapipeline.core.fs.device import S3Bucket, specified_bucket\nfrom aaintdatapipeline.core.fs.device import unified_bucket\nimport zlib\n\nbucket_name = \"prod_appannie_android\"\ns3 = S3Bucket(Conf(bucket_name = bucket_name))\nconf = Conf(\n        bucket_name=bucket_name,\n        bucket_class=S3Bucket\n)\npath = \"country-ranks/{_date}/23/{_country_code}\".format(_date='2019-09-16', _country_code=\"CN\")\nbucket = specified_bucket(conf)\nraw_data = zlib.decompress(bucket.get(\"country-ranks/2019-09-16/23/CN\"))\n\nfor _data in raw_data.splitlines():\n    if \"MUSIC_AND_AUDIO\" in _data:\n        _data_list = _data.split(\",\")\n        _rank_list = _data_list[4].split(\" \")\n        print _data_list[:3]\n        print len(_rank_list)\n        for _rank in _rank_list:\n            print _rank\n\n\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20191119-035451_89482630","metadata":{},"outputs":[],"source":["\n\ndate = \"2019-09-16\"\ndevice_code = \"android-all\"\n\nprint spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-free/unified/app-tech.store.app-rank.v1/fact/date={}/device_code={}/\".format(date,device_code)).select([\"app_id\",\"free_download\"]).filter(\"country_code='CN' AND category_id='400047'\").orderBy(\"free_download\").show(1000)\n"]},{"cell_type":"code","execution_count":0,"id":"20191119-032400_2104474079","metadata":{},"outputs":[],"source":["%%sh\n#2019-09-16,android-all,CN,400047,free_download,638,1307\n\nPGPASSWORD='dNzWtSV3pKTx' psql -h 10.2.10.132 -U citus_bdp_usage_qa -d aa_citus_db -p 5432 << EOF \nSELECT app_id, free_download FROM store.store_app_rank_fact_v1  WHERE (date='2019-09-16') AND category_id=400047 AND country_code='CN' AND ( granularity = 'hourly' ) AND ( hour = 23 ) ORDER BY free_download ASC;\nEOF\n"]},{"cell_type":"code","execution_count":0,"id":"20191122-092817_693282954","metadata":{},"outputs":[],"source":["\nfrom aaintdatapipeline.core.conf import Conf\nfrom aaintdatapipeline.core.fs.device import S3Bucket, specified_bucket\nfrom aaintdatapipeline.core.fs.device import unified_bucket\nimport zlib\n\nbucket_name = \"prod_appannie_ios\"\ns3 = S3Bucket(Conf(bucket_name = bucket_name))\nconf = Conf(\n        bucket_name=bucket_name,\n        bucket_class=S3Bucket\n)\npath = \"country-ranks/{_date}/23/{_country_code}\".format(_date='2014-11-01', _country_code=\"CN\")\nbucket = specified_bucket(conf)\nraw_data = zlib.decompress(bucket.get(\"country-ranks/2014-11-01/23/143465\"))\n\nfor _data in raw_data.splitlines():\n        _data_list = _data.split((\"\\t\"))\n        _date = _data_list[0]\n        _category_id = _data_list[2]\n        _country_id = _data_list[1]\n        _feed_id = _data_list[3]\n        _rank_list = _data_list[4].split(\" \")\n        # print _data_list\n        if _date==\"2014-11-01\" and _category_id=='36' and _feed_id=='0' and _country_id=='143465':\n            print _data\n        # print _data_list[:3]\n        # print len(_rank_list)\n        # for _rank in _rank_list:\n        #     print _rank\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20191122-093036_1151894155","metadata":{},"outputs":[],"source":["%%sh\n#2019-09-16,android-all,CN,400047,free_download,638,1307\n\nPGPASSWORD='dNzWtSV3pKTx' psql -h 10.2.10.132 -U citus_bdp_usage_qa -d aa_citus_db -p 5432 << EOF \nSELECT count(*) FROM store.store_app_rank_fact_v1  WHERE (date='2014-11-01') AND category_id=100000 AND country_code='CN' AND ( granularity = 'hourly' ) AND ( hour = 23 ) AND (device_code='ios-phone') AND (free_download is not null);\nSELECT * FROM store.store_app_rank_fact_v1  WHERE (date='2014-11-03') AND (category_id=100000) AND (country_code='CN') AND ( granularity = 'hourly' ) AND ( hour = 23 ) AND (device_code='ios-phone') AND (free_download is not null) ORDER BY free_download ASC;\nEOF\n"]},{"cell_type":"code","execution_count":0,"id":"20191122-095642_790708218","metadata":{},"outputs":[],"source":["\n\ndate = \"2014-11-03\"\ndevice_code = \"ios-phone\"\n\nprint spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-free/unified/app-tech.store.app-rank.v1/fact/date={}/device_code={}/\".format(date,device_code)).select([\"app_id\",\"free_download\"]).filter(\"country_code='CN' AND category_id='100000' AND free_download is not null\").orderBy(\"free_download\").show(5000)\n"]},{"cell_type":"code","execution_count":0,"id":"20191119-034202_665122478","metadata":{},"outputs":[],"source":["%%sh\n\n# aws s3 ls s3://prod_appannie_android/country-ranks/\naws s3 ls s3://b2c-prod-data-pipeline-unified-store-free/unified/app-tech.store.app-rank.v1/fact/date=2019-09-16/device_code=android-all/\naws s3 ls s3://b2c-prod-data-pipeline-unified-store-free/unified/app-tech.store.app-rank.v1/fact/\n"]},{"cell_type":"code","execution_count":0,"id":"20191125-020213_395101025","metadata":{},"outputs":[],"source":["%%sh\n\n# aws s3 ls s3://prod_appannie_ios/country-ranks/2014-11-12/23/ | grep -- 'US\\|143441'\n# aws s3 ls s3://prod_appannie_android/country-ranks/2014-02-14/23/ | awk '{print $4}' | grep -v -E '^[a-zA-Z0-9]{2}$'\n# aws s3 ls --recursive s3://prod_appannie_android/country-ranks/ | awk '{print $4}' | grep -v -E '\\/[a-zA-Z]{2}$'\naws s3 ls --recursive s3://prod_appannie_ios/country-ranks/ | awk '{print $4}' | grep -v -E '\\/[0-9]{6}$'\n"]},{"cell_type":"code","execution_count":0,"id":"20191119-034728_1410749219","metadata":{},"outputs":[],"source":["%%sh\n\naws s3 ls s3://prod_appannie_android/country-ranks/2016-10-30/23/\n"]},{"cell_type":"code","execution_count":0,"id":"20191205-051346_1294155124","metadata":{},"outputs":[],"source":["%%sh\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}