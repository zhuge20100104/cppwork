{"cells":[{"cell_type":"code","execution_count":0,"id":"20190909-140647_1100683911","metadata":{},"outputs":[],"source":["\nfrom copy import deepcopy\nimport time\nimport pandas as pd\nimport datetime\nimport random\n\n# PARAMS\ndate_time_str = \"2016-01-01\t,\t2016-06-30\"\n\nbegin_date = datetime.datetime.strptime(date_time_str.split(\",\")[0].strip(), '%Y-%m-%d')\nend_date = datetime.datetime.strptime(date_time_str.split(\",\")[1].strip(), '%Y-%m-%d')\nDEBUG = False\n\n# CONSTANTS\nDEVICE_ID_CODE_MAPPING_WITHOUT_ALL = {\n    1001: 'android-phone',\n    1002: 'android-tablet',\n    2001: 'ios-phone',\n    2002: 'ios-tablet',\n}\n\n\nDEVICE_ID_CODE_MAPPING = {\n    1000: 'android-all',\n    1001: 'android-phone',\n    1002: 'android-tablet',\n    2000: 'ios-all',\n    2001: 'ios-phone',\n    2002: 'ios-tablet',\n}\n\nAD_PLATFORMS = {\n    1: 'ALL',\n    101: 'ADMOB',\n    109: 'TAPJOY',\n    110: 'CHARTBOOST',\n    111: 'INMOBI',\n    112: 'ADCOLONY',\n    114: 'APPLOVIN',\n    116: 'VUNGLE',\n    121: 'UNITYADS',\n    136: 'FACEBOOK',\n    142: 'SUPERSONIC',\n    171: 'STARTAPP',\n    200: 'TWITTER',\n    201: 'INSTAGRAM',\n    202: 'FBA',\n    203: 'YOUTUBE',\n    311: 'MOPUB',\n    316: 'FYBER',\n    324: 'FBCREATIVESONLY',\n    325: 'IGCREATIVESONLY',\n}\n\nMKT_COUNTRY_CODE = ['CN', 'AU', 'BR', 'CA', 'FI', 'FR', 'DE', 'HK', 'IN', 'ID', 'IT', 'JP', 'MX', 'NZ', 'NO', 'RU', 'KR', 'ES', 'SE', 'TW', 'TH', 'TR', 'GB', 'US', 'DK']\n\ndef get_date_list(begin_date, end_date, freq):\n    date_list = [x.strftime('%Y-%m-%d') for x in list(pd.date_range(start=begin_date, end=end_date, freq=freq))]\n    return date_list\n\nDATE_LIST = get_date_list(begin_date, end_date, \"D\")\n\n# UTILS\ndef log(strlog):\n    if DEBUG == True:\n        print strlog\n\ndef write_to_file(filename, logstr):\n    print logstr\n    with open(filename,'a') as file_object:\n        file_object.write(logstr + \"\\n\")\n\ndef get_random(data_list):\n    return random.choice(data_list)\n\n\ndef get_campaign_id_from_unified(campaign_sha):\n    log(\"campaign_sha : {}\".format(campaign_sha))\n    s3_path = \"s3://b2c-prod-data-pipeline-unified-market/unified/app-tech.market.campaign-id-mapping.v1/dimension/\"\n    df_unified = spark.read.parquet(s3_path).filter(\"campaign_original_id='{}'\".format(campaign_sha)).collect()\n    return df_unified[0].campaign_id\n\ndef get_creative_id_from_unified(creative_sha):\n    log(\"creative_sha : {}\".format(creative_sha))\n    s3_path = \"s3://b2c-prod-data-pipeline-unified-market/unified/app-tech.market.creative-id-mapping.v1/dimension/\"\n    df_unified = spark.read.parquet(s3_path).filter(\"creative_md5='{}'\".format(creative_sha)).collect()\n    return df_unified[0].creative_id\n\ndef get_platform_device_type_from_device_id(device_id):\n    platform = int(device_id / 1000)\n    device_type = device_id % 100\n    return platform, device_type\n\ndef get_random_filter_dict_from_raw(s3_mart, date):\n    MAX_STEP = 10\n    random_flag = True\n    for try_steps in range(1, MAX_STEP +1):\n        device_id = get_random(DEVICE_ID_CODE_MAPPING_WITHOUT_ALL.keys())\n        platform,device_type = get_platform_device_type_from_device_id(device_id)\n        filter_dict = {\n            \"device_id\": device_id,\n            \"network_id\": get_random(AD_PLATFORMS.keys()),\n            \"platform\": platform,\n            \"device_type\": device_type,\n            \"country\": get_random(MKT_COUNTRY_CODE),\n            \"date\": date\n        }\n\n        log(filter_dict)\n        s3_path = \"s3://aardvark-prod-dca-data/fact/MKT_META_DATA_NEW/version=2.0.0/date={date}/\".format(**filter_dict)\n        filter_one_sql = \"country='{country}' AND platform='{platform}' AND device_type='{device_type}' AND network_id='{network_id}'\".format(\n            **filter_dict)\n        if try_steps == MAX_STEP:\n            filter_one_sql = \"True\".format(**filter_dict)\n            random_flag = False\n        df_unified = []\n        try:\n            log(\"{}  {}\".format(s3_path, filter_one_sql))\n            df_unified = spark.read.parquet(s3_path).filter(filter_one_sql).limit(1).collect()\n            df_unified_row = df_unified[0]\n            log(df_unified_row)\n\n            filter_dict[\"country\"] = df_unified_row['country']\n            filter_dict[\"platform\"] = df_unified_row['platform']\n            filter_dict[\"device_type\"] = df_unified_row['device_type']\n            filter_dict[\"network_id\"] = df_unified_row['network_id']\n            filter_dict[\"device_id\"] = int(\"{}00{}\".format(df_unified_row['platform'], df_unified_row['device_type']))\n\n            filter_dict[\"creative_id_sha\"] = df_unified_row['creative_id']\n            filter_dict[\"ad_app_id\"] = df_unified_row['advertiser_app_id']\n            filter_dict[\"campaign_id_sha\"] = df_unified_row['campaign_id']\n            filter_dict[\"pub_app_id\"] = df_unified_row['publisher_app_id']\n            return filter_dict, random_flag\n        except Exception, e:\n            print \"s\"\n            continue\n    return None, random_flag\n\n\n# CODE MAIN\npass_count = 0\nfail_count = 0\n\ntimestamp = time.strftime('%Y-%m-%d_%H-%M-%S', time.localtime(time.time()))\nlog_filename = '/tmp/db_log_{}.log'.format(DATE_LIST[0])\n\nfor date in DATE_LIST:\n    MAX_STEP = 10\n    for i in range(1, MAX_STEP+1):\n        time_start = time.time()\n        raw_mart_name = \"ad_app_pub_app_estimate\"\n        filter_dict, random_flag = get_random_filter_dict_from_raw(raw_mart_name, date)\n        if filter_dict is None:\n            print \"NO RAW DATA for {}\".format(date)\n            break\n        log(filter_dict)\n        for key in deepcopy(filter_dict):\n            if key == \"device_id\":\n                filter_dict[\"device_code\"] = DEVICE_ID_CODE_MAPPING[filter_dict[key]]\n            if key == \"country\":\n                filter_dict[\"country_code\"] = filter_dict[key]\n            if key == \"network_id\":\n                filter_dict[\"ad_platform_id\"] = filter_dict[\"network_id\"]\n            if key == \"creative_id_sha\":\n                filter_dict[\"creative_id\"] = get_creative_id_from_unified(filter_dict[key])\n            if key == \"campaign_id_sha\":\n                filter_dict[\"campaign_id\"] = get_campaign_id_from_unified(filter_dict[key]) if filter_dict[key] else -1\n\n        log(filter_dict)\n        s3_path = \"s3://b2c-prod-data-pipeline-unified-market/unified/app-tech.market.creative-log.v1/fact/date={date}/device_code={device_code}/\".format(\n            **filter_dict)\n        filter_sql = \"ad_platform_id='{ad_platform_id}' AND pub_app_id='{pub_app_id}' AND ad_app_id='{ad_app_id}' \" \\\n                     \"AND country_code='{country_code}' AND creative_id={creative_id} AND campaign_id='{campaign_id}' \".format(\n            **filter_dict)\n\n        df_unified = spark.read.parquet(s3_path).filter(filter_sql).collect()\n        log(df_unified)\n        time_end = time.time()\n\n        time_cost = int(time_end-time_start)\n        if len(df_unified) == 1:\n            pass_count += 1\n\n            logstr = \"PASS P:{} F:{} T:{} D:{} R:{}\".format(pass_count,fail_count, time_cost, date, random_flag)\n            write_to_file(log_filename, logstr)\n\n        else:\n            fail_count += 1\n            logstr = \"FAIL P:{} F:{} T:{} D:{} R:{}\".format(pass_count,fail_count,time_cost,date, random_flag)\n            write_to_file(log_filename, logstr)\n            write_to_file(log_filename, filter_dict)\n            write_to_file(log_filename, df_unified)\n        if not random_flag:\n            print \"NOT RANDOM for {}\".format(date)\n            break\n\n"]},{"cell_type":"code","execution_count":0,"id":"20190909-143206_1192165058","metadata":{},"outputs":[],"source":["\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}