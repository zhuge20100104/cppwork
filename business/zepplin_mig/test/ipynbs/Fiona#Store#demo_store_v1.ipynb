{"cells":[{"cell_type":"code","execution_count":0,"id":"20210113-090614_1715798635","metadata":{},"outputs":[],"source":["%%sh\nPGPASSWORD='duI3wInpB@g82os2' psql -h 10.2.10.132 -p 5432 -Ucitus1_datapipeline -d aa_citus_db << EOF\nSET search_path = 'store';\n-- \\d\n--select * from store.store_market_size_fact_v1 where date='2020-10-01' and device_code= 'ios-tablet' and country_code='CA' and category_id = 100009 order by est_market_size_revenue\nselect * from store.store_market_size_fact_v1 where date between '2020-01-03' and '2020-01-09' and country_code='US' and category_id in (100000, 400000) limit 10;\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20200509-062612_820051250","metadata":{},"outputs":[],"source":["\n\ndef platform_feed_to_metric(platform, feed):\n    mapping = [\n        ['ios', 0, 'iphone_free'],\n        ['ios',1, 'iphone_paid'],\n        ['ios',2, 'iphone_revenue'],\n        ['ios',101,'ipad_free'],\n        ['ios',100,'ipad_paid'],\n        ['ios',102,'ipad_revenue'],\n        ['android',0,'est_free_app_download'],\n        ['android',1,'est_paid_app_download'],\n        ['android',2,'est_revenue'],\n    ]\n    return [x for x in mapping if (x[0], x[1]) == (platform, feed)][0][2]\n    \nplatform_feed_to_metric(\"ios\",0)"]},{"cell_type":"code","execution_count":0,"id":"20200509-054555_300641065","metadata":{},"outputs":[],"source":["\n\nimport datetime\nfrom pyspark.sql import types as T\nfrom pyspark.sql import functions as F\n\n\nstart_week = \"2015-01-01\"\nend_week = \"2015-02-01\"\n\nreal_date1 = datetime.date(*[int(x) for x in start_week.split('-')])\nreal_date2 = datetime.date(*[int(x) for x in end_week.split('-')])\ndate_range = real_date2 - real_date1\ndates = list()\nsar_list=list()\nfor days in xrange(date_range.days):\n    dates.append(str(real_date1 + datetime.timedelta(days)))\n\ndates_temp=list()\nsar_list=list()\nfor days in xrange(date_range.days):\n    dates_temp.append(real_date1 + datetime.timedelta(days))\n    if (real_date1 + datetime.timedelta(days)).weekday() == 5:\n        temp=list()\n        while dates_temp:\n            temp.append(dates_temp.pop())\n        sar_list.append(str(real_date1 + datetime.timedelta(days)))\n\n\ndaily_csv_schema = T.StructType(\n    [\n        T.StructField(\"store_id\", T.IntegerType(), True),\n        T.StructField(\"date\", T.StringType(), True),\n        T.StructField(\"platform_id\", T.IntegerType(), True),\n        T.StructField(\"vertical\", T.IntegerType(), True),\n        T.StructField(\"feed\", T.IntegerType(), True),\n        T.StructField(\"id\", T.LongType(), True),\n        T.StructField(\"est\", T.IntegerType(), True),\n        T.StructField(\"category\", T.IntegerType(), True),\n        T.StructField(\"rank\", T.IntegerType(), True)\n    ]\n)\n\n\n\nweekly_csv_schema = T.StructType(\n    [\n        T.StructField(\"id\", T.LongType(), True),\n        T.StructField(\"store_id\", T.IntegerType(), True),\n        T.StructField(\"category\", T.IntegerType(), True),\n        T.StructField(\"start_date\", T.StringType(), True),\n        T.StructField(\"end_date\", T.StringType(), True),\n        T.StructField(\"iphone_free\", T.IntegerType(), True),\n        T.StructField(\"iphone_paid\", T.IntegerType(), True),\n        T.StructField(\"iphone_revenue\", T.IntegerType(), True),\n        T.StructField(\"ipad_free\", T.LongType(), True),\n        T.StructField(\"ipad_paid\", T.IntegerType(), True),\n        T.StructField(\"ipad_revenue\", T.IntegerType(), True)\n    ]\n)\n \nmonthly_csv_schema = T.StructType(\n    [\n        T.StructField(\"id\", T.LongType(), True),\n        T.StructField(\"store_id\", T.IntegerType(), True),\n        T.StructField(\"category\", T.IntegerType(), True),\n        T.StructField(\"year\", T.StringType(), True),\n        T.StructField(\"month\", T.StringType(), True),\n        T.StructField(\"iphone_free\", T.IntegerType(), True),\n        T.StructField(\"iphone_paid\", T.IntegerType(), True),\n        T.StructField(\"iphone_revenue\", T.IntegerType(), True),\n        T.StructField(\"ipad_free\", T.LongType(), True),\n        T.StructField(\"ipad_paid\", T.IntegerType(), True),\n        T.StructField(\"ipad_revenue\", T.IntegerType(), True)\n    ]\n)\n       \n\nprint 'test date'\nprint dates\nprint sar_list\n \n\ndf_1 = spark.read.option(\"basePath\", \"s3://b2c-prod-dca-store-estimates/store_est/v_final/DAY/\").schema(daily_csv_schema).csv(\"s3://b2c-prod-dca-store-estimates/store_est/v_final/DAY/{%s}/ios/sbe_est_app/*/\" % \",\".join(dates), sep=\"\\t\").cache()\ndf_2 = spark.read.option(\"basePath\", \"s3://b2c-prod-dca-store-estimates/store_est/v_final/MONTH/\").schema(monthly_csv_schema).csv(\"s3://b2c-prod-dca-store-estimates/store_est/v_final/MONTH/{%s}/ios/sbe_est_app/*/\" % dates[-1], sep=\"\\t\").cache()\ndf_3 = spark.read.option(\"basePath\", \"s3://b2c-prod-dca-store-estimates/store_est/v_final/WEEK/\").schema(weekly_csv_schema).csv(\"s3://b2c-prod-dca-store-estimates/store_est/v_final/WEEK/{%s}/ios/sbe_est_app/*/\" % \",\".join(sar_list), sep=\"\\t\").cache()\n\ndf_1.createOrReplaceTempView(\"daily_data\")\ndf_2.createOrReplaceTempView(\"monthly_data\")\ndf_3.createOrReplaceTempView(\"weekly_data\")\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200509-055032_666102011","metadata":{},"outputs":[],"source":["\nspark.sql(\"select * from daily_data where id=378736412 and store_id=143462 and category=100 \").show(2)\nspark.sql(\"select * from weekly_data where id=378736412 and store_id=143462 and category=100 \").show()\nspark.sql(\"select * from monthly_data where id=378736412 and store_id=143462 and category=100 \").show()"]},{"cell_type":"code","execution_count":0,"id":"20200509-055539_228162629","metadata":{},"outputs":[],"source":["\nspark.sql(\"select * from daily_data where id=585544408 and store_id=143496 and category=7019 and feed=101 \").show(2) # ipad free\nspark.sql(\"select * from weekly_data where id=585544408 and store_id=143496 and category=7019\").show()\nspark.sql(\"select * from monthly_data where id=585544408 and store_id=143496 and category=7019 \").show()"]},{"cell_type":"code","execution_count":0,"id":"20200509-062528_114053560","metadata":{},"outputs":[],"source":["\ntest_df = spark.sql('''\nSELECT * \nFROM   ( \n                SELECT   id, \n                         store_id, \n                         category, \n                         platform_id, \n                         vertical, \n                         feed, \n                         Sum(est) AS est\n                FROM     daily_data \n                WHERE    feed IN ( 0, \n                                  1, \n                                  2, \n                                  101, \n                                  100, \n                                  102 ) \n                GROUP BY id, \n                         store_id, \n                         category, \n                         platform_id, \n                         vertical, \n                         feed\n                          ) PIVOT ( max(est) FOR feed IN (0, \n                                                          1, \n                                                          2, \n                                                          101, \n                                                          100, \n                                                          102) ) ''').withColumnRenamed(\"0\", platform_feed_to_metric('ios',0)).withColumnRenamed(\"1\", platform_feed_to_metric('ios',1)).withColumnRenamed(\"2\", platform_feed_to_metric('ios',2)).withColumnRenamed(\"101\", platform_feed_to_metric('ios',101)).withColumnRenamed(\"100\", platform_feed_to_metric('ios',100)).withColumnRenamed(\"102\", platform_feed_to_metric('ios',102)).na.fill(0).cache()\ntest_df.createOrReplaceTempView(\"transfer\")\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200509-062638_977444665","metadata":{},"outputs":[],"source":["\nspark.sql(\"select * from transfer\").show(2)\ndiff_df_1 = spark.sql(\"select id, category, store_id, iphone_free, iphone_paid, iphone_revenue, ipad_free, ipad_paid, ipad_revenue from transfer except all select id, category, store_id, iphone_free, iphone_paid, iphone_revenue, ipad_free, ipad_paid, ipad_revenue from monthly_data \").cache()\ndiff_df_2 = spark.sql(\"select id, category, store_id, iphone_free, iphone_paid, iphone_revenue, ipad_free, ipad_paid, ipad_revenue from monthly_data except all select id, category, store_id, iphone_free, iphone_paid, iphone_revenue, ipad_free, ipad_paid, ipad_revenue from transfer\").cache()\nprint diff_df_1.take(10)\nprint diff_df_2.take(10)\n"]},{"cell_type":"code","execution_count":0,"id":"20200509-061336_2136203551","metadata":{},"outputs":[],"source":["\nspark.sql(\"select id, category, sum(est) from daily_data where id=585544408 and store_id=143496 and feed=0 group by category, id \").show(32) # ipad free\nspark.sql(\"select id, category, est, date from daily_data where id=585544408 and store_id=143496 and feed=0  \").show(500) # ipad free\n\nspark.sql(\"select * from weekly_data where id=585544408 and store_id=143496 \").show()\nspark.sql(\"select * from monthly_data where id=585544408 and store_id=143496  \").show()\n\n\n\n\n\n\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200509-064746_1971241215","metadata":{},"outputs":[],"source":["\nnew_transfor_df = spark.sql('''\nSELECT\n  *\nFROM\n  (\n    SELECT\n      id,\n      Sum(est) AS est,\n      category,\n      store_id,\n      platform_id,\n      feed,\n      vertical\n    FROM\n      (\n        SELECT\n          DISTINCT d1.id,\n          d1.est,\n          d1.store_id,\n          d1.date,\n          d1.feed,\n          d1.vertical,\n          d1.platform_id,\n          d2.category\n        FROM\n          daily_data AS d1\n          JOIN daily_data AS d2 \n          ON d1.id = d2.id\n          AND d1.store_id = d2.store_id\n          AND d1.feed = d2.feed\n          AND d1.vertical = d2.vertical\n          AND d1.platform_id = d2.platform_id\n      ) AS t\n    WHERE\n      feed IN (\n        0,\n        1,\n        2,\n        101,\n        100,\n        102\n      )\n    GROUP BY\n      id,\n      store_id,\n      category,\n      platform_id,\n      vertical,\n      feed\n  ) PIVOT (\n    max(est) FOR feed IN (\n      0,\n      1,\n      2,\n      101,\n      100,\n      102\n    )\n  )\n''').withColumnRenamed(\"0\", platform_feed_to_metric('ios',0)).withColumnRenamed(\"1\", platform_feed_to_metric('ios',1)).withColumnRenamed(\"2\", platform_feed_to_metric('ios',2)).withColumnRenamed(\"101\", platform_feed_to_metric('ios',101)).withColumnRenamed(\"100\", platform_feed_to_metric('ios',100)).withColumnRenamed(\"102\", platform_feed_to_metric('ios',102)).na.fill(0).cache()\n                                                        \nnew_transfor_df.createOrReplaceTempView(\"transfer_new\")\n\nspark.sql(\"select * from transfer_new where id=585544408 and store_id=143496\").show()\n"]},{"cell_type":"code","execution_count":0,"id":"20200509-062314_1938590039","metadata":{},"outputs":[],"source":["\ntest_df = spark.sql('''\nSELECT * \nFROM   ( \n                SELECT   id, \n                         store_id, \n                         category, \n                         platform_id, \n                         vertical, \n                         feed, \n                         Sum(est) AS est\n                FROM     \n                        (select \n                        distinct \n                        id, \n                         store_id, \n                         platform_id, \n                         vertical, \n                         feed,\n                         est from daily_data) \n                         as distinct_data\n                WHERE    feed IN ( 0, \n                                  1, \n                                  2, \n                                  101, \n                                  100, \n                                  102 ) \n                AND  id=585544408 and store_id=143496 and feed=0 \n                GROUP BY id, \n                         store_id, \n                         category, \n                         platform_id, \n                         vertical, \n                         feed\n                          ) PIVOT ( max(est) FOR feed IN (0, \n                                                          1, \n                                                          2, \n                                                          101, \n                                                          100, \n                                                          102) ) ''').withColumnRenamed(\"0\", platform_feed_to_metric('ios',0)).withColumnRenamed(\"1\", platform_feed_to_metric('ios',1)).withColumnRenamed(\"2\", platform_feed_to_metric('ios',2)).withColumnRenamed(\"101\", platform_feed_to_metric('ios',101)).withColumnRenamed(\"100\", platform_feed_to_metric('ios',100)).withColumnRenamed(\"102\", platform_feed_to_metric('ios',102)).na.fill(0).cache()\ntest_df.createOrReplaceTempView(\"transfer\")\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200509-090309_1477993244","metadata":{},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":0,"id":"20200509-063707_1834077477","metadata":{},"outputs":[],"source":["\nprint spark.sql(\"select id, category, store_id, iphone_free, iphone_paid, iphone_revenue, ipad_free, ipad_paid, ipad_revenue from transfer_new where category =100 except select id, category, store_id, iphone_free, iphone_paid, iphone_revenue, ipad_free, ipad_paid, ipad_revenue from monthly_data where category =100 order by iphone_paid desc \").show(200)\n\nprint spark.sql(\"select id, category, store_id, iphone_free, iphone_paid, iphone_revenue, ipad_free, ipad_paid, ipad_revenue from monthly_data where category =100 except select id, category, store_id, iphone_free, iphone_paid, iphone_revenue, ipad_free, ipad_paid, ipad_revenue from transfer_new where category =100  order by iphone_paid desc \").show(200)\n\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200509-063729_1489859326","metadata":{},"outputs":[],"source":["\n# spark.sql(\"select * from daily_data where id=891453663 and store_id=143441 and date between '2015-01-03' and '2015-01-10' and feed = 1 and category in (100, 36) order by category desc \").show()\n# spark.sql(\"select * from weekly_data where id=891453663 and store_id=143441 and category=100   \").show(2)\nspark.sql(\"select * from monthly_data where id=891453663 and store_id=143441  \").show()\n"]},{"cell_type":"code","execution_count":0,"id":"20200509-085141_1764244172","metadata":{},"outputs":[],"source":["\n+--------+----------+-----------+--------+----+---------+---+--------+----+\n|store_id|      date|platform_id|vertical|feed|       id|est|category|rank|\n+--------+----------+-----------+--------+----+---------+---+--------+----+\n|  143441|2015-01-09|          1|       0|   1|891453663|1|     100|  43|\n|  143441|2015-01-03|          1|       0|   1|891453663|1|     100|  38|\n|  143441|2015-01-08|          1|       0|   1|891453663|1|     100|  31|\n|  143441|2015-01-10|          1|       0|   1|891453663|1|     100|  43|\n|  143441|2015-01-05|          1|       0|   1|891453663|1|     100|  75|\n|  143441|2015-01-07|          1|       0|   1|891453663|1|     100| 103|\n|  143441|2015-01-04|          1|       0|   1|891453663|1|     100|  49|\n|  143441|2015-01-06|          1|       0|   1|891453663|1|     100|  79|\n|  143441|2015-01-03|          1|       0|   1|891453663|1|      36| 106|\n|  143441|2015-01-08|          1|       0|   1|891453663|1|      36|  83|\n+--------+----------+-----------+--------+----+---------+---+--------+----+\n\nweekly = 7 36\nweekly = 7 100\n\nweekly = 2 36\nweekly = 7 100\n"]},{"cell_type":"code","execution_count":0,"id":"20200509-074427_2143608316","metadata":{},"outputs":[],"source":["\nprint spark.sql(\"select * from transfer_new where id=891453663 and store_id=143441\").show()"]},{"cell_type":"code","execution_count":0,"id":"20200509-074812_1099030586","metadata":{},"outputs":[],"source":["\n14237344.000/39529475.000"]},{"cell_type":"code","execution_count":0,"id":"20200509-074855_699895599","metadata":{},"outputs":[],"source":["\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}