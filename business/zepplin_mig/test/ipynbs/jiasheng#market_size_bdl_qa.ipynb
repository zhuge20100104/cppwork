{"cells":[{"cell_type":"code","execution_count":0,"id":"20201005-113125_1286482238","metadata":{},"outputs":[],"source":["\nimport psycopg2\nimport datetime\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nimport aaplproxy\nfrom aadatapipelinecore.core.urn import Urn\nfrom aaplproxy.da.local_sqlrunner import LocalSqlRunner\nfrom aadatapipelinecore.core.utils.module import application_settings\nfrom pyspark.sql import Row\nfrom pyspark.sql.types import *\nfrom pyspark.sql import functions as F\ndef citus_row(start,end):\n    def get_data_in_citus(start,end):\n        citus_dsn_ = (\n            \"dbname='{db}' user='{user}' password='{password}' \"\n            \"host='{host}' port='{port}'\".format(\n                db=\"aa_citus_db\",\n                user=\"citus_bdp_usage_qa\",\n                host=\"10.2.10.132\",\n                password=\"dNzWtSV3pKTx\",\n                port=5432\n            )\n        )\n        count_sql = \"SELECT category_id, CAST(SUM(est_market_size_download)AS bigint)AS sum_est_market_size_download,CAST(SUM(est_market_size_revenue) AS bigint)AS sum_est_market_size_revenue, count(1) FROM store.store_market_size_fact_v1  WHERE date >='{}' AND date<='{}' AND category_id=400027  group by category_id order by category_id desc\".format(start,end)\n        db_data = query(citus_dsn_, count_sql)\n        sum_sql = \"SELECT CAST(SUM(est_market_size_download)AS bigint)AS sum_est_market_size_download,CAST(SUM(est_market_size_revenue) AS bigint)AS sum_est_market_size_revenue, count(1) FROM store.store_market_size_fact_v1  WHERE date >='{}' AND date<='{}' \".format(start,end)\n        sum_data = query(citus_dsn_, sum_sql)\n        print(sum_data)\n        return db_data\n    def query(dsn, sql):\n        with psycopg2.connect(dsn) as conn:\n            conn.autocommit = True\n            with conn.cursor() as cur:\n                cur.execute(sql)\n                result = cur.fetchall()\n                conn.commit()\n        return result\n    result = get_data_in_citus(start,end)\n    return [Row(category_id=r[0],sum_est_market_size_download=r[1], sum_est_market_size_revenue=r[2], count=r[3]) for r in result]\ndef generate_citus_result(spark, citus_data):\n    schema = StructType([\n    StructField(\"category_id\", StringType(), True),\n    StructField(\"sum_est_market_size_download\", LongType(), True),\n    StructField(\"sum_est_market_size_revenue\", LongType(), True),\n    StructField(\"count\", LongType(), True)\n    ])\n    df_3 = spark.createDataFrame(citus_data, schema)\n    df_3.createOrReplaceTempView(\"citus_data\")\n    return spark.sql(\"select * from citus_data\")\nprint(\"================online=======================\")\nonline_df = generate_citus_result(spark,citus_row(\"2020-08-01\",\"2020-08-01\"))\nonline_df.show()\nprint(\"================BDL=========================\")\nsample_data_df=spark.read.format(\"delta\").load(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.market-size.v1/fact/\")\nsample_data_df.createOrReplaceTempView(\"sample_data\")\nprint(\"Not distinct data\")\nspark.sql(\"SELECT SUM(est_market_size_download) as sum_est_market_size_download, SUM(est_market_size_revenue) as sum_est_market_size_revenue,count(1) FROM sample_data where date = '2020-08-01'  \").show()\ntest_sample_data_df =spark.sql(\"select category_id,SUM(est_market_size_download) as sum_est_market_size_download, SUM(est_market_size_revenue) as sum_est_market_size_revenue,count(1) FROM sample_data where date = '2020-08-01' and category_id=400027 and (device_code = 'android-all' or device_code = 'ios-all' or device_code = 'ios-tablet' or device_code = 'ios-phone') group by category_id order by category_id desc\")\ntest_sample_data_df.createOrReplaceTempView(\"test_sample_data\")\ntest_sample_data_df.show()\n\nprint(\"except all test\")\ntest_sample_data_df.exceptAll(online_df).show()\n\n\nprint(\"Distinct data\")\nspark.sql(\"select distinct app_price_type_id, category_id, country_code, device_code, purchase_type_id, granularity, date, est_market_size_download, est_market_size_revenue FROM sample_data where date = '2020-08-01' \").createOrReplaceTempView(\"distinct_sample_data\")\n\nspark.sql(\"SELECT SUM(est_market_size_download) as sum_est_market_size_download, SUM(est_market_size_revenue) as sum_est_market_size_revenue,count(1) FROM distinct_sample_data \").show()\n\ndistinct_data_df = spark.sql(\"select category_id,SUM(est_market_size_download) as sum_est_market_size_download, SUM(est_market_size_revenue) as sum_est_market_size_revenue,count(1) FROM distinct_sample_data where category_id=400027  group by category_id order by category_id desc\")\ndistinct_data_df.show()\n\nprint(\"except all test\")\ndistinct_data_df.exceptAll(online_df).show()"]},{"cell_type":"code","execution_count":0,"id":"20201005-123136_455441920","metadata":{},"outputs":[],"source":["\nspark.sql(\"select * from sample_data where category_id = 400027 and est_market_size_download = 23297488 and est_market_size_revenue= 813448\").show()\n"]},{"cell_type":"code","execution_count":0,"id":"20201005-124343_666219687","metadata":{},"outputs":[],"source":["%%sh\n\naws s3 ls s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.market-size.v1/fact/"]},{"cell_type":"code","execution_count":0,"id":"20201005-145441_68983364","metadata":{},"outputs":[],"source":["%%sh\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}