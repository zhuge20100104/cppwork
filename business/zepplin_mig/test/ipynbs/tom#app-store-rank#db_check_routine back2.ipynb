{"cells":[{"cell_type":"code","execution_count":0,"id":"20191202-102223_26950095","metadata":{},"outputs":[],"source":["\n\n# Copyright (c) 2018 App Annie Inc. All rights reserved.\n\n\"\"\"\nDB Check modules\n\"\"\"\nimport unittest\n\nimport datetime\nimport croniter\nfrom sqlalchemy.dialects.postgresql import psycopg2\nfrom aaintdatapipeline.application.app_qa.conf.settings import PRODUCT_SERVICE_ENDPOINT, \\\n    MICRO_SERVICE_ACCESS_ID, MICRO_SERVICE_SECRET_KEY, PG_AA_NAME, PG_AA_ACCESS_ID, PG_AA_HOSTS, PG_AA_SECRET_KEY, \\\n    PG_AA_AMAZON_NAME, PG_AA_AMAZON_ACCESS_ID, PG_AA_AMAZON_HOSTS, PG_AA_AMAZON_SECRET_KEY\nfrom aaintdatapipeline.core.utils import microservice\n\nfrom copy import deepcopy\nfrom aaintdatapipeline.application.app_qa.common.db_check_utils import query\nfrom aaintdatapipeline.application.app_qa.conf.settings import CITUS_MKT_NAME\nfrom aaintdatapipeline.application.app_qa.conf.settings import CITUS_AA_CITUS_DB_NAME, \\\n    CITUS_AA_CITUS_DB_ACCESS_ID, CITUS_AA_CITUS_DB_HOSTS, CITUS_AA_CITUS_DB_SECRET_KEY\n# from aaintdatapipeline.application.app_qa.db_check_v1.pyspark_test import PySparkTest\nfrom aaintdatapipeline.core.conf import Conf\nfrom aaintdatapipeline.core.fs.device import S3Bucket, specified_bucket\nimport zlib\nimport pandas as pd\nimport pandas.io.sql as sqlio\nimport psycopg2\n\n# base_test.py\nimport os\nimport shutil\nimport unittest\n\nfrom aaintdatapipeline.core.conf.settings import ROOT\nfrom aaintdatapipeline.core.fs.device import meta_bucket, raw_bucket, unified_bucket\nfrom aaintdatapipeline.core.fs.device.bucket import unified_data_system_config_bucket\nfrom aaintdatapipeline.core.utils.commandline import env\nfrom aaintdatapipeline.core.utils.encode import activate_system_utf8\nfrom aaintdatapipeline.core.utils.spark import create_spark, eject_all_caches\n\n\nclass PipelineTest(unittest.TestCase):\n    routing_config = None\n    trigger_datetime = None\n    prev_etl_datetime = None\n\n    def __init__(self, methodName='runTest', trigger_datetime=None):\n        super(PipelineTest, self).__init__(methodName)\n        self.trigger_datetime = trigger_datetime or datetime.datetime.utcnow()\n        self.check_date_str = self._get_check_date_str_from_routing_config(self.trigger_datetime)\n        self.prev_etl_datetime = self._get_pre_etl_completed_date()\n\n    def setUp(self):\n        super(PipelineTest, self).setUp()\n        self._verify_config()\n\n    @classmethod\n    def setUpClass(cls):\n        super(PipelineTest, cls).setUpClass()\n        activate_system_utf8()\n        env(PYTHONIOENCODING='utf8')\n        cls.spark = create_spark()\n        cls.sc = cls.spark.sparkContext\n\n    def _verify_config(cls):\n        cls.assertIsNotNone(cls.routing_config)\n        cls.assertIsNotNone(cls.trigger_datetime)\n        cls.assertIsNotNone(cls.prev_etl_datetime)\n        cls.assertIsNotNone(cls.check_date_str)\n\n    def _get_check_date_str_from_routing_config(self, trigger_datetime):\n        \"\"\"\n        return the date of : <days_delta> ago from previous scheduled date&time of <cron_time>.\n        e.g.\n        config = (\"0 9 * * *\", 1), today is 2019-10-27 8:00\n        so previous scheduled date&time is 2019-10-26 9:00\n        will return \"2019-10-25\"\n\n        :param config: config format: (<cron_time>, <days_delta>)\n        :type config: tuple\n        the cron_time please refer to https://support.acquia.com/hc/en-us/articles/360004224494-Cron-time-string-format\n        the days_delta is the days ago from the expected date.\n        :return: date string of \"%Y-%m-%d\"\n        :type return: str\n        \"\"\"\n        schedule, days_delta = self.routing_config\n        # here use UTC now\n        cron = croniter.croniter(schedule, trigger_datetime)\n        date = cron.get_prev(datetime.datetime) - datetime.timedelta(days=days_delta)\n        return date.strftime(\"%Y-%m-%d\")\n\n    def _get_pre_etl_completed_date(self):\n        schedule, _ = self.routing_config\n        cron = croniter.croniter(schedule, self.trigger_datetime)\n        date = cron.get_prev(datetime.datetime)\n        return date\n\n\ndef rank_bucket(bucket_str):\n    \"\"\"\n    Get Bucket Object from bucket string\n    :param bucket_str: string like: s3://xxx.xxx\n    :type bucket_str: str\n    :return: bucket_object\n    :rtype: bucket_object\n    \"\"\"\n    conf = Conf(\n        bucket_name=bucket_str,\n        bucket_class=S3Bucket\n    )\n    return specified_bucket(conf)\n\n\nclass AppStoreRankRawData():\n    bucket_name = \"\"\n    bucket_path = \"\"\n    data_split_str = \"\"\n    rank_list_split_str = \"\"\n    rank_split_str = \"\"\n    accept_feeds = []\n    country_code_mapping = {}\n    category_id_mapping = {}\n    metric_mapping = {}\n    market_code = \"\"\n    filename_available = []\n\n    def get(self, date, country_code, category_id):\n        df = self.get_raw_data_by_date(date)\n        return df.loc[(df.country_code == country_code) & (df.category_id == category_id )]\n\n    def parse_mapping(self, df):\n        if self.country_code_mapping:\n            df = df.replace({\"country_code\": self.country_code_mapping})\n\n        if self.category_id_mapping:\n            df[\"category_id\"] = pd.to_numeric(df[\"category_id\"])\n            df = df.replace({\"category_id\": self.category_id_mapping})\n\n        if self.metric_mapping:\n            df[\"metric\"] = pd.to_numeric(df[\"metric\"])\n            df = df.replace({\"metric\": self.metric_mapping})\n        return df\n\n\n    def parse_df_to_unified_format(self, df):\n        columns = [\"app_id\", \"category_id\", \"country_code\",\n                   \"free_download\", \"paid_download\", \"revenue\", \"new_free_download\", \"new_paid_download\", ]\n        new_df = pd.DataFrame(columns=columns)\n        for index,row in df.iterrows():\n            if len(row.app_rank_list)==0:\n                continue\n            for index,app_id in enumerate(row.app_rank_list, start=1):\n                free_download = index if df.metric == 'free_download' else None\n                paid_download = index if df.metric == 'paid_download' else None\n                revenue = index if df.metric == 'revenue' else None\n                new_free_download = index if df.metric == 'new_free_download' else None\n                new_paid_download = index if df.metric == 'new_paid_download' else None\n                new_df.append([app_id, df.category_id, df.country_code,\n                               free_download, paid_download, revenue, new_free_download, new_paid_download])\n\n    def get_unified_format(self, date):\n        df = self.get_raw_data_by_date(date)\n        return self.parse_df_to_unified_format(df)\n\n    def get_raw_data_by_date(self, date):\n        \"\"\"\n        :return: raw_data_frame\n        :rtype: list_of_dic\n        raw_data:\n        _________________________________________________________________________________\n        |    date    |   country_id   |  category_id  |   feed_id   |   rank (app_id)   |\n        |------------|----------------|---------------|-------------|-------------------|\n        | 2019-04-27 | 143441(bigint) |   6016 (int)  |   0 (int)   | 376510438(bigint) |\n        ---------------------------------------------------------------------------------\n        unified_data:\n        _____________________________________________________________________________________\n        |  country_code  |   category_id   |       app_id       | feed_name (free_download) |\n        |----------------|-----------------|--------------------|---------------------------|\n        |      'US'      | 100026 (bigint) | 376510438 (bigint) |    25 (int) (app_rank)    |\n        -------------------------------------------------------------------------------------\n        \"\"\"\n        path = \"{_bucket_path}/{_date}/23/\".format(_date=date, _bucket_path=self.bucket_path)\n        bucket = rank_bucket(self.bucket_name)\n        columns = ['date', 'country_code', 'category_id', 'metric', 'app_rank_list']\n\n        _raw_data_list = []\n        for filepath in bucket.list(path):\n            filename = filepath.replace(path, '')\n            if filename not in self.filename_available:\n                continue\n            _raw_data = zlib.decompress(bucket.get(filepath))\n            for _line in _raw_data.splitlines():\n                line_data = _line.split(self.data_split_str)\n                app_rank_list = [rank_app for rank_app in line_data[4].split(self.rank_list_split_str) if\n                                 rank_app.strip() != '']\n                if self.rank_split_str:\n                    app_rank_list = [app_rank.split(self.rank_split_str)[1] for app_rank in app_rank_list]\n                line_data[4] = app_rank_list\n                _raw_data_list.append(line_data)\n        return self.parse_mapping(pd.DataFrame(_raw_data_list, columns=columns))\n\n# class IPhoneRaw(AppStoreRankRawData):\n#     bucket_name = \"prod_appannie_ios\"\n#     bucket_path = \"country-ranks\"\n#     data_split_str = \"\\t\"\n#     rank_list_split_str = \" \"\n#     accept_feeds = [0, 1, 2]\n#\n#\n# class IPadRaw(AppStoreRankRawData):\n#     bucket_name = \"prod_appannie_ios\"\n#     bucket_path = \"country-ranks\"\n#     data_split_str = \"\\t\"\n#     rank_list_split_str = \" \"\n\n\n# class MacRaw(AppStoreRankRawData):\n#     bucket_name = \"prod_appannie_ios\"\n#     bucket_path = \"mac/country-ranks\"\n#     data_split_str = \"\\t\"\n#     rank_list_split_str = \" \"\n\nMETRIC_MAPPING = {\n    'tv-os-tv': {\n        0: 'free_download',\n        1: 'paid_download',\n        2: 'revenue'\n    },\n    'amazon-store':{\n        'android-all':{\n            0: 'free_download',\n            1: 'paid_download',\n            3: 'new_free_download'\n        }\n    }\n\n}\nCOUNTRY_CODE_MAPPING = {\n    'ios': {143441: 'US', 143442: 'FR', 143443: 'DE', 143444: 'GB', 143445: 'AT',\n            143446: 'BE', 143447: 'FI', 143448: 'GR', 143449: 'IE', 143450: 'IT',\n            143451: 'LU', 143452: 'NL', 143453: 'PT', 143454: 'ES', 143455: 'CA',\n            143456: 'SE', 143457: 'NO', 143458: 'DK', 143459: 'CH', 143460: 'AU',\n            143461: 'NZ', 143462: 'JP', 143463: 'HK', 143464: 'SG', 143465: 'CN',\n            143466: 'KR', 143467: 'IN', 143468: 'MX', 143469: 'RU', 143470: 'TW',\n            143471: 'VN', 143472: 'ZA', 143473: 'MY', 143474: 'PH', 143475: 'TH',\n            143476: 'ID', 143477: 'PK', 143478: 'PL', 143479: 'SA', 143480: 'TR',\n            143481: 'AE', 143482: 'HU', 143483: 'CL', 143484: 'NP', 143485: 'PA',\n            143486: 'LK', 143487: 'RO', 143489: 'CZ', 143491: 'IL', 143492: 'UA',\n            143493: 'KW', 143494: 'HR', 143495: 'CR', 143496: 'SK', 143497: 'LB',\n            143498: 'QA', 143499: 'SI', 143501: 'CO', 143502: 'VE', 143503: 'BR',\n            143504: 'GT', 143505: 'AR', 143506: 'SV', 143507: 'PE', 143508: 'DO',\n            143509: 'EC', 143510: 'HN', 143511: 'JM', 143512: 'NI', 143513: 'PY',\n            143514: 'UY', 143515: 'MO', 143516: 'EG', 143517: 'KZ', 143518: 'EE',\n            143519: 'LV', 143520: 'LT', 143521: 'MT', 143523: 'MD', 143524: 'AM',\n            143525: 'BW', 143526: 'BG', 143528: 'JO', 143529: 'KE', 143530: 'MK',\n            143531: 'MG', 143532: 'ML', 143533: 'MU', 143534: 'NE', 143535: 'SN',\n            143536: 'TN', 143537: 'UG', 143538: 'AI', 143539: 'BS', 143540: 'AG',\n            143541: 'BB', 143542: 'BM', 143543: 'VG', 143544: 'KY', 143545: 'DM',\n            143546: 'GD', 143547: 'MS', 143548: 'KN', 143549: 'LC', 143550: 'VC',\n            143551: 'TT', 143552: 'TC', 143553: 'GY', 143554: 'SR', 143555: 'BZ',\n            143556: 'BO', 143557: 'CY', 143558: 'IS', 143559: 'BH', 143560: 'BN',\n            143561: 'NG', 143562: 'OM', 143563: 'DZ', 143564: 'AO', 143565: 'BY',\n            143566: 'UZ', 143568: 'AZ', 143571: 'YE', 143572: 'TZ', 143573: 'GH',\n            143575: 'AL', 143576: 'BJ', 143577: 'BT', 143578: 'BF', 143579: 'KH',\n            143580: 'CV', 143581: 'TD', 143582: 'CG', 143583: 'FJ', 143584: 'GM',\n            143585: 'GW', 143586: 'KG', 143587: 'LA', 143588: 'LR', 143589: 'MW',\n            143590: 'MR', 143591: 'FM', 143592: 'MN', 143593: 'MZ', 143594: 'NA',\n            143595: 'PW', 143597: 'PG', 143598: 'ST', 143599: 'SC', 143600: 'SL',\n            143601: 'SB', 143602: 'SZ', 143603: 'TJ', 143604: 'TM', 143605: 'ZW',\n            0: 'WW'},\n    'amazon-store':{\n        'android-all':{\n            'UK' : 'GB',\n        }\n    }\n}\nCATEGORY_ID_MAPPING = {\n    \"tv-os-tv\": {\n        36: 300000,\n        360: 300001,\n        6004: 300002,\n        6009: 300003,\n        6012: 300004,\n        6013: 300005,\n        6014: 300006,\n        6016: 300007,\n        6017: 300008\n    },\n    'amazon-store':{\n        'android-all': {\n        10: 720000,\n        6395703011: 720001,\n        6395710011: 720003,\n        6395709011: 720004,\n        6395711011: 720005,\n        6395712011: 720006,\n        6395713011: 720007,\n        6395702011: 720008,\n        6395714011: 720009,\n        6395715011: 720010,\n        6395716011: 720011,\n        6395717011: 720012,\n        6395720011: 720015,\n        6395726011: 720016,\n        6395718011: 720017,\n        6395727011: 720019,\n        6395729011: 720020,\n        6395745011: 720021,\n        6395728011: 720022,\n        6395730011: 720024,\n        6395731011: 720025,\n        6395732011: 720026,\n        6395733011: 720028,\n        6395734011: 720029,\n        6395735011: 720030,\n        6395736011: 720031,\n        6395737011: 720032,\n        6395738011: 720033,\n        6395747011: 720034,\n        6395744011: 720035,\n        8: 720000,\n        148152071: 720001,\n        148153071: 720003,\n        148154071: 720004,\n        148155071: 720005,\n        148156071: 720006,\n        148157071: 720007,\n        148158071: 720008,\n        148159071: 720009,\n        148160071: 720010,\n        148161071: 720011,\n        148162071: 720012,\n        148165071: 720013,\n        148163071: 720015,\n        148164071: 720016,\n        148166071: 720018,\n        148167071: 720019,\n        148168071: 720020,\n        148169071: 720021,\n        152899071: 720022,\n        148170071: 720024,\n        148171071: 720025,\n        148172071: 720026,\n        148173071: 720028,\n        148174071: 720029,\n        148175071: 720030,\n        148176071: 720031,\n        148177071: 720032,\n        148178071: 720033,\n        148180071: 720034,\n        148181071: 720035,\n        2: 720000,\n        1720677031: 720001,\n        1720683031: 720002,\n        1720684031: 720003,\n        1720685031: 720004,\n        1720686031: 720005,\n        1720687031: 720006,\n        1720688031: 720007,\n        1720689031: 720009,\n        1720690031: 720010,\n        1720691031: 720011,\n        1720692031: 720012,\n        1720693031: 720013,\n        1720712031: 720014,\n        1720694031: 720015,\n        1720700031: 720016,\n        1720701031: 720018,\n        1720702031: 720019,\n        1720703031: 720020,\n        1720704031: 720021,\n        1720705031: 720022,\n        1720706031: 720023,\n        1720707031: 720025,\n        1720708031: 720026,\n        1720714031: 720027,\n        1720709031: 720028,\n        1720710031: 720029,\n        1720711031: 720030,\n        1720713031: 720032,\n        1720724031: 720034,\n        1720725031: 720035,\n        3: 720000,\n        1726743031: 720001,\n        1726749031: 720002,\n        1726750031: 720003,\n        1726751031: 720004,\n        1726752031: 720005,\n        1726753031: 720006,\n        1726754031: 720007,\n        1726755031: 720009,\n        1726756031: 720010,\n        1726757031: 720011,\n        1726758031: 720012,\n        1726759031: 720013,\n        1726778031: 720014,\n        1726760031: 720015,\n        1726766031: 720016,\n        1726767031: 720018,\n        1726768031: 720019,\n        1726769031: 720020,\n        1726770031: 720021,\n        1726771031: 720022,\n        1726772031: 720023,\n        1726773031: 720025,\n        1726774031: 720026,\n        1726775031: 720028,\n        1726776031: 720029,\n        1726777031: 720030,\n        1726779031: 720032,\n        1726780031: 720033,\n        1726790031: 720034,\n        1726791031: 720035,\n        4: 720000,\n        1722761031: 720001,\n        1722767031: 720002,\n        1722768031: 720003,\n        1722769031: 720004,\n        1722770031: 720005,\n        1722771031: 720006,\n        1722772031: 720007,\n        1722773031: 720009,\n        1722774031: 720010,\n        1722775031: 720011,\n        1722776031: 720012,\n        1722777031: 720013,\n        1722796031: 720014,\n        1722778031: 720015,\n        1722784031: 720016,\n        1722785031: 720018,\n        1722786031: 720019,\n        1722787031: 720020,\n        1722788031: 720021,\n        1722789031: 720022,\n        1722790031: 720023,\n        1722791031: 720025,\n        1722792031: 720026,\n        1722793031: 720028,\n        1722794031: 720029,\n        1722795031: 720030,\n        1722797031: 720032,\n        1722798031: 720033,\n        1722808031: 720034,\n        1722809031: 720035,\n        5: 720000,\n        1725417031: 720001,\n        1725423031: 720002,\n        1725424031: 720003,\n        1725425031: 720004,\n        1725426031: 720005,\n        1725427031: 720006,\n        1725428031: 720007,\n        1725429031: 720009,\n        1725430031: 720010,\n        1725431031: 720011,\n        1725432031: 720012,\n        1725433031: 720013,\n        1725452031: 720014,\n        1725434031: 720015,\n        1725440031: 720016,\n        1725441031: 720018,\n        1725442031: 720019,\n        1725443031: 720020,\n        1725444031: 720021,\n        1725445031: 720022,\n        1725446031: 720023,\n        1725447031: 720025,\n        1725448031: 720026,\n        1725449031: 720028,\n        1725450031: 720029,\n        1725451031: 720030,\n        1725453031: 720032,\n        1725454031: 720033,\n        1725464031: 720034,\n        1725465031: 720035,\n        6: 720000,\n        2386858051: 720001,\n        2386869051: 720002,\n        2386864051: 720003,\n        2386865051: 720004,\n        2386866051: 720005,\n        2386867051: 720006,\n        2386868051: 720007,\n        2386870051: 720009,\n        2386871051: 720010,\n        2386872051: 720011,\n        2386873051: 720012,\n        2386874051: 720013,\n        2386892051: 720014,\n        2386875051: 720015,\n        2386881051: 720016,\n        2386882051: 720018,\n        2386883051: 720019,\n        2386884051: 720020,\n        2386885051: 720021,\n        2386894051: 720022,\n        2386886051: 720023,\n        2386887051: 720025,\n        2386888051: 720026,\n        2386889051: 720028,\n        2386890051: 720029,\n        2386891051: 720030,\n        2386893051: 720032,\n        2386895051: 720033,\n        2386905051: 720034,\n        2386906051: 720035,\n        7: 720000,\n        1710348031: 720001,\n        1710359031: 720002,\n        1710354031: 720003,\n        1710355031: 720004,\n        1710356031: 720005,\n        1710357031: 720006,\n        1710358031: 720007,\n        1710360031: 720009,\n        1710361031: 720010,\n        1710362031: 720011,\n        1710363031: 720012,\n        1710364031: 720013,\n        1710383031: 720014,\n        1710365031: 720015,\n        1710371031: 720016,\n        1710372031: 720018,\n        1710373031: 720019,\n        1710374031: 720020,\n        1710375031: 720021,\n        1710376031: 720022,\n        1710377031: 720023,\n        1710378031: 720025,\n        1710379031: 720026,\n        1710380031: 720028,\n        1710381031: 720029,\n        1710382031: 720030,\n        1710384031: 720032,\n        1710385031: 720033,\n        1710395031: 720034,\n        1710396031: 720035,\n        1: 720000,\n        2478833011: 720001,\n        2478832011: 720002,\n        2478840011: 720003,\n        2478839011: 720004,\n        2478841011: 720005,\n        2478842011: 720006,\n        2478843011: 720007,\n        2478844011: 720009,\n        2478845011: 720010,\n        2478846011: 720011,\n        2478847011: 720012,\n        2478867011: 720014,\n        2478849011: 720015,\n        2478855011: 720016,\n        3310778011: 720017,\n        2478858011: 720019,\n        2478860011: 720020,\n        2577638011: 720021,\n        2478859011: 720022,\n        2478861011: 720024,\n        2478862011: 720025,\n        2478863011: 720026,\n        2478864011: 720028,\n        2478865011: 720029,\n        2478866011: 720030,\n        2478868011: 720032,\n        2478869011: 720033,\n        3310683011: 720034,\n        2478875011: 720035\n        }\n    }\n}\n\n\nclass AppleTvRaw(AppStoreRankRawData):\n    bucket_name = \"prod_appannie_appletv\"\n    bucket_path = \"country-ranks\"\n    data_split_str = \",\"\n    rank_list_split_str = \" \"\n    rank_split_str = \"-\"\n    country_code_mapping = None\n    category_id_mapping = CATEGORY_ID_MAPPING['tv-os-tv']\n    metric_mapping = METRIC_MAPPING['tv-os-tv']\n\n    device_code = \"tv-os-tv\"\n    market_code = 'apple-store'\n\n    # this should be a product_service\n    def get_code_app_id_mapping(self, code_list, dsn):\n        sql_code_list = \"','\".join(code_list)\n        sql = \"select id,code from product where code in ('{}')\".format(sql_code_list)\n        conn = psycopg2.connect(dsn)\n        df = sqlio.read_sql_query(sql, conn)\n        return df\n\n\nclass AmazonRaw(AppStoreRankRawData):\n    bucket_name = \"prod_appannie_amazon\"\n    bucket_path = \"country-ranks\"\n    data_split_str = \",\"\n    rank_list_split_str = \" \"\n    rank_split_str = \"-\"\n    device_code = \"android-all\"\n    market_code = 'amazon-store'\n\n    filename_available = ['FR', 'CN', 'CA', 'DE', 'JP', 'IT', 'US', 'UK', 'ES']\n\n    country_code_mapping = COUNTRY_CODE_MAPPING[market_code][device_code]\n    category_id_mapping = CATEGORY_ID_MAPPING[market_code][device_code]\n    metric_mapping = METRIC_MAPPING[market_code][device_code]\n\n    # this should be a product_service\n    def get_code_app_id_mapping(self, code_list, dsn):\n        sql_code_list = \"','\".join(code_list)\n        sql = \"select id,code from app where code in ('{}')\".format(sql_code_list)\n        conn = psycopg2.connect(dsn)\n        df = sqlio.read_sql_query(sql, conn)\n        return df\n\n\n# class GooglePlayRaw(AppStoreRankRawData):\n#     bucket_name = \"prod_appannie_android\"\n#     bucket_path = \"country-ranks\"\n#     data_split_str = \",\"\n#     rank_list_split_str = \" \"\n#     accept_feeds = [0, 1, 2]\n\n\n# CONSTANTS\nAPP_STORE_RANK_METRICS = [\"free_download\", \"new_paid_download\", \"revenue\", \"paid_download\", \"new_free_download\"]\ncitus_dsn = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=CITUS_AA_CITUS_DB_NAME,\n        user=CITUS_AA_CITUS_DB_ACCESS_ID,\n        host=CITUS_AA_CITUS_DB_HOSTS[0][0],\n        password=CITUS_AA_CITUS_DB_SECRET_KEY,\n        port=CITUS_AA_CITUS_DB_HOSTS[0][1]\n    )\n)\naa_dsn = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_AA_NAME,\n        user=PG_AA_ACCESS_ID,\n        host=PG_AA_HOSTS[0][0],\n        password=PG_AA_SECRET_KEY,\n        port=PG_AA_HOSTS[0][1]\n    )\n)\n\naa_amazon_dsn = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_AA_AMAZON_NAME,\n        user=PG_AA_AMAZON_ACCESS_ID,\n        host=PG_AA_AMAZON_HOSTS[0][0],\n        password=PG_AA_AMAZON_SECRET_KEY,\n        port=PG_AA_AMAZON_HOSTS[0][1]\n    )\n)\n\n\n\n\nclass AppleTvUnified():\n    device_code = 'tv-os-tv'\n    s3_path = \"s3://b2c-prod-data-pipeline-unified-store-free/unified/app-tech.store.app-rank.v1/fact/\"\n\n    def get(self, date, country_code, category_id):\n        df = spark.read.parquet(\"{}date={}/device_code={}/\".format(self.s3_path, date, self.device_code))\n        return df.filter(\"country_code='{country_code}' and category_id='{category_id}'\".format(\n            country_code=country_code, category_id=category_id)).toPandas()\n\nclass AmazonUnified(AppleTvUnified):\n    device_code = 'android-all'\n    s3_path = \"s3://b2c-prod-data-pipeline-unified-store-free/unified/app-tech.store.app-rank.v2/fact/\"\n\nclass AppleTvDB():\n    schema = \"store\"\n    table = \"store_app_rank_fact_v1\"\n    device_code = 'tv-os-tv'\n\n    def get(self, date, country_code, category_id):\n        sql = \"SELECT * from {schema}.{table} where date ='{date}' AND device_code='{device_code}' AND \" \\\n              \"country_code='{country_code}' AND category_id='{category_id}'\".format(\n            schema=self.schema, table=self.table, date=date, device_code=self.device_code,\n            country_code=country_code, category_id=category_id)\n        result = self.query_df(citus_dsn, sql)\n        return result\n\n    @staticmethod\n    def query(dsn, sql):\n        with psycopg2.connect(dsn) as conn:\n            conn.autocommit = True\n            with conn.cursor() as cur:\n                cur.execute(sql)\n                df = pd.DataFrame(cur.fetchall())\n                df.columns = cur.keys()\n                conn.commit()\n        return df\n\n    @staticmethod\n    def query_df(dsn, sql):\n        conn = psycopg2.connect(dsn)\n        df = sqlio.read_sql_query(sql, conn)\n        return df\n\nclass AmazonDB(AppleTvDB):\n    device_code = 'android-all'\n\n\n# CASES\n\nclass AppStoreRankDailyTest(PipelineTest):\n    routing_config = ('* 9 * * *', 1)\n\n    def test_apple_tv_etl_process(self):\n        country_code = 'US'\n        category_id = 300000\n        raw_df = AppleTvRaw().get(self.check_date_str, country_code, category_id)\n        unified_df = AppleTvUnified().get(self.check_date_str, country_code, category_id)\n        db_df = AppleTvDB().get(self.check_date_str,  country_code, category_id)\n        for index,row in raw_df.iterrows():\n            code_ids = row.app_rank_list\n            metric = row.metric\n            app_id_mapping_df = AppleTvRaw().get_code_app_id_mapping(code_ids, aa_dsn)\n            raw_app_rank_list = pd.DataFrame(code_ids, columns=['code']).merge(app_id_mapping_df, on='code', how=\"left\").id.tolist()\n            unified_app_rank_list = unified_df[pd.notnull(unified_df[metric])].sort_values(metric).app_id.tolist()\n            db_app_rank_list = db_df[pd.notnull(db_df[metric])].sort_values(metric).app_id.tolist()\n\n            self.assertTrue(raw_app_rank_list==unified_app_rank_list==db_app_rank_list)\n\n    def test_amazon_etl_process(self):\n        # raw_df = AmazonRaw().get(self.check_date_str, country, category_id)\n        raw_df = AmazonRaw().get_raw_data_by_date(self.check_date_str)\n        for index,row in raw_df.iterrows():\n            code_ids = row.app_rank_list\n            metric = row.metric\n            category_id = row.category_id\n            country_code = row.country_code\n\n\n            unified_df = AmazonUnified().get(self.check_date_str, country_code, category_id)\n\n            app_id_mapping_df = AmazonRaw().get_code_app_id_mapping(code_ids, aa_amazon_dsn)\n            raw_app_rank_list = pd.DataFrame(code_ids, columns=['code']).merge(app_id_mapping_df, on='code', how=\"left\").id.tolist()\n            unified_app_rank_list = unified_df[pd.notnull(unified_df[metric])].sort_values(metric).app_id.tolist()\n\n            self.assertTrue(raw_app_rank_list==unified_app_rank_list)\n\n            if 720000 <= category_id < 800000:\n                db_df = AmazonDB().get(self.check_date_str, country_code, category_id)\n                db_app_rank_list = db_df[pd.notnull(db_df[metric])].sort_values(metric).app_id.tolist()\n                self.assertTrue(raw_app_rank_list==db_app_rank_list)  # ==db_app_rank_list\n\n    def test_amazon_completeness(self):\n        raw_df = AmazonRaw().get_raw_data_by_date(self.check_date_str)\n        raw_rank_count = 0\n        raw_rank_sum = 0\n\n\n\n\n\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20191212-075515_1422485429","metadata":{},"outputs":[],"source":["\n\n\nimport datetime\n\ndef get_sum_count_raw(date_str):\n    raw_reader = AmazonRaw()\n    raw_reader.category_id_mapping = None\n    raw_df = raw_reader.get_raw_data_by_date(date_str)\n\n    columns = [\"app_id\", \"category_id\", \"country_code\",\n               \"free_download\", \"paid_download\", \"revenue\", \"new_free_download\", \"new_paid_download\", ]\n\n    amazon_count = 0\n    amazon_count_dict = {}\n    amazon_sum = 0\n\n    for df_index,row in raw_df.iterrows():\n        country_code = row.country_code if row.country_code!='UK' else 'GB'\n        legacy_category_id = row.category_id\n        if len(row.app_rank_list)==0:\n            continue\n        if country_code not in amazon_count_dict:\n            amazon_count_dict[country_code] = {}\n        if legacy_category_id not in amazon_count_dict[country_code]:\n            amazon_count_dict[country_code][legacy_category_id] = 0\n        df = pd.DataFrame([[app_id,app_index] for app_index,app_id in enumerate(row.app_rank_list, start=1)], columns=[ \"code\", \"rank\"])\n        aggregation_functions = {'rank': 'min'}\n        df_new = df.groupby(df['code'],as_index=False).aggregate(aggregation_functions).reindex(columns=df.columns)\n        app_id_mapping_df = AmazonRaw().get_code_app_id_mapping(df_new.code.tolist(), aa_amazon_dsn)\n        df_new = df_new.merge(app_id_mapping_df, on='code', how=\"left\")\n        \n        amazon_count += len(df_new[df_new.id.notnull()])\n        amazon_count_dict[country_code][legacy_category_id] += len(df_new[df_new.id.notnull()])\n        amazon_sum += df_new[df_new.id.notnull()][\"rank\"].sum()\n    return amazon_count, amazon_sum, amazon_count_dict\n    \n\n\nprint get_sum_count_raw('2019-03-03')\n"]},{"cell_type":"code","execution_count":0,"id":"20191212-092347_1311464745","metadata":{},"outputs":[],"source":["\n\nfrom pyspark.sql import functions as F\n\ndef get_sum_count_unified(date_str):\n    df = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-free/unified/app-tech.store.app-rank.v2/fact/date={}/device_code=android-all/\".format(date_str))\n\n    ############## all 0-3 should be transformed, 2 is not load to db\n    df_unified = df.groupBy([\"country_code\",\"legacy_category_id\"]).agg(F.count(\"free_download\").alias(\"free_download_count\"),F.count(\"paid_download\").alias(\"paid_download_count\"), F.count(\"revenue\").alias(\"revenue_count\"), F.count(\"new_free_download\").alias(\"new_free_download_count\"), F.sum(\"free_download\").alias(\"free_download_sum\"),F.sum(\"paid_download\").alias(\"paid_download_sum\"),  F.sum(\"revenue\").alias(\"revenue_sum\"), F.sum(\"new_free_download\").alias(\"new_free_download_sum\")).collect()\n    \n    unified_count = 0\n    unified_sum = 0\n    \n    amazon_count_dict = {}\n    for data in df_unified:\n        country_code = data.country_code\n        legacy_category_id = str(data.legacy_category_id)\n        if country_code not in amazon_count_dict:\n            amazon_count_dict[country_code] = {}\n        if legacy_category_id not in amazon_count_dict[country_code]:\n            amazon_count_dict[country_code][legacy_category_id] = 0\n        amazon_count_dict[country_code][legacy_category_id] += sum([data.free_download_count, data.paid_download_count, data.new_free_download_count, data.revenue_count])\n        unified_count += sum([data.free_download_count, data.paid_download_count, data.new_free_download_count, data.revenue_count])\n        unified_sum += sum([data.free_download_sum or 0, data.paid_download_sum or 0, data.new_free_download_sum or 0, data.revenue_sum or 0])\n\n    return unified_count, unified_sum, amazon_count_dict\n\nprint get_sum_count_unified('2019-03-03')\n"]},{"cell_type":"code","execution_count":0,"id":"20191213-001820_9958698","metadata":{},"outputs":[],"source":["\n\ndebug_date_str = '2013-04-26'\n\nunified_amazon_count, unified_amazon_sum, unified_amazon_count_dict = get_sum_count_unified(debug_date_str)\nraw_amazon_count, raw_amazon_sum, raw_amazon_count_dict =  get_sum_count_raw(debug_date_str)\n\n\nprint \"{} {}\".format(len(raw_amazon_count_dict.keys()), len(unified_amazon_count_dict.keys()))\nprint \"{} {}\".format(raw_amazon_count, unified_amazon_count)\nprint \"{} {}\".format(raw_amazon_sum, unified_amazon_sum)\n\nfor raw_c in raw_amazon_count_dict:\n    print raw_c\n    for raw_cat in raw_amazon_count_dict[raw_c]:\n        raw_count = raw_amazon_count_dict[raw_c][raw_cat]\n        unified_count = unified_amazon_count_dict[raw_c][raw_cat]\n        diff_count = raw_count - unified_count\n        if diff_count>0:\n            print \"{} {} {} {} {}\".format(raw_c,raw_cat, diff_count,raw_count, unified_count )\n"]},{"cell_type":"code","execution_count":0,"id":"20191213-003256_284533010","metadata":{},"outputs":[],"source":["\n\npd.set_option('display.max_rows',500)\npd.set_option('display.max_colwidth', 100)\n\npd.set_option('precision', 0) #设置精度\npd.set_option('display.float_format', lambda x: '%.5f' % x) \n\n\n\n\nraw_reader = AmazonRaw()\nraw_reader.category_id_mapping = None\nraw_df = raw_reader.get_raw_data_by_date(debug_date_str)\napp_df =  raw_df[raw_df.category_id=='2478858011'][raw_df.metric=='paid_download']\n\n\ncode_ids = app_df.app_rank_list.tolist()[0]\napp_id_mapping_df = AmazonRaw().get_code_app_id_mapping(code_ids, aa_amazon_dsn)\nraw_app_rank_list = pd.DataFrame(code_ids, columns=['code']).merge(app_id_mapping_df, on='code', how=\"left\")\n\nprint raw_app_rank_list\n"]},{"cell_type":"code","execution_count":0,"id":"20191212-234656_1685077826","metadata":{},"outputs":[],"source":["\n\nprint debug_date_str\n# df = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-free/unified/app-tech.store.app-rank.v2/fact/date={}/device_code=android-all/\".format(debug_date_str)).select(\"app_id\",\"free_download\",\"category_id\", \"legacy_category_id\").filter(\"free_download is not null and legacy_category_id=2479040011\").orderBy(\"free_download\").show(500)\n# df = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-free/unified/app-tech.store.app-rank.v2/fact/date={}/device_code=android-all/\".format(debug_date_str)).filter(\"legacy_category_id=2479040011\").show(500)\n\ndf = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-free/unified/app-tech.store.app-rank.v2/fact/date={}/device_code=android-all/\".format(debug_date_str)).filter(\"paid_download is not null and legacy_category_id=2478858011\").orderBy(\"paid_download\")\nprint df.count()\nprint df.show(500)\n"]},{"cell_type":"code","execution_count":0,"id":"20191213-021145_372958995","metadata":{},"outputs":[],"source":["\n\ndf = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-free/unified/app-tech.store.app-rank.v2/fact/date={}/device_code=android-all/\".format(debug_date_str)).select(\"app_id\",\"free_download\",\"category_id\", \"legacy_category_id\").filter(\"=\").show()"]},{"cell_type":"code","execution_count":0,"id":"20191212-101457_536964973","metadata":{},"outputs":[],"source":["\n\ndef get_date_list(begin_date, end_date, freq):\n    date_list = [x.strftime('%Y-%m-%d') for x in list(pd.date_range(start=begin_date, end=end_date, freq=freq))]\n    return date_list\n\n# begin_date = datetime.datetime.strptime(\"2012-09-12\", '%Y-%m-%d')\n# end_date = datetime.datetime.strptime(\"2019-12-11\", '%Y-%m-%d')\n\n\nbegin_date = datetime.datetime.strptime(\"2015-03-01\", '%Y-%m-%d')\nend_date = datetime.datetime.strptime(\"2017-03-01\", '%Y-%m-%d')\n\nDATE_LIST = get_date_list(begin_date, end_date, \"D\")\n\n\nprint \"%table date\\tcount_diff\\tsum_diff\"\n\nfor date_str in DATE_LIST:\n    try:\n        u_count, u_sum, _ = get_sum_count_unified(date_str)\n        r_count, r_sum, _ = get_sum_count_raw(date_str)\n        count_diff = r_count - u_count\n        sum_diff = r_sum - u_sum\n        print \"{}\\t{}\\t{}\".format(date_str, count_diff, sum_diff)\n    except Exception as e:\n        print \"{}\\t{}\\t{}\".format(date_str, -10, -10 )\n    "]},{"cell_type":"code","execution_count":0,"id":"20191212-234059_1870132076","metadata":{},"outputs":[],"source":["\n\ndef get_date_list(begin_date, end_date, freq):\n    date_list = [x.strftime('%Y-%m-%d') for x in list(pd.date_range(start=begin_date, end=end_date, freq=freq))]\n    return date_list\n\n# begin_date = datetime.datetime.strptime(\"2012-09-12\", '%Y-%m-%d')\n# end_date = datetime.datetime.strptime(\"2019-12-11\", '%Y-%m-%d')\n\nbegin_date = datetime.datetime.strptime(\"2012-10-01\", '%Y-%m-%d')\nend_date = datetime.datetime.strptime(\"2013-04-30\", '%Y-%m-%d')\n\nDATE_LIST = get_date_list(begin_date, end_date, \"D\")\n\nprint \"%table date\\tcount_diff\\tsum_diff\"\n\nfor date_str in DATE_LIST:\n    try:\n        u_count, u_sum, _ = get_sum_count_unified(date_str)\n        r_count, r_sum, _ = get_sum_count_raw(date_str)\n        count_diff = r_count - u_count\n        sum_diff = r_sum - u_sum\n        print \"{}\\t{}\\t{}\".format(date_str, count_diff, sum_diff)\n    except Exception as e:\n        print \"{}\\t{}\\t{}\".format(date_str, -10, -10 )\n    "]},{"cell_type":"code","execution_count":0,"id":"20191209-083325_444958769","metadata":{},"outputs":[],"source":["\n\n\ncheck_date_str = '2019-10-27'\n\nraw_df = AmazonRaw().get_raw_data_by_date(check_date_str)\n\nfor index,row in raw_df.iterrows():\n    code_ids = row.app_rank_list\n    metric = row.metric\n    category_id = row.category_id\n    country_code = row.country_code\n    if not  720000<=category_id<800000:\n        continue\n\n    unified_df = AmazonUnified().get(check_date_str, country_code, category_id)\n    # db_df = AmazonDB().get(check_date_str, country_code, category_id)\n\n    app_id_mapping_df = AmazonRaw().get_code_app_id_mapping(code_ids, aa_amazon_dsn)\n    raw_app_rank_list = pd.DataFrame(code_ids, columns=['code']).merge(app_id_mapping_df, on='code', how=\"left\").id.tolist()\n    \n    unified_app_rank_list = unified_df[pd.notnull(unified_df[metric])].sort_values(metric).app_id.tolist()\n    # db_app_rank_list = db_df[pd.notnull(db_df[metric])].sort_values(metric).app_id.tolist()\n\n    if set(raw_app_rank_list) == set(unified_app_rank_list):\n        print \"{} {} {} {} {}\".format(check_date_str, category_id, country_code, metric, True)\n    else:\n        print \"{} {} {} {} {}\".format(check_date_str, category_id, country_code, metric, False)\n        print raw_app_rank_list\n        print unified_app_rank_list\n"]},{"cell_type":"code","execution_count":0,"id":"20191212-050610_44429380","metadata":{},"outputs":[],"source":["\n\nspark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-free/unified/app-tech.store.app-rank.v2/fact/date=2019-01-01/device_code=android-all\").show(1)"]},{"cell_type":"code","execution_count":0,"id":"20191203-020000_177791657","metadata":{},"outputs":[],"source":["\nimport sys\nimport datetime\nimport traceback\n\n\ndef debug(case):\n    std_out_origin= sys.stdout\n    std_err_origin= sys.stderr\n    try:\n        suite =  unittest.TestSuite()\n        suite.addTest(case)\n        runner = unittest.TextTestRunner(verbosity=2, buffer=True)\n        runner.run(suite)\n    except Exception as ex:\n        traceback.print_exception(type(ex), ex, ex.__traceback__)\n    finally:\n        sys.stdout = std_out_origin\n        sys.stderr = std_err_origin\n    \n\ntestcase = AppStoreRankDailyTest(\"test_apple_tv_etl_process\", datetime.datetime.utcnow() )\ndebug(testcase)\n"]},{"cell_type":"code","execution_count":0,"id":"20191202-102255_602363697","metadata":{},"outputs":[],"source":["\n\n\nfrom aaintdatapipeline.core.utils.spark import create_spark, eject_all_caches\n\neject_all_caches(spark)\n\ndef get_date_list(begin_date, end_date, freq):\n    date_list = [x.strftime('%Y-%m-%d') for x in list(pd.date_range(start=begin_date, end=end_date, freq=freq))]\n    return date_list\n\nbegin_date = datetime.datetime.strptime(\"2012-09-12\", '%Y-%m-%d')\nend_date = datetime.datetime.strptime(\"2019-12-11\", '%Y-%m-%d')\nDATE_LIST = get_date_list(begin_date, end_date, \"D\")\n\n\nfor date in DATE_LIST:\n    # amazon_raw_df = AmazonRaw().get_raw_data_by(date)\n    try:\n        raw_df = AmazonRaw().get_raw_data_by(date)\n        # raw_df = AppleTvRaw().get_raw_data_by(date)\n        if set(raw_df.date.tolist()) !=  set([date]):\n            print \"{} {} {}\".format(date, set(raw_df.date.tolist()), set(raw_df[raw_df.date!=date].country_code.tolist()) )\n        else:\n            pass\n    except Exception as e:\n        print \"{} {}\".format(date, e.message )\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20191210-014732_1942227191","metadata":{},"outputs":[],"source":["%%sh\n\n# aws s3 ls s3://prod_appannie_ios/mac/country-ranks/2014-09-15/23/143505\n# aws s3 cp s3://prod_appannie_ios/mac/country-ranks/2014-09-16/23/143531 /tmp/\n# aws s3 ls s3://prod_appannie_amazon/country-ranks/\n# aws s3 ls s3://prod_appannie_amazon/country-ranks/2017-11-29/\n# aws s3 ls s3://prod_appannie_amazon/country-ranks/2018-06-28/\n# aws s3 ls s3://prod_appannie_amazon/country-ranks/2019-10-18/23/\n# aws s3 ls s3://prod_appannie_amazon/country-ranks/2014-10-18/23/\n# aws s3 ls s3://b2c-prod-data-pipeline-unified-store-free/unified/app-tech.store.app-rank.v2/fact/date=2014-11-25/device_code=android-all/\naws s3 ls s3://prod_appannie_amazon/country-ranks/2012-10-17/23/\n\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20191211-033602_163245728","metadata":{},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":0,"id":"20191203-014315_1702388048","metadata":{},"outputs":[],"source":["\n\namazon_raw_df = AmazonRaw().get_raw_data_by(\"2012-09-12\")\nprint amazon_raw_df\n\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20191212-005716_1969359551","metadata":{},"outputs":[],"source":["%%sh\n\nPGPASSWORD='2mHdFW6%#REu' psql -h 10.2.26.136 -U app_bdp_usage_qa -d aa -p 6432 << EOF \nselect id,code from product where code in ('363590051', '544007664', '545519333', '376510438', '324684580', '491730359', '462780547', '294056623', '420455839', '1193350206', '571096102', '317469184', '442839435', '364191819', '971265422', '460177396', '529997671', '530168168', '886445756', '767268733', '510855668', '550221096', '429775439', '284035177', '389781154', '398349296', '487285735', '335744614', '751712884', '493619333', '367623543', '505728417', '945077360', '331786748', '1025120568', '996246479', '1428385620', '1136238277', '347411942', '711074743', '661695783', '924373886', '300255638', '404593641', '1387514950', '1178814251', '465092669', '1296362751', '460494135', '542511686', '610391947', '799551807', '1245330908', '422366403', '906788127', '1101436320', '1039067950', '571711580', '576009463', '383925190', '295646461', '284882215', '484232467', '739360888', '417871100', '376038666', '905401434', '334256223', '383457673', '642410271', '579966222', '339532909', '1329018000', '435138734', '1320098114', '378092432', '329913454', '377951542', '833517462', '911115712', '957987596', '1194749500', '333903271', '1199519834', '396885309', '876520365', '596133590', '413522634', '932554205', '1383614816', '286058814', '471966214', '1049321283', '967093677', '1101434093', '556164008', '398018310', '1065376196', '307184892', '1201642309', '841118013', '1143776821', '899247664', '300704847', '1090599922', '1248646044', '1002340615', '596402997', '430018488', '457446957', '919790315', '1075603018', '1031660123', '1141876504', '319740707', '1033037451', '1057375015', '1226640954', '316025912', '564540143', '896014310', '1206838907', '656176278', '596546023', '332184886', '472567577', '425194759', '1101436941', '334325516', '300048137', '474679690', '1148320769', '1414799250', '1044871992', '1076619087', '594261405', '1111281685', '445553058', '454316134', '485756277', '1075872386', '1330343129', '376183339', '1094452432', '1089249069', '493605531', '551798799', '550252401', '571800810', '1134655040', '310738695', '840919914', '1129523589', '675276583', '1165206979', '1050712293', '1352933197', '973784199', '1081221532', '1086978383', '1449636821', '1454275199', '1426824242', '650377962', '1116818988', '1353108336', '396972659', '1280494355', '680595680', '331806276', '281941097', '533173905', '464988855', '879902807', '1043589663', '1075813502', '336978041', '700797306', '613398383', '1042102183', '1117365978', '944245256', '352509417', '1108964305', '1243599288', '364387007', '1436283101', '1028734023', '819258848', '1074374051', '1046593064', '1246969117', '934459219', '282935706', '995082390', '1046996690', '364269164', '686218010', '504847776', '659283309') ;\nEOF\n\n"]},{"cell_type":"code","execution_count":0,"id":"20191212-045236_1024840419","metadata":{},"outputs":[],"source":["%%sh\n"]},{"cell_type":"code","execution_count":0,"id":"20191212-032745_1048909745","metadata":{},"outputs":[],"source":["%%sh\n\nPGPASSWORD='2mHdFW6%#REu' psql -h pg-n-slave-4edc958bda550bbc.elb.us-east-1.amazonaws.com -U app_bdp_usage_qa -d aa_amazon -p 5433 << EOF \n\\d+ app;\nselect id,code from app limit 1;\nEOF\n\n"]},{"cell_type":"code","execution_count":0,"id":"20191209-095500_807563419","metadata":{},"outputs":[],"source":["%%sh\n\nPGPASSWORD='2mHdFW6%#REu' psql -h 10.2.26.136 -U app_bdp_usage_qa -d dna -p 6432 << EOF \n\\d;\nSELECT * FROM publisher_match_run_info limit 1 ;\nSELECT * FROM publisher_match_result limit 1 ;\n\nEOF\n"]},{"cell_type":"code","execution_count":0,"id":"20191210-044045_1427842341","metadata":{},"outputs":[],"source":["\n\n\nimport unittest\n\nimport datetime\nimport croniter\nfrom sqlalchemy.dialects.postgresql import psycopg2\n\n# from aaintdatapipeline.application.app_qa.db_check_v1.pyspark_test import PySparkTest\nfrom aaintdatapipeline.core.conf import Conf\nfrom aaintdatapipeline.core.fs.device import S3Bucket, specified_bucket\nimport zlib\nimport pandas as pd\nimport pandas.io.sql as sqlio\nimport psycopg2\n\n\ndef rank_bucket(bucket_str):\n    \"\"\"\n    Get Bucket Object from bucket string\n    :param bucket_str: string like: s3://xxx.xxx\n    :type bucket_str: str\n    :return: bucket_object\n    :rtype: bucket_object\n    \"\"\"\n    conf = Conf(\n        bucket_name=bucket_str,\n        bucket_class=S3Bucket\n    )\n    return specified_bucket(conf)\n\n\nbucket = rank_bucket(\"prod_appannie_amazon\")\ndf = zlib.decompress(bucket.get(\"country-ranks/{}/23/US\".format(debug_date_str))) \n\nfor _line in df.splitlines():\n    line_data = _line.split(\",\")\n    if \"2479040011\" in line_data :\n        print  _line\n# print df\n\n# import glob\n# import zlib\n# import sys\n\n# with open(\"/tmp/143531\", 'rb') as compressed:\n#     data = zlib.decompress(compressed.read())\n#     print data\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20191213-021852_1641571643","metadata":{},"outputs":[],"source":["\ndf = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-free/unified/app-tech.store.app-rank.v2/fact/date={}/device_code=android-all/\".format(debug_date_str))\nfor metric in [\"free_download\",\"paid_download\", \"new_free_download\"]:\n    df.select(\"app_id\", metric).filter(\"legacy_category_id=1724202031 and {} is not null\".format(metric)).orderBy(metric).show(10000)\n"]},{"cell_type":"code","execution_count":0,"id":"20191213-065733_1427455053","metadata":{},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":0,"id":"20191211-072155_623853249","metadata":{},"outputs":[],"source":["\nfrom aaintdatapipeline.application.app_qa.conf.settings import PRODUCT_SERVICE_ENDPOINT, \\\n    MICRO_SERVICE_ACCESS_ID, MICRO_SERVICE_SECRET_KEY, PG_AA_NAME, PG_AA_ACCESS_ID, PG_AA_AMAZON_HOSTS, PG_AA_SECRET_KEY\n\nprint PG_AA_AMAZON_HOSTS"]},{"cell_type":"code","execution_count":0,"id":"20191212-014948_43039937","metadata":{},"outputs":[],"source":["\n\nfrom bdce.common.utils import update_application_code\nupdate_application_code(\n    spark, role=\"BDP-PROD-APP-INT-QA\", application_name=\"qa-data-db-check-debug\"\n)\n"]},{"cell_type":"code","execution_count":0,"id":"20191212-024509_464910759","metadata":{},"outputs":[],"source":["%%sh\n\n\nls -al /tmp/zeppelin_application_code/aaintdatapipeline\nls -al /home/hadoop/bdp/application/aaintdatapipeline\n# mv /home/hadoop/bdp/application/aaintdatapipeline /home/hadoop/bdp/application/aaintdatapipeline_bak_2\n# cp -r /tmp/zeppelin_application_code/aaintdatapipeline /home/hadoop/bdp/application/aaintdatapipeline\n\nls -al /home/hadoop/bdp/application/aaintdatapipeline/application/app_qa/conf/settings_local.py\ncat /home/hadoop/bdp/application/aaintdatapipeline/application/app_qa/conf/settings_local.py\nenv"]},{"cell_type":"code","execution_count":0,"id":"20191212-024607_1124646040","metadata":{},"outputs":[],"source":["%%sh\n\nenv\n"]},{"cell_type":"code","execution_count":0,"id":"20191215-005650_180752593","metadata":{},"outputs":[],"source":["%%sh\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}