{"cells":[{"cell_type":"code","execution_count":0,"id":"20200911-075347_1370817452","metadata":{},"outputs":[],"source":["%%sh\nraw_data_path = s3://aardvark-prod-pdx-mdm-to-int/basic_kpi/version=1.0.0/range_type=DAY/date=2018-01-04/platform=1/\nunified_data_path_legacy = s3://b2c-prod-data-pipeline-unified-usage/unified/usage.basic-kpi.v5/fact/\nraw_domain_path = s3://b2c-prod-dca-mobile-web-to-int/oss/MOBILE_WEB_DOMAIN_BASIC_METRICS/version=v1.0.0/\naws s3 ls  s3://b2c-prod-data-pipeline-unified-store-free/unified/store.app.v1/dimension/"]},{"cell_type":"code","execution_count":0,"id":"20201110-033406_1489259432","metadata":{},"outputs":[],"source":["%%sh\nPGPASSWORD='wZw8cfBuuklIskVG' psql -h 10.2.6.141  -U citus_bdp_prod_app_int_qa -d aa_store_db -p 5432 << EOF \nset search_path=store;\n\nselect *  from store_est_category_fact_v1 where country_code='US'and device_code in ('ios-phone') \nand date between '2020-09-01' and '2020-09-30' and app_id = 1434655572 and category_id = 100003 and country_code = 'US';\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20201106-063730_1196143781","metadata":{},"outputs":[],"source":["\nunified_path = \"s3://b2c-prod-data-pipeline-unified-usage/unified/usage.basic-kpi.v6/fact/product_type_code=app/granularity_code=weekly/date=2020-09-05/\"\ncategory_path = \"s3://b2c-prod-data-pipeline-unified-usage/unified/usage.category.v6/dimension/product_type_code=app/granularity_code=weekly/date=2020-09-05/\"\nbasic_raw_path = \"s3://aardvark-prod-pdx-mdm-to-int/basic_kpi/version=1.0.0/range_type=WEEK/date=2020-09-05/platform=1/\"\nspark.read.format(\"delta\").load(unified_path).createOrReplaceTempView(\"test_unified\")\nspark.read.format(\"delta\").load(category_path).createOrReplaceTempView(\"test_category\")\n# spark.read.format(\"parquet\").load(basic_raw_path).createOrReplaceTempView(\"test_raw\")\n# spark.sql(\"select count(distinct product_key) as basic_count from test_unified \").show()\n# spark.sql(\"select count(1) as category_count from test_category where country_code <> 'ROW'\").show()\n# spark.sql(\"select * from test_raw where app_id=20600013700573 \").show(10, False)\n# spark.sql(\"select product_key, count(1) as count from test_category where category_key = 400013 and device_code = 'android-phone'  group by product_key order by product_key desc \").show(1000, False)\nspark.sql(\"select distinct country_code from test_category where device_code = 'android-phone' and product_key = 20600013700573 and category_key = 400013\").show(1000, False)\n# spark.sql(\"select sum(est_active_users), sum(est_population) from test_unified where product_type_code='app' and granularity_code='monthly' and country_code <> 'ROW'\").show()\n# spark.sql(\"select count(distinct product_key, device_code, country_code, granularity_code, date) as basic_distinct_count from test_unified\").show()"]},{"cell_type":"code","execution_count":0,"id":"20201104-032014_1214149239","metadata":{},"outputs":[],"source":["\n\nimport pandas as pd\nfrom pyspark.sql import functions as F\nfrom datetime import datetime\nfrom applications.db_check_v1.common.db_check_utils import query\nfrom conf.settings import PG_USAGE_HOSTS, PG_USAGE_NAME, PG_USAGE_ACCESS_ID, PG_USAGE_SECRET_KEY, \\\n    CITUS_USAGE_NAME, CITUS_USAGE_ACCESS_ID, CITUS_USAGE_HOSTS, CITUS_USAGE_SECRET_KEY\n\nPLPROXY_DSN = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_USAGE_NAME,\n        user=PG_USAGE_ACCESS_ID,\n        host=PG_USAGE_HOSTS[0][0],\n        password=PG_USAGE_SECRET_KEY,\n        port=PG_USAGE_HOSTS[0][1]\n    )\n)\n\ndef get_date_list(begin_date, end_date, freq):\n    date_list = [x.strftime('%Y-%m-%d') for x in list(pd.date_range(start=begin_date, end=end_date, freq=freq))]\n    return date_list\n\n\nbegin_date = datetime(2020, 8, 1)\nend_date = datetime(2020, 9, 30)\n\nDATE_GRANULARITY_MAPPINGLIST = {\n    \"daily\": get_date_list(begin_date, end_date, \"D\"),\n    \"weekly\": get_date_list(begin_date, end_date, \"W-SAT\"),\n    \"monthly\": get_date_list(begin_date, end_date, \"M\")\n}\n\n\nDATE_GRANULARITY_MAPPINGLIST[\"monthly\"].reverse()\nDATE_GRANULARITY_MAPPINGLIST[\"weekly\"].reverse()\nDATE_GRANULARITY_MAPPINGLIST[\"daily\"].reverse()\n\nprint DATE_GRANULARITY_MAPPINGLIST[\"monthly\"]\nprint DATE_GRANULARITY_MAPPINGLIST[\"weekly\"]\nprint DATE_GRANULARITY_MAPPINGLIST[\"daily\"]"]},{"cell_type":"code","execution_count":0,"id":"20201103-105826_608008977","metadata":{},"outputs":[],"source":["\n\nimport pandas as pd\nfrom pyspark.sql import functions as F\nfrom datetime import datetime\nfrom applications.db_check_v1.common.db_check_utils import query\nfrom pyspark.sql import Row\nfrom conf.settings import PG_USAGE_HOSTS, PG_USAGE_NAME, PG_USAGE_ACCESS_ID, PG_USAGE_SECRET_KEY, \\\n    CITUS_USAGE_NAME, CITUS_USAGE_ACCESS_ID, CITUS_USAGE_HOSTS, CITUS_USAGE_SECRET_KEY\nfrom pyspark.sql.types import StructType, StructField, LongType, IntegerType, DoubleType, ShortType\n\nPLPROXY_DSN = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_USAGE_NAME,\n        user=PG_USAGE_ACCESS_ID,\n        host=PG_USAGE_HOSTS[0][0],\n        password=PG_USAGE_SECRET_KEY,\n        port=PG_USAGE_HOSTS[0][1]\n    )\n)\ndate_count_sql =  \"\"\"select  sum(count) from plproxy.execute_select($proxy$\nSELECT count(1) as count\nFROM mu.category_{granularity}_{device} where \ndate = '{date}' and category_id = {legacy_category_id} $proxy$)\n t (count bigint) ;\n\"\"\"\n\ndomain_count_sql = \"\"\"\nselect  sum(count) from plproxy.execute_select($proxy$\nSELECT count(1) as count\nFROM mw.category_{simple_granularity}_{device_code} where \ndate = '{date}' and category_id = {unified_category_id} $proxy$)\n t (count bigint) ;\n\"\"\"\n\n\n# granularity_list = ['daily', 'weekly', 'monthly']\ngranularity_list = ['daily']\ndevice_list = [1001, 1002, 2001, 2002]\nios_device_list = [ 2001, 2002]\ngp_device_list = [1001, 1002]\ndevice_code_list = ['android-phone', 'android-tablet', 'ios-phone', 'ios-tablet']\n# device_code_list = ['ios-tablet']\ndevice_mapping = {1001:'android-phone', 1002:'android-tablet', 2001:'ios-phone', 2002:'ios-tablet'}\n\n\nlegacy_ios_category_list = [6016, 6017, 6018, 6020, 6021, 6022, 6023, 6024, 36, 6001, 7001, 7002, 7003, 7004, 7005, 7006, 7007, 7008, 7009, 7010, 7011, 7012, 7013, 7014, 7015, 7016, 7017, 7018, 7019, 100, 360, 361, 362, 6000, 363, 6002, 6003, 6004, 6005, 6006, 6007, 6008, 6009, 6010, 6011, 6012, 6013, 6014, 6015]\n\n# legacy_ios_category_list = [6016, 6017, 6014]\n\nios_category_mapping = {6016: 800022, 6017: 800021, 6018: 800019, 6020: 800028, 6021: 800030, 6022: 800019, 6023: 800024, 6024: 800033, 36: 800000, 6001: 800038, 7001: 800002, 7002: 800003, 7003: 800002, 7004: 800004, 7005: 800006, 7006: 800006, 7007: 800006, 7008: 800007, 7009: 800008, 7010: 800008, 7011: 800010, 7012: 800005, 7013: 800011, 7014: 800012, 7015: 800013, 7016: 800014, 7017: 800012, 7018: 800015, 7019: 800016, 100: 800018, 360: 800041, 361: 800042, 362: 800043, 6000: 800020, 363: 800044, 6002: 800036, 6003: 800037, 6004: 800035, 6005: 800034, 6006: 800019, 6007: 800032, 6008: 800031, 6009: 800030, 6010: 800037, 6011: 800029, 6012: 800026, 6013: 800025, 6014: 800001, 6015: 800023}\n\nlegacy_gp_category_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75]\n\ngp_category_mapping = {1: 800000, 2: 800001, 3: 800002, 4: 800005, 5: 800006, 6: 800005, 7: 800009, 8: 800011, 9: 800014, 10: 800017, 11: 800018, 12: 800019, 13: 800020, 14: 800019, 15: 800034, 16: 800021, 17: 800022, 18: 800023, 19: 800025, 20: 800019, 21: 800026, 22: 800027, 23: 800031, 24: 800028, 25: 800029, 26: 800030, 27: 800036, 28: 800031, 29: 800032, 30: 800033, 31: 800034, 32: 800035, 33: 800036, 34: 800037, 35: 800037, 36: 800038, 37: 800040, 38: 800002, 39: 800003, 40: 800016, 41: 800002, 42: 800004, 43: 800006, 44: 800006, 46: 800007, 47: 800008, 48: 800010, 49: 800005, 51: 800012, 52: 800013, 54: 800012, 55: 800015, 56: 800041, 57: 800042, 58: 800043, 59: 800044, 60: 800041, 61: 800041, 62: 800041, 63: 800041, 64: 800041, 65: 800041, 66: 800039, 67: 800032, 68: 800026, 69: 800033, 70: 800026, 71: 800026, 72: 800022, 73: 800024, 75: 800025}\n\nlegacy_to_individual_ios = {36: 100000, 6014: 100001, 7001: 100002, 7002: 100003, 7003: 100004, 7004: 100005, 7005: 100006, 7006: 100007, 7007: 100008, 7008: 100009, 7009: 100010, 7010: 100011, 7011: 100012, 7012: 100013, 7013: 100014, 7014: 100015, 7015: 100016, 7016: 100017, 7017: 100018, 7018: 100019, 7019: 100020, 100: 100021, 6018: 100022, 6000: 100023, 6022: 100024, 6017: 100025, 6016: 100026, 6015: 100027, 6023: 100028, 6013: 100029, 360: 100030, 361: 100031, 362: 100032, 363: 100033, 6012: 100034, 6021: 100035, 6020: 100064, 6011: 100065, 6010: 100066, 6009: 100067, 6008: 100068, 6007: 100069, 6006: 100070, 6024: 100071, 6005: 100072, 6004: 100073, 6003: 100075, 6002: 100076, 6001: 100077}\n\nunified_category_list = [800000, 800001, 800002, 800003, 800004, 800005, 800006, 800007, 800008, 800009, 800010, 800011, 800012, 800013, 800014, 800015, 800016, 800017, 800018, 800019, 800020, 800021, 800022, 800023, 800024, 800025, 800026, 800027, 800028, 800029, 800030, 800031, 800032, 800033, 800034, 800035, 800036, 800037, 800038, 800039, 800040, 800041, 800042, 800043, 800044]\n\n\ndef get_plproxy_count(sql_str=date_count_sql):\n    for device in ios_device_list:\n        for granularity in granularity_list:\n            for date in DATE_GRANULARITY_MAPPINGLIST[granularity]:\n                for category in legacy_ios_category_list:\n                    result = query(PLPROXY_DSN, sql_str.format(granularity=granularity, date=date, device=device, legacy_category_id=category))\n                    print device_mapping[device], granularity, date, category, result[0][0]\n\n\ndef get_unified_result():\n    category_path = \"s3://b2c-prod-data-pipeline-unified-usage/unified/usage.category.v6/dimension/product_type_code=app/granularity_code={granularity}/date={date}/\"\n    for device in ios_device_list:\n        for granularity in granularity_list:\n            for date in DATE_GRANULARITY_MAPPINGLIST[granularity]:\n                for category in legacy_ios_category_list:\n                    spark.read.format(\"delta\").load(category_path.format(granularity=granularity, date=date)).createOrReplaceTempView(\"test_category\")\n                    df = spark.sql(\"select count(1) as count from test_category where device_code = '{device}' and category_key = {category} and country_code <> 'ROW'\".format(device=device_mapping[device], category=legacy_to_individual_ios[category])).collect()\n                    # print df[0][0]\n                    print device_mapping[device], granularity, date, category, df[0][0]\n                    \nsimple_device_list = ['ip', 'ap']\n# simple_granularity_list = ['m', 'w', 'd' ]\nsimple_granularity_list = ['m' ]\ngranularity_mapping = {'d':'daily', 'w':'weekly', 'm': 'monthly'}\n\ndef get_domain_plproxy_count(sql_str=domain_count_sql):\n    for simple_device in simple_device_list:\n        for simple_granularity in simple_granularity_list:\n            for date in DATE_GRANULARITY_MAPPINGLIST[granularity_mapping[simple_granularity]]:\n                for unified_category in unified_category_list:\n                    result = query(PLPROXY_DSN, sql_str.format(simple_granularity=simple_granularity, device_code=simple_device, date=date,  unified_category_id=unified_category))\n                    print simple_device, simple_granularity, date, unified_category, result[0][0]\n        \ndef get_domain_unified_result():\n    phone_list = ['ios-phone', 'android-phone']\n    category_path = \"s3://b2c-prod-data-pipeline-unified-usage/unified/usage.category.v6/dimension/product_type_code=domain/granularity_code={granularity}/date={date}/\"\n    for device in phone_list:\n        for simple_granularity in simple_granularity_list:\n            for date in DATE_GRANULARITY_MAPPINGLIST[granularity_mapping[simple_granularity]]:\n                for unified_category in unified_category_list:\n                    spark.read.format(\"delta\").load(category_path.format(granularity=granularity_mapping[simple_granularity], date=date)).createOrReplaceTempView(\"test_category\")\n                    df = spark.sql(\"select count(1) as count from test_category where device_code = '{device}' and unified_category_key = {unified_category} and country_code <> 'ROW'\".format(device=device, unified_category=unified_category)).collect()\n                    print device, simple_granularity, date, unified_category, df[0][0]\n\n\n                \ndef get_unified_tmp(date, device_code, individual_category_id, granularity):\n    category_path_tmp = \"s3://b2c-prod-data-pipeline-unified-usage/unified/usage.category.v6/dimension/product_type_code=app/granularity_code={granularity}/date={date}/\".format(granularity=granularity, date=date)\n    spark.read.format(\"delta\").load(category_path_tmp).createOrReplaceTempView(\"test_category_tmp\")\n    spark.sql(\"select distinct product_key as app_id from test_category_tmp where device_code = '{device_code}' and category_key = {individual_category_id} and country_code <> 'ROW'\".format(device_code=device_code, individual_category_id=individual_category_id)).createOrReplaceTempView(\"unified_app\")\n    # spark.sql(\"select distinct country_code from test_category_tmp where device_code = 'ios-tablet'   and product_key = 284882215\").show(100, False)\n            \n            \ndef get_plproxy_tmp(date, device_id, legacy_category_id, granularity):\n    date_count_sql_tmp =  \"\"\"select  distinct app_id from plproxy.execute_select($proxy$\nSELECT distinct app_id as app_id\nFROM mu.category_{granularity}_{device_id} where \ndate = '{date}' and category_id in ({legacy_category_id}) $proxy$)\n t (app_id bigint);\n\"\"\".format(device_id=device_id, date=date, legacy_category_id=legacy_category_id, granularity=granularity)\n    print date_count_sql_tmp\n    result = query(PLPROXY_DSN, date_count_sql_tmp)\n    df_data = [Row(app_id=r[0]) for r in result]\n    _schema =StructType([StructField(\"app_id\", LongType(), False)])\n    df_plproxy = spark.createDataFrame(data=df_data, schema=_schema)\n    return df_plproxy\n    # print result[0][0]\n    \ndef get_main_category(app_view):\n    path = \"s3://b2c-prod-data-pipeline-unified-store-free/unified/store.app.v1/dimension/\"\n    spark.read.format(\"parquet\").load(path).createOrReplaceTempView(\"test\")\n    spark.sql(\"select id, last_updated, release_date,current_release_date, category_id  from test where id in  (select app_id from {app_view})\".format(app_view=app_view)).show(100, False)\n    \ndef get_rank_category(app_view):\n    rank_path = \"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est-category-rank.v1/fact/granularity=monthly/date=2020-09-30/\"\n    spark.read.format(\"parquet\").load(rank_path).createOrReplaceTempView(\"rank_category\")\n    spark.sql(\"select * from rank_category where app_id = 1477487725 limit 10\").show(10, False)\n    spark.sql(\"select distinct app_id, category_id from rank_category where app_id in (select app_id from {app_view}) and category_id = 100004\".format(app_view=app_view)).show(100, False)\n    \ndef compare():\n    date = '2020-08-22'\n    device_id = 1001\n    device_code = 'android-phone'\n    legacy_category_id = 57\n    individual_category_id = 400063\n    granularity = 'weekly'\n    df_plproxy = get_plproxy_tmp(date, device_id, legacy_category_id, granularity)\n    get_unified_tmp(date, device_code, individual_category_id, granularity)\n    df_plproxy.createOrReplaceTempView(\"plproxy_app\")\n    spark.sql(\"select app_id from plproxy_app except select app_id from unified_app\").createOrReplaceTempView(\"plproxy_diff_unified\")\n    spark.sql(\"select app_id from unified_app except select app_id from plproxy_app \").createOrReplaceTempView(\"unifid_diff_plproxy\")\n    \n    spark.sql(\"select app_id as plproxy_diff_unified from plproxy_diff_unified\").show(100, False)\n    spark.sql(\"select app_id as unifid_diff_plproxy from unifid_diff_plproxy\").show(100, False)\n    \n    get_main_category(\"plproxy_diff_unified\")\n    get_main_category(\"unifid_diff_plproxy\")\n    \n    \n    \n# get_rank_category(\"unifid_diff_plproxy\")\nget_plproxy_count()\n\n    "]},{"cell_type":"code","execution_count":0,"id":"20201105-023005_600307300","metadata":{},"outputs":[],"source":["\n\npath = \"s3://b2c-prod-data-pipeline-unified-store-free/unified/store.app.v1/dimension/\"\nspark.read.format(\"parquet\").load(path).createOrReplaceTempView(\"test\")\nspark.sql(\"select id, last_updated, release_date,current_release_date, category_id  from test where id in  (20600011762403)\").show(100, False)"]},{"cell_type":"code","execution_count":0,"id":"20201104-071805_1565668490","metadata":{},"outputs":[],"source":["\nspark.sql(\"select * from test_category_tmp where device_code = 'ios-tablet' and category_key=100005 and product_key in (1137491018, 341532096,1126032958)\").show(100, False)"]},{"cell_type":"code","execution_count":0,"id":"20201022-020325_1662951912","metadata":{},"outputs":[],"source":["\n\nimport pandas as pd\nfrom pyspark.sql import functions as F\nfrom datetime import datetime\nfrom applications.db_check_v1.common.db_check_utils import query\nfrom pyspark.sql import Row\nfrom conf.settings import PG_USAGE_HOSTS, PG_USAGE_NAME, PG_USAGE_ACCESS_ID, PG_USAGE_SECRET_KEY, \\\n    CITUS_USAGE_NAME, CITUS_USAGE_ACCESS_ID, CITUS_USAGE_HOSTS, CITUS_USAGE_SECRET_KEY\nfrom pyspark.sql.types import StructType, StructField, LongType, IntegerType, DoubleType, ShortType\n\nPLPROXY_DSN = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_USAGE_NAME,\n        user=PG_USAGE_ACCESS_ID,\n        host=PG_USAGE_HOSTS[0][0],\n        password=PG_USAGE_SECRET_KEY,\n        port=PG_USAGE_HOSTS[0][1]\n    )\n)\n\nlegacy_ios_category_list = [6016, 6017, 6018, 6020, 6021, 6022, 6023, 6024, 36, 6001, 7001, 7002, 7003, 7004, 7005, 7006, 7007, 7008, 7009, 7010, 7011, 7012, 7013, 7014, 7015, 7016, 7017, 7018, 7019, 100, 360, 361, 362, 6000, 363, 6002, 6003, 6004, 6005, 6006, 6007, 6008, 6009, 6010, 6011, 6012, 6013, 6014, 6015]\nios_category_mapping = {6016: 800022, 6017: 800021, 6018: 800019, 6020: 800028, 6021: 800030, 6022: 800019, 6023: 800024, 6024: 800033, 36: 800000, 6001: 800038, 7001: 800002, 7002: 800003, 7003: 800002, 7004: 800004, 7005: 800006, 7006: 800006, 7007: 800006, 7008: 800007, 7009: 800008, 7010: 800008, 7011: 800010, 7012: 800005, 7013: 800011, 7014: 800012, 7015: 800013, 7016: 800014, 7017: 800012, 7018: 800015, 7019: 800016, 100: 800018, 360: 800041, 361: 800042, 362: 800043, 6000: 800020, 363: 800044, 6002: 800036, 6003: 800037, 6004: 800035, 6005: 800034, 6006: 800019, 6007: 800032, 6008: 800031, 6009: 800030, 6010: 800037, 6011: 800029, 6012: 800026, 6013: 800025, 6014: 800001, 6015: 800023}\n\nlegacy_gp_category_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75]\n\ngp_category_mapping = {1: 800000, 2: 800001, 3: 800002, 4: 800005, 5: 800006, 6: 800005, 7: 800009, 8: 800011, 9: 800014, 10: 800017, 11: 800018, 12: 800019, 13: 800020, 14: 800019, 15: 800034, 16: 800021, 17: 800022, 18: 800023, 19: 800025, 20: 800019, 21: 800026, 22: 800027, 23: 800031, 24: 800028, 25: 800029, 26: 800030, 27: 800036, 28: 800031, 29: 800032, 30: 800033, 31: 800034, 32: 800035, 33: 800036, 34: 800037, 35: 800037, 36: 800038, 37: 800040, 38: 800002, 39: 800003, 40: 800016, 41: 800002, 42: 800004, 43: 800006, 44: 800006, 46: 800007, 47: 800008, 48: 800010, 49: 800005, 51: 800012, 52: 800013, 54: 800012, 55: 800015, 56: 800041, 57: 800042, 58: 800043, 59: 800044, 60: 800041, 61: 800041, 62: 800041, 63: 800041, 64: 800041, 65: 800041, 66: 800039, 67: 800032, 68: 800026, 69: 800033, 70: 800026, 71: 800026, 72: 800022, 73: 800024, 75: 800025}\n\n\nlegacy_category_list = [36, 6014, 7012, 6004, 6008]\n# legacy_gp_category_list = [1, 2, 44, 13, 63]\nlegacy_gp_category_list = [13]\ngp_category_mapping = {1: 400000,\n    2: 400001,\n    44: 400007,\n    13: 400031,\n    63: 400068\n    \n}\n# legacy_category_list = [6014]\ndevice_id_list = [1001, 1002, 2001, 2002]\ncategory_mapping = {\n    36: 800000,\n    6014:800001,\n    7012:800005,\n    6004:800035,\n    6008:800031\n}\nunified_category_list = [800000, 800001, 800005, 800035, 800031]\n# unified_category_list = [800001]\n\naggr_sql = \"\"\"select  app_id, rank, kpi, estimate from plproxy.execute_select($proxy$\nSELECT app_id, rank, kpi, estimate\nFROM mu.category_weekly_2001_143441 where \ndate in ('2020-09-05', '2020-09-12') \nand rank <= 1000 \nand category_id = {legacy_category_id} $proxy$)\n t (app_id bigint, rank integer, kpi smallint, estimate double precision) order by rank asc;\n\"\"\"\n\n\ndef get_plproxy_result(sql_str):\n    plproxy_result = []\n    result = query(PLPROXY_DSN, sql_str)\n    df_data = [Row(app_id=r[0], rank=r[1], kpi=r[2], estimate=r[3]) for r in result]\n    _schema =StructType([StructField(\"app_id\", LongType(), False), \n    StructField(\"rank\", IntegerType(), False),\n    StructField(\"kpi\", ShortType(), False),\n    StructField(\"estimate\", DoubleType(), False)])\n    df_plproxy = spark.createDataFrame(data=df_data, schema=_schema)\n    return df_plproxy\n    \ndef get_plproxy_domain_result(sql_str):\n    plproxy_result = []\n    result = query(PLPROXY_DSN, sql_str)\n    df_data = [Row(domain_id=r[0], est_usage_penetration=r[1], rank_est_usage_penetration=r[2]) for r in result]\n    _schema =StructType([StructField(\"domain_id\", LongType(), False), \n    StructField(\"est_usage_penetration\", DoubleType(), False),\n    StructField(\"rank_est_usage_penetration\", IntegerType(), False)])\n    df_plproxy = spark.createDataFrame(data=df_data, schema=_schema)\n    return df_plproxy\n\ndef get_unified_data():\n    domain_unified_source_path = \"s3://b2c-prod-data-pipeline-unified-mobileweb-paid/unified/mobileweb.basic.v4/fact/granularity=w/month=202005/date=2020-05-16\"\n    \n    spark.read.format(\"delta\").load(unified_source_path).createOrReplaceTempView(\"test_unified\")\n    spark.sql(\"select distinct domain_id from test_unified where  est_average_active_users <> 0 and est_average_active_users is not null order by domain_id asc\").createOrReplaceTempView(\"unified_df_new\")\n\ndef get_plproxy_data():\n     df_plproxy=get_plproxy_result()\n     df_plproxy.createOrReplaceTempView(\"plproxy_df_new\")\n     spark.sql(\"select count(distinct app_id) from plproxy_df_new\").show(10, False)\n    #  spark.sql(\"select * from plproxy_df_new order by rank asc\").show(10000, False)\n     \n     spark.sql(\"select app_id, avg(estimate) as estimate from plproxy_df_new group by app_id order by estimate desc\").show(10000, False)\n\n\n\ndef compare_single():\n    single_sql =  \"\"\"select  app_id, rank, kpi, estimate from plproxy.execute_select($proxy$\nSELECT app_id, rank, kpi, estimate\nFROM mu.category_weekly_1001_1000 where \ndate = '2020-09-12' \nand rank <= 1000 \nand category_id = {legacy_category_id} $proxy$)\n t (app_id bigint, rank integer, kpi smallint, estimate double precision) order by rank asc;\n\"\"\"\n    for category in legacy_gp_category_list:\n        df_plproxy=get_plproxy_result(single_sql.format(legacy_category_id=category))\n        df_plproxy.createOrReplaceTempView(\"plproxy_df\")\n        spark.sql(\"select product_key as app_id from basic_with_category_weekly where date = '2020-09-12' and device_code = 'android-phone' and country_code='WW' and category_key={category} order by est_usage_penetration desc limit 1000\".format(category=gp_category_mapping[category])).createOrReplaceTempView(\"apps_new\")\n        spark.sql(\"select app_id from plproxy_df except select app_id from apps_new\").createOrReplaceTempView(\"plproxy_diff_new\")\n        spark.sql(\"select app_id from apps_new except select app_id from plproxy_df\").createOrReplaceTempView(\"new_diff_plproxy\")\n        # print \"category is {category}\".format(category=category)\n        spark.sql(\"select app_id as plproxy_diff_new from plproxy_diff_new\").show(1000, False)\n        spark.sql(\"select app_id as new_diff_plproxy from new_diff_plproxy\").show(1000, False)\n        \n        spark.sql(\"select count(1) as plproxy from plproxy_df\").show(1000, False)\n        spark.sql(\"select count(1) as new from apps_new\").show(1000, False)\n        \n        # plproxy_diff_new = spark.sql(\"select count(1) as plproxy_diff_snowflake from plproxy_diff_new\").collect()\n        # new_diff_plproxy = spark.sql(\"select count(1) as snowflake_diff_plproxy from new_diff_plproxy\").collect()\n        # print \"category\", category, \"plproxy_diff_new\", plproxy_diff_new[0][0], \"new_diff_plproxy\", new_diff_plproxy[0][0]\n\ndef compare_aggr():\n    # basic_with_category_{granularity}; .format(date='2020-08-31', legacy_category_id=36)\n    \n    for category in legacy_category_list:\n        df_plproxy=get_plproxy_result(aggr_sql.format(legacy_category_id=category))\n        df_plproxy.createOrReplaceTempView(\"plproxy_df\")\n        spark.sql(\"select app_id, max(estimate) as estimate from plproxy_df group by app_id order by estimate desc limit 1000\").createOrReplaceTempView(\"plproxy_aggr\")\n        \n        spark.sql(\"select product_key as app_id, sum(est_active_users)/sum(est_population) as aggr_up from basic_with_category_weekly where date in  ('2020-08-29', '2020-08-22') and device_code = 'ios-phone' and country_code='US' and unified_category_key={unified_category} group by app_id order by aggr_up desc limit 1000\".format(unified_category=category_mapping[category])).createOrReplaceTempView(\"apps_new\")\n        spark.sql(\"select app_id from plproxy_aggr except select app_id from apps_new\").createOrReplaceTempView(\"plproxy_diff_new\")\n        spark.sql(\"select app_id from apps_new except select app_id from plproxy_aggr\").createOrReplaceTempView(\"new_diff_plproxy\")\n        # print \"category is {category}\".format(category=category)\n        spark.sql(\"select app_id as plproxy_diff_new from plproxy_diff_new order by app_id desc\").show(1000, False)\n        spark.sql(\"select app_id as new_diff_plproxy from new_diff_plproxy order by app_id desc\").show(1000, False)\n        \n        spark.sql(\"select app_id as plproxy_diff_new from plproxy_diff_new order by app_id desc\").show(1000, False)\n        spark.sql(\"select app_id as new_diff_plproxy from new_diff_plproxy order by app_id desc\").show(1000, False)\n        \n        # plproxy_diff_new = spark.sql(\"select count(1) as plproxy_diff_new from plproxy_diff_new\").collect()\n        # new_diff_plproxy = spark.sql(\"select count(1) as new_diff_plproxy from new_diff_plproxy\").collect()\n        # print \"category\", category, \"plproxy_diff_new\", plproxy_diff_new[0][0], \"new_diff_plproxy\", new_diff_plproxy[0][0]\n        \ndef compare_single_domain():\n    domain_single_sql = \"\"\"\nselect  domain_id, est_usage_penetration, rank_est_usage_penetration from plproxy.execute_select($proxy$\nSELECT domain_id, est_usage_penetration, rank_est_usage_penetration\nFROM mw.category_m_ap where \ndate = '2020-08-31' and category_id = {unified_category_id} and country_code = 'us' and rank_est_usage_penetration < 1000 $proxy$)\n t (domain_id bigint, est_usage_penetration real, rank_est_usage_penetration int) ;\n\"\"\" \n    for category in unified_category_list:\n        df_plproxy=get_plproxy_domain_result(domain_single_sql.format(unified_category_id=category))\n        df_plproxy.createOrReplaceTempView(\"plproxy_df\")\n        spark.sql(\"select product_key as domain_id from basic_with_category_monthly where date = '2020-08-31' and device_code = 'android-phone' and country_code='US' and unified_category_key={category} order by est_usage_penetration desc limit 1000\".format(category=category)).createOrReplaceTempView(\"domain_new\")\n        spark.sql(\"select domain_id from plproxy_df except select domain_id from domain_new\").createOrReplaceTempView(\"plproxy_diff_new\")\n        spark.sql(\"select domain_id from domain_new except select domain_id from plproxy_df\").createOrReplaceTempView(\"new_diff_plproxy\")\n        # print \"category is {category}\".format(category=category)\n        # spark.sql(\"select count(distinct domain_id) from domain_new\").show(1000, False)\n        # spark.sql(\"select count(1) as new_diff_plproxy from new_diff_plproxy\").show(1000, False)\n        \n        \n        plproxy_diff_new = spark.sql(\"select count(1) as plproxy_diff_new from plproxy_diff_new\").collect()\n        new_diff_plproxy = spark.sql(\"select count(1) as new_diff_plproxy from new_diff_plproxy\").collect()\n        print \"category\", category, \"plproxy_diff_new\", plproxy_diff_new[0][0], \"new_diff_plproxy\", new_diff_plproxy[0][0]\n        \ndef compare_domain_aggr():\n    domain_aggr_sql = \"\"\"\nselect  domain_id, est_usage_penetration, rank_est_usage_penetration from plproxy.execute_select($proxy$\nSELECT domain_id, est_usage_penetration, rank_est_usage_penetration\nFROM mw.category_w_ip_us where \ndate in ('2020-08-15', '2020-08-22') and category_id = {unified_category_id} and rank_est_usage_penetration < 1000 $proxy$)\n t (domain_id bigint, est_usage_penetration real, rank_est_usage_penetration int) ;\n\"\"\" \n    for category in unified_category_list:\n        df_plproxy=get_plproxy_domain_result(domain_aggr_sql.format(unified_category_id=category))\n        df_plproxy.createOrReplaceTempView(\"plproxy_df\")\n        spark.sql(\"select domain_id, max(est_usage_penetration) as est_usage_penetration from plproxy_df group by domain_id order by est_usage_penetration desc limit 1000\").createOrReplaceTempView(\"plproxy_aggr\")\n        \n        spark.sql(\"select product_key as domain_id, sum(est_active_users)/sum(est_population) as aggr_up from basic_with_category_weekly where date in  ('2020-08-15', '2020-08-22') and device_code = 'ios-phone' and country_code='US' and unified_category_key={unified_category} group by product_key order by aggr_up desc limit 1000\".format(unified_category=category)).createOrReplaceTempView(\"domain_new\")\n        # spark.sql(\"select count(1) from domain_new\").show(10, False)\n        # spark.sql(\"select count(1) from plproxy_aggr\").show(10, False)\n        spark.sql(\"select domain_id from plproxy_aggr except select domain_id from domain_new\").createOrReplaceTempView(\"plproxy_diff_new\")\n        spark.sql(\"select domain_id from domain_new except select domain_id from plproxy_aggr\").createOrReplaceTempView(\"new_diff_plproxy\")\n        \n        plproxy_diff_new = spark.sql(\"select count(1) as plproxy_diff_new from plproxy_diff_new\").collect()\n        new_diff_plproxy = spark.sql(\"select count(1) as new_diff_plproxy from new_diff_plproxy\").collect()\n        print \"category\", category, \"plproxy_diff_new\", plproxy_diff_new[0][0], \"new_diff_plproxy\", new_diff_plproxy[0][0]\n    \n    \ncompare_domain_aggr()\n# unified_source_path = \"s3://b2c-prod-data-pipeline-unified-mobileweb-paid/unified/mobileweb.basic.v4/fact/granularity=w/date=2020-05-16\"\n# spark.read.format(\"delta\").load(unified_source_path).show(10)\n"]},{"cell_type":"code","execution_count":0,"id":"20201030-064329_1498542380","metadata":{},"outputs":[],"source":["\n# spark.sql(\"select * from basic_with_category_weekly where date in  ('2020-08-29', '2020-08-22') and device_code = 'ios-phone' and country_code='US' and unified_category_key=800001\").createOrReplaceTempView(\"new_data\")\n\nspark.sql(\"select  product_key,est_usage_penetration from new_data where product_key in (select app_id from new_diff_plproxy) and date = '2020-08-22' order by product_key desc\").show(100, False)\n\n       "]},{"cell_type":"code","execution_count":0,"id":"20200918-040737_1935830413","metadata":{},"outputs":[],"source":["\nraw_data_path =  \"s3://aardvark-prod-pdx-mdm-to-int/basic_kpi/version=1.0.0/range_type=DAY/date=2020-08-01/\"\nusage_basic_unified_path = \"s3://b2c-prod-data-pipeline-unified-usage/unified/usage.app-basic-kpi.v8/fact/product_type_name=app/granularity=monthly/\"\nraw_domain_path = \"\"\nspark.read.option(\"basePath\", \"s3://aardvark-prod-pdx-mdm-to-int/basic_kpi/version=1.0.0\").parquet(raw_data_path).createOrReplaceTempView(\"test\")\nspark.read.format(\"delta\").load(usage_basic_unified_path).createOrReplaceTempView(\"test_unified\")\nspark.sql(\"select count(distinct country_code,device_code,date,product_id,market_code,granularity) from test_unified where est_active_users is not null and est_active_users <> 0\").createOrReplaceTempView(\"unified_remove_category\")\n# spark.read.format(\"delta\").load(raw_data_path).createOrReplaceTempView(\"test\")\n\n# distint app count\n# spark.sql(\"select product_id from test_unified where unified_category_key = 0 limit 10\").show()\nspark.sql(\"select distinct app_id from test\").createOrReplaceTempView(\"raw_app_list\")\nspark.sql(\"select distinct product_id from test_unified\").createOrReplaceTempView(\"unified_app_list\")\n# spark.sql(\"select * from unified_app_list limit 10\").show()\nspark.sql(\"select app_id from raw_app_list EXCEPT select product_id from unified_app_list\").createOrReplaceTempView(\"app_diff\")\nspark.sql(\"select count(*) from app_diff\").show()\n# spark.sql(\"select * from app_diff order by app_id asc\").show()\n# spark.sql(\"select * from test where app_id = 20600000328027\").show()\n# spark.sql(\"select * from test_unified where product_id = 20600000328027\").show()\n# device_count\nspark.sql(\"select count(*)  as raw_line_count from test where AU is not null and AU <> 0\").show()\nspark.sql(\"select count(*)  as unified_line_count from unified_remove_category\").show()\n"]},{"cell_type":"code","execution_count":0,"id":"20201030-053944_624495110","metadata":{},"outputs":[],"source":["\ngranularity_list = [\"monthly\", \"weekly\", \"daily\"]\ncategory_path = \"s3://b2c-prod-data-pipeline-unified-usage/unified/usage.category.v6/dimension/product_type_code=domain/\"\nusage_basic_after_transform = \"s3://b2c-prod-data-pipeline-unified-usage/unified/usage.basic-kpi.v6/fact/product_type_code=domain/\"\nfor granularity in granularity_list:\n    filter_str = \"date between '2020-08-01' and '2020-08-31' and granularity_code = '{granularity}'\".format(granularity=granularity)\n    print filter_str\n    spark.read.format(\"delta\").load(category_path).filter(filter_str).createOrReplaceTempView(\"category_view\")\n    spark.read.format(\"delta\").load(usage_basic_after_transform).filter(filter_str).createOrReplaceTempView(\"basic_view\")\n    spark.sql(\"\"\"\nselect basic.DATE_KEY,\nbasic.DEVICE_CODE,\nbasic.COUNTRY_CODE,basic.COUNTRY_KEY,\nbasic.date,\nbasic.DEVICE_KEY,basic.GRANULARITY_CODE,basic.GRANULARITY_KEY,basic.MARKET_CODE,\nbasic.MARKET_KEY,basic.PRODUCT_KEY,basic.PRODUCT_TYPE_CODE,basic.PRODUCT_TYPE_KEY,\nbasic.EST_TOTAL_TIME_MILLISECONDS_OF_MAIN_CATEGORY,basic.EST_WIFI_BYTES,basic.EST_ACTIVE_USERS,\nbasic.EST_TOTAL_BYTES,basic.EST_TOTAL_SESSION_COUNT_OF_MAIN_CATEGORY,\nbasic.EST_TOTAL_BYTES_OF_MAIN_CATEGORY,basic.EST_TOTAL_ACTIVE_DAYS,basic.EST_INSTALL_BASE,\nbasic.EST_POPULATION,basic.EST_TOTAL_TIME_MILLISECONDS,basic.EST_TOTAL_SESSION_COUNT,\nbasic.DEVICE_FORM_FACTOR_CODE,basic.DEVICE_FORM_FACTOR_KEY,basic.PARENT_DEVICE_CODE,basic.PARENT_DEVICE_KEY,basic.PLATFORM_CODE,basic.PLATFORM_KEY,\nbasic.est_usage_penetration,\nmap.category_key as category_key,\nmap.unified_category_key as unified_category_key\nfrom basic_view basic\njoin category_view map\non basic.date = map.date\nand basic.product_key = map.product_key\nand basic.granularity_code = map.granularity_code\nand basic.country_code = map.country_code\nand basic.device_code = map.device_code\n    \"\"\").createOrReplaceTempView(\"basic_with_category_{granularity}\".format(granularity=granularity))\n    # spark.sql(\"select count(1) from category_view\").show(1, False)\n    # spark.sql(\"select count(1) from basic_with_category_{granularity}\".format(granularity=granularity)).show(1, False)\n    \n"]},{"cell_type":"code","execution_count":0,"id":"20200924-025357_326482456","metadata":{},"outputs":[],"source":["\ngranularity_list = [\"monthly\", \"weekly\", \"daily\"]\n\nusage_basic_after_transform = \"s3://b2c-prod-data-pipeline-unified-usage/unified/usage.basic-kpi.v6/fact/product_type_code=app/\"\nusage_basic_before_transform = \"s3://b2c-prod-data-pipeline-unified-usage/unified/usage.basic-kpi.v1/fact/\"\n\nfor granularity in granularity_list:\n    filter_str = \"date between '2020-08-01' and '2020-08-31' and granularity = '{granularity}' and est_average_active_users is not null and est_average_active_users <> 0\".format(granularity=granularity)\n    filter_str_after = \"date between '2020-08-01' and '2020-08-31' and granularity_code = '{granularity}' and est_active_users is not null and est_active_users <> 0\".format(granularity=granularity)\n    spark.read.format(\"parquet\").load(usage_basic_before_transform).filter(filter_str).createOrReplaceTempView(\"before_trans\")\n    spark.read.format(\"delta\").load(usage_basic_after_transform).filter(filter_str_after).createOrReplaceTempView(\"after_trans\")\n    spark.sql(\"select date, count(1) as before_trans from before_trans group by date order by date desc\").show(100, False)\n    spark.sql(\"select date, count(1) as after_trans from after_trans where country_code not in ('ROW') group by date order by date desc\").show(100, False)\n\n# df1 = spark.read.option(\"basePath\", \"s3://b2c-prod-data-pipeline-unified-usage/unified/usage.basic-kpi.v6/fact\").parquet(usage_basic_unified_path).createOrReplaceTempView(\"test\")\n# spark.read.format(\"delta\").load(usage_basic_unified_path).createOrReplaceTempView(\"test\")\n# spark.sql(\"select * from test limit 1\").printSchema()\n\n# spark.sql(\"select distinct(country_code,device_code,date,product_id,market_code,granularity) from test group by country_code,device_code,date,product_id,market_code,granularity\").createOrReplaceTempView(\"unified_remove_category\")\n# spark.sql(\"select count(*) from unified_remove_category\").show()\n"]},{"cell_type":"code","execution_count":0,"id":"20201030-074627_1653779374","metadata":{},"outputs":[],"source":["\nspark.read.format(\"delta\").load(usage_basic_after_transform).filter(\"date between '2020-08-01' and '2020-08-31' and granularity_code = 'monthly' and est_active_users is not null and est_active_users <> 0\").createOrReplaceTempView(\"after_trans\")\nspark.sql(\"select sum(est_active_users), sum(est_usage_penetration), sum(est_open_rate), sum(est_total_session_count)/sum(est_active_users) as est_average_session_count_per_user  from after_trans where country_code not in ('WW', 'CN') and product_key = '284882215' and device_code = 'ios-phone' group by product_key\").show(10, False)\nspark.sql(\"select est_active_users, est_usage_penetration, est_open_rate, est_average_session_count_per_user from after_trans where country_code in ('WW') and product_key = '284882215' and device_code = 'ios-phone' \").show(10, False)"]},{"cell_type":"code","execution_count":0,"id":"20201030-035154_1813569249","metadata":{},"outputs":[],"source":["\nspark.sql(\"select count(1) from after_trans where est_active_users is null or est_active_users == 0\").show()"]},{"cell_type":"code","execution_count":0,"id":"20201023-021136_1101864064","metadata":{},"outputs":[],"source":["%%sh\naws s3 ls s3://b2c-prod-data-pipeline-unified-usage/unified/usage.basic-kpi.v6/fact/product_type_code=app/"]},{"cell_type":"code","execution_count":0,"id":"20200911-082559_1488405389","metadata":{},"outputs":[],"source":["%%sh\n# PGPASSWORD='2mHdFW6%#REu' psql -h internal-aa-prod-plproxy-internal-4-329644124.us-east-1.elb.amazonaws.com -U app_bdp_usage_qa -d cohort -p 7432 << EOF \n# internal-aa-prod-usage-plproxy-internal-1640809782.us-east-1.elb.amazonaws.com\nPGPASSWORD='2mHdFW6%#REu' psql -h internal-aa-prod-usage-plproxy-internal-1640809782.us-east-1.elb.amazonaws.com -U app_bdp_usage_qa -d cohort -p 7432 << EOF\n            select  app_id, rank, kpi, estimate from plproxy.execute_select(\\$proxy\\$\nSELECT app_id, rank, kpi, estimate FROM mu.category_daily where date = '2020-08-01' and rank <= 1000 and category_id = 36\nand store_id = 143441 and device_id = 2001 \\$proxy\\$)\n t (app_id bigint, rank integer, kpi smallint, estimate double precision) order by rank asc;\n\n\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20201116-073023_1615268121","metadata":{},"outputs":[],"source":["%%sh\n\nPGPASSWORD='2mHdFW6%#REu' psql -h internal-aa-prod-plproxy-internal-4-329644124.us-east-1.elb.amazonaws.com -U app_bdp_usage_qa -d dailyest -p 7432 << EOF\n            select  distinct category_id from plproxy.execute_select(\\$proxy\\$\nSELECT distinct category_id\nFROM aa.app_store_daily_estimate_1_143441_202008 where\ndate between '2020-08-01' and '2020-08-31'\nand app_id in (1487212912)\nand category_id = 7012 and feed_id in (0,1,2)\\$proxy\\$)\n t (category_id int );\n\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20201030-035544_974524002","metadata":{},"outputs":[],"source":["\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}