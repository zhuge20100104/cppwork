{"cells":[{"cell_type":"code","execution_count":0,"id":"20190815-093706_1591096848","metadata":{},"outputs":[],"source":["pyspark\nfrom aaintdatapipeline.core.fs.device import meta_bucket\nimport collections\nfrom copy import deepcopy\nfrom aaintdatapipeline.core.pipeline.type_ import DataType, EventType, ManipulationType\nfrom aaintdatapipeline.core.utils.identifier import date_time, type_\nfrom aaintdatapipeline.core.utils import avro_, json_\nfrom aaintdatapipeline.core.fs.router import EventRouter\nfrom aaintdatapipeline.core.fs.device import meta_bucket\n\n\ns3_path = \"s3://b2b-prod-int-data-pipeline-metastore/meta/events/app-int.city-level-usage.v1/load/insert/220190808061256077/aidp35adf9791115505117fc027362ff153d.avro\"\n\n\n\ndef _get_params_from_avro():\n    # prefix = EventRouter(urn).logic_key()\n    # try:\n    # key = meta_bucket().all(prefix)[0]\n    # print \"key in urn\"\n    # print key\n    s3_prefix = \"meta/events/app-int.city-level-usage.v1/load/insert/220190808061256077/\"\n    key = meta_bucket().all(s3_prefix)[0]\n    data = meta_bucket().get(key)\n    encode_parms_ = avro_.read(byte_array=data)[0]['params']\n    parms_in_dict = json_.loads(encode_parms_)['py/collections.namedtuple']\n    return collections.namedtuple(\"parms\", parms_in_dict['fields']) \\\n        ._make(parms_in_dict['values'])\n    # except:\n    #     return  None\n\n'workflow_description' in dir(_get_params_from_avro())\n"]},{"cell_type":"code","execution_count":0,"id":"20190815-094835_1712740172","metadata":{},"outputs":[],"source":["%%sh\n\n#PGPASSWORD=2mHdFW6%#REu psql -h 10.2.6.27 -p 5433 -Uapp_bdp_usage_qa -d mkt_est << EOF\n#select max(id) from mkt.s3_path_creative_id_map where update_time < '2019-05-01';\n\n\n# PGPASSWORD=2mHdFW6%#REu psql -h 10.2.6.213 -p 5432 -Uapp_bdp_usage_qa -d mkt_est << EOF\n# \\l\n\n\n#PG_MKT_EST_P0_HOSTS = [(‘10.2.6.27’, 5433)]\n#PG_MKT_EST_P1_HOSTS = [(‘10.2.6.245’, 5434)]\n#PG_MKT_EST_P2_HOSTS = [(‘10.2.6.42’, 5435)]\n#PG_MKT_EST_P3_HOSTS = [(‘10.2.6.148’, 5436)]\n#PG_MKT_EST_P4_HOSTS = [(‘10.2.6.49’, 5437)]\n#PG_MKT_EST_P5_HOSTS = [(‘10.2.6.52’, 5438)]\n#PG_MKT_EST_P6_HOSTS = [(‘10.2.6.187’, 5439)]\n#PG_MKT_EST_P7_HOSTS = [(‘10.2.6.254’, 5440)]\n\nPGPASSWORD=2mHdFW6%#REu psql -h 10.2.6.213 -p 5432 -Uapp_bdp_usage_qa -d mkt_est << EOF \nSELECT sum(creative_id)\nFROM plproxy.execute_select_nestloop($proxy$\n\tSELECT count(creative_id)\n\tFROM mkt.meta_creative_1001\n$proxy$) t (creative_id BIGINT)\n\n# PGPASSWORD=2mHdFW6%#REu psql -h 10.2.6.27 -p 5433 -Uapp_bdp_usage_qa -d mkt_est << EOF\n# SELECT count(creative_id) FROM mkt.meta_creative_1001\n\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20190816-020829_58197931","metadata":{},"outputs":[],"source":["\nimport datetime\nimport psycopg2\nfrom contextlib import closing\n\n# PGPASSWORD=2mHdFW6%#REu psql -h 10.2.6.213 -p 5432 -Uapp_bdp_usage_qa -d mkt_est << EOF\ndbinfo = {\n    'NAME': 'mkt_est',\n    'USER': 'app_bdp_usage_qa',\n    'PASSWORD': '2mHdFW6%#REu',\n    'HOST': '10.2.6.213',\n    'PORT': 5432,\n    \n}\n\ndbinfo = {\n    'NAME': 'mkt_est',\n    'USER': 'app_bdp_usage_qa',\n    'PASSWORD': '2mHdFW6%#REu',\n    'HOST': '10.2.6.27',\n    'PORT': 5433,\n    \n}\n# dsn = \"dbname='{dbname}' user='{user}' host='{host}' port='{port}' password='{passwd}'\".format(dbname=dbinfo['NAME'], user=dbinfo['USER'], passwd=dbinfo['PASSWORD'],host=dbinfo['HOST'], port=dbinfo['PORT'])\n# print dsn\nconn = psycopg2.connect(dbname=dbinfo['NAME'], user=dbinfo['USER'], password=dbinfo['PASSWORD'],host=dbinfo['HOST'], port=dbinfo['PORT'])\n\n# psycopg2.connect(database=\"postgres\",\n#                                     user=self.user,\n#                                     password=self.passwd)\n# conn = psycopg2.connect(dsn)\ndef select(sql):\n    with closing(conn.cursor()) as cur:\n        cur.execute(sql)\n        rows = cur.fetchall()\n        cnt = cur.rowcount\n    return rows, cnt\n    \n    \ndef get_db_count(key, schema, table):\n    sql = \"\"\"\n         SELECT sum({key}) FROM plproxy.execute_select\n         ($$\n              SELECT count({key}) FROM {schema}.{table}\n         $$) t ({key} REAL)\n    \"\"\".format(\n        key=key,\n        schema=schema,\n        table=table\n    )\n    select(sql)\n    \nget_db_count('creative_id', 'mkt', 'weekly_creative_detail_estimate_1001_1' )\n"]},{"cell_type":"code","execution_count":0,"id":"20190818-094753_1095937009","metadata":{},"outputs":[],"source":["\nimport datetime\nimport psycopg2\nfrom contextlib import closing\n\ndbinfo = {\n    'NAME': 'mkt_est',\n    'USER': 'app_bdp_usage_qa',\n    'PASSWORD': '2mHdFW6%#REu',\n    'HOST': '10.2.6.27',\n    'PORT': 5433,\n    \n}\n\nconn = psycopg2.connect(dbname=dbinfo['NAME'], user=dbinfo['USER'], password=dbinfo['PASSWORD'],host=dbinfo['HOST'], port=dbinfo['PORT'])\n\ndef select(sql):\n    with closing(conn.cursor()) as cur:\n        cur.execute(sql)\n        rows = cur.fetchall()\n        cnt = cur.rowcount\n    return rows, cnt\n    \ndef get_db_count(key, schema, table):\n    sql = \"\"\"\n        select max(id) from mkt.s3_path_creative_id_map where update_time < '2019-05-01';\n    \"\"\".format(\n        key=key,\n        schema=schema,\n        table=table\n    )\n    return select(sql)\n    \nrows, _ = get_db_count('creative_id', 'mkt', 'weekly_creative_detail_estimate_1001_1')\nprint rows[0][0]\n\ntable = \"mkt.meta_creative_{device_id}_{store_id}_{network_id}\"\n\n\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20190818-100919_58765135","metadata":{},"outputs":[],"source":["\nfrom itertools import product\nimport datetime\nimport psycopg2\nfrom contextlib import closing\nimport time\n\nGP_COUNTRY_CODE = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 61, 64, 65, 74, 78, 80, 84, 86, 95, 1000]\nIOS_COUNTRY_CODE = [0, 143441, 143442, 143443, 143444, 143445, 143446, 143447, 143448, 143449, 143450, 143451, 143452, 143453, 143454, 143455, 143456, 143457, 143458, 143459, 143460, 143461, 143462, 143463, 143464, 143465, 143466, 143467, 143468, 143469, 143470, 143471, 143472, 143473, 143474, 143475, 143476, 143477, 143478, 143479, 143480, 143481, 143482, 143483, 143484, 143485, 143486, 143487, 143489, 143491, 143492, 143493, 143494, 143495, 143496, 143497, 143498, 143499, 143501, 143502, 143503, 143504, 143505, 143506, 143507, 143508, 143509, 143510, 143511, 143512, 143513, 143514, 143515, 143516, 143517, 143518, 143519, 143520, 143521, 143523, 143524, 143525, 143526, 143528, 143529, 143530, 143531, 143532, 143533, 143534, 143535, 143536, 143537, 143538, 143539, 143540, 143541, 143542, 143543, 143544, 143545, 143546, 143547, 143548, 143549, 143550, 143551, 143552, 143553, 143554, 143555, 143556, 143557, 143558, 143559, 143560, 143561, 143562, 143563, 143564, 143565, 143566, 143568, 143571, 143572, 143573, 143575, 143576, 143577, 143578, 143579, 143580, 143581, 143582, 143583, 143584, 143585, 143586, 143587, 143588, 143589, 143590, 143591, 143592, 143593, 143594, 143595, 143597, 143598, 143599, 143600, 143601, 143602, 143603, 143604, 143605]\nGP_DEVICE_ID = [1001, 1002] # 1000\nIOS_DEVICE_ID = [2001, 2002] # 2000\nNETWORK = [1, 203, 324, 101, 136, 201, 202, 171, 109, 110, 111, 112, 200, 114, 116, 142, 311, 121, 316, 325]\nDATE = ['201501', '201502', '201503', '201504', '201505', '201506', '201507', '201508', '201509', '201510', '201511', '201512', '201601', '201602', '201603', '201604', '201605', '201606', '201607', '201608', '201609', '201610', '201611', '201612', '201701', '201702', '201703', '201704', '201705', '201706', '201707', '201708', '201709', '201710', '201711', '201712', '201801', '201802', '201803', '201804', '201805', '201806', '201807', '201808', '201809', '201810', '201811', '201812', '201901', '201902', '201903', '201904']\n\ndbinfo = {'NAME': 'mkt_est', 'USER': 'app_bdp_usage_qa', 'PASSWORD': '2mHdFW6%#REu', 'HOST': '10.2.6.27', 'PORT': 5433}\ndblist = [('10.2.6.27', 5433), ('10.2.6.245', 5434), ('10.2.6.42', 5435), ('10.2.6.148', 5436), ('10.2.6.49', 5437), ('10.2.6.52', 5438), ('10.2.6.187', 5439), ('10.2.6.254', 5440)]\n\ntime = time.strftime('%Y-%m-%d_%H-%M-%S',time.localtime(time.time()))\nlog_filename = '/tmp/db_{time}.log'.format(time=time)\nprint log_filename\n\ndef select(sql):\n    conn = psycopg2.connect(dbname=dbinfo['NAME'], user=dbinfo['USER'], password=dbinfo['PASSWORD'],host=dbinfo['HOST'], port=dbinfo['PORT'])\n    with closing(conn.cursor()) as cur:\n        cur.execute(sql)\n        rows = cur.fetchall()\n        cnt = cur.rowcount\n    return rows, cnt\n\ndef get_device_store_list():\n    sql_list = []\n    for device_id, store_id  in product(GP_DEVICE_ID, GP_COUNTRY_CODE):\n        sql_list.append((device_id, store_id))\n    for device_id, store_id in product(IOS_DEVICE_ID, IOS_COUNTRY_CODE):\n        sql_list.append((device_id, store_id))\n    print len(sql_list)\n    return sql_list\n\ndef write_to_file(filename, str):\n    with open(filename,'a') as file_object:\n        file_object.write(str)\n\nfor device_id,store_id in get_device_store_list():\n    table_name = 'meta_creative'\n    # SQL RESULT\n    result = 0\n    sql_str = \"{device_id}_{store_id}\".format(device_id=device_id, store_id=store_id)\n    for host, port in dblist:\n        dbinfo['HOST'] = host\n        dbinfo['PORT'] = port\n        try:\n            sql =  \"SELECT count(distinct(device_id, store_id, network_id, creative_id, ad_app_id, first_seen, last_seen)) FROM mkt.meta_creative_{sql_str} WHERE creative_id <= 90100006099406\".format(sql_str=sql_str)\n            # print sql # debug\n            r, _ = select(sql)\n            result += r[0][0]\n            # print result # debug\n        except Exception, e:\n            error_result=e.message.replace('\\n', '\\\\n')\n            if \"does not exist\" in error_result:\n                error_result = -1\n    # S3 RESULT\n    s3_result = 0\n    s3_path = \"s3://b2c-prod-data-pipeline-unified-market/unified/app-tech.market.legacy-meta_creative.v1/dimension/device_id={device_id}/store_id={store_id}/\".format(device_id=device_id, store_id=store_id)\n    try:\n        s3_result = spark.read.parquet(s3_path).count()\n    except Exception, e:\n        error_s3_result = -1\n\n    result_str = \"mkt.meta_creative_{},{},{}\\n\".format(sql_str, result or error_result,s3_result or error_s3_result)\n    write_to_file(log_filename, result_str)\n    # raise Exception\n    \n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20190819-124748_1806912913","metadata":{},"outputs":[],"source":["%%sh\n\ncat /tmp/db_2019-08-19_12-50-45.log\n\n"]},{"cell_type":"code","execution_count":0,"id":"20190818-145626_1015133730","metadata":{},"outputs":[],"source":["\nfrom itertools import product\nimport datetime\nimport psycopg2\nfrom contextlib import closing\nimport time\n\nGP_COUNTRY_CODE = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 61, 64, 65, 74, 78, 80, 84, 86, 95, 1000]\nIOS_COUNTRY_CODE = [0, 143441, 143442, 143443, 143444, 143445, 143446, 143447, 143448, 143449, 143450, 143451, 143452, 143453, 143454, 143455, 143456, 143457, 143458, 143459, 143460, 143461, 143462, 143463, 143464, 143465, 143466, 143467, 143468, 143469, 143470, 143471, 143472, 143473, 143474, 143475, 143476, 143477, 143478, 143479, 143480, 143481, 143482, 143483, 143484, 143485, 143486, 143487, 143489, 143491, 143492, 143493, 143494, 143495, 143496, 143497, 143498, 143499, 143501, 143502, 143503, 143504, 143505, 143506, 143507, 143508, 143509, 143510, 143511, 143512, 143513, 143514, 143515, 143516, 143517, 143518, 143519, 143520, 143521, 143523, 143524, 143525, 143526, 143528, 143529, 143530, 143531, 143532, 143533, 143534, 143535, 143536, 143537, 143538, 143539, 143540, 143541, 143542, 143543, 143544, 143545, 143546, 143547, 143548, 143549, 143550, 143551, 143552, 143553, 143554, 143555, 143556, 143557, 143558, 143559, 143560, 143561, 143562, 143563, 143564, 143565, 143566, 143568, 143571, 143572, 143573, 143575, 143576, 143577, 143578, 143579, 143580, 143581, 143582, 143583, 143584, 143585, 143586, 143587, 143588, 143589, 143590, 143591, 143592, 143593, 143594, 143595, 143597, 143598, 143599, 143600, 143601, 143602, 143603, 143604, 143605]\nGP_DEVICE_ID = [1001, 1002] # 1000\nIOS_DEVICE_ID = [2001, 2002] # 2000\nGRANULARIY = [\"weekly\", \"monthly\"]\nNETWORK = [1, 203, 324, 101, 136, 201, 202, 171, 109, 110, 111, 112, 200, 114, 116, 142, 311, 121, 316, 325]\nDATE = ['201501', '201502', '201503', '201504', '201505', '201506', '201507', '201508', '201509', '201510', '201511', '201512', '201601', '201602', '201603', '201604', '201605', '201606', '201607', '201608', '201609', '201610', '201611', '201612', '201701', '201702', '201703', '201704', '201705', '201706', '201707', '201708', '201709', '201710', '201711', '201712', '201801', '201802', '201803', '201804', '201805', '201806', '201807', '201808', '201809', '201810', '201811', '201812', '201901', '201902', '201903', '201904']\n\ndbinfo = {'NAME': 'mkt_est', 'USER': 'app_bdp_usage_qa', 'PASSWORD': '2mHdFW6%#REu', 'HOST': '10.2.6.27', 'PORT': 5433}\ndblist = [('10.2.6.27', 5433), ('10.2.6.245', 5434), ('10.2.6.42', 5435), ('10.2.6.148', 5436), ('10.2.6.49', 5437), ('10.2.6.52', 5438), ('10.2.6.187', 5439), ('10.2.6.254', 5440)]\n\ntime = time.strftime('%Y-%m-%d_%H-%M-%S',time.localtime(time.time()))\nlog_filename = '/tmp/db_{time}.log'.format(time=time)\nprint log_filename\n\ndef select(sql):\n    conn = psycopg2.connect(dbname=dbinfo['NAME'], user=dbinfo['USER'], password=dbinfo['PASSWORD'],host=dbinfo['HOST'], port=dbinfo['PORT'])\n    with closing(conn.cursor()) as cur:\n        cur.execute(sql)\n        rows = cur.fetchall()\n        cnt = cur.rowcount\n    return rows, cnt\n\ndef get_device_store_list():\n    product_list = []\n    for device_id, store_id  in product(GP_DEVICE_ID, GP_COUNTRY_CODE):\n        product_list.append((device_id, store_id))\n    for device_id, store_id in product(IOS_DEVICE_ID, IOS_COUNTRY_CODE):\n        product_list.append((device_id, store_id))\n    print len(product_list)\n    return product_list\n\ndef get_granularity_device_store_list():\n    product_list = []\n    for granularity, device_id, store_id  in product(GRANULARIY, GP_DEVICE_ID, GP_COUNTRY_CODE):\n        product_list.append((granularity, device_id, store_id))\n    for granularity, device_id, store_id in product(GRANULARIY, IOS_DEVICE_ID, IOS_COUNTRY_CODE):\n        product_list.append((granularity, device_id, store_id))\n    print len(product_list)\n    return product_list\n\n\ndef write_to_file(filename, str):\n    with open(filename,'a') as file_object:\n        file_object.write(str)\n\nfor granularity,device_id,store_id in get_granularity_device_store_list():\n    table_name = 'ad_app_estimate'\n    # SQL RESULT\n    result = 0\n    sql_str = \"{granularity}_{table_name}_{device_id}_{store_id}\".format(table_name=table_name, device_id=device_id, store_id=store_id, granularity=granularity)\n    for host, port in dblist:\n        dbinfo['HOST'] = host\n        dbinfo['PORT'] = port\n        try:\n            sql =  \"SELECT count(date) FROM mkt.{sql_str} WHERE date < '2019-05-01'\".format(sql_str=sql_str)\n            # print sql # debug\n            r, _ = select(sql)\n            result += r[0][0]\n            # print result # debug\n        except Exception, e:\n            # print e.message\n            error_result=e.message.replace('\\n', '\\\\n')\n            if \"does not exist\" in error_result:\n                error_result = -1\n    # S3 RESULT\n    s3_result = 0\n    s3_path = \"s3://b2c-prod-data-pipeline-unified-market/unified/app-tech.market.legacy-ad_app_estimate.v1/fact/granularity={granularity}/device_id={device_id}/store_id={store_id}/part-{granularity}-{device_id}-{store_id}.c000.gz.parquet\".format(granularity=granularity, device_id=device_id, store_id=store_id)\n    try:\n        s3_result = spark.read.parquet(s3_path).count()\n    except Exception, e:\n        error_s3_result = -1\n\n    result_str = \"{},{},{}\\n\".format(sql_str, result or error_result,s3_result or error_s3_result)\n    write_to_file(log_filename, result_str)\n    # raise Exception"]},{"cell_type":"code","execution_count":0,"id":"20190818-162040_1802787876","metadata":{},"outputs":[],"source":["\nfrom itertools import product\nimport datetime\nimport psycopg2\nfrom contextlib import closing\nimport time\n\nGP_COUNTRY_CODE = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 61, 64, 65, 74, 78, 80, 84, 86, 95, 1000]\nIOS_COUNTRY_CODE = [0, 143441, 143442, 143443, 143444, 143445, 143446, 143447, 143448, 143449, 143450, 143451, 143452, 143453, 143454, 143455, 143456, 143457, 143458, 143459, 143460, 143461, 143462, 143463, 143464, 143465, 143466, 143467, 143468, 143469, 143470, 143471, 143472, 143473, 143474, 143475, 143476, 143477, 143478, 143479, 143480, 143481, 143482, 143483, 143484, 143485, 143486, 143487, 143489, 143491, 143492, 143493, 143494, 143495, 143496, 143497, 143498, 143499, 143501, 143502, 143503, 143504, 143505, 143506, 143507, 143508, 143509, 143510, 143511, 143512, 143513, 143514, 143515, 143516, 143517, 143518, 143519, 143520, 143521, 143523, 143524, 143525, 143526, 143528, 143529, 143530, 143531, 143532, 143533, 143534, 143535, 143536, 143537, 143538, 143539, 143540, 143541, 143542, 143543, 143544, 143545, 143546, 143547, 143548, 143549, 143550, 143551, 143552, 143553, 143554, 143555, 143556, 143557, 143558, 143559, 143560, 143561, 143562, 143563, 143564, 143565, 143566, 143568, 143571, 143572, 143573, 143575, 143576, 143577, 143578, 143579, 143580, 143581, 143582, 143583, 143584, 143585, 143586, 143587, 143588, 143589, 143590, 143591, 143592, 143593, 143594, 143595, 143597, 143598, 143599, 143600, 143601, 143602, 143603, 143604, 143605]\nGP_DEVICE_ID = [1001, 1002] # 1000\nIOS_DEVICE_ID = [2001, 2002] # 2000\nGRANULARIY = [\"weekly\", \"monthly\"]\nNETWORK = [1, 203, 324, 101, 136, 201, 202, 171, 109, 110, 111, 112, 200, 114, 116, 142, 311, 121, 316, 325]\nDATE = ['201501', '201502', '201503', '201504', '201505', '201506', '201507', '201508', '201509', '201510', '201511', '201512', '201601', '201602', '201603', '201604', '201605', '201606', '201607', '201608', '201609', '201610', '201611', '201612', '201701', '201702', '201703', '201704', '201705', '201706', '201707', '201708', '201709', '201710', '201711', '201712', '201801', '201802', '201803', '201804', '201805', '201806', '201807', '201808', '201809', '201810', '201811', '201812', '201901', '201902', '201903', '201904']\n\ndbinfo = {'NAME': 'mkt_est', 'USER': 'app_bdp_usage_qa', 'PASSWORD': '2mHdFW6%#REu', 'HOST': '10.2.6.27', 'PORT': 5433}\ndblist = [('10.2.6.27', 5433), ('10.2.6.245', 5434), ('10.2.6.42', 5435), ('10.2.6.148', 5436), ('10.2.6.49', 5437), ('10.2.6.52', 5438), ('10.2.6.187', 5439), ('10.2.6.254', 5440)]\n\ntime = time.strftime('%Y-%m-%d_%H-%M-%S',time.localtime(time.time()))\nlog_filename = '/tmp/db_{time}.log'.format(time=time)\nprint log_filename\n\ndef select(sql):\n    conn = psycopg2.connect(dbname=dbinfo['NAME'], user=dbinfo['USER'], password=dbinfo['PASSWORD'],host=dbinfo['HOST'], port=dbinfo['PORT'])\n    with closing(conn.cursor()) as cur:\n        cur.execute(sql)\n        rows = cur.fetchall()\n        cnt = cur.rowcount\n    return rows, cnt\n\ndef get_device_store_list():\n    product_list = []\n    for device_id, store_id  in product(GP_DEVICE_ID, GP_COUNTRY_CODE):\n        product_list.append((device_id, store_id))\n    for device_id, store_id in product(IOS_DEVICE_ID, IOS_COUNTRY_CODE):\n        product_list.append((device_id, store_id))\n    print len(product_list)\n    return product_list\n\ndef get_granularity_device_store_list():\n    product_list = []\n    for granularity, device_id, store_id  in product(GRANULARIY, GP_DEVICE_ID, GP_COUNTRY_CODE):\n        product_list.append((granularity, device_id, store_id))\n    for granularity, device_id, store_id in product(GRANULARIY, IOS_DEVICE_ID, IOS_COUNTRY_CODE):\n        product_list.append((granularity, device_id, store_id))\n    print len(product_list)\n    return product_list\n\n\ndef write_to_file(filename, str):\n    with open(filename,'a') as file_object:\n        file_object.write(str)\n\nfor granularity,device_id,store_id in get_granularity_device_store_list():\n    table_name = 'ad_app_detail_estimate'\n    # SQL RESULT\n    result = 0\n    sql_str = \"{granularity}_{table_name}_{device_id}_{store_id}\".format(table_name=table_name, device_id=device_id, store_id=store_id, granularity=granularity)\n    for host, port in dblist:\n        dbinfo['HOST'] = host\n        dbinfo['PORT'] = port\n        try:\n            sql =  \"SELECT count(date) FROM mkt.{sql_str} WHERE date < '2019-05-01'\".format(sql_str=sql_str)\n            # print sql # debug\n            r, _ = select(sql)\n            result += r[0][0]\n            # print result # debug\n        except Exception, e:\n            # print e.message\n            error_result=e.message.replace('\\n', '\\\\n')\n            if \"does not exist\" in error_result:\n                error_result = -1\n    # S3 RESULT\n    s3_result = 0\n    s3_path = \"s3://b2c-prod-data-pipeline-unified-market/unified/app-tech.market.legacy-{table_name}.v1/fact/granularity={granularity}/device_id={device_id}/store_id={store_id}/part-{granularity}-{device_id}-{store_id}.c000.gz.parquet\".format(table_name=table_name,granularity=granularity, device_id=device_id, store_id=store_id)\n    try:\n        s3_result = spark.read.parquet(s3_path).count()\n    except Exception, e:\n        error_s3_result = -1\n\n    result_str = \"{},{},{}\\n\".format(sql_str, result or error_result,s3_result or error_s3_result)\n    write_to_file(log_filename, result_str)\n    # raise Exception"]},{"cell_type":"code","execution_count":0,"id":"20190818-162325_721471404","metadata":{},"outputs":[],"source":["\n\nfrom itertools import product\nimport datetime\nimport psycopg2\nfrom contextlib import closing\nimport time\n\nGP_COUNTRY_CODE = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 61, 64, 65, 74, 78, 80, 84, 86, 95, 1000]\nIOS_COUNTRY_CODE = [0, 143441, 143442, 143443, 143444, 143445, 143446, 143447, 143448, 143449, 143450, 143451, 143452, 143453, 143454, 143455, 143456, 143457, 143458, 143459, 143460, 143461, 143462, 143463, 143464, 143465, 143466, 143467, 143468, 143469, 143470, 143471, 143472, 143473, 143474, 143475, 143476, 143477, 143478, 143479, 143480, 143481, 143482, 143483, 143484, 143485, 143486, 143487, 143489, 143491, 143492, 143493, 143494, 143495, 143496, 143497, 143498, 143499, 143501, 143502, 143503, 143504, 143505, 143506, 143507, 143508, 143509, 143510, 143511, 143512, 143513, 143514, 143515, 143516, 143517, 143518, 143519, 143520, 143521, 143523, 143524, 143525, 143526, 143528, 143529, 143530, 143531, 143532, 143533, 143534, 143535, 143536, 143537, 143538, 143539, 143540, 143541, 143542, 143543, 143544, 143545, 143546, 143547, 143548, 143549, 143550, 143551, 143552, 143553, 143554, 143555, 143556, 143557, 143558, 143559, 143560, 143561, 143562, 143563, 143564, 143565, 143566, 143568, 143571, 143572, 143573, 143575, 143576, 143577, 143578, 143579, 143580, 143581, 143582, 143583, 143584, 143585, 143586, 143587, 143588, 143589, 143590, 143591, 143592, 143593, 143594, 143595, 143597, 143598, 143599, 143600, 143601, 143602, 143603, 143604, 143605]\nGP_DEVICE_ID = [1001, 1002] # 1000\nIOS_DEVICE_ID = [2001, 2002] # 2000\nGRANULARIY = [\"weekly\", \"monthly\"]\nNETWORK = [1, 203, 324, 101, 136, 201, 202, 171, 109, 110, 111, 112, 200, 114, 116, 142, 311, 121, 316, 325]\nDATE = ['201501', '201502', '201503', '201504', '201505', '201506', '201507', '201508', '201509', '201510', '201511', '201512', '201601', '201602', '201603', '201604', '201605', '201606', '201607', '201608', '201609', '201610', '201611', '201612', '201701', '201702', '201703', '201704', '201705', '201706', '201707', '201708', '201709', '201710', '201711', '201712', '201801', '201802', '201803', '201804', '201805', '201806', '201807', '201808', '201809', '201810', '201811', '201812', '201901', '201902', '201903', '201904']\n\ndbinfo = {'NAME': 'mkt_est', 'USER': 'app_bdp_usage_qa', 'PASSWORD': '2mHdFW6%#REu', 'HOST': '10.2.6.27', 'PORT': 5433}\ndblist = [('10.2.6.27', 5433), ('10.2.6.245', 5434), ('10.2.6.42', 5435), ('10.2.6.148', 5436), ('10.2.6.49', 5437), ('10.2.6.52', 5438), ('10.2.6.187', 5439), ('10.2.6.254', 5440)]\n\ntime = time.strftime('%Y-%m-%d_%H-%M-%S',time.localtime(time.time()))\nlog_filename = '/tmp/db_{time}.log'.format(time=time)\nprint log_filename\n\ndef select(sql):\n    conn = psycopg2.connect(dbname=dbinfo['NAME'], user=dbinfo['USER'], password=dbinfo['PASSWORD'],host=dbinfo['HOST'], port=dbinfo['PORT'])\n    with closing(conn.cursor()) as cur:\n        cur.execute(sql)\n        rows = cur.fetchall()\n        cnt = cur.rowcount\n    return rows, cnt\n\ndef get_device_store_list():\n    product_list = []\n    for device_id, store_id  in product(GP_DEVICE_ID, GP_COUNTRY_CODE):\n        product_list.append((device_id, store_id))\n    for device_id, store_id in product(IOS_DEVICE_ID, IOS_COUNTRY_CODE):\n        product_list.append((device_id, store_id))\n    print len(product_list)\n    return product_list\n\ndef get_granularity_device_store_list():\n    product_list = []\n    for granularity, device_id, store_id  in product(GRANULARIY, GP_DEVICE_ID, GP_COUNTRY_CODE):\n        product_list.append((granularity, device_id, store_id))\n    for granularity, device_id, store_id in product(GRANULARIY, IOS_DEVICE_ID, IOS_COUNTRY_CODE):\n        product_list.append((granularity, device_id, store_id))\n    print len(product_list)\n    return product_list\n\n\ndef write_to_file(filename, str):\n    with open(filename,'a') as file_object:\n        file_object.write(str)\n\nfor granularity,device_id,store_id in get_granularity_device_store_list():\n    table_name = 'ad_app_pub_estimate'\n    # SQL RESULT\n    result = 0\n    sql_str = \"{granularity}_{table_name}_{device_id}_{store_id}\".format(table_name=table_name, device_id=device_id, store_id=store_id, granularity=granularity)\n    for host, port in dblist:\n        dbinfo['HOST'] = host\n        dbinfo['PORT'] = port\n        try:\n            sql =  \"SELECT count(date) FROM mkt.{sql_str} WHERE date < '2019-05-01'\".format(sql_str=sql_str)\n            # print sql # debug\n            r, _ = select(sql)\n            result += r[0][0]\n            # print result # debug\n        except Exception, e:\n            # print e.message\n            error_result=e.message.replace('\\n', '\\\\n')\n            if \"does not exist\" in error_result:\n                error_result = -1\n    # S3 RESULT\n    s3_result = 0\n    s3_path = \"s3://b2c-prod-data-pipeline-unified-market/unified/app-tech.market.legacy-{table_name}.v1/fact/granularity={granularity}/device_id={device_id}/store_id={store_id}/part-{granularity}-{device_id}-{store_id}.c000.gz.parquet\".format(table_name=table_name,granularity=granularity, device_id=device_id, store_id=store_id)\n    try:\n        s3_result = spark.read.parquet(s3_path).count()\n    except Exception, e:\n        error_s3_result = -1\n\n    result_str = \"{},{},{}\\n\".format(sql_str, result or error_result,s3_result or error_s3_result)\n    write_to_file(log_filename, result_str)\n    # raise Exception"]},{"cell_type":"code","execution_count":0,"id":"20190818-162442_1218212155","metadata":{},"outputs":[],"source":["\n\nfrom itertools import product\nimport datetime\nimport psycopg2\nfrom contextlib import closing\nimport time\n\nGP_COUNTRY_CODE = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 61, 64, 65, 74, 78, 80, 84, 86, 95, 1000]\nIOS_COUNTRY_CODE = [0, 143441, 143442, 143443, 143444, 143445, 143446, 143447, 143448, 143449, 143450, 143451, 143452, 143453, 143454, 143455, 143456, 143457, 143458, 143459, 143460, 143461, 143462, 143463, 143464, 143465, 143466, 143467, 143468, 143469, 143470, 143471, 143472, 143473, 143474, 143475, 143476, 143477, 143478, 143479, 143480, 143481, 143482, 143483, 143484, 143485, 143486, 143487, 143489, 143491, 143492, 143493, 143494, 143495, 143496, 143497, 143498, 143499, 143501, 143502, 143503, 143504, 143505, 143506, 143507, 143508, 143509, 143510, 143511, 143512, 143513, 143514, 143515, 143516, 143517, 143518, 143519, 143520, 143521, 143523, 143524, 143525, 143526, 143528, 143529, 143530, 143531, 143532, 143533, 143534, 143535, 143536, 143537, 143538, 143539, 143540, 143541, 143542, 143543, 143544, 143545, 143546, 143547, 143548, 143549, 143550, 143551, 143552, 143553, 143554, 143555, 143556, 143557, 143558, 143559, 143560, 143561, 143562, 143563, 143564, 143565, 143566, 143568, 143571, 143572, 143573, 143575, 143576, 143577, 143578, 143579, 143580, 143581, 143582, 143583, 143584, 143585, 143586, 143587, 143588, 143589, 143590, 143591, 143592, 143593, 143594, 143595, 143597, 143598, 143599, 143600, 143601, 143602, 143603, 143604, 143605]\nGP_DEVICE_ID = [1001, 1002] # 1000\nIOS_DEVICE_ID = [2001, 2002] # 2000\nGRANULARIY = [\"weekly\", \"monthly\"]\nNETWORK = [1, 203, 324, 101, 136, 201, 202, 171, 109, 110, 111, 112, 200, 114, 116, 142, 311, 121, 316, 325]\nDATE = ['201501', '201502', '201503', '201504', '201505', '201506', '201507', '201508', '201509', '201510', '201511', '201512', '201601', '201602', '201603', '201604', '201605', '201606', '201607', '201608', '201609', '201610', '201611', '201612', '201701', '201702', '201703', '201704', '201705', '201706', '201707', '201708', '201709', '201710', '201711', '201712', '201801', '201802', '201803', '201804', '201805', '201806', '201807', '201808', '201809', '201810', '201811', '201812', '201901', '201902', '201903', '201904']\n\ndbinfo = {'NAME': 'mkt_est', 'USER': 'app_bdp_usage_qa', 'PASSWORD': '2mHdFW6%#REu', 'HOST': '10.2.6.27', 'PORT': 5433}\ndblist = [('10.2.6.27', 5433), ('10.2.6.245', 5434), ('10.2.6.42', 5435), ('10.2.6.148', 5436), ('10.2.6.49', 5437), ('10.2.6.52', 5438), ('10.2.6.187', 5439), ('10.2.6.254', 5440)]\n\ntime = time.strftime('%Y-%m-%d_%H-%M-%S',time.localtime(time.time()))\nlog_filename = '/tmp/db_{time}.log'.format(time=time)\nprint log_filename\n\ndef select(sql):\n    conn = psycopg2.connect(dbname=dbinfo['NAME'], user=dbinfo['USER'], password=dbinfo['PASSWORD'],host=dbinfo['HOST'], port=dbinfo['PORT'])\n    with closing(conn.cursor()) as cur:\n        cur.execute(sql)\n        rows = cur.fetchall()\n        cnt = cur.rowcount\n    return rows, cnt\n\ndef get_device_store_list():\n    product_list = []\n    for device_id, store_id  in product(GP_DEVICE_ID, GP_COUNTRY_CODE):\n        product_list.append((device_id, store_id))\n    for device_id, store_id in product(IOS_DEVICE_ID, IOS_COUNTRY_CODE):\n        product_list.append((device_id, store_id))\n    print len(product_list)\n    return product_list\n\ndef get_granularity_device_store_list():\n    product_list = []\n    for granularity, device_id, store_id  in product(GRANULARIY, GP_DEVICE_ID, GP_COUNTRY_CODE):\n        product_list.append((granularity, device_id, store_id))\n    for granularity, device_id, store_id in product(GRANULARIY, IOS_DEVICE_ID, IOS_COUNTRY_CODE):\n        product_list.append((granularity, device_id, store_id))\n    print len(product_list)\n    return product_list\n\n\ndef write_to_file(filename, str):\n    with open(filename,'a') as file_object:\n        file_object.write(str)\n\nfor granularity,device_id,store_id in get_granularity_device_store_list():\n    table_name = 'pub_app_estimate'\n    # SQL RESULT\n    result = 0\n    sql_str = \"{granularity}_{table_name}_{device_id}_{store_id}\".format(table_name=table_name, device_id=device_id, store_id=store_id, granularity=granularity)\n    for host, port in dblist:\n        dbinfo['HOST'] = host\n        dbinfo['PORT'] = port\n        try:\n            sql =  \"SELECT count(date) FROM mkt.{sql_str} WHERE date < '2019-05-01'\".format(sql_str=sql_str)\n            # print sql # debug\n            r, _ = select(sql)\n            result += r[0][0]\n            # print result # debug\n        except Exception, e:\n            # print e.message\n            error_result=e.message.replace('\\n', '\\\\n')\n            if \"does not exist\" in error_result:\n                error_result = -1\n    # S3 RESULT\n    s3_result = 0\n    s3_path = \"s3://b2c-prod-data-pipeline-unified-market/unified/app-tech.market.legacy-{table_name}.v1/fact/granularity={granularity}/device_id={device_id}/store_id={store_id}/part-{granularity}-{device_id}-{store_id}.c000.gz.parquet\".format(table_name=table_name,granularity=granularity, device_id=device_id, store_id=store_id)\n    try:\n        s3_result = spark.read.parquet(s3_path).count()\n    except Exception, e:\n        error_s3_result = -1\n\n    result_str = \"{},{},{}\\n\".format(sql_str, result or error_result,s3_result or error_s3_result)\n    write_to_file(log_filename, result_str)\n    # raise Exception"]},{"cell_type":"code","execution_count":0,"id":"20190818-162708_1451865627","metadata":{},"outputs":[],"source":["\n\nfrom itertools import product\nimport datetime\nimport psycopg2\nfrom contextlib import closing\nimport time\n\nGP_COUNTRY_CODE = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 61, 64, 65, 74, 78, 80, 84, 86, 95, 1000]\nIOS_COUNTRY_CODE = [0, 143441, 143442, 143443, 143444, 143445, 143446, 143447, 143448, 143449, 143450, 143451, 143452, 143453, 143454, 143455, 143456, 143457, 143458, 143459, 143460, 143461, 143462, 143463, 143464, 143465, 143466, 143467, 143468, 143469, 143470, 143471, 143472, 143473, 143474, 143475, 143476, 143477, 143478, 143479, 143480, 143481, 143482, 143483, 143484, 143485, 143486, 143487, 143489, 143491, 143492, 143493, 143494, 143495, 143496, 143497, 143498, 143499, 143501, 143502, 143503, 143504, 143505, 143506, 143507, 143508, 143509, 143510, 143511, 143512, 143513, 143514, 143515, 143516, 143517, 143518, 143519, 143520, 143521, 143523, 143524, 143525, 143526, 143528, 143529, 143530, 143531, 143532, 143533, 143534, 143535, 143536, 143537, 143538, 143539, 143540, 143541, 143542, 143543, 143544, 143545, 143546, 143547, 143548, 143549, 143550, 143551, 143552, 143553, 143554, 143555, 143556, 143557, 143558, 143559, 143560, 143561, 143562, 143563, 143564, 143565, 143566, 143568, 143571, 143572, 143573, 143575, 143576, 143577, 143578, 143579, 143580, 143581, 143582, 143583, 143584, 143585, 143586, 143587, 143588, 143589, 143590, 143591, 143592, 143593, 143594, 143595, 143597, 143598, 143599, 143600, 143601, 143602, 143603, 143604, 143605]\nGP_DEVICE_ID = [1001, 1002] # 1000\nIOS_DEVICE_ID = [2001, 2002] # 2000\nGRANULARIY = [\"weekly\", \"monthly\"]\nNETWORK = [1, 203, 324, 101, 136, 201, 202, 171, 109, 110, 111, 112, 200, 114, 116, 142, 311, 121, 316, 325]\nDATE = ['201501', '201502', '201503', '201504', '201505', '201506', '201507', '201508', '201509', '201510', '201511', '201512', '201601', '201602', '201603', '201604', '201605', '201606', '201607', '201608', '201609', '201610', '201611', '201612', '201701', '201702', '201703', '201704', '201705', '201706', '201707', '201708', '201709', '201710', '201711', '201712', '201801', '201802', '201803', '201804', '201805', '201806', '201807', '201808', '201809', '201810', '201811', '201812', '201901', '201902', '201903', '201904']\n\ndbinfo = {'NAME': 'mkt_est', 'USER': 'app_bdp_usage_qa', 'PASSWORD': '2mHdFW6%#REu', 'HOST': '10.2.6.27', 'PORT': 5433}\ndblist = [('10.2.6.27', 5433), ('10.2.6.245', 5434), ('10.2.6.42', 5435), ('10.2.6.148', 5436), ('10.2.6.49', 5437), ('10.2.6.52', 5438), ('10.2.6.187', 5439), ('10.2.6.254', 5440)]\n\ntime = time.strftime('%Y-%m-%d_%H-%M-%S',time.localtime(time.time()))\nlog_filename = '/tmp/db_{time}.log'.format(time=time)\nprint log_filename\n\ndef select(sql):\n    conn = psycopg2.connect(dbname=dbinfo['NAME'], user=dbinfo['USER'], password=dbinfo['PASSWORD'],host=dbinfo['HOST'], port=dbinfo['PORT'])\n    with closing(conn.cursor()) as cur:\n        cur.execute(sql)\n        rows = cur.fetchall()\n        cnt = cur.rowcount\n    return rows, cnt\n\ndef get_device_store_list():\n    product_list = []\n    for device_id, store_id  in product(GP_DEVICE_ID, GP_COUNTRY_CODE):\n        product_list.append((device_id, store_id))\n    for device_id, store_id in product(IOS_DEVICE_ID, IOS_COUNTRY_CODE):\n        product_list.append((device_id, store_id))\n    print len(product_list)\n    return product_list\n\ndef get_granularity_device_store_list():\n    product_list = []\n    for granularity, device_id, store_id  in product(GRANULARIY, GP_DEVICE_ID, GP_COUNTRY_CODE):\n        product_list.append((granularity, device_id, store_id))\n    for granularity, device_id, store_id in product(GRANULARIY, IOS_DEVICE_ID, IOS_COUNTRY_CODE):\n        product_list.append((granularity, device_id, store_id))\n    print len(product_list)\n    return product_list\n\n\ndef write_to_file(filename, str):\n    with open(filename,'a') as file_object:\n        file_object.write(str)\n\nfor granularity,device_id,store_id in get_granularity_device_store_list():\n    table_name = 'pub_app_detail_estimate'\n    # SQL RESULT\n    result = 0\n    sql_str = \"{granularity}_{table_name}_{device_id}_{store_id}\".format(table_name=table_name, device_id=device_id, store_id=store_id, granularity=granularity)\n    for host, port in dblist:\n        dbinfo['HOST'] = host\n        dbinfo['PORT'] = port\n        try:\n            sql =  \"SELECT count(date) FROM mkt.{sql_str} WHERE date < '2019-05-01'\".format(sql_str=sql_str)\n            # print sql # debug\n            r, _ = select(sql)\n            result += r[0][0]\n            # print result # debug\n        except Exception, e:\n            # print e.message\n            error_result=e.message.replace('\\n', '\\\\n')\n            if \"does not exist\" in error_result:\n                error_result = -1\n    # S3 RESULT\n    s3_result = 0\n    s3_path = \"s3://b2c-prod-data-pipeline-unified-market/unified/app-tech.market.legacy-{table_name}.v1/fact/granularity={granularity}/device_id={device_id}/store_id={store_id}/part-{granularity}-{device_id}-{store_id}.c000.gz.parquet\".format(table_name=table_name,granularity=granularity, device_id=device_id, store_id=store_id)\n    try:\n        s3_result = spark.read.parquet(s3_path).count()\n    except Exception, e:\n        error_s3_result = -1\n\n    result_str = \"{},{},{}\\n\".format(sql_str, result or error_result,s3_result or error_s3_result)\n    write_to_file(log_filename, result_str)\n    # raise Exception"]},{"cell_type":"code","execution_count":0,"id":"20190818-162558_1416988630","metadata":{},"outputs":[],"source":["\n\nfrom itertools import product\nimport datetime\nimport psycopg2\nfrom contextlib import closing\nimport time\n\nGP_COUNTRY_CODE = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 61, 64, 65, 74, 78, 80, 84, 86, 95, 1000]\nIOS_COUNTRY_CODE = [0, 143441, 143442, 143443, 143444, 143445, 143446, 143447, 143448, 143449, 143450, 143451, 143452, 143453, 143454, 143455, 143456, 143457, 143458, 143459, 143460, 143461, 143462, 143463, 143464, 143465, 143466, 143467, 143468, 143469, 143470, 143471, 143472, 143473, 143474, 143475, 143476, 143477, 143478, 143479, 143480, 143481, 143482, 143483, 143484, 143485, 143486, 143487, 143489, 143491, 143492, 143493, 143494, 143495, 143496, 143497, 143498, 143499, 143501, 143502, 143503, 143504, 143505, 143506, 143507, 143508, 143509, 143510, 143511, 143512, 143513, 143514, 143515, 143516, 143517, 143518, 143519, 143520, 143521, 143523, 143524, 143525, 143526, 143528, 143529, 143530, 143531, 143532, 143533, 143534, 143535, 143536, 143537, 143538, 143539, 143540, 143541, 143542, 143543, 143544, 143545, 143546, 143547, 143548, 143549, 143550, 143551, 143552, 143553, 143554, 143555, 143556, 143557, 143558, 143559, 143560, 143561, 143562, 143563, 143564, 143565, 143566, 143568, 143571, 143572, 143573, 143575, 143576, 143577, 143578, 143579, 143580, 143581, 143582, 143583, 143584, 143585, 143586, 143587, 143588, 143589, 143590, 143591, 143592, 143593, 143594, 143595, 143597, 143598, 143599, 143600, 143601, 143602, 143603, 143604, 143605]\nGP_DEVICE_ID = [1001, 1002] # 1000\nIOS_DEVICE_ID = [2001, 2002] # 2000\nGRANULARIY = [\"weekly\", \"monthly\"]\nNETWORK = [1, 203, 324, 101, 136, 201, 202, 171, 109, 110, 111, 112, 200, 114, 116, 142, 311, 121, 316, 325]\nDATE = ['201501', '201502', '201503', '201504', '201505', '201506', '201507', '201508', '201509', '201510', '201511', '201512', '201601', '201602', '201603', '201604', '201605', '201606', '201607', '201608', '201609', '201610', '201611', '201612', '201701', '201702', '201703', '201704', '201705', '201706', '201707', '201708', '201709', '201710', '201711', '201712', '201801', '201802', '201803', '201804', '201805', '201806', '201807', '201808', '201809', '201810', '201811', '201812', '201901', '201902', '201903', '201904']\n\ndbinfo = {'NAME': 'mkt_est', 'USER': 'app_bdp_usage_qa', 'PASSWORD': '2mHdFW6%#REu', 'HOST': '10.2.6.27', 'PORT': 5433}\ndblist = [('10.2.6.27', 5433), ('10.2.6.245', 5434), ('10.2.6.42', 5435), ('10.2.6.148', 5436), ('10.2.6.49', 5437), ('10.2.6.52', 5438), ('10.2.6.187', 5439), ('10.2.6.254', 5440)]\n\ntime = time.strftime('%Y-%m-%d_%H-%M-%S',time.localtime(time.time()))\nlog_filename = '/tmp/db_{time}.log'.format(time=time)\nprint log_filename\n\ndef select(sql):\n    conn = psycopg2.connect(dbname=dbinfo['NAME'], user=dbinfo['USER'], password=dbinfo['PASSWORD'],host=dbinfo['HOST'], port=dbinfo['PORT'])\n    with closing(conn.cursor()) as cur:\n        cur.execute(sql)\n        rows = cur.fetchall()\n        cnt = cur.rowcount\n    return rows, cnt\n\ndef get_device_store_list():\n    product_list = []\n    for device_id, store_id  in product(GP_DEVICE_ID, GP_COUNTRY_CODE):\n        product_list.append((device_id, store_id))\n    for device_id, store_id in product(IOS_DEVICE_ID, IOS_COUNTRY_CODE):\n        product_list.append((device_id, store_id))\n    print len(product_list)\n    return product_list\n\ndef get_granularity_device_store_list():\n    product_list = []\n    for granularity, device_id, store_id  in product(GRANULARIY, GP_DEVICE_ID, GP_COUNTRY_CODE):\n        product_list.append((granularity, device_id, store_id))\n    for granularity, device_id, store_id in product(GRANULARIY, IOS_DEVICE_ID, IOS_COUNTRY_CODE):\n        product_list.append((granularity, device_id, store_id))\n    print len(product_list)\n    return product_list\n\n\ndef write_to_file(filename, str):\n    with open(filename,'a') as file_object:\n        file_object.write(str)\n\nfor granularity,device_id,store_id in get_granularity_device_store_list():\n    table_name = 'creative_category'\n    # SQL RESULT\n    result = 0\n    sql_str = \"{granularity}_{table_name}_{device_id}_{store_id}\".format(table_name=table_name, device_id=device_id, store_id=store_id, granularity=granularity)\n    for host, port in dblist:\n        dbinfo['HOST'] = host\n        dbinfo['PORT'] = port\n        try:\n            sql =  \"SELECT count(date) FROM mkt.{sql_str} WHERE date < '2019-05-01'\".format(sql_str=sql_str)\n            # print sql # debug\n            r, _ = select(sql)\n            result += r[0][0]\n            # print result # debug\n        except Exception, e:\n            # print e.message\n            error_result=e.message.replace('\\n', '\\\\n')\n            if \"does not exist\" in error_result:\n                error_result = -1\n    # S3 RESULT\n    s3_result = 0\n    s3_path = \"s3://b2c-prod-data-pipeline-unified-market/unified/app-tech.market.legacy-{table_name}.v1/fact/granularity={granularity}/device_id={device_id}/store_id={store_id}/part-{granularity}-{device_id}-{store_id}.c000.gz.parquet\".format(table_name=table_name,granularity=granularity, device_id=device_id, store_id=store_id)\n    try:\n        s3_result = spark.read.parquet(s3_path).count()\n    except Exception, e:\n        error_s3_result = -1\n\n    result_str = \"{},{},{}\\n\".format(sql_str, result or error_result,s3_result or error_s3_result)\n    write_to_file(log_filename, result_str)\n    # raise Exception"]},{"cell_type":"code","execution_count":0,"id":"20190818-163048_1457982698","metadata":{},"outputs":[],"source":["\n\nfrom itertools import product\nimport datetime\nimport psycopg2\nfrom contextlib import closing\nimport time\n\nGP_COUNTRY_CODE = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 61, 64, 65, 74, 78, 80, 84, 86, 95, 1000]\nIOS_COUNTRY_CODE = [0, 143441, 143442, 143443, 143444, 143445, 143446, 143447, 143448, 143449, 143450, 143451, 143452, 143453, 143454, 143455, 143456, 143457, 143458, 143459, 143460, 143461, 143462, 143463, 143464, 143465, 143466, 143467, 143468, 143469, 143470, 143471, 143472, 143473, 143474, 143475, 143476, 143477, 143478, 143479, 143480, 143481, 143482, 143483, 143484, 143485, 143486, 143487, 143489, 143491, 143492, 143493, 143494, 143495, 143496, 143497, 143498, 143499, 143501, 143502, 143503, 143504, 143505, 143506, 143507, 143508, 143509, 143510, 143511, 143512, 143513, 143514, 143515, 143516, 143517, 143518, 143519, 143520, 143521, 143523, 143524, 143525, 143526, 143528, 143529, 143530, 143531, 143532, 143533, 143534, 143535, 143536, 143537, 143538, 143539, 143540, 143541, 143542, 143543, 143544, 143545, 143546, 143547, 143548, 143549, 143550, 143551, 143552, 143553, 143554, 143555, 143556, 143557, 143558, 143559, 143560, 143561, 143562, 143563, 143564, 143565, 143566, 143568, 143571, 143572, 143573, 143575, 143576, 143577, 143578, 143579, 143580, 143581, 143582, 143583, 143584, 143585, 143586, 143587, 143588, 143589, 143590, 143591, 143592, 143593, 143594, 143595, 143597, 143598, 143599, 143600, 143601, 143602, 143603, 143604, 143605]\nGP_DEVICE_ID = [1001, 1002] # 1000\nIOS_DEVICE_ID = [2001, 2002] # 2000\nGRANULARIY = [\"weekly\", \"monthly\"]\nNETWORK = [1, 203, 324, 101, 136, 201, 202, 171, 109, 110, 111, 112, 200, 114, 116, 142, 311, 121, 316, 325]\nDATE = ['201501', '201502', '201503', '201504', '201505', '201506', '201507', '201508', '201509', '201510', '201511', '201512', '201601', '201602', '201603', '201604', '201605', '201606', '201607', '201608', '201609', '201610', '201611', '201612', '201701', '201702', '201703', '201704', '201705', '201706', '201707', '201708', '201709', '201710', '201711', '201712', '201801', '201802', '201803', '201804', '201805', '201806', '201807', '201808', '201809', '201810', '201811', '201812', '201901', '201902', '201903', '201904']\n\ndbinfo = {'NAME': 'mkt_est', 'USER': 'app_bdp_usage_qa', 'PASSWORD': '2mHdFW6%#REu', 'HOST': '10.2.6.27', 'PORT': 5433}\ndblist = [('10.2.6.27', 5433), ('10.2.6.245', 5434), ('10.2.6.42', 5435), ('10.2.6.148', 5436), ('10.2.6.49', 5437), ('10.2.6.52', 5438), ('10.2.6.187', 5439), ('10.2.6.254', 5440)]\n\ntime = time.strftime('%Y-%m-%d_%H-%M-%S',time.localtime(time.time()))\nlog_filename = '/tmp/db_{time}.log'.format(time=time)\nprint log_filename\n\ndef select(sql):\n    conn = psycopg2.connect(dbname=dbinfo['NAME'], user=dbinfo['USER'], password=dbinfo['PASSWORD'],host=dbinfo['HOST'], port=dbinfo['PORT'])\n    with closing(conn.cursor()) as cur:\n        cur.execute(sql)\n        rows = cur.fetchall()\n        cnt = cur.rowcount\n    return rows, cnt\n\ndef get_device_store_list():\n    product_list = []\n    for device_id, store_id  in product(GP_DEVICE_ID, GP_COUNTRY_CODE):\n        product_list.append((device_id, store_id))\n    for device_id, store_id in product(IOS_DEVICE_ID, IOS_COUNTRY_CODE):\n        product_list.append((device_id, store_id))\n    print len(product_list)\n    return product_list\n\ndef get_granularity_device_store_list():\n    product_list = []\n    for granularity, device_id, store_id  in product(GRANULARIY, GP_DEVICE_ID, GP_COUNTRY_CODE):\n        product_list.append((granularity, device_id, store_id))\n    for granularity, device_id, store_id in product(GRANULARIY, IOS_DEVICE_ID, IOS_COUNTRY_CODE):\n        product_list.append((granularity, device_id, store_id))\n    print len(product_list)\n    return product_list\n\n\ndef write_to_file(filename, str):\n    with open(filename,'a') as file_object:\n        file_object.write(str)\n\nfor granularity,device_id,store_id in get_granularity_device_store_list():\n    table_name = 'ad_app_category'\n    # SQL RESULT\n    result = 0\n    sql_str = \"{granularity}_{table_name}_{device_id}_{store_id}\".format(table_name=table_name, device_id=device_id, store_id=store_id, granularity=granularity)\n    for host, port in dblist:\n        dbinfo['HOST'] = host\n        dbinfo['PORT'] = port\n        try:\n            sql =  \"SELECT count(date) FROM mkt.{sql_str} WHERE date < '2019-05-01'\".format(sql_str=sql_str)\n            # print sql # debug\n            r, _ = select(sql)\n            result += r[0][0]\n            # print result # debug\n        except Exception, e:\n            # print e.message\n            error_result=e.message.replace('\\n', '\\\\n')\n            if \"does not exist\" in error_result:\n                error_result = -1\n    # S3 RESULT\n    s3_result = 0\n    s3_path = \"s3://b2c-prod-data-pipeline-unified-market/unified/app-tech.market.legacy-{table_name}.v1/fact/granularity={granularity}/device_id={device_id}/store_id={store_id}/part-{granularity}-{device_id}-{store_id}.c000.gz.parquet\".format(table_name=table_name,granularity=granularity, device_id=device_id, store_id=store_id)\n    try:\n        s3_result = spark.read.parquet(s3_path).count()\n    except Exception, e:\n        error_s3_result = -1\n\n    result_str = \"{},{},{}\\n\".format(sql_str, result or error_result,s3_result or error_s3_result)\n    write_to_file(log_filename, result_str)\n    # raise Exception"]},{"cell_type":"code","execution_count":0,"id":"20190818-163128_1732491209","metadata":{},"outputs":[],"source":["\n\nfrom itertools import product\nimport datetime\nimport psycopg2\nfrom contextlib import closing\nimport time\n\nGP_COUNTRY_CODE = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 61, 64, 65, 74, 78, 80, 84, 86, 95, 1000]\nIOS_COUNTRY_CODE = [0, 143441, 143442, 143443, 143444, 143445, 143446, 143447, 143448, 143449, 143450, 143451, 143452, 143453, 143454, 143455, 143456, 143457, 143458, 143459, 143460, 143461, 143462, 143463, 143464, 143465, 143466, 143467, 143468, 143469, 143470, 143471, 143472, 143473, 143474, 143475, 143476, 143477, 143478, 143479, 143480, 143481, 143482, 143483, 143484, 143485, 143486, 143487, 143489, 143491, 143492, 143493, 143494, 143495, 143496, 143497, 143498, 143499, 143501, 143502, 143503, 143504, 143505, 143506, 143507, 143508, 143509, 143510, 143511, 143512, 143513, 143514, 143515, 143516, 143517, 143518, 143519, 143520, 143521, 143523, 143524, 143525, 143526, 143528, 143529, 143530, 143531, 143532, 143533, 143534, 143535, 143536, 143537, 143538, 143539, 143540, 143541, 143542, 143543, 143544, 143545, 143546, 143547, 143548, 143549, 143550, 143551, 143552, 143553, 143554, 143555, 143556, 143557, 143558, 143559, 143560, 143561, 143562, 143563, 143564, 143565, 143566, 143568, 143571, 143572, 143573, 143575, 143576, 143577, 143578, 143579, 143580, 143581, 143582, 143583, 143584, 143585, 143586, 143587, 143588, 143589, 143590, 143591, 143592, 143593, 143594, 143595, 143597, 143598, 143599, 143600, 143601, 143602, 143603, 143604, 143605]\nGP_DEVICE_ID = [1001, 1002] # 1000\nIOS_DEVICE_ID = [2001, 2002] # 2000\nGRANULARIY = [\"weekly\", \"monthly\"]\nNETWORK = [1, 203, 324, 101, 136, 201, 202, 171, 109, 110, 111, 112, 200, 114, 116, 142, 311, 121, 316, 325]\nDATE = ['201501', '201502', '201503', '201504', '201505', '201506', '201507', '201508', '201509', '201510', '201511', '201512', '201601', '201602', '201603', '201604', '201605', '201606', '201607', '201608', '201609', '201610', '201611', '201612', '201701', '201702', '201703', '201704', '201705', '201706', '201707', '201708', '201709', '201710', '201711', '201712', '201801', '201802', '201803', '201804', '201805', '201806', '201807', '201808', '201809', '201810', '201811', '201812', '201901', '201902', '201903', '201904']\n\ndbinfo = {'NAME': 'mkt_est', 'USER': 'app_bdp_usage_qa', 'PASSWORD': '2mHdFW6%#REu', 'HOST': '10.2.6.27', 'PORT': 5433}\ndblist = [('10.2.6.27', 5433), ('10.2.6.245', 5434), ('10.2.6.42', 5435), ('10.2.6.148', 5436), ('10.2.6.49', 5437), ('10.2.6.52', 5438), ('10.2.6.187', 5439), ('10.2.6.254', 5440)]\n\ntime = time.strftime('%Y-%m-%d_%H-%M-%S',time.localtime(time.time()))\nlog_filename = '/tmp/db_{time}.log'.format(time=time)\nprint log_filename\n\ndef select(sql):\n    conn = psycopg2.connect(dbname=dbinfo['NAME'], user=dbinfo['USER'], password=dbinfo['PASSWORD'],host=dbinfo['HOST'], port=dbinfo['PORT'])\n    with closing(conn.cursor()) as cur:\n        cur.execute(sql)\n        rows = cur.fetchall()\n        cnt = cur.rowcount\n    return rows, cnt\n\ndef get_device_store_list():\n    product_list = []\n    for device_id, store_id  in product(GP_DEVICE_ID, GP_COUNTRY_CODE):\n        product_list.append((device_id, store_id))\n    for device_id, store_id in product(IOS_DEVICE_ID, IOS_COUNTRY_CODE):\n        product_list.append((device_id, store_id))\n    print len(product_list)\n    return product_list\n\ndef get_granularity_device_store_list():\n    product_list = []\n    for granularity, device_id, store_id  in product(GRANULARIY, GP_DEVICE_ID, GP_COUNTRY_CODE):\n        product_list.append((granularity, device_id, store_id))\n    for granularity, device_id, store_id in product(GRANULARIY, IOS_DEVICE_ID, IOS_COUNTRY_CODE):\n        product_list.append((granularity, device_id, store_id))\n    print len(product_list)\n    return product_list\n\n\ndef write_to_file(filename, str):\n    with open(filename,'a') as file_object:\n        file_object.write(str)\n\nfor granularity,device_id,store_id in get_granularity_device_store_list():\n    table_name = 'pub_app_category'\n    # SQL RESULT\n    result = 0\n    sql_str = \"{granularity}_{table_name}_{device_id}_{store_id}\".format(table_name=table_name, device_id=device_id, store_id=store_id, granularity=granularity)\n    for host, port in dblist:\n        dbinfo['HOST'] = host\n        dbinfo['PORT'] = port\n        try:\n            sql =  \"SELECT count(date) FROM mkt.{sql_str} WHERE date < '2019-05-01'\".format(sql_str=sql_str)\n            # print sql # debug\n            r, _ = select(sql)\n            result += r[0][0]\n            # print result # debug\n        except Exception, e:\n            # print e.message\n            error_result=e.message.replace('\\n', '\\\\n')\n            if \"does not exist\" in error_result:\n                error_result = -1\n    # S3 RESULT\n    s3_result = 0\n    s3_path = \"s3://b2c-prod-data-pipeline-unified-market/unified/app-tech.market.legacy-{table_name}.v1/fact/granularity={granularity}/device_id={device_id}/store_id={store_id}/part-{granularity}-{device_id}-{store_id}.c000.gz.parquet\".format(table_name=table_name,granularity=granularity, device_id=device_id, store_id=store_id)\n    try:\n        s3_result = spark.read.parquet(s3_path).count()\n    except Exception, e:\n        error_s3_result = -1\n\n    result_str = \"{},{},{}\\n\".format(sql_str, result or error_result,s3_result or error_s3_result)\n    write_to_file(log_filename, result_str)\n    # raise Exception"]},{"cell_type":"code","execution_count":0,"id":"20190818-163231_937281857","metadata":{},"outputs":[],"source":["\n\nfrom itertools import product\nimport datetime\nimport psycopg2\nfrom contextlib import closing\nimport time\n\nGP_COUNTRY_CODE = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 61, 64, 65, 74, 78, 80, 84, 86, 95, 1000]\nIOS_COUNTRY_CODE = [0, 143441, 143442, 143443, 143444, 143445, 143446, 143447, 143448, 143449, 143450, 143451, 143452, 143453, 143454, 143455, 143456, 143457, 143458, 143459, 143460, 143461, 143462, 143463, 143464, 143465, 143466, 143467, 143468, 143469, 143470, 143471, 143472, 143473, 143474, 143475, 143476, 143477, 143478, 143479, 143480, 143481, 143482, 143483, 143484, 143485, 143486, 143487, 143489, 143491, 143492, 143493, 143494, 143495, 143496, 143497, 143498, 143499, 143501, 143502, 143503, 143504, 143505, 143506, 143507, 143508, 143509, 143510, 143511, 143512, 143513, 143514, 143515, 143516, 143517, 143518, 143519, 143520, 143521, 143523, 143524, 143525, 143526, 143528, 143529, 143530, 143531, 143532, 143533, 143534, 143535, 143536, 143537, 143538, 143539, 143540, 143541, 143542, 143543, 143544, 143545, 143546, 143547, 143548, 143549, 143550, 143551, 143552, 143553, 143554, 143555, 143556, 143557, 143558, 143559, 143560, 143561, 143562, 143563, 143564, 143565, 143566, 143568, 143571, 143572, 143573, 143575, 143576, 143577, 143578, 143579, 143580, 143581, 143582, 143583, 143584, 143585, 143586, 143587, 143588, 143589, 143590, 143591, 143592, 143593, 143594, 143595, 143597, 143598, 143599, 143600, 143601, 143602, 143603, 143604, 143605]\nGP_DEVICE_ID = [1000] # 1000\nIOS_DEVICE_ID = [2000] # 2000\nGRANULARIY = [\"monthly\",\"weekly\"]\nNETWORK = [1, 203, 324, 101, 136, 201, 202, 171, 109, 110, 111, 112, 200, 114, 116, 142, 311, 121, 316, 325]\nDATE = ['201501', '201502', '201503', '201504', '201505', '201506', '201507', '201508', '201509', '201510', '201511', '201512', '201601', '201602', '201603', '201604', '201605', '201606', '201607', '201608', '201609', '201610', '201611', '201612', '201701', '201702', '201703', '201704', '201705', '201706', '201707', '201708', '201709', '201710', '201711', '201712', '201801', '201802', '201803', '201804', '201805', '201806', '201807', '201808', '201809', '201810', '201811', '201812', '201901', '201902', '201903', '201904']\n\ndbinfo = {'NAME': 'mkt_est', 'USER': 'app_bdp_usage_qa', 'PASSWORD': '2mHdFW6%#REu', 'HOST': '10.2.6.27', 'PORT': 5433}\ndblist = [('10.2.6.27', 5433), ('10.2.6.245', 5434), ('10.2.6.42', 5435), ('10.2.6.148', 5436), ('10.2.6.49', 5437), ('10.2.6.52', 5438), ('10.2.6.187', 5439), ('10.2.6.254', 5440)]\n\ntime = time.strftime('%Y-%m-%d_%H-%M-%S',time.localtime(time.time()))\nlog_filename = '/tmp/db_{time}.log'.format(time=time)\nprint log_filename\n\ndef select(sql):\n    conn = psycopg2.connect(dbname=dbinfo['NAME'], user=dbinfo['USER'], password=dbinfo['PASSWORD'],host=dbinfo['HOST'], port=dbinfo['PORT'])\n    with closing(conn.cursor()) as cur:\n        cur.execute(sql)\n        rows = cur.fetchall()\n        cnt = cur.rowcount\n    return rows, cnt\n\ndef get_device_store_list():\n    product_list = []\n    for device_id, store_id  in product(GP_DEVICE_ID, GP_COUNTRY_CODE):\n        product_list.append((device_id, store_id))\n    for device_id, store_id in product(IOS_DEVICE_ID, IOS_COUNTRY_CODE):\n        product_list.append((device_id, store_id))\n    print len(product_list)\n    return product_list\n\ndef get_granularity_device_store_list():\n    product_list = []\n    for granularity, device_id, store_id  in product(GRANULARIY, GP_DEVICE_ID, GP_COUNTRY_CODE):\n        product_list.append((granularity, device_id, store_id))\n    for granularity, device_id, store_id in product(GRANULARIY, IOS_DEVICE_ID, IOS_COUNTRY_CODE):\n        product_list.append((granularity, device_id, store_id))\n    print len(product_list)\n    return product_list\n\ndef get_granularity_device_list():\n    product_list = []\n    for granularity, device_id  in product(GRANULARIY, GP_DEVICE_ID):\n        product_list.append((granularity, device_id))\n    for granularity, device_id in product(GRANULARIY, IOS_DEVICE_ID):\n        product_list.append((granularity, device_id))\n    print len(product_list)\n    return product_list\n\n\ndef write_to_file(filename, str):\n    with open(filename,'a') as file_object:\n        file_object.write(str)\n\nfor granularity,device_id in get_granularity_device_list():\n    table_name = 'adpo_estimate'\n    # SQL RESULT\n    result = 0\n    sql_str = \"{granularity}_{table_name}_{device_id}\".format(table_name=table_name, device_id=device_id, granularity=granularity)\n    for host, port in dblist:\n        dbinfo['HOST'] = host\n        dbinfo['PORT'] = port\n        try:\n            sql =  \"SELECT count(date) FROM mkt.{sql_str} WHERE date < '2019-05-01'\".format(sql_str=sql_str)\n            # print sql # debug\n            r, _ = select(sql)\n            result += r[0][0]\n            # print result # debug\n        except Exception, e:\n            # print e.message\n            error_result=e.message.replace('\\n', '\\\\n')\n            if \"does not exist\" in error_result:\n                error_result = -1\n    # S3 RESULT\n    s3_result = 0\n    s3_path = \"s3://b2c-prod-data-pipeline-unified-market/unified/app-tech.market.legacy-{table_name}.v1/fact/granularity={granularity}/device_id={device_id}/\".format(table_name=table_name,granularity=granularity, device_id=device_id)\n    try:\n        s3_result = spark.read.parquet(s3_path).count()\n    except Exception, e:\n        error_s3_result = -1\n\n    result_str = \"{},{},{}\\n\".format(sql_str, result or error_result,s3_result or error_s3_result)\n    write_to_file(log_filename, result_str)\n    # raise Exception"]},{"cell_type":"code","execution_count":0,"id":"20190818-163233_765220451","metadata":{},"outputs":[],"source":["\n\nfrom itertools import product\nimport datetime\nimport psycopg2\nfrom contextlib import closing\nimport time\n\nGP_COUNTRY_CODE = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 61, 64, 65, 74, 78, 80, 84, 86, 95, 1000]\nIOS_COUNTRY_CODE = [0, 143441, 143442, 143443, 143444, 143445, 143446, 143447, 143448, 143449, 143450, 143451, 143452, 143453, 143454, 143455, 143456, 143457, 143458, 143459, 143460, 143461, 143462, 143463, 143464, 143465, 143466, 143467, 143468, 143469, 143470, 143471, 143472, 143473, 143474, 143475, 143476, 143477, 143478, 143479, 143480, 143481, 143482, 143483, 143484, 143485, 143486, 143487, 143489, 143491, 143492, 143493, 143494, 143495, 143496, 143497, 143498, 143499, 143501, 143502, 143503, 143504, 143505, 143506, 143507, 143508, 143509, 143510, 143511, 143512, 143513, 143514, 143515, 143516, 143517, 143518, 143519, 143520, 143521, 143523, 143524, 143525, 143526, 143528, 143529, 143530, 143531, 143532, 143533, 143534, 143535, 143536, 143537, 143538, 143539, 143540, 143541, 143542, 143543, 143544, 143545, 143546, 143547, 143548, 143549, 143550, 143551, 143552, 143553, 143554, 143555, 143556, 143557, 143558, 143559, 143560, 143561, 143562, 143563, 143564, 143565, 143566, 143568, 143571, 143572, 143573, 143575, 143576, 143577, 143578, 143579, 143580, 143581, 143582, 143583, 143584, 143585, 143586, 143587, 143588, 143589, 143590, 143591, 143592, 143593, 143594, 143595, 143597, 143598, 143599, 143600, 143601, 143602, 143603, 143604, 143605]\nGP_DEVICE_ID = [1000] # 1000\nIOS_DEVICE_ID = [2000] # 2000\nGRANULARIY = [\"monthly\",\"weekly\"]\nNETWORK = [1, 203, 324, 101, 136, 201, 202, 171, 109, 110, 111, 112, 200, 114, 116, 142, 311, 121, 316, 325]\nDATE = ['201501', '201502', '201503', '201504', '201505', '201506', '201507', '201508', '201509', '201510', '201511', '201512', '201601', '201602', '201603', '201604', '201605', '201606', '201607', '201608', '201609', '201610', '201611', '201612', '201701', '201702', '201703', '201704', '201705', '201706', '201707', '201708', '201709', '201710', '201711', '201712', '201801', '201802', '201803', '201804', '201805', '201806', '201807', '201808', '201809', '201810', '201811', '201812', '201901', '201902', '201903', '201904']\n\ndbinfo = {'NAME': 'mkt_est', 'USER': 'app_bdp_usage_qa', 'PASSWORD': '2mHdFW6%#REu', 'HOST': '10.2.6.27', 'PORT': 5433}\ndblist = [('10.2.6.27', 5433), ('10.2.6.245', 5434), ('10.2.6.42', 5435), ('10.2.6.148', 5436), ('10.2.6.49', 5437), ('10.2.6.52', 5438), ('10.2.6.187', 5439), ('10.2.6.254', 5440)]\n\ntime = time.strftime('%Y-%m-%d_%H-%M-%S',time.localtime(time.time()))\nlog_filename = '/tmp/db_{time}.log'.format(time=time)\nprint log_filename\n\ndef select(sql):\n    conn = psycopg2.connect(dbname=dbinfo['NAME'], user=dbinfo['USER'], password=dbinfo['PASSWORD'],host=dbinfo['HOST'], port=dbinfo['PORT'])\n    with closing(conn.cursor()) as cur:\n        cur.execute(sql)\n        rows = cur.fetchall()\n        cnt = cur.rowcount\n    return rows, cnt\n\ndef get_device_store_list():\n    product_list = []\n    for device_id, store_id  in product(GP_DEVICE_ID, GP_COUNTRY_CODE):\n        product_list.append((device_id, store_id))\n    for device_id, store_id in product(IOS_DEVICE_ID, IOS_COUNTRY_CODE):\n        product_list.append((device_id, store_id))\n    print len(product_list)\n    return product_list\n\ndef get_granularity_device_store_list():\n    product_list = []\n    for granularity, device_id, store_id  in product(GRANULARIY, GP_DEVICE_ID, GP_COUNTRY_CODE):\n        product_list.append((granularity, device_id, store_id))\n    for granularity, device_id, store_id in product(GRANULARIY, IOS_DEVICE_ID, IOS_COUNTRY_CODE):\n        product_list.append((granularity, device_id, store_id))\n    print len(product_list)\n    return product_list\n\ndef get_granularity_device_list():\n    product_list = []\n    for granularity, device_id  in product(GRANULARIY, GP_DEVICE_ID):\n        product_list.append((granularity, device_id))\n    for granularity, device_id in product(GRANULARIY, IOS_DEVICE_ID):\n        product_list.append((granularity, device_id))\n    print len(product_list)\n    return product_list\n\n\ndef write_to_file(filename, str):\n    with open(filename,'a') as file_object:\n        file_object.write(str)\n\nfor granularity,device_id in get_granularity_device_list():\n    table_name = 'adpo_detail_estimate'\n    # SQL RESULT\n    result = 0\n    sql_str = \"{granularity}_{table_name}_{device_id}\".format(table_name=table_name, device_id=device_id, granularity=granularity)\n    for host, port in dblist:\n        dbinfo['HOST'] = host\n        dbinfo['PORT'] = port\n        try:\n            sql =  \"SELECT count(date) FROM mkt.{sql_str} WHERE date < '2019-05-01'\".format(sql_str=sql_str)\n            # print sql # debug\n            r, _ = select(sql)\n            result += r[0][0]\n            # print result # debug\n        except Exception, e:\n            # print e.message\n            error_result=e.message.replace('\\n', '\\\\n')\n            if \"does not exist\" in error_result:\n                error_result = -1\n    # S3 RESULT\n    s3_result = 0\n    s3_path = \"s3://b2c-prod-data-pipeline-unified-market/unified/app-tech.market.legacy-{table_name}.v1/fact/granularity={granularity}/device_id={device_id}/\".format(table_name=table_name,granularity=granularity, device_id=device_id)\n    try:\n        s3_result = spark.read.parquet(s3_path).count()\n    except Exception, e:\n        error_s3_result = -1\n\n    result_str = \"{},{},{}\\n\".format(sql_str, result or error_result,s3_result or error_s3_result)\n    write_to_file(log_filename, result_str)\n    # raise Exception"]},{"cell_type":"code","execution_count":0,"id":"20190819-011735_698253887","metadata":{},"outputs":[],"source":["%%sh\naws s3 ls --recursive s3://b2c-prod-data-pipeline-unified-market/unified/app-tech.market.legacy-adpo_estimate.v1/fact/ \ncat /tmp/db_2019-08-19_02-28-56.log\n\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20190818-115119_163673679","metadata":{},"outputs":[],"source":["\n\n# print spark.read.parquet('s3://b2c-prod-data-pipeline-unified-market/unified/app-tech.market.legacy-meta_creative.v1/dimension/device_id=1001/store_id=35/part-1001-35.c000.gz.parquet').\n# print spark.read.parquet('s3://b2c-prod-data-pipeline-unified-market/unified/app-tech.market.legacy-creative_extension_map.v1/dimension/_partition=_default_partition/part-_default_partition.c000.gz.parquet').count()\ndf = spark.read.parquet('s3://b2c-prod-data-pipeline-unified-market/unified/app-tech.market.legacy-s3_path_creative_id_map.v1/dimension/_partition=_default_partition/part-_default_partition.c000.gz.parquet')\n\ntypes = [f for f in df.columns]\nprint types\nprint dir(df)\n"]},{"cell_type":"code","execution_count":0,"id":"20190819-011438_1035077628","metadata":{},"outputs":[],"source":["\nimport psycopg2\nfrom contextlib import closing\n\ndblist = [('10.2.6.27', 5433), ('10.2.6.245', 5434), ('10.2.6.42', 5435), ('10.2.6.148', 5436), ('10.2.6.49', 5437), ('10.2.6.52', 5438), ('10.2.6.187', 5439), ('10.2.6.254', 5440)]\ndef select(sql):\n    conn = psycopg2.connect(dbname=dbinfo['NAME'], user=dbinfo['USER'], password=dbinfo['PASSWORD'],host=dbinfo['HOST'], port=dbinfo['PORT'])\n    with closing(conn.cursor()) as cur:\n        cur.execute(sql)\n        rows = cur.fetchall()\n        cnt = cur.rowcount\n    return rows, cnt\n\n# SQL RESULT\nfor host, port in dblist:\n    dbinfo['HOST'] = host\n    dbinfo['PORT'] = port\n    try:\n        sql =  \"SELECT max(last_seen) FROM mkt.meta_creative_1002_38 WHERE creative_id <= 90100006099406\".format(sql_str=sql_str)\n        # print sql # debug\n        r, _ = select(sql)\n        print r\n    except Exception, e:\n       print e.message\n       \n# # S3 RESULT\n# s3_result = 0\n# s3_path = \"s3://b2c-prod-data-pipeline-unified-market/unified/app-tech.market.legacy-meta_creative.v1/dimension/device_id={device_id}/store_id={store_id}/\".format(device_id=device_id, store_id=store_id)\n# try:\n#     s3_result = spark.read.parquet(s3_path).count()\n# except Exception, e:\n#     error_s3_result = -1\n\n# result_str = \"mkt.meta_creative_{},{},{}\\n\".format(sql_str, result or error_result,s3_result or error_s3_result)\n# write_to_file(log_filename, result_str)\n# raise Exception\n    \n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20190819-020943_1996631014","metadata":{},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":0,"id":"20190819-023558_1363855369","metadata":{},"outputs":[],"source":["%%sh\n\ncat /tmp/db_2019-08-19_02-47-54.log\n\n\n\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20190819-023627_1237346175","metadata":{},"outputs":[],"source":["\n\nfrom itertools import product\nimport datetime\nimport psycopg2\nfrom contextlib import closing\nimport time\n\nGP_COUNTRY_CODE = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 61, 64, 65, 74, 78, 80, 84, 86, 95, 1000]\nIOS_COUNTRY_CODE = [0, 143441, 143442, 143443, 143444, 143445, 143446, 143447, 143448, 143449, 143450, 143451, 143452, 143453, 143454, 143455, 143456, 143457, 143458, 143459, 143460, 143461, 143462, 143463, 143464, 143465, 143466, 143467, 143468, 143469, 143470, 143471, 143472, 143473, 143474, 143475, 143476, 143477, 143478, 143479, 143480, 143481, 143482, 143483, 143484, 143485, 143486, 143487, 143489, 143491, 143492, 143493, 143494, 143495, 143496, 143497, 143498, 143499, 143501, 143502, 143503, 143504, 143505, 143506, 143507, 143508, 143509, 143510, 143511, 143512, 143513, 143514, 143515, 143516, 143517, 143518, 143519, 143520, 143521, 143523, 143524, 143525, 143526, 143528, 143529, 143530, 143531, 143532, 143533, 143534, 143535, 143536, 143537, 143538, 143539, 143540, 143541, 143542, 143543, 143544, 143545, 143546, 143547, 143548, 143549, 143550, 143551, 143552, 143553, 143554, 143555, 143556, 143557, 143558, 143559, 143560, 143561, 143562, 143563, 143564, 143565, 143566, 143568, 143571, 143572, 143573, 143575, 143576, 143577, 143578, 143579, 143580, 143581, 143582, 143583, 143584, 143585, 143586, 143587, 143588, 143589, 143590, 143591, 143592, 143593, 143594, 143595, 143597, 143598, 143599, 143600, 143601, 143602, 143603, 143604, 143605]\nGP_DEVICE_ID = [1000, 1001, 1002]\nIOS_DEVICE_ID = [2000, 2001, 2002]\nGRANULARIY = [\"weekly\", \"monthly\"]\nNETWORK = [1, 203, 324, 101, 136, 201, 202, 171, 109, 110, 111, 112, 200, 114, 116, 142, 311, 121, 316, 325]\nDATE = ['201501', '201502', '201503', '201504', '201505', '201506', '201507', '201508', '201509', '201510', '201511', '201512', '201601', '201602', '201603', '201604', '201605', '201606', '201607', '201608', '201609', '201610', '201611', '201612', '201701', '201702', '201703', '201704', '201705', '201706', '201707', '201708', '201709', '201710', '201711', '201712', '201801', '201802', '201803', '201804', '201805', '201806', '201807', '201808', '201809', '201810', '201811', '201812', '201901', '201902', '201903', '201904']\n\ndbinfo = {'NAME': 'mkt_est', 'USER': 'app_bdp_usage_qa', 'PASSWORD': '2mHdFW6%#REu', 'HOST': '10.2.6.27', 'PORT': 5433}\ndblist = [('10.2.6.27', 5433), ('10.2.6.245', 5434), ('10.2.6.42', 5435), ('10.2.6.148', 5436), ('10.2.6.49', 5437), ('10.2.6.52', 5438), ('10.2.6.187', 5439), ('10.2.6.254', 5440)]\n\ntime = time.strftime('%Y-%m-%d_%H-%M-%S',time.localtime(time.time()))\nlog_filename = '/tmp/db_{time}.log'.format(time=time)\nprint log_filename\n\ndef select(sql):\n    conn = psycopg2.connect(dbname=dbinfo['NAME'], user=dbinfo['USER'], password=dbinfo['PASSWORD'],host=dbinfo['HOST'], port=dbinfo['PORT'])\n    with closing(conn.cursor()) as cur:\n        cur.execute(sql)\n        rows = cur.fetchall()\n        cnt = cur.rowcount\n    return rows, cnt\n\ndef get_device_store_list():\n    product_list = []\n    for device_id, store_id  in product(GP_DEVICE_ID, GP_COUNTRY_CODE):\n        product_list.append((device_id, store_id))\n    for device_id, store_id in product(IOS_DEVICE_ID, IOS_COUNTRY_CODE):\n        product_list.append((device_id, store_id))\n    print len(product_list)\n    return product_list\n\ndef get_granularity_device_store_list():\n    product_list = []\n    for granularity, device_id, store_id  in product(GRANULARIY, GP_DEVICE_ID, GP_COUNTRY_CODE):\n        product_list.append((granularity, device_id, store_id))\n    for granularity, device_id, store_id in product(GRANULARIY, IOS_DEVICE_ID, IOS_COUNTRY_CODE):\n        product_list.append((granularity, device_id, store_id))\n    print len(product_list)\n    return product_list\n\n\ndef write_to_file(filename, str):\n    with open(filename,'a') as file_object:\n        file_object.write(str)\n\nfor granularity,device_id,store_id in get_granularity_device_store_list():\n    table_name = 'ad_app_category'\n    # SQL RESULT\n    result = 0\n    sql_str = \"{granularity}_{table_name}_{device_id}_{store_id}\".format(table_name=table_name, device_id=device_id, store_id=store_id, granularity=granularity)\n    for host, port in dblist:\n        dbinfo['HOST'] = host\n        dbinfo['PORT'] = port\n        try:\n            sql =  \"SELECT count(date) FROM mkt.{sql_str} WHERE date < '2019-05-01'\".format(sql_str=sql_str)\n            # print sql # debug\n            r, _ = select(sql)\n            result += r[0][0]\n            # print result # debug\n        except Exception, e:\n            # print e.message\n            error_result=e.message.replace('\\n', '\\\\n')\n            if \"does not exist\" in error_result:\n                error_result = -1\n    # S3 RESULT\n    s3_result = 0\n    s3_path = \"s3://b2c-prod-data-pipeline-unified-market/unified/app-tech.market.legacy-{table_name}.v1/fact/granularity={granularity}/device_id={device_id}/store_id={store_id}/part-{granularity}-{device_id}-{store_id}.c000.gz.parquet\".format(table_name=table_name,granularity=granularity, device_id=device_id, store_id=store_id)\n    try:\n        s3_result = spark.read.parquet(s3_path).count()\n    except Exception, e:\n        error_s3_result = -1\n\n    result_str = \"{},{},{}\\n\".format(sql_str, result or error_result,s3_result or error_s3_result)\n    write_to_file(log_filename, result_str)\n    # raise Exception"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}