{"cells":[{"cell_type":"code","execution_count":0,"id":"20200625-054833_230766078","metadata":{},"outputs":[],"source":["\nfrom bdce.common.utils import update_application_code\nupdate_application_code(spark, role=\"BDP-PROD-APP-INT-QA\", application_name=\"zidong-application-autopipeline\")\n\n# reload dependencies from temp\nspark.sparkContext.addPyFile(\"/tmp/zeppelin_application_code/libs/python/dependencies.zip\")\n# spark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nimport aaplproxy"]},{"cell_type":"code","execution_count":0,"id":"20200625-054538_466909294","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql.functions import sum\nfrom pyspark.sql.functions import desc\nfrom aadatapipelinecore.core.urn import Urn\nimport psycopg2\nfrom pyspark.sql import Row\nfrom dateutil.relativedelta import relativedelta\nfrom aaplproxy.connection import ClusterConnection\nfrom conf import settings\nfrom aadatapipelinecore.core.loader.plproxy import build_db_settings\nimport datetime as d\nimport datetime\nfrom datetime import timedelta\n\n\ntest_result = []\nPG_AA_HOSTS = [('10.2.6.141', 5432)]\nPG_AA_NAME = 'aa_store_db'\nPG_AA_ACCESS_ID = 'citus_bdp_prod_app_int_qa'\nPG_AA_SECRET_KEY = 'wZw8cfBuuklIskVG'\n\naa_dsn = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_AA_NAME,\n        user=PG_AA_ACCESS_ID,\n        host=PG_AA_HOSTS[0][0],\n        password=PG_AA_SECRET_KEY,\n        port=PG_AA_HOSTS[0][1]\n    )\n)\n\nurn = Urn(\n    namespace=\"app-qa.db-check.v1\",\n    owner=\"app_qa\"\n)\nsql = \"\"\"select count(1), \n        sum(est_free_app_download), \n        sum(est_paid_app_download), \n        sum(est_revenue)\n        from store.store_est_category_t_{}_fact_v1 \n        where date between '{}' and '{}' and granularity='{}';\"\"\"\n\n\ndef query(dsn, sql):\n    with psycopg2.connect(dsn) as conn:\n        conn.autocommit = True\n        with conn.cursor() as cur:\n            cur.execute(sql)\n            result = cur.fetchall()\n            conn.commit()\n    return result\n\n\ndict_test = {'weekly': ['2010-07-10', '2020-06-20'],\n             'monthly': ['2010-07-31', '2020-04-30'],\n             'quarterly' : ['2010-09-30', '2020-03-31'],\n             'yearly' : ['2010-12-31', '2019-12-31']\n}\n\n\ndef get_date_range(date_list, granularity):\n    result = []\n    start = datetime.datetime.strptime(date_list[0], '%Y-%m-%d')\n    end = datetime.datetime.strptime(date_list[1], '%Y-%m-%d')\n    if granularity == 'weekly':\n        while start <= end:\n            date_row = datetime.datetime.strftime(start, '%Y-%m-%d')\n            result.append(date_row)\n            start += relativedelta(weeks=1)\n    elif granularity == 'monthly':\n        while start <= end:\n            date_row = datetime.datetime.strftime(start, '%Y-%m-%d')\n            result.append(date_row)\n            start += relativedelta(months=1)\n    elif granularity == 'quarterly':\n        while start <= end:\n            date_row = datetime.datetime.strftime(start, '%Y-%m-%d')\n            result.append(date_row)\n            start += relativedelta(months=3)\n    elif granularity == 'yearly':\n        while start <= end:\n            date_row = datetime.datetime.strftime(start, '%Y-%m-%d')\n            result.append(date_row)\n            start += relativedelta(months=12)\n    # print result\n    return result\n\n\ndef check_store_unified_db_completeness(date_list, graularity):\n    for date in date_list:\n        if graularity == 'weekly' or graularity == 'monthly':\n            pre_agg_df = spark.read.format(\"delta\").load(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est-category.v3/fact/\").where(\"granularity='{}' and date='{}' and data_stage='final'\".format(graularity, date))\n        else:\n            pre_agg_df = spark.read.format(\"delta\").load(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est-category-pre-aggr.v3/fact/\").where(\"granularity='{}' and date='{}' and data_stage='final'\".format(graularity, date))\n        pre_agg_df.createOrReplaceTempView(\"pre_agg_df\")\n        unified_result = spark.sql(\"select count(1), sum(free_app_download), sum(paid_app_download), sum(revenue) from pre_agg_df\").collect()\n        db_result = query(aa_dsn, sql.format(graularity[0], date, date, graularity))\n        # print date\n        # print unified_result[0][0]\n        # print db_result\n        if unified_result[0][0] == db_result[0][0] and unified_result[0][1] == db_result[0][1] and unified_result[0][2] == db_result[0][2] and unified_result[0][3] == db_result[0][3]:\n            print \"Completeness Test PASS! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0]) \n        else:\n            print \"Completeness Test FAIL!!!!! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0]) \n        break\n\n\nfor key, value in dict_test.items():\n    print key, value\n    check_store_unified_db_completeness(get_date_range(value, key), key)\n    break"]},{"cell_type":"code","execution_count":0,"id":"20200625-054639_1888309594","metadata":{},"outputs":[],"source":["%%sh\nPGPASSWORD='wZw8cfBuuklIskVG' psql -h 10.2.6.141  -U citus_bdp_prod_app_int_qa -d aa_store_db -p 5432 << EOF \nset search_path=store;\nselect count(1), sum(est_free_app_download), sum(est_paid_app_download), sum(est_revenue),  sum(est_organic_download),  sum(est_paid_download) from store.store_est_category_t_m_fact_v1 where date='2010-07-31' and granularity='monthly';\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20200625-055820_1758490677","metadata":{},"outputs":[],"source":["\nend = '2012-09-30'\ngranularity = 'monthly'\npre_agg_df = spark.read.format(\"delta\").load(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/\" \\\n            \"store.app-est-category.v3/fact/\").where(\"granularity='{}' and date='{}' and data_stage='final'\".format(granularity, end))\npre_agg_df.show()"]},{"cell_type":"code","execution_count":0,"id":"20200625-061239_1058982285","metadata":{},"outputs":[],"source":["\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}