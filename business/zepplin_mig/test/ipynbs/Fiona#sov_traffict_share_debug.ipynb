{"cells":[{"cell_type":"code","execution_count":0,"id":"20200227-061243_1049790279","metadata":{},"outputs":[],"source":["%%sh\n# aws s3 ls s3://prod.appannie.mktint.data/oss/SEARCH_ADS_KEYWORD_SOV/routine/granularity=daily/date=2020-02-15/platform=1/app_type=SINGLE_APP/\n# aws s3 ls s3://b2c-prod-data-pipeline-unified-aso/unified/app-tech.aso.sov-search-ads-keyword-fact.v1/fact/granularity=daily/date=2019-07-03/country_code=KR/\n \n# aws s3 ls s3://b2c-prod-data-pipeline-unified-aso/unified/app-tech.aso.keyword-trafficshare.v1/\n# aws s3 ls s3://b2c-prod-data-pipeline-unified-aso/unified/aso.keyword-trafficshare.v1/fact/granularity=daily/date=20÷19-01-11/dev÷ice_code=android-all/\n \n# aws s3 ls s3://prod.appannie.aso.paid.product/aso/oss/traffic_share/version=1.0.0/range_type=DAY/\n  #date=2020-02-22/device_code=android-all/ --recursive --human --summarize | tail -30\n\n# aws s3 ls s3://b2c-prod-data-pipeline-unified-aso/unified/aso.sov-search-ads-keyword-fact.v1/fact/granularity=daily/\n aws s3 ls s3://b2c-prod-data-pipeline-unified-aso/unified/app-tech.market.aso-keyword-trafficshare.v1/fact/granularity=daily/\n\n\n\n\n\n# aws s3 ls s3://b2c-prod-data-pipeline-unified-aso/unified/app-tech.aso.sov-search-ads-keyword-fact.v1/fact/granularity=daily/\n# aws s3 ls s3://b2c-prod-data-pipeline-unified-aso/unified/app-tech.aso.sov-search-ads-keyword-fact.v1/fact/granularity=daily/date=2019-07-03/country_code=AU/\n\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200309-015150_891435331","metadata":{},"outputs":[],"source":["\ndef get_compared_data(date, country):\n    df_new = spark.read.format(\"delta\").load(\"s3://b2c-prod-data-pipeline-unified-aso/unified/aso.sov-search-ads-keyword-fact.v1/fact/\").where(\"granularity='daily'\").filter(\"date='{}' and app_type='SINGLE_APP' and country_code='{}'\".format(date,country))\n    df_old = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-aso/unified/app-tech.aso.sov-search-ads-keyword-fact.v1/fact/granularity=daily/date={}/\".format(date)).filter(\"app_type='SINGLE_APP' and country_code='{}'\".format(country))\n\n    columns_list = df_old.columns\n    columns_list.remove(\"doc_id\")\n    list1= df_new.sample(False, 0.001, seed=0).limit(5).take(5)\n    return list1, df_old\n\ntest_list, df_old = get_compared_data('2020-03-01','JP')\n\n\n\ndef compare(test_list, df_old):\n    for x in range(5):\n        list2 = df_old.filter(\"keyword_id='{}'\".format(test_list[x][\"keyword_id\"])).collect()\n        # print list2\n        for column in columns_list:\n            if test_list[x][column] != list2[0][column]:\n                print 'not equal',column, test_list[x][column], list2[0][column]\n    print 'pass'           \n\ncompare(test_list, df_old)"]},{"cell_type":"code","execution_count":0,"id":"20200228-025245_2047483237","metadata":{},"outputs":[],"source":["\nlist_str = \"','\".join(map(str,diff))\n# keyword_list_unified \nzero = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-aso/unified//fact/granularity=daily/date=2019-01-01/device_code=ios-phone/\").filter(\"country_code='KW' and keyword_id in ('{}')\".format(list_str)).collect()\n\n# print keyword_list_unified[0]\n\n# traffic_share_list = zero[0][\"traffic_share_list\"]\n\n# for x in traffic_share_list:\n#     print round(x, 6)==0\n\nfor record in zero:\n    print record\n    for traffic_share_score in record[\"traffic_share_list\"]:\n        # print traffic_share_score\n        if round(traffic_share_score, 6)==0:\n            pass\n        else:\n            print traffic_share_score"]},{"cell_type":"code","execution_count":0,"id":"20200228-015209_75008102","metadata":{},"outputs":[],"source":["\nimport pyspark.sql.functions as F\nfrom pyspark.sql.functions import size\nimport psycopg2\nimport datetime\n\nstart = '2020-02-01'\nend = '2020-02-29'\nreal_date1 = datetime.date(*[int(x) for x in start.split('-')])\nreal_date2 = datetime.date(*[int(x) for x in end.split('-')])\ndate_range =  real_date2 - real_date1\ndates = list()\nfor days in xrange(date_range.days):\n    dates.append(real_date1 + datetime.timedelta(days))\n\n\ndevice_code_list=[\"ios-phone\",\"ios-tablet\",\"android-all\"]\n\n\n\ndef get_unified_new_df(date,device):\n    df=spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-aso/unified/aso.keyword-trafficshare.v1/fact/granularity=daily/date={}/device_code={}/\".format(date,device)).cache()\n    new_df = df.withColumn(\"traffic_share_list\", F.expr(\"filter(traffic_share_list, x-> x>=0.0000005 )\"))\n    new_df = new_df.filter(F.size(\"traffic_share_list\") >0)\n    unified_new_df = new_df.groupBy(\"country_code\").agg({\"*\":\"count\"}).collect()\n    return unified_new_df\n    \n    \n\ndef get_data_in_citus(date,device):\n    citus_dsn_ = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=\"aa_mkt_db\",\n        user=\"citus_mkt_qa\",\n        host=\"internal-aa-citus-mkt-elb-1511434527.us-east-1.elb.amazonaws.com\",\n        password=\"rn*Wh%osCl2C\",\n        port=7432\n        )\n    )\n    sql = \"select country_code, count(*) from aso.aso_keyword_trafficshare_fact_v1  where date='{}' and device_code='{}' group by country_code \".format(date,device)\n    db_data = query(citus_dsn_, sql)\n    return db_data\n# sql = \"select * from aso.aso_keyword_trafficshare_fact_v1 where date='2019-01-01' and device_code='ios-phone'  and keyword_id = '1030'\"\n# sql = \"select keyword_id from aso.aso_keyword_trafficshare_fact_v1 where date='2019-01-01' and device_code='ios-phone'\"\n\n# sql = \"select count(*) from aso.aso_keyword_trafficshare_fact_v1  where date='2019-01-01' and device_code='ios-phone'  \"\n# sql = \"select * from aso.aso_keyword_trafficshare_fact_v1 where date='2019-01-01' and device_code='ios-phone' and country_code='KW' limit 1\"\n\ndef query(dsn, sql):\n    with psycopg2.connect(dsn) as conn:\n        conn.autocommit = True\n        with conn.cursor() as cur:\n            cur.execute(sql)\n            result = cur.fetchall()\n            conn.commit()\n    return result\n    \n# print unified_new_df[0]\n# print unified_new_df[1]\n# keyword_list_unified=new_df.filter(\"country_code='KW'\").select(\"keyword_id\").collect()\n\n\n\n\ndef compare(date,device, unified_new_df,test_result ):\n    key = [\"country_code\", \"count(1)\"]\n    unified_data_dict=dict()\n    for data in unified_new_df:\n        unified_data_dict[data[key[0]]]=data[key[1]]\n\n    for x in range(0,len(unified_new_df)):\n        if (test_result[x][1]-unified_data_dict[test_result[x][0]]) !=0:\n            print '{}, {}, country code: {} , db {} , unified {}, diff db - unified : {}'.format(date,device, test_result[x][0] ,test_result[x][1], unified_data_dict[test_result[x][0]], test_result[x][1]-unified_data_dict[test_result[x][0]])\n\n\n\n\nfor d in dates:\n    print d\n    for device in device_code_list:\n        compare(d,device, get_unified_new_df(d,device), get_data_in_citus(d,device))\n\n    "]},{"cell_type":"code","execution_count":0,"id":"20200228-015637_1700437310","metadata":{},"outputs":[],"source":["\n\nimport psycopg2\nimport datetime\n\ndef get_data_in_citus(date,device):\n    citus_dsn_ = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=\"aa_mkt_db\",\n        user=\"citus_mkt_qa\",\n        host=\"internal-aa-citus-mkt-elb-1511434527.us-east-1.elb.amazonaws.com\",\n        password=\"rn*Wh%osCl2C\",\n        port=7432\n        )\n    )\n    sql = \"select country_code, count(*) from aso.aso_keyword_trafficshare_fact_v1  where date='2019-01-01' and device_code='ios-phone' group by country_code \"\n    db_data = query(citus_dsn_, sql)\n    return db_data\n# sql = \"select * from aso.aso_keyword_trafficshare_fact_v1 where date='2019-01-01' and device_code='ios-phone'  and keyword_id = '1030'\"\n# sql = \"select keyword_id from aso.aso_keyword_trafficshare_fact_v1 where date='2019-01-01' and device_code='ios-phone'\"\n\n# sql = \"select count(*) from aso.aso_keyword_trafficshare_fact_v1  where date='2019-01-01' and device_code='ios-phone'  \"\n# sql = \"select * from aso.aso_keyword_trafficshare_fact_v1 where date='2019-01-01' and device_code='ios-phone' and country_code='KW' limit 1\"\n\ndef query(dsn, sql):\n    with psycopg2.connect(dsn) as conn:\n        conn.autocommit = True\n        with conn.cursor() as cur:\n            cur.execute(sql)\n            result = cur.fetchall()\n            conn.commit()\n    return result\n# query(citus_dsn_, sql)\n# test_result = query(citus_dsn_, sql)\n\n\n\n# print test_result"]},{"cell_type":"code","execution_count":0,"id":"20200228-022713_891265772","metadata":{},"outputs":[],"source":["\n# print unified_new_df\ntest_result = keyword_id_list\nkey = [\"country_code\", \"count(1)\"]\nunified_data_dict=dict()\nfor data in unified_new_df:\n    unified_data_dict[data[key[0]]]=data[key[1]]\n\n# print unified_data_dict\nfor x in range(0,len(unified_new_df)):\n    print 'country code: {} , db {} , unified {}, diff db - unified : {}'.format(test_result[x][0] ,test_result[x][1], unified_data_dict[test_result[x][0]], test_result[x][1]-unified_data_dict[test_result[x][0]])"]},{"cell_type":"code","execution_count":0,"id":"20200228-031555_388976546","metadata":{},"outputs":[],"source":["\nprint keyword_id_list[0][0]\nprint keyword_list_unified[0][\"keyword_id\"]\nunified_list = [x[\"keyword_id\"] for x in keyword_list_unified ]\nprint unified_list[0]\n\ndb_list = [ x[0] for x in keyword_id_list ]\nprint db_list[0]\n\nprint 'new'\nprint len(keyword_id_list)\nprint len(unified_list)\n# for keyword in keyword_id_list:\n#     # print keyword\n#     if keyword[0] not in unified_list:\n        # print keyword[0]\ndiff = list(set(unified_list).difference(set(db_list)))\nprint diff\n\n\n# list_str = \"','\".join(map(str,diff))\n# zero = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-aso/unified/aso.keyword-trafficshare.v1/fact/granularity=daily/date=2019-01-01/device_code=ios-phone/\").filter(\"country_code='KW' and keyword_id in ('{}')\".format(list_str)).collect()\n# for record in zero:\n#     print record\n#     for traffic_share_score in record[\"traffic_share_list\"]:\n#         # print traffic_share_score\n#         if round(traffic_share_score, 6)==0:\n#             pass\n#         else:\n#             print record\n"]},{"cell_type":"code","execution_count":0,"id":"20200228-034027_551530315","metadata":{},"outputs":[],"source":["\n# unified_detail = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-aso/unified/aso.keyword-trafficshare.v1/fact/granularity=daily/date=2019-01-01/device_code=ios-phone/\").filter(\"country_code='KW' and keyword_id='5145055'\").collect()\n# unified_cloumns=spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-aso/unified/aso.keyword-trafficshare.v1/fact/granularity=daily/date=2019-01-01/device_code=ios-phone/\").filter(\"country_code='KW' and keyword_id='5145055'\").columns\n\n\nprint detail\nprint unified_detail\nprint unified_cloumns.pop(0)\n\nfor x in range(0,len(unified_detail)):\n    print unified_detail[unified_cloumns[x]]\n"]},{"cell_type":"code","execution_count":0,"id":"20200228-021043_590004913","metadata":{},"outputs":[],"source":["%%sh\nPGPASSWORD='rn*Wh%osCl2C' psql -h internal-aa-citus-mkt-elb-1511434527.us-east-1.elb.amazonaws.com  -U citus_mkt_qa -d aa_mkt_db -p 7432 << EOF \nset search_path=aso;\n--select * from aso.aso_keyword_trafficshare_fact_v1  limit 1  ;\n\nselect count(*) from aso.aso_sov_search_ads_keyword_fact_v1 where country_code='US' and device_code='ios-phone' and granularity='daily' and date='2020-12-14';\n\nEOF \n\n"]},{"cell_type":"code","execution_count":0,"id":"20200227-061420_9366946","metadata":{},"outputs":[],"source":["\nimport datetime\n\nstart = '2019-09-14'\nend = '2019-09-15'\nreal_date1 = datetime.date(*[int(x) for x in start.split('-')])\nreal_date2 = datetime.date(*[int(x) for x in end.split('-')])\ndate_range =  real_date2 - real_date1\ndates = list()\nfor days in xrange(date_range.days):\n    dates.append(real_date1 + datetime.timedelta(days))\n\ncount_list=[]\nfor x in dates:\n    print x\n    count_list.extend(spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-aso/unified/app-tech.aso.sov-search-ads-keyword-fact.v1/fact/granularity=daily/date={}/\".format(x)).filter(\"app_type='SINGLE_APP' and device_code in ( 'ios-phone', 'android-all' ,'ios-tablet')\").groupBy(\"_identifier\").agg({\"*\":\"count\"}).orderBy(\"count(1)\").collect())"]},{"cell_type":"code","execution_count":0,"id":"20200227-062912_1100568330","metadata":{},"outputs":[],"source":["\n\nimport psycopg2\nimport datetime\n\ncitus_dsn_ = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=\"aa_mkt_db\",\n        user=\"citus_mkt_qa\",\n        host=\"internal-aa-citus-mkt-elb-1511434527.us-east-1.elb.amazonaws.com\",\n        password=\"rn*Wh%osCl2C\",\n        port=7432\n    )\n)\n# sql = \"select * from aso.aso_keyword_trafficshare_fact_v1 limit 1;\"\nsql = \"select count(distinct keyword_id) from aso.aso_keyword_trafficshare_fact_v1 where country_code='JP' and date='2017-01-01' and device_code='android-all' \"\n\ndef query(dsn, sql):\n    with psycopg2.connect(dsn) as conn:\n        conn.autocommit = True\n        with conn.cursor() as cur:\n            cur.execute(sql)\n            result = cur.fetchall()\n            conn.commit()\n    return result\n    \ntest_result = query(citus_dsn_, sql)\n\nprint test_result\n"]},{"cell_type":"code","execution_count":0,"id":"20200227-092403_622493971","metadata":{},"outputs":[],"source":["\nfrom elasticsearch import Elasticsearch\nimport datetime\nstart = '2020-03-06'\nend = '2020-03-09'\nreal_date1 = datetime.date(*[int(x) for x in start.split('-')])\nreal_date2 = datetime.date(*[int(x) for x in end.split('-')])\ndate_range =  real_date2 - real_date1\ndates = list()\nfor days in xrange(date_range.days):\n    dates.append(real_date1 + datetime.timedelta(days))\n# print dates\ndef es_doc(date):\n    # print 'review_id ', review_id\n    es_connection = Elasticsearch([\"http://internal-aa-prod-int-elasticsearch-v5-1589259492.us-east-1.elb.amazonaws.com:19200\"],http_auth=(\"app_bdp_usage_qa\",\"euIGw5c6cP3D\"),port=19200)\n    doc = es_connection.count(index=\"aso-kpi-sov_search_ads_keyword_fact_v1_daily*\", body={\"query\":{\"match\":{\"date\":\"{}\".format(date)}}})\n    return date, doc[\"count\"]\nfor x in dates:\n    print es_doc(str(x))\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200227-053340_906632527","metadata":{},"outputs":[],"source":["\nimport datetime\nstart = '2020-03-06'\nend = '2020-03-09'\nreal_date1 = datetime.date(*[int(x) for x in start.split('-')])\nreal_date2 = datetime.date(*[int(x) for x in end.split('-')])\ndate_range =  real_date2 - real_date1\ndates = list()\nfor days in xrange(date_range.days):\n    dates.append(real_date1 + datetime.timedelta(days))\n\nfor date in dates:\n    print spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-aso/unified/app-tech.aso.sov-search-ads-keyword-fact.v1/fact/granularity=daily/date={}/\".format(date)).filter(\"app_type='SINGLE_APP' and device_code in ( 'ios-phone', 'android-all' ,'ios-tablet')\").groupBy(\"_identifier\").agg({\"*\":\"count\"}).orderBy(\"count(1)\").show()\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200227-053351_1873893349","metadata":{},"outputs":[],"source":["\nimport psycopg2\nimport datetime\nimport datetime\nstart = '2020-03-06'\nend = '2020-03-09'\nreal_date1 = datetime.date(*[int(x) for x in start.split('-')])\nreal_date2 = datetime.date(*[int(x) for x in end.split('-')])\ndate_range =  real_date2 - real_date1\ndates = list()\nfor days in xrange(date_range.days):\n    dates.append(real_date1 + datetime.timedelta(days))\n\ncitus_dsn_ = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=\"aa_mkt_db\",\n        user=\"citus_mkt_qa\",\n        host=\"internal-aa-citus-mkt-elb-1511434527.us-east-1.elb.amazonaws.com\",\n        password=\"rn*Wh%osCl2C\",\n        port=7432\n    )\n)\nsql = \"select count(*) from aso.aso_sov_search_ads_keyword_fact_v1 where date='{}' and granularity='daily'\"\n\nsql_list = [sql.format(x) for x in dates]\nprint sql_list\ndef query(dsn, sql):\n    with psycopg2.connect(dsn) as conn:\n        conn.autocommit = True\n        with conn.cursor() as cur:\n            cur.execute(sql)\n            result = cur.fetchall()\n            conn.commit()\n    return result\n\nresult = []\nfor x in sql_list:\n    result.extend(query(citus_dsn_, x))\n\nfor x in result:\n    print x[0]"]},{"cell_type":"code","execution_count":0,"id":"20200227-053539_315384677","metadata":{},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}