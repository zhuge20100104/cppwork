{"cells":[{"cell_type":"code","execution_count":0,"id":"20210811-220454_1131315689","metadata":{},"outputs":[],"source":["\n\nimport datetime\nimport pandas as pd\n\ndef get_date_list(begin_date, end_date, freq):\n    date_list = [x.strftime('%Y-%m-%d') for x in list(pd.date_range(start=begin_date, end=end_date, freq=freq))]\n    return date_list\n\n\ndef get_date_granularity_mapping_list(begin_date, end_date):\n    date_granularity_mapping_list = {\n        \"monthly\": get_date_list(begin_date, end_date, \"M\")\n    }\n    return date_granularity_mapping_list\n\nbegin_date = datetime.datetime.strptime(\"2018-06-03\", '%Y-%m-%d')\nend_date = datetime.datetime.strptime(\"2021-08-31\", '%Y-%m-%d')\n\n\nDATE_DICT = get_date_granularity_mapping_list(begin_date, end_date)\nrange_type_mapping = {\"daily\":\"DAY\",\"monthly\":\"MONTH\",\"weekly\":\"WEEK\"}\n\n\nfor granularity in DATE_DICT:\n    for date in DATE_DICT[granularity]:\n        \n        try:\n            s3path = \"s3://aardvark-prod-pdx-mdm-to-int/to_tech/audience/version=fix_crow_1.0.0/range_type={range_type}/date={date}/\".format(range_type=range_type_mapping[granularity], date=date)\n            spark.read.parquet(s3path).createOrReplaceTempView(\"test_audience\")\n            df = spark.sql(\"select  '{granularity}' as granularity, '{date}' as date, count(distinct(app_id)) as count_app_id, count(distinct(country)) as count_country, count(distinct(device_type)) as count_device_type,count(distinct(age)) as count_age, count(distinct(gender)) as count_gender, sum(IDX) as sum from test_audience\".format(date=date, granularity=granularity))\n            df.write.format(\"parquet\").save(\"s3://b2c-prod-data-pipeline-qa/aa.gwang.s6usage/2021-08-11/audience/\", mode=\"append\") #append\n            print(\"PASS on {} {}\".format(granularity, date))\n        except Exception as e:\n            print(\"ERROR on {} {}\".format(granularity, date))"]},{"cell_type":"code","execution_count":0,"id":"20210811-220706_795839951","metadata":{},"outputs":[],"source":["\ndate='2021-08-11'\n\nspark.read.parquet(\"s3://b2c-prod-data-pipeline-qa/aa.gwang.s6usage/{}/audience/\".format(date)).coalesce(1).write.csv(\"s3://b2c-prod-data-pipeline-qa/aa.gwang.s6usage/adhoc/{}/audience.csv\".format(date),header = 'true')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}