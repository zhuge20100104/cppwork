{"cells":[{"cell_type":"code","execution_count":0,"id":"20200511-072618_873368286","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql import types as T\nfrom pyspark.sql import functions as F\nfrom aadatapipelinecore.core.urn import Urn\nfrom aadatapipelinecore.core.pipeline import type_\nfrom applications.common.parser import SqlParser\nfrom applications.common.executor import SqlExecutor\nfrom applications.auto_pipeline.transform import _view\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nimport aaplproxy\ndef run(spark, raw_data, sql_text, dry_run=True):\n    urn = Urn(namespace=raw_data[\"namespace\"])\n    source_data_list = raw_data.pop(\"source\")\n    raw_data.update(raw_data.pop(\"options\"))\n    _view(spark, sql_text, None, source_data_list)\n    context = raw_data\n    tasks = SqlParser(spark, sql_text, context).parse()\n    if dry_run:\n        sql_executor = DryRunSqlExecutor\n    else:\n        sql_executor = SqlExecutor\n    sql_executor(urn, spark, tasks, type_.EventType.TRANSFORM, context).run()\nsql_text =\"\"\"\nWITH domain_id_name_mapping AS (\n    SELECT\n        db_table(\n            engine=\"plproxy\",\n            database=\"aa\",\n            sql=\"SELECT domain_id AS domain_id, name AS domain_name FROM aa_domain_metadata WHERE is_disabled IN ('f') and sensitive_status IN (0)\"\n        )\n);\n\"\"\"\n\n\ntest_date='2020-03-24'\nnamespace = \"aa.store.market-size.v1\"\ningest_msg = {\n    \"namespace\": \"aa.store.market-size.v1\",\n    \"job_type\": \"routine\",\n    \"options\":{},\n    \"source\": [\n        {}\n    ]\n}\nrun(spark, ingest_msg, sql_text)\nspark.sql(\"select * from domain_id_name_mapping limit 3\").show()\nspark.sql(\"select * from rank_raw limit 3\").show()\n"]},{"cell_type":"code","execution_count":0,"id":"20200511-031002_591082286","metadata":{},"outputs":[],"source":["%md\n#### download attribution raw data - download attribution share value from DF\n```python\nraw_path=\"s3://b2c-mktint-prod-dca-kpi/download_attribution/week_and_month_routine/v1.0.0/WEEK/2020-04-18/AU/part-00000-038bcf58-df5a-487d-b1c9-534b8e30cac4-c000.snappy.parquet\"\nspark.read.parquet(raw_path).where(\"product_id in (1093474684, 20600013167630)\").show()\n+-------------+------------+-----------+----------+--------------+------------------------------+\n|  device_code|country_code|granularity|      date|    product_id|est_non_organic_download_share|\n+-------------+------------+-----------+----------+--------------+------------------------------+\n|    ios-phone|          au|     weekly|2020-04-18|    1093474684|                    0.48971623|\n|android-phone|          au|     weekly|2020-04-18|20600013167630|                     0.3903653|\n+-------------+------------+-----------+----------+--------------+------------------------------+\n```\n\n#### download attribution raw data - unified store est value from store unified data\n```python\nbase_path=\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/granularity=daily\"\nparquet_path=\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/granularity=daily/date=2020-04-{17,18}\"\nsql_where=\"date in ('{}') and app_id in (1093474684 ,20600013167630 ) and country_code='AU' \".format(\"','\".join(['2020-04-18','2020-04-17']))\nspark.read.option(\"basePath\", base_path).parquet(parquet_path).where(sql_where).show()\n+------------------+--------------+------------+-----------------+-----------------+-------+-----------+---------------+----------+-----------+\n|       _identifier|        app_id|country_code|free_app_download|paid_app_download|revenue|revenue_iap|revenue_non_iap|      date|device_code|\n+------------------+--------------+------------+-----------------+-----------------+-------+-----------+---------------+----------+-----------+\n|220200420045618974|    1093474684|          AU|               89|             null|   null|       null|           null|2020-04-18|    ios-all|\n|220200420045717774|    1093474684|          AU|               60|             null|   null|       null|           null|2020-04-17|  ios-phone|\n|220200420045618974|    1093474684|          AU|               89|             null|   null|       null|           null|2020-04-18|  ios-phone|\n|220200420045717774|    1093474684|          AU|               63|             null|   null|       null|           null|2020-04-17|    ios-all|\n|220200420045717774|    1093474684|          AU|                3|             null|   null|       null|           null|2020-04-17| ios-tablet|\n|220200421062240465|20600013167630|          AU|             1388|             null|   null|       null|           null|2020-04-18|android-all|\n|220200421062340592|20600013167630|          AU|             1234|             null|   null|       null|           null|2020-04-17|android-all|\n+------------------+--------------+------------+-----------------+-----------------+-------+-----------+---------------+----------+-----------+\n```\n\n#### download attribution unified data:\n```python\nbase_path=\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.download-attribution.v3/fact/\"\nsql_where=\"granularity='daily' and  date in ('{}') and app_id in (1093474684 ,20600013167630 ) and country_code='AU' \".format(\"','\".join(['2020-04-18','2020-04-17']))\nspark.read.format(\"delta\").load(base_path).where(sql_where).show()\n\n+-----------+------------------+----------+----------+-----------+------------+--------------+-----------------+-----------------+-------+----------------------+\n|granularity|       _identifier|data_stage|      date|device_code|country_code|        app_id|free_app_download|paid_app_download|revenue|organic_download_share|\n+-----------+------------------+----------+----------+-----------+------------+--------------+-----------------+-----------------+-------+----------------------+\n|      daily|220200423104651269|     final|2020-04-18|  ios-phone|          AU|    1093474684|               89|             null|   null|    0.5102837681770325|\n|      daily|220200423104651269|     final|2020-04-17|  ios-phone|          AU|    1093474684|               60|             null|   null|    0.5102837681770325|\n|      daily|220200423104651269|     final|2020-04-18|android-all|          AU|20600013167630|             1388|             null|   null|    0.6096346974372864|\n|      daily|220200423104651269|     final|2020-04-17|android-all|          AU|20600013167630|             1234|             null|   null|    0.6096346974372864|\n|      daily|220200423104651269|     final|2020-04-17| ios-tablet|          AU|    1093474684|                3|             null|   null|    0.5102837681770325|\n+-----------+------------------+----------+----------+-----------+------------+--------------+-----------------+-----------------+-------+----------------------+\n\n```"]},{"cell_type":"code","execution_count":0,"id":"20200511-040608_863831982","metadata":{},"outputs":[],"source":["%md\nAccuracy Test Steps:\n1. mapping device code of raw data from DF same as unified data\n2. join raw data from DF to raw data from store est data\n3. filter data with both free_app_download and paid_app_download are not null, and coalesce the null value to 0 for both raw data \n4. compare data"]},{"cell_type":"code","execution_count":0,"id":"20200511-030327_1444521630","metadata":{},"outputs":[],"source":["\nimport datetime\nfrom pyspark.sql import types as T\nfrom pyspark.sql import functions as F\n\nfrom aadatapipelinecore.core.urn import Urn\nfrom aadatapipelinecore.core.pipeline import type_\nfrom applications.common.parser import SqlParser\nfrom applications.common.executor import SqlExecutor\nfrom applications.auto_pipeline.transform import _view\nfrom aadatapipelinecore.core.utils.spark import eject_all_caches\n\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nimport aaplproxy\n\nstart = \"2016-08-28\"\nend = \"2016-09-05\"\n\nreal_date1 = datetime.date(*[int(x) for x in start.split('-')])\nreal_date2 = datetime.date(*[int(x) for x in end.split('-')])\ndate_range = real_date2 - real_date1\ndates = list()\nsar_list = list()\nfor days in xrange(date_range.days):\n    dates.append(real_date1 + datetime.timedelta(days))\n    if (real_date1 + datetime.timedelta(days)).weekday() == 5:\n        temp = list()\n        while dates:\n            temp.append(dates.pop())\n        sar_list.append({real_date1 + datetime.timedelta(days): temp})\n\ntest_path = list()\n\nfor x in sar_list:\n    for key, item in x.items():\n        test_path.append(\n            (\n                [\n                    \"s3://b2c-mktint-prod-dca-kpi/download_attribution/week_and_month_routine/v1.0.0/WEEK/{}/*/\".format(\n                        key)],\n                [i.strftime(\"%Y-%m-%d\") for i in item],\n                [\n                    \"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/granularity=daily/date={}\".format(\n                        i) for i in item]\n            )\n        )\n\n\nclass DryRunSqlExecutor(SqlExecutor):\n    def _verify_tasks(self):\n        pass\n\n\ndef run(spark, raw_data, sql_text, dry_run=True):\n    urn = Urn(namespace=raw_data[\"namespace\"])\n    source_data_list = raw_data.pop(\"source\")\n    raw_data.update(raw_data.pop(\"options\"))\n    _view(spark, sql_text, None, source_data_list)\n    context = raw_data\n    tasks = SqlParser(spark, sql_text, context).parse()\n    if dry_run:\n        sql_executor = DryRunSqlExecutor\n    else:\n        sql_executor = SqlExecutor\n    sql_executor(urn, spark, tasks, type_.EventType.TRANSFORM, context).run()\n\n\ndef test_download_attribution(test_data):\n    # print test_data\n    spark.read.option(\"basePath\",\n                      \"s3://b2c-mktint-prod-dca-kpi/download_attribution/week_and_month_routine/v1.0.0/WEEK/\").parquet(\n        test_data[0][0]).createOrReplaceTempView(\"download_attribution\")\n\n    print test_data[1]\n    spark.read.format(\"delta\").load(\n        \"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.download-attribution.v3/fact/\").where(\n        \"granularity='daily' and  date in ('{}') \".format(\"','\".join(\n            test_data[1]))).createOrReplaceTempView(\"test_unified_download_attribution\")\n\n    sql_text = \"\"\"\n\nWITH download_attribution AS \n( \n       SELECT *, \n              Cast(est_non_organic_download_share AS DECIMAL(36,20)) AS new_est_non_organic_download_share\n       FROM   download_attribution ); \n       \nWITH download_attribution_1 AS \n( \n       SELECT device_code, \n              country_code, \n              granularity, \n              date, \n              product_id, \n              new_est_non_organic_download_share, \n              CASE \n                     WHEN device_code='android-phone' THEN 'android-all' \n                     WHEN device_code='ios-phone' THEN 'ios-tablet' \n              END AS new_device_code \n       FROM   download_attribution ); \n       \n       \nWITH download_attribution_2 AS \n( \n                SELECT DISTINCT * \n                FROM            ( \n                                       SELECT new_device_code AS device_code, \n                                              country_code, \n                                              granularity, \n                                              date, \n                                              product_id, \n                                              new_est_non_organic_download_share AS est_non_organic_download_share\n                                       FROM   download_attribution_1 \n                                       UNION ALL \n                                       SELECT device_code, \n                                              country_code, \n                                              granularity, \n                                              date, \n                                              product_id, \n                                              est_non_organic_download_share \n                                       FROM   download_attribution ) AS t1 \n                WHERE           device_code!='android-phone' );WITH union_data AS \n( \n                SELECT          *, \n                                store_unified.device_code  AS unified_device_code , \n                                store_unified.country_code AS unified_country_code \n                FROM            store_unified \n                FULL OUTER JOIN download_attribution_2 \n                ON              store_unified.device_code=download_attribution_2.device_code \n                AND             store_unified.country_code=Upper(download_attribution_2.country_code)\n                AND             store_unified.app_id=download_attribution_2.product_id \n                WHERE           est_non_organic_download_share IS NOT NULL ); \n                \n                \nWITH calculate_data_prepare AS \n( \n       SELECT app_id, \n              COALESCE(free_app_download, 0)  AS free_app_download, \n              COALESCE(paid_app_download, 0 ) AS paid_app_download, \n              revenue, \n              unified_device_code, \n              unified_country_code, \n              est_non_organic_download_share \n       FROM   union_data \n       WHERE  NOT ( \n                     free_app_download IS NULL \n              AND    paid_app_download IS NULL) );WITH caculate_data AS \n( \n       SELECT app_id, \n              free_app_download, \n              paid_app_download, \n              revenue, \n              unified_device_code, \n              unified_country_code, \n              est_non_organic_download_share \n       FROM   calculate_data_prepare ); \n       \n       \nWITH compare_data_raw AS \n( \n       SELECT app_id, \n              free_app_download, \n              paid_app_download, \n              unified_device_code                  AS device_code, \n              unified_country_code                 AS country_code, \n              (1 - est_non_organic_download_share) AS organic_download_share \n       FROM   caculate_data ); \n       \n       \nWITH compare_data_unified AS \n( \n       SELECT app_id, \n              COALESCE(free_app_download, 0 ) AS free_app_download, \n              COALESCE(paid_app_download, 0 ) AS paid_app_download, \n              device_code, \n              country_code, \n              organic_download_share \n       FROM   test_unified_download_attribution );\n\n    \"\"\"\n\n\n    namespace = \"aa.store.market-size.v1\"\n    ingest_msg = {\n        \"namespace\": \"aa.store.market-size.v1\",\n        \"job_type\": \"routine\",\n        \"options\": {},\n        \"source\": [\n            {\n                \"data_encoding\": \"parquet\",\n                \"compression\": \"gzip\",\n                \"name\": \"store_unified\",\n                \"path\": test_data[2]\n            }\n\n        ]\n    }\n\n    run(spark, ingest_msg, sql_text)\n\n    df_1 = spark.sql(\"SELECT * FROM compare_data_raw WHERE app_id IS NOT NULL EXCEPT ALL SELECT * FROM compare_data_unified WHERE app_id IS NOT NULL\")\n    spark.sql(\"SELECT * FROM compare_data_unified EXCEPT ALL SELECT * FROM compare_data_raw\")\n    count_1 = spark.sql(\"SELECT Count(*) FROM compare_data_raw where app_id IS NOT NULL\").take(1)\n    count_2 = spark.sql(\"SELECT Count(*) FROM compare_data_unified \").take(1)\n    if count_1[0][0] != count_2[0][0]:\n        print 'failed!!!!!!!!!!!!!'\n\n\n    eject_all_caches(spark)\n\n\nsc.parallelize(map(test_download_attribution, test_path), 1)\n"]},{"cell_type":"code","execution_count":0,"id":"20200511-063950_1980688355","metadata":{},"outputs":[],"source":["%md\n#### store est unified data:\n```python\nbase_path=\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/granularity=daily/date=2020-04-17/\"\nsql_where=\"app_id in (1093474684 ,20600013167630) and country_code='AU'\"\nspark.read.parquet(base_path).where(sql_where).show()\n+------------------+--------------+------------+-----------------+-----------------+-------+-----------+---------------+-----------+\n|       _identifier|        app_id|country_code|free_app_download|paid_app_download|revenue|revenue_iap|revenue_non_iap|device_code|\n+------------------+--------------+------------+-----------------+-----------------+-------+-----------+---------------+-----------+\n|220200420045717774|    1093474684|          AU|               60|             null|   null|       null|           null|  ios-phone|\n|220200420045717774|    1093474684|          AU|               63|             null|   null|       null|           null|    ios-all|\n|220200420045717774|    1093474684|          AU|                3|             null|   null|       null|           null| ios-tablet|\n|220200421062340592|20600013167630|          AU|             1234|             null|   null|       null|           null|android-all|\n+------------------+--------------+------------+-----------------+-----------------+-------+-----------+---------------+-----------+\n\n```\n\n\n#### store category unified data:\n```python\nbase_path=\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est-category-rank.v1/fact/granularity=daily/date=2020-04-17\"\nsql_where=\"app_id in (1093474684 ,20600013167630) and country_code='AU'\"\nspark.read.parquet(base_path).where(sql_where).show()\n+------------------+--------------+-----------+------------+-----------------+-----------------+-------+-----------+---------------+-----------+\n|       _identifier|        app_id|category_id|country_code|free_app_download|paid_app_download|revenue|revenue_iap|revenue_non_iap|device_code|\n+------------------+--------------+-----------+------------+-----------------+-----------------+-------+-----------+---------------+-----------+\n|220200420045717774|    1093474684|     100000|          AU|             3157|             null|   null|       null|           null|  ios-phone|\n|220200420045717774|    1093474684|     100000|          AU|             3898|             null|   null|       null|           null|    ios-all|\n|220200420045717774|    1093474684|     100021|          AU|             2417|             null|   null|       null|           null|    ios-all|\n|220200420045717774|    1093474684|     100034|          AU|              133|             null|   null|       null|           null|    ios-all|\n|220200420045717774|    1093474684|     100021|          AU|             2139|             null|   null|       null|           null|  ios-phone|\n|220200420045717774|    1093474684|     100034|          AU|              123|             null|   null|       null|           null|  ios-phone|\n|220200420045717774|    1093474684|     100000|          AU|             8142|             null|   null|       null|           null| ios-tablet|\n|220200420045717774|    1093474684|     100034|          AU|              219|             null|   null|       null|           null| ios-tablet|\n|220200420045717774|    1093474684|     100021|          AU|             4398|             null|   null|       null|           null| ios-tablet|\n|220200421062340592|20600013167630|     400000|          AU|              116|             null|   null|       null|           null|android-all|\n|220200421062340592|20600013167630|     400001|          AU|               38|             null|   null|       null|           null|android-all|\n|220200421062340592|20600013167630|     400002|          AU|                4|             null|   null|       null|           null|android-all|\n+------------------+--------------+-----------+------------+-----------------+-----------------+-------+-----------+---------------+-----------+\n```\n"]},{"cell_type":"code","execution_count":0,"id":"20200511-065452_850453641","metadata":{},"outputs":[],"source":["%md\n\nCount Test Steps:\n1. Join store category / est table, according to category rank get top N, ignore ios-all data\n2. Set metric as null for category temp table if metric rank is not in top N\n3. filter data with both free_app_download and paid_app_download are not null, and coalesce the null value to 0 for both raw data\n4. Use count to get est/category table count\n5. Use the count to compare with data from DB\n6. Save the test data to qa bucket\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200511-030724_732974433","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql import types as T\nfrom pyspark.sql import functions as F\nimport datetime\n\nfrom aadatapipelinecore.core.urn import Urn\nfrom aadatapipelinecore.core.pipeline import type_\nfrom applications.common.parser import SqlParser\nfrom applications.common.executor import SqlExecutor\nfrom applications.auto_pipeline.transform import _view\n\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nimport aaplproxy\n\nclass DryRunSqlExecutor(SqlExecutor):\n    def _verify_tasks(self):\n        pass\ndef run(spark, raw_data, sql_text, dry_run=True):\n    urn = Urn(namespace=raw_data[\"namespace\"])\n    source_data_list = raw_data.pop(\"source\")\n    raw_data.update(raw_data.pop(\"options\"))\n    _view(spark, sql_text, None, source_data_list)\n    context = raw_data\n    tasks = SqlParser(spark, sql_text, context).parse()\n    if dry_run:\n        sql_executor = DryRunSqlExecutor\n    else:\n        sql_executor = SqlExecutor\n    sql_executor(urn, spark, tasks, type_.EventType.TRANSFORM, context).run()\n\n\nstart='2013-01-01'\nend='2013-01-02'\nreal_date1 = datetime.date(*[int(x) for x in start.split('-')])\nreal_date2 = datetime.date(*[int(x) for x in end.split('-')])\ndate_range = real_date2 - real_date1\ndates = list()\nfor days in xrange(date_range.days):\n    dates.append(real_date1 + datetime.timedelta(days))\ndates.reverse()\n\n\ndef test_count(test_date):\n    # test_date = '2017-08-01'\n    namespace = \"aa.store.market-size.v1\"\n    \n    ingest_msg = {\n        \"namespace\": \"aa.store.market-size.v1\",\n        \"job_type\": \"routine\",\n        \"options\": {},\n        \"source\": [\n            {\n                \"data_encoding\": \"parquet\",\n                \"compression\": \"gzip\",\n                \"name\": \"store_unified\",\n                \"path\": [\n                    \"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/granularity=daily/date={}\".format(\n                        test_date)],\n\n            }, {\n                \"data_encoding\": \"parquet\",\n                \"compression\": \"gzip\",\n                \"name\": \"rank_unified\",\n                \"path\": [\n                    \"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est-category-rank.v1/fact/granularity=daily/date={}\".format(\n                        test_date)],\n\n            }, {\n                \"data_encoding\": \"parquet\",\n                \"compression\": \"gzip\",\n                \"name\": \"category_mapping_deminsion_service\",\n                \"path\": [\"s3://b2c-prod-data-pipeline-qa/aa.store/store_cateogry_mapping\"],\n            },\n            {\n                \"data_encoding\": \"csv\",\n                \"compression\": \"gzip\",\n                \"name\": \"ios_country_mapping\",\n                \"data_schema\": [\n                    {\"name\": \"store_id\", \"type\": \"int\", \"nullable\": False},\n                    {\"name\": \"country_code\", \"type\": \"string\", \"nullable\": False},\n                    {\"name\": \"country_name\", \"type\": \"string\", \"nullable\": False}\n                ],\n                \"csv_options\": {\n                    'header': True,\n                    'sep': '\\t',\n                    'quote': '',\n                    'encoding': 'utf-8',\n                    'escape': ''\n                },\n    \n                \"path\": [\"s3://b2c-prod-dca-store-estimates/store_back/dimension/IOS_COUNTRY_MAPPING\"],\n            },\n            {\n                \"data_encoding\": \"csv\",\n                \"compression\": \"gzip\",\n                \"name\": \"android_country_mapping\",\n                \"data_schema\": [\n                    {\"name\": \"store_id\", \"type\": \"int\", \"nullable\": False},\n                    {\"name\": \"country_code\", \"type\": \"string\", \"nullable\": False},\n                    {\"name\": \"country_name\", \"type\": \"string\", \"nullable\": False}\n                ],\n                \"csv_options\": {\n                    'header': True,\n                    'sep': '\\t',\n                    'quote': '',\n                    'encoding': 'utf-8',\n                    'escape': ''\n                },\n    \n                \"path\": [\"s3://b2c-prod-dca-store-estimates/store_back/dimension/ANDROID_COUNTRY_MAPPING\"],\n            }\n        ]\n    }\n    \n    sql_text = \"\"\"\n    \n    \n    -- rank_unified,store_unified\n    WITH unified_data_test AS \n    ( \n                    SELECT          store_unified.country_code, \n                                    store_unified.device_code, \n                                    store_unified.free_app_download AS est_free_app_download , \n                                    store_unified.paid_app_download AS est_paid_app_download, \n                                    store_unified.revenue           AS est_revenue, \n                                    store_unified.revenue_iap       AS est_revenue_iap, \n                                    store_unified.revenue_non_iap   AS est_revenue_non_iap, \n                                    rank_unified.category_id, \n                                    rank_unified.app_id, \n                                    rank_unified.free_app_download, \n                                    rank_unified.paid_app_download, \n                                    rank_unified.revenue, \n                                    rank_unified.revenue_iap, \n                                    rank_unified.revenue_non_iap, \n                                    rank_unified.granularity, \n                                    rank_unified.date \n                    FROM            rank_unified \n                    FULL OUTER JOIN store_unified \n                    ON              rank_unified.app_id = store_unified.app_id \n                    AND             rank_unified.country_code = store_unified.country_code \n                    AND             rank_unified.device_code = store_unified.device_code \n                    AND             rank_unified.date = store_unified.date );\n    \n    \n    \n    WITH unified_rank_filter_data_free_app_download AS \n    ( \n           SELECT * \n           FROM   unified_data_test \n           WHERE ( ( ( \n                                free_app_download<=1000 \n                         AND    country_code!=\"WW\" ) \n                  OR     ( \n                                free_app_download<=4000 \n                         AND    country_code==\"WW\" ) ) \n           OR     ( ( \n                                paid_app_download<=1000 \n                         AND    country_code!=\"WW\" ) \n                  OR     ( \n                                paid_app_download<=4000 \n                         AND    country_code==\"WW\" ) ) \n           OR     ( ( \n                                revenue<=1000 \n                         AND    country_code!=\"WW\" ) \n                  OR     ( \n                                revenue<=4000 \n                         AND    country_code==\"WW\" ) ) )\n           AND    device_code!='ios-all'\n    );\n    \n    \n    \n           WITH unified_category_filter_data_free_app_download AS \n    ( \n           SELECT * ,\n           CASE WHEN (free_app_download > 1000 and country_code !='WW') or (free_app_download > 4000 and country_code =='WW' ) or (free_app_download is null or free_app_download <= 0) Then null else est_free_app_download END AS est_free_app_download_category,\n           CASE WHEN (paid_app_download > 1000 and country_code !='WW') or (paid_app_download > 4000 and country_code =='WW' ) or (paid_app_download is null or paid_app_download <= 0) Then null else est_paid_app_download END AS est_paid_app_download_category,\n           CASE WHEN (revenue > 1000 and country_code !='WW') or (revenue > 4000 and country_code =='WW') or (revenue is null or revenue <= 0) Then null else est_revenue  END AS est_revenue_category\n           FROM   unified_rank_filter_data_free_app_download \n\n\n    );    \n\n    \n    \"\"\"\n\n\n    run(spark, ingest_msg, sql_text)\n    # current est test:\n    free_app_download_count = spark.sql(\n        \"SELECT Count(app_id) FROM (SELECT DISTINCT app_id, country_code, device_code, est_free_app_download from unified_rank_filter_data_free_app_download WHERE est_free_app_download IS NOT NULL ) AS test\").take(\n        1)\n    paid_app_download_count = spark.sql(\n        \"SELECT Count(app_id) FROM (SELECT DISTINCT app_id, country_code, device_code, est_paid_app_download from unified_rank_filter_data_free_app_download WHERE est_paid_app_download IS NOT NULL ) AS test\").take(\n        1)\n    revenue_count = spark.sql(\n        \"SELECT Count(app_id) FROM (SELECT DISTINCT app_id, country_code, device_code, est_revenue from unified_rank_filter_data_free_app_download WHERE est_revenue IS NOT NULL ) AS test \").take(\n        1)\n        \n        \n\n    free_app_download_category_count = spark.sql(\n        \"SELECT Count(*) FROM (SELECT app_id, country_code, device_code, category_id, est_free_app_download FROM unified_category_filter_data_free_app_download WHERE est_free_app_download_category IS NOT NULL ) AS test\").take(\n        1)\n    paid_app_download_category_count = spark.sql(\n        \"SELECT Count(*) FROM (SELECT app_id, country_code, device_code, category_id, est_paid_app_download FROM unified_category_filter_data_free_app_download WHERE est_paid_app_download_category IS NOT NULL ) AS test\").take(\n        1)\n    revenue_category_count = spark.sql(\n        \"SELECT Count(*) FROM (SELECT app_id, country_code, device_code, category_id, est_revenue FROM unified_category_filter_data_free_app_download WHERE est_revenue_category IS NOT NULL ) AS test \").take(\n        1)\n    \n    import psycopg2\n    import datetime\n    \n    spark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\n    import aaplproxy\n    from aadatapipelinecore.core.urn import Urn\n    from aaplproxy.da.local_sqlrunner import LocalSqlRunner\n    from aadatapipelinecore.core.utils.module import application_settings\n    from pyspark.sql import Row\n    \n    \n    def citus_row_category(date, country_code, market_code, device_code, category_id, metric_name):\n        def get_data_in_citus(date, country_code, market_code, device_code, category_id, metric_name):\n            citus_dsn_ = (\n                \"dbname='{db}' user='{user}' password='{password}' \"\n                \"host='{host}' port='{port}'\".format(\n                    db=\"aa_store_db\",\n                    user=\"citus_bdp_prod_app_int_qa\",\n                    host=\"10.2.10.254\",\n                    password=\"wZw8cfBuuklIskVG\",\n                    port=5432\n                )\n            )\n\n            sql_est_free = \"SELECT Count(*) FROM store.store_est_fact_v6 WHERE date='{}' and granularity='daily' and est_free_app_download IS NOT NULL \".format(\n                date)\n            sql_est_paid = \"SELECT Count(*) FROM store.store_est_fact_v6 WHERE date='{}' and granularity='daily' and est_paid_app_download IS NOT NULL \".format(\n                date)\n            sql_est_download = \"SELECT Count(*) FROM store.store_est_fact_v6 WHERE date='{}' and granularity='daily' and est_revenue IS NOT NULL \".format(\n                date)\n                \n            sql_category_free = \"SELECT Count(*) FROM store.store_est_category_fact_v6 WHERE date='{}' and granularity='daily' and est_free_app_download IS NOT NULL\".format(\n                date)\n            sql_category_paid = \"SELECT Count(*) FROM store.store_est_category_fact_v6 WHERE date='{}' and granularity='daily' and est_paid_app_download IS NOT NULL\".format(\n                date)\n            sql_category_revenue = \"SELECT Count(*) FROM store.store_est_category_fact_v6 WHERE date='{}' and granularity='daily' and est_revenue IS NOT NULL\".format(\n                date)\n                \n            sql_est_app_count = \"SELECT Count (DISTINCT app_id) FROM store.store_est_fact_v6 WHERE date='{}' and granularity='daily' \".format(date) ; \n            sql_category_app_count = \"SELECT count (DISTINCT app_id) FROM store.store_est_category_fact_v6 WHERE date='{}' and granularity='daily' \".format(date) ; \n\n\n            sql_est_app_count = \"SELECT Count (DISTINCT app_id) FROM store.store_est_fact_v6 WHERE date='{}' and granularity='daily' \".format(date) ; \n            sql_category_app_count = \"SELECT Count (DISTINCT app_id) FROM store.store_est_category_fact_v6 WHERE date='{}' and granularity='daily' \".format(date) ; \n\n\n\n            # db_category_count_result = ''  # query(citus_dsn_, sql_category)\n    \n            query_list = [sql_est_free, sql_est_paid, sql_est_download]\n            data_est_count_result = [query(citus_dsn_, sql) for sql in query_list]\n            \n            query_list_category = [sql_category_free, sql_category_paid, sql_category_revenue]\n            data_category_count_result = [query(citus_dsn_, sql) for sql in query_list_category]\n\n            data_est_app_id_count_result = query(citus_dsn_, sql_est_app_count)\n            data_category_app_id_count_result = query(citus_dsn_, sql_category_app_count)\n\n    \n            # print 'running.....'\n            return data_category_count_result, data_est_count_result, data_est_app_id_count_result, data_category_app_id_count_result\n    \n        def query(dsn, sql):\n            with psycopg2.connect(dsn) as conn:\n                conn.autocommit = True\n                with conn.cursor() as cur:\n                    cur.execute(sql)\n                    result = cur.fetchall()\n                    conn.commit()\n            return result\n    \n        result_category, result_est, result_est_app_count, result_category_app_count = get_data_in_citus(date, country_code, market_code, device_code, category_id,\n                                                        metric_name)\n        return  [ Row(app_id=r[0]) for r in result_category], [Row(app_id=r[0]) for r in result_est], [Row(app_id=result_est_app_count[0])], [Row(app_id=result_category_app_count[0])]\n\n    \n    \n    db_test_result_category, db_test_result_est, db_est_count, db_category_count = citus_row_category(test_date, 'US', 'apple-store', 'ios-phone', 100000,\n                                        'est_free_app_download')\n    \n    unified_result = [free_app_download_count[0][0], paid_app_download_count[0][0], revenue_count[0][0]]\n    db_result = [compare_data[0][0] for compare_data in db_test_result_est]\n    \n    unified_category_result=[free_app_download_category_count[0][0], paid_app_download_category_count[0][0], revenue_category_count[0][0]]\n    db_category_result = [compare_data[0][0] for compare_data in db_test_result_category]\n    \n\n    from datetime import datetime\n    df_write_result = spark.createDataFrame([('est', test_date.strftime(\"%Y-%m-%d\"), unified_result, db_result), \n                                            (\"category\", test_date.strftime(\"%Y-%m-%d\"), unified_category_result, db_category_result)], \n                                            schema=[\"type\",\"test_date\",\"unified\",\"db\"])\n\n    from aadatapipelinecore.core.utils.retry import retry\n    def write_test_result(df_write_result):\n        df_write_result.write.format(\"delta\").save(\"s3://b2c-prod-data-pipeline-qa/aa.store/result_store_unified_db_count_demo/\",\n                                          mode=\"append\",\n                                          partitionBy=[\"type\"])\n    retry(write_test_result,(df_write_result,),{},interval=10)\n    \n    \n    if unified_result == db_result:\n        print test_date, 'est pass'\n    else:\n        print test_date, 'est failed!!!!!'\n\n\n    if unified_category_result == db_category_result:\n        print test_date, 'category pass'\n    else:\n        print test_date, 'category failed!!!!!'\n\n\n    if db_est_count[0][0] == db_category_count[0][0]:\n        print test_date, 'app_count pass'\n    else:\n        print test_date, 'app_count failed!!!!!'\n\n\n\nsc.parallelize(map(test_count, dates), 1)\n"]},{"cell_type":"code","execution_count":0,"id":"20200511-070611_300400373","metadata":{},"outputs":[],"source":["\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}