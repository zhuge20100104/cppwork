{"cells":[{"cell_type":"code","execution_count":0,"id":"20220412-071610_1596238593","metadata":{},"outputs":[],"source":["%%sh\n\n# ls -al /usr/lib/zeppelin/local-repo/helium-registry-cache/a6618b3e-540a-340e-b624-07bf7f2b5e7d\n# ls -al /var/lib/zeppelin/local-repo/helium-registry-cache\n\nls -al /etc/zeppelin/conf.dist\ncat /etc/zeppelin/conf.dist/zeppelin-site.xml\n\n\n\n\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20220412-072216_1841245880","metadata":{},"outputs":[],"source":["%%sh\n\naws s3 ls s3://b2c-prod-dca-bdp-data/BDP-PROD-APP-INT-QA/user_data/zeppelin_521/notebook/2G9J8782Y/note.json\naws s3 cp s3://b2c-prod-dca-bdp-data/BDP-PROD-APP-INT-QA/user_data/zeppelin_521/notebook/2G9J8782Y/note.json \ncat  /tmp/2G9J8782Y.json\n"]},{"cell_type":"code","execution_count":0,"id":"20210527-113727_890376048","metadata":{},"outputs":[],"source":["\nprint(\"Start\")"]},{"cell_type":"code","execution_count":0,"id":"20191227-101546_278685021","metadata":{},"outputs":[],"source":["\nfrom pyspark.storagelevel import StorageLevel\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import BooleanType\nfrom datetime import datetime\n\n\n# Snowflake Production\nsfOptions = {\n  \"sfURL\" : \"appannie_aa_int_prod.us-east-1.snowflakecomputing.com\",\n  \"sfUser\" : \"app_bdp_data_validation_qa\",\n  \"sfPassword\" : \"0HN#s@Wa5$1R8jVj\",\n  \"sfDatabase\" : \"AA_INTELLIGENCE_PRODUCTION\",\n  \"sfSchema\" : \"ADL_STORE_PAID\",\n  \"sfWarehouse\" : \"wh_dod_read7\"\n}\nSNOWFLAKE_SOURCE_NAME = \"net.snowflake.spark.snowflake\"\n\n\nstart_date = '2020-01-01'\nend_date = '2021-01-30'\n\ndownload_channel = spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n    .options(**sfOptions) \\\n    .option(\"query\",  f\"select distinct date from FACT_STORE_PRODUCT_DOWNLOAD_CHANNEL_V1_CLUSTER_BY_DATE where date>='{start_date}' and date<='{end_date}';\") \\\n    .load()\ndownload_attribution = spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n    .options(**sfOptions) \\\n    .option(\"query\",  f\"select distinct date from FACT_STORE_PRODUCT_DOWNLOAD_ATTRIBUTION_V1_CLUSTER_BY_DATE where date>='{start_date}' and date<='{end_date}';\") \\\n    .load()\n\nprint(download_channel.count())\nprint(download_channel.count() == download_attribution.count())\n"]},{"cell_type":"code","execution_count":0,"id":"20210527-153816_556721791","metadata":{},"outputs":[],"source":["\nfrom pyspark.storagelevel import StorageLevel\nfrom pyspark.sql.functions import *\nfrom datetime import date\nimport random\n\n\nstart = date(2020, 1, 1)\nend = date(2021, 1, 31)\n\nfor i in random.sample(range(start.toordinal(), end.toordinal()), 20):\n    current = str(date.fromordinal(i))\n    \n    download_channel = spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n        .options(**sfOptions) \\\n        .option(\"query\",  f\"select distinct(product_key) from FACT_STORE_PRODUCT_DOWNLOAD_CHANNEL_V1_CLUSTER_BY_DATE where \n        date='{current}';\") \\\n        .load()\n    download_attribution = spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n        .options(**sfOptions) \\\n        .option(\"query\",  f\"select distinct(product_key) from FACT_STORE_PRODUCT_DOWNLOAD_ATTRIBUTION_V1_CLUSTER_BY_DATE where date='{current}';\") \\\n        .load()\n    \n    if download_channel.count() != download_attribution.count():\n        print(f\"Count dismatch on date: {current}\")\n        break\n        \n    print(\".\", end=\"\")\n    \nprint(\"Checked.\")\n"]},{"cell_type":"code","execution_count":0,"id":"20210528-065059_158160274","metadata":{},"outputs":[],"source":["\nfrom pyspark.storagelevel import StorageLevel\nfrom pyspark.sql.functions import *\nfrom datetime import date\nimport random\n\n\nstart = date(2020, 1, 1)\nend = date(2021, 1, 31)\n\nfor i in random.sample(range(start.toordinal(), end.toordinal()), 20):\n    current = str(date.fromordinal(i))\n    \n    download_channel = spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n        .options(**sfOptions) \\\n        .option(\"query\",  f\"select product_key from FACT_STORE_PRODUCT_DOWNLOAD_CHANNEL_V1_CLUSTER_BY_DATE where (device_code='ios-phone' or device_code='ios-tablet' or device_code='android-all') and date='{current}';\") \\\n        .load()\n    download_attribution = spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n        .options(**sfOptions) \\\n        .option(\"query\",  f\"select product_key from FACT_STORE_PRODUCT_DOWNLOAD_ATTRIBUTION_V1_CLUSTER_BY_DATE where (device_code='ios-phone' or device_code='ios-tablet' or device_code='android-all') and date='{current}';\") \\\n        .load()\n    \n    if download_channel.count() != download_attribution.count():\n        print(download_channel.count())\n        print(download_attribution.count())\n        print(f\"Count dismatch on date: {current}\")\n        break\n        \n    print(\".\", end=\"\")\n    \nprint(\"Checked.\")\n"]},{"cell_type":"code","execution_count":0,"id":"20210527-153944_1954574688","metadata":{},"outputs":[],"source":["\nfrom pyspark.storagelevel import StorageLevel\nfrom pyspark.sql.functions import *\nfrom datetime import date\nimport random\n\nstart = date(2020, 1, 1)\nend = date(2021, 1, 31)\n\nfor i in random.sample(range(start.toordinal(), end.toordinal()), 10):\n    current = str(date.fromordinal(i))\n    \n    dc = spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n        .options(**sfOptions) \\\n        .option(\"query\",  f\"select * from FACT_STORE_PRODUCT_DOWNLOAD_CHANNEL_V1_CLUSTER_BY_DATE where (device_code='ios-phone' or device_code='ios-tablet' or device_code='android-all') and date='{current}';\") \\\n        .load()\n    dc.persist(StorageLevel.MEMORY_ONLY)\n    da = spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n        .options(**sfOptions) \\\n        .option(\"query\",  f\"select * from FACT_STORE_PRODUCT_DOWNLOAD_ATTRIBUTION_V1_CLUSTER_BY_DATE where (device_code='ios-phone' or device_code='ios-tablet' or device_code='android-all') and date='{current}';\") \\\n        .load()\n    da.persist(StorageLevel.MEMORY_ONLY)\n\n    right = dc.selectExpr(\"device_key\", \"country_key\", \"product_key\",\n                          \"EST_ORGANIC_DOWNLOAD as v1\", \"EST_PAID_DOWNLOAD as v2\",\n                          \"EST_PAID_SEARCH_DOWNLOAD as v3\", \"EST_PAID_IN_APP_ADS_DOWNLOAD as v4\", \"EST_ORGANIC_SEARCH_DOWNLOAD as v5\", \"EST_ORGANIC_FEATURED_DOWNLOAD as v6\",\n                          \"EST_DOWNLOAD as t\")\n    left = da.selectExpr(\"device_key\", \"country_key\", \"product_key\", \n                         \"EST_ORGANIC_DOWNLOAD as old_v1\", \"EST_PAID_DOWNLOAD as old_v2\")\n    joined = left.join(right, [\"device_key\", \"country_key\", \"product_key\"], how='left')\n    \n    if joined.filter(\"v1!=old_v1 or v2!=old_v2 or v1!=v5+v6 or v2!=v3+v4\").count() != 0:\n        print(f\"Data dismatch on date: {current}\")\n        break\n        \n    print(\".\", end=\"\")\n    \nprint(\"Checked.\")\n"]},{"cell_type":"code","execution_count":0,"id":"20210527-164019_2016124375","metadata":{},"outputs":[],"source":["\n\ndownload_channel = spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n    .options(**sfOptions) \\\n    .option(\"query\",  f\"select * from FACT_STORE_PRODUCT_DOWNLOAD_CHANNEL_V1_CLUSTER_BY_DATE where  (device_code='ios-phone' or device_code='ios-tablet' or device_code='android-all') and date>='{start_date}' and date<='{end_date}';\") \\\n    .load()\ndownload_attribution = spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n    .options(**sfOptions) \\\n    .option(\"query\",  f\"select * from FACT_STORE_PRODUCT_DOWNLOAD_ATTRIBUTION_V1_CLUSTER_BY_DATE where  (device_code='ios-phone' or device_code='ios-tablet' or device_code='android-all') and date>='{start_date}' and date<='{end_date}';\") \\\n    .load()\n\nleft = download_channel.selectExpr(\"sum(est_download) as t\", \"sum(est_organic_download) as v1\", \"sum(est_paid_download) as v2\",\n                                   \"sum(est_paid_search_download) as v3\", \n                                   \"sum(est_paid_in_app_ads_download) as v4\", \n                                   \"sum(est_organic_search_download) as v5\", \n                                   \"sum(est_organic_featured_download) as v6\").collect()\nright = download_attribution.selectExpr(\"sum(est_organic_download) as old_v1\",\n                                        \"sum(est_paid_download) as old_v2\").collect()\n    \nprint(left[0].t == left[0].v1+left[0].v2)\nprint(left[0].t == left[0].v3+left[0].v4+left[0].v5+left[0].v6)\n\nprint(left[0].v1 == right[0].old_v1)\nprint(left[0].v2 == right[0].old_v2)"]},{"cell_type":"code","execution_count":0,"id":"20210528-024141_1952020587","metadata":{},"outputs":[],"source":["\nfrom pyspark.storagelevel import StorageLevel\nfrom pyspark.sql.functions import *\nfrom datetime import date\nimport random\n\n\nstart = date(2020, 1, 1)\nend = date(2021, 1, 31)\n\nfor i in random.sample(range(start.toordinal(), end.toordinal()), 20):\n    i = date(2021, 1, 10).toordinal()\n    current = str(date.fromordinal(i))\n    \n    dc = spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n        .options(**sfOptions) \\\n        .option(\"query\",  f\"select sum(est_organic_download) as v1, sum(est_paid_download) as v2 from FACT_STORE_PRODUCT_DOWNLOAD_CHANNEL_V1_CLUSTER_BY_DATE where  (device_code='ios-phone' or device_code='ios-tablet' or device_code='android-all') and date='{current}';\") \\\n        .load().collect()\n    da = spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n        .options(**sfOptions) \\\n        .option(\"query\",  f\"select sum(est_organic_download) as v1, sum(est_paid_download) as v2 from FACT_STORE_PRODUCT_DOWNLOAD_ATTRIBUTION_V1_CLUSTER_BY_DATE where  (device_code='ios-phone' or device_code='ios-tablet' or device_code='android-all') and date='{current}';\") \\\n        .load().collect()\n    \n    if dc[0].V1 != da[0].V1 or dc[0].V2 != da[0].V2:\n        print(dc)\n        print(da)\n        print(f\"Count dismatch on date: {current}\")\n        break\n        \n    print(\".\", end=\"\")\n\n\nprint(\"Checked.\")"]},{"cell_type":"code","execution_count":0,"id":"20210528-033835_1944833726","metadata":{},"outputs":[],"source":["\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}