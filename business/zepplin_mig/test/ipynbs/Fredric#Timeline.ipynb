{"cells":[{"cell_type":"code","execution_count":0,"id":"20210811-090428_1531045589","metadata":{},"outputs":[],"source":["\n\nfrom pyspark.storagelevel import StorageLevel\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import BooleanType\n\nimport json\n\n\n## Production Environments\n\n# snowflake production\nsfOptions = {\n  \"sfURL\" : \"appannie_aa_int_prod.us-east-1.snowflakecomputing.com\",\n  \"sfUser\" : \"app_bdp_data_validation_qa\",\n  \"sfPassword\" : \"0HN#s@Wa5$1R8jVj\",\n  \"sfDatabase\" : \"AA_INTELLIGENCE_PRODUCTION\",\n  \"sfSchema\" : \"ADL_MASTER\",\n  \"sfWarehouse\" : \"wh_dod_read7\"\n}\nSNOWFLAKE_SOURCE_NAME = \"net.snowflake.spark.snowflake\"\n\nquery_statement = '''select event_type_name, product_key,change_time, old_value, new_value, meta from ADL_MASTER.DIM_EVENT_V2_CLUSTER_BY_PRODUCT_KEY \n                 where event_type_name='screenshot_change' and change_time >= '2021-05-01' '''\ndf = spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n  .options(**sfOptions) \\\n  .option(\"query\", query_statement) \\\n  .load()\n\ndf.count()\n\ndef get_common_keys(old_keys, new_keys):\n    common_keys = list()\n    for old_key in old_keys:\n        if old_key in new_keys:\n            common_keys.append(old_key)\n    return common_keys\n\n\n@udf(returnType=BooleanType())\ndef is_cal_correct(old_value, new_value, meta_):\n    old_data = json.loads(old_value)\n    new_data = json.loads(new_value)\n    meta_data = json.loads(meta_)\n    \n    if isinstance(old_data, list) or isinstance(new_data, list) or isinstance(meta_data, list):\n        return True\n    \n    old_keys = old_data.keys()\n    new_keys = new_data.keys()\n\n    common_keys_ = get_common_keys(old_keys, new_keys)\n    common_keys_final = sorted(common_keys_, reverse=True)\n    \"\"\"\n    Example: \n    Meta  value:\n        \"default\": \"111\"\n        Old value: \"default\": [\"1.png\"] \n        New value: \"default\": [\"2.png\"]\n    \"\"\"\n    for key, value in meta_data.items():\n        for common_key in common_keys_final:\n            if common_key.startswith(key):\n                old_values = old_data[common_key]\n                new_values = new_data[common_key]\n                len_equal = (len(old_values) == len(new_values))\n                if (value.find(\"1\") == -1) and (not len_equal):\n                    return False\n\n    return True\n    \n    \n\nresult_df = df.filter(\"old_value is not null and new_value is not null and meta is not null\").withColumn(\"is_cal_right\",  is_cal_correct(col(\"old_value\"), col(\"new_value\"), col(\"meta\")))\nwrong_df = result_df.filter(col(\"is_cal_right\")==False)\nright_df = result_df.filter(col(\"is_cal_right\")==True)\nprint(\"CAL_WRONG_COUNT:\" + str(wrong_df.count()))\nwrong_df.show(10, False)\n\n"]},{"cell_type":"code","execution_count":0,"id":"20210811-090621_1789084334","metadata":{},"outputs":[],"source":["\n\nfrom pyspark.storagelevel import StorageLevel\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import BooleanType\n\n\nimport json\n\n\n## Production Environments\n\n# snowflake production\nsfOptions = {\n  \"sfURL\" : \"appannie_aa_int_prod.us-east-1.snowflakecomputing.com\",\n  \"sfUser\" : \"app_bdp_data_validation_qa\",\n  \"sfPassword\" : \"0HN#s@Wa5$1R8jVj\",\n  \"sfDatabase\" : \"AA_INTELLIGENCE_PRODUCTION\",\n  \"sfSchema\" : \"ADL_MASTER\",\n  \"sfWarehouse\" : \"wh_dod_read7\"\n}\nSNOWFLAKE_SOURCE_NAME = \"net.snowflake.spark.snowflake\"\n\nquery_statement = '''select event_type_name, product_key,change_time, old_value, new_value, meta from ADL_MASTER.DIM_EVENT_V2_CLUSTER_BY_PRODUCT_KEY \n                 where event_type_name='screenshot_change' and change_time >= '2021-05-01' '''\ndf = spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n  .options(**sfOptions) \\\n  .option(\"query\", query_statement) \\\n  .load()\n\ndf.count()\n\n\ndef get_ios_key(key_str):\n    if key_str.startswith(\"iphone\"):\n        return \"iphone\"\n    elif key_str.startswith(\"ipad\"):\n        return \"ipad\"\n    else:\n        return key_str\n\ndef merge_keys(src, dest):\n    for key in dest:\n        ios_key = get_ios_key(key)\n        if ios_key not in src:\n            src.append(ios_key)\n    return src\n\ndef cal_meta_contains_no_new_value_key(meta_keys, merged_keys):\n    for meta_key in meta_keys:\n        if meta_key not in merged_keys:\n            return False\n    return True\n\n\n@udf(returnType=BooleanType())\ndef is_key_consistent(old_value, new_value, meta_):\n    old_data = json.loads(old_value)\n    new_data = json.loads(new_value)\n    meta_data = json.loads(meta_)\n    ## skip the error data which old_data is a list\n    if isinstance(old_data, list) or isinstance(new_data, list) or isinstance(meta_data, list):\n        return True\n    \n    old_keys = list(old_data.keys())\n    new_keys = list(new_data.keys())\n    \n    merged_keys_src = list()\n    duplicated_keys = old_keys + new_keys\n    \n    merged_keys = merge_keys(merged_keys_src, duplicated_keys)\n    meta_keys = list(meta_data.keys())\n\n    merged_keys_sorted = sorted(merged_keys, reverse=True)\n    meta_keys_sorted = sorted(meta_keys, reverse=True)\n    if not cal_meta_contains_no_new_value_key(meta_keys_sorted, merged_keys_sorted):\n        return False\n    return True\n    \n\nresult_df = df.filter(\"old_value is not null and new_value is not null and meta is not null\").withColumn(\"is_key_consistent\",  is_key_consistent(col(\"old_value\"), col(\"new_value\"), col(\"meta\")))\nwrong_df = result_df.filter(col(\"is_key_consistent\")==False)\nright_df = result_df.filter(col(\"is_key_consistent\")==True)\nprint(\"INCONSISTENT_COUNT:\" + str(wrong_df.count()))\nwrong_df.show(10, False)\n\n"]},{"cell_type":"code","execution_count":0,"id":"20210812-012001_1782412523","metadata":{},"outputs":[],"source":["\n\nsfOptions = {\n  \"sfURL\" : \"appannie_aa_int_prod.us-east-1.snowflakecomputing.com\",\n  \"sfUser\" : \"app_bdp_data_validation_qa\",\n  \"sfPassword\" : \"0HN#s@Wa5$1R8jVj\",\n  \"sfDatabase\" : \"AA_INTELLIGENCE_PRODUCTION\",\n  \"sfWarehouse\" : \"wh_dod_read7\"\n}\nSNOWFLAKE_SOURCE_NAME = \"net.snowflake.spark.snowflake\"\n\nquery_statement = '''select event_type_name, product_key,change_time, old_value, new_value, meta from ADL_MASTER.DIM_EVENT_V2_CLUSTER_BY_PRODUCT_KEY \n                 where event_type_name='screenshot_change' and change_time >= '2021-05-01' '''\ndf = spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n  .options(**sfOptions) \\\n  .option(\"query\", query_statement) \\\n  .load()\n  \n# df.show(10)\n\ndf2 = spark.sql(\"select * from  ADL_MASTER.DIM_EVENT_V2_CLUSTER_BY_PRODUCT_KEY limit 10\")\ndf2.show(1)\n"]},{"cell_type":"code","execution_count":0,"id":"20210906-080936_173991024","metadata":{},"outputs":[],"source":["%%sh\n\n# aws s3 cp s3://b2c-prod-dca-bdp-data/BDP-PROD-APP-INT-QA/user_data/zeppelin_521/notebook/2G9J8782Y/note.json - \n\n# aws s3 cp  s3://b2c-prod-dca-bdp-data/BDP-PROD-APP-INT-QA/user_data/zeppelin/notebook/2DRSB9VB4/note.json - \n\n# aws s3 ls  s3://b2c-prod-dca-bdp-data/BDP-PROD-APP-INT-QA/user_data/zeppelin/notebook/2DRSB9VB4/note.json\n\naws s3 ls s3://b2c-prod-dca-bdp-data/BDP-PROD-APP-INT-QA/user_data/zeppelin_521/notebook/ | wc -l"]},{"cell_type":"code","execution_count":0,"id":"20220413-063358_928369495","metadata":{},"outputs":[],"source":["%%sh\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}