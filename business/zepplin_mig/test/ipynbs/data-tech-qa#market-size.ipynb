{"cells":[{"cell_type":"code","execution_count":0,"id":"20200217-005359_1817664494","metadata":{},"outputs":[],"source":["\n\nimport psycopg2\nimport datetime\nfrom applications.db_check_v1.cases.store.market_size_v1.constants import MARKET_SIZE_DSN\n\ntoday = datetime.datetime.today()\ndate_delta = z.input(\"max_days\")\ndate_start = today + datetime.timedelta(0-int(date_delta)-1)\n\n\nsql = 'SELECT date,device_code,count(*) FROM store.store_market_size_fact_v1  WHERE ( date between \\'{date_start}\\' AND \\'{today}\\'  ) GROUP BY date, device_code ORDER BY date ASC'.format(date_start=date_start, today=today)\n\ndef query(dsn, sql):\n    with psycopg2.connect(dsn) as conn:\n        conn.autocommit = True\n        with conn.cursor() as cur:\n            cur.execute(sql)\n            result = cur.fetchall()\n            conn.commit()\n    return result\n    \ntest_result = query(MARKET_SIZE_DSN, sql)\nprint \"%table {}\\t{}\\t{}\".format( \"date\", \"device_code\", \"count\")\n\nfor result in test_result:\n    date,device_code,count = result\n    print \"{}\\t{}\\t{}\".format(date.strftime(\"%Y-%m-%d\"), device_code, count)\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200217-005540_36379875","metadata":{},"outputs":[],"source":["%%sh\n\nPGPASSWORD='dNzWtSV3pKTx' psql -h 10.2.10.132 -U citus_bdp_usage_qa -d aa_citus_db -p 5432 << EOF \n\nSELECT * from store.store_market_size_latest_date_v1 limit 100;\n\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20200218-121110_1939123733","metadata":{},"outputs":[],"source":["%%sh\n\nPGPASSWORD='2mHdFW6%#REu' psql -h internal-aa-prod-plproxy-internal-4-329644124.us-east-1.elb.amazonaws.com -U app_bdp_usage_qa -d dailyest -p 7432 << EOF \nselect device_id, date, store_id, kpi, category_id, app_type_id, purchase_type_id, estimate from plproxy.execute_select_nestloop(\\$proxy\\$ \n    select device_id, date, store_id, kpi, category_id, app_type_id, purchase_type_id, estimate\n    from ms.market_size_daily_estimate_1000 \n    where \n        date = '2020-01-10' and \n        purchase_type_id=12 and \n        app_type_id=2 and \n        store_id=14 and \n        category_id in (65) \n\\$proxy\\$) tbl (device_id SMALLINT, date DATE, store_id INT, kpi SMALLINT, category_id INT, app_type_id SMALLINT, purchase_type_id SMALLINT, estimate BIGINT);\nEOF\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200519-050244_1639976051","metadata":{},"outputs":[],"source":["%%sh\n#aws s3 ls s3://b2c-prod-dca-store-estimates/store_estv2/MARKET_SIZE_ESTIMATES_FINAL/version=2.0.0/range_type=DAY/date=2020-01-26/platform=android/\n#aws s3 ls s3://b2c-prod-dca-store-estimates/store_estv2/MARKET_SIZE_ESTIMATES_FINAL/version=2.0.0/range_type=DAY/date=2020-01-28/platform=android/\n#aws s3 ls s3://b2c-prod-dca-store-estimates/store_estv2/MARKET_SIZE_ESTIMATES_FINAL/version=2.0.0/range_type=DAY/date=2020-01-01/platform=android/\n\naws s3 ls s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.market-size.v1/fact/granularity=daily/date=2020-01-17/device_code=android-all/"]},{"cell_type":"code","execution_count":0,"id":"20200520-014455_303311310","metadata":{},"outputs":[],"source":["\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/code.zip\")\nimport pandas as pd\npd.set_option('expand_frame_repr', False)\n"]},{"cell_type":"code","execution_count":0,"id":"20200522-033401_392477242","metadata":{},"outputs":[],"source":["\n\n\"\"\"\nDB Check modules\n\"\"\"\n\nimport datetime\nfrom applications.db_check_v1.common.base_test import PipelineTest\nfrom applications.db_check_v1.common.db_check_utils import query_df, etl_skip\nfrom applications.db_check_v1.common.constants import COUNTRY_CODE_MAPPING_BY_MARKET_CODE as COUNTRY_CODE_MAPPING, \\\n    CATEGORY_ID_MAPPING_BY_MARLKET_AND_DEVICE_CODE as CATEGORY_ID_MAPPING\nfrom applications.db_check_v1.common.utils import get_week_start_end_date, get_date_list\nfrom applications.db_check_v1.cases.store.market_size_v1.constants import MARKET_SIZE_DSN\n\n\nclass MarketSizeRawData(object):\n    raw_s3_path = \"s3://b2c-prod-dca-store-estimates/store_estv2/MARKET_SIZE_ESTIMATES_FINAL/\" \\\n                  \"version=2.0.0/range_type=DAY/date={date}/\"\n    device_code_mapping = {\n        \"0google-play\": \"android-all\",\n        \"1ios\": \"ios-all\",\n        \"1ipad\": \"ios-tablet\",\n        \"1iphone\": \"ios-phone\",\n    }\n\n    metric_mapping = {\n        \"downloads\": \"est_market_size_download\",\n        \"revenue\": \"est_market_size_revenue\"\n    }\n\n    dimension_mapping = {\n        \"price_type\": \"app_price_type_id\",\n        \"purchase_type\": \"purchase_type_id\"\n    }\n\n    def __init__(self, spark):\n        self.spark = spark\n\n    def get(self, date):\n        df = self._get_raw_data_by_date(date)\n        df = self._parse_mapping(df)\n        df = self._parse_unified_format(df)\n        df = self._data_clean_up(df)\n        return df\n\n    def _data_clean_up(self, df):\n        # clean unknown mapping\n        category_id_list = list(set(CATEGORY_ID_MAPPING[\"apple-store\"][\"ios-all\"].values() +\n                                    CATEGORY_ID_MAPPING[\"google-play\"][\"android-all\"].values()))\n\n        country_code_list = list(set(COUNTRY_CODE_MAPPING[\"apple-store\"].values() +\n                                     COUNTRY_CODE_MAPPING[\"google-play\"].values()))\n\n        df = df[(df['category_id'].isin(category_id_list)) & (df['country_code'].isin(country_code_list))]\n        return df\n\n    def _parse_mapping(self, df):\n        # country_code mapping\n        df.loc[df[\"platform_id\"] == 0] = df.loc[df[\"platform_id\"] == 0].\\\n            replace({\"store_id\": COUNTRY_CODE_MAPPING[\"google-play\"]})\n        df.loc[df[\"platform_id\"] == 1] = df.loc[df[\"platform_id\"] == 1].\\\n            replace({\"store_id\": COUNTRY_CODE_MAPPING[\"apple-store\"]})\n        df = df.rename(columns={'store_id': 'country_code'})\n\n        # category_id mapping\n        df.loc[df[\"platform_id\"] == 0] = df.loc[df[\"platform_id\"] == 0].\\\n            replace({\"category_id\": CATEGORY_ID_MAPPING[\"google-play\"][\"android-all\"]})\n        df.loc[df[\"platform_id\"] == 1] = df.loc[df[\"platform_id\"] == 1].\\\n            replace({\"category_id\": CATEGORY_ID_MAPPING[\"apple-store\"][\"ios-all\"]})\n\n        # device_code mapping\n        df[\"device_code\"] = df[\"platform_id\"].astype(str) + df[\"device\"]\n        df = df.replace({\"device_code\": self.device_code_mapping})\n        return df\n\n    def _parse_unified_format(self, df):\n        df = df.rename(columns=self.dimension_mapping)\n        df = df.pivot_table(index=[\"app_price_type_id\", \"purchase_type_id\", \"category_id\",\n                                   \"device_code\", \"country_code\"], columns='data_type', values='estimate')\n        df.reset_index(inplace=True)\n        df.columns.name = None\n        df = df.rename(columns=self.metric_mapping)\n        return df\n\n    def _get_raw_data_by_date(self, date):\n        \"\"\"\n        +--------+----------+-----------+-----------+---------+----------+-------------+-----------+--------+\n        |store_id|      date|platform_id|     device|data_type|price_type|purchase_type|category_id|estimate|\n        +--------+----------+-----------+-----------+---------+----------+-------------+-----------+--------+\n        |      10|2020-01-10|          0|google-play|downloads|         1|           10|          1|11981138|\n        +--------+----------+-----------+-----------+---------+----------+-------------+-----------+--------+\n        \"\"\"\n        # schema = StructType([\n        #     StructField(\"store_id\", IntegerType(), False),\n        #     StructField(\"date\", StringType(), False),\n        #     StructField(\"platform_id\", IntegerType(), False),\n        #     StructField(\"device\", StringType(), False),\n        #     StructField(\"data_type\", StringType(), False),\n        #     StructField(\"price_type\", IntegerType(), False),\n        #     StructField(\"purchase_type\", IntegerType(), False),\n        #     StructField(\"category_id\", IntegerType(), False),\n        #     StructField(\"estimate\", LongType(), False)\n        # ])\n        raw_df = self.spark.read.parquet(self.raw_s3_path.format(date=date))\n        return raw_df.toPandas()\n\n    def get_rank_count_and_sum_by_date(self, date):\n        pass\n        # return raw_count, raw_sum\n\n\nclass MarketSizeUnifiedData(object):\n    unified_s3_path = \"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.market-size.v1/fact/\" \\\n                      \"granularity=daily/date={}/\"\n\n    def __init__(self, spark):\n        self.spark = spark\n\n    def get(self, date):\n        #unified_df = self.spark.read.parquet(self.unified_s3_path.format(date)).toPandas()\n        \n        unified_df = self.spark.read.format(\"delta\").load(self.unified_s3_path.format(date)).toPandas()\n        unified_df = unified_df.drop([\"_identifier\"], axis=1)\n        return unified_df\n\n\nclass MarketSizeDBData(object):\n    def get(self, date):\n        sql = \"SELECT * FROM store.store_market_size_fact_v1 WHERE date='{}'\".format(date)\n        return query_df(MARKET_SIZE_DSN, sql)\n\n    def get_led(self):\n        sql = \"SELECT * FROM store.store_market_size_latest_date_v1\"\n        return query_df(MARKET_SIZE_DSN, sql)\n\n\nclass TestMarketSizeWeekly(PipelineTest):\n    # Every Tuesday 16:00 UTC time will refresh the data of last Full Week.\n    trigger_date_config = ('* 16 * * 2', 3)\n\n    def _compare_df(self, df1, df2, log=''):\n        len_diff = 0\n        for diff_type in [\"left\", \"right\"]:\n            diff_df = df1.merge(df2, indicator=True, how=diff_type)  # .loc[lambda x : x['_merge']!='both']\n            diff_df = diff_df.loc[diff_df[\"_merge\"] != \"both\"]\n            len_diff = len(diff_df) if len(diff_df)>len_diff else len_diff\n            if len(diff_df) != 0:\n                print diff_type\n                print \"dataframe overview of df1 and df2\"\n                print diff_df\n                print \"dimension overview of diff df\"\n                print diff_df.country_code.unique()\n                print diff_df.category_id.unique()\n                print diff_df.device_code.unique()\n            print \"found mismatch when compare the raw, unified, db. diff count is \\n {}, logs:{}\".format(len(diff_df), log)\n            # self.assertEqual(len(diff_df), 0,\n            #                  msg=\"found mismatch when compare the raw, unified, db.\"\n            #                      \" diff count is \\n {}, logs:{}\".format(len(diff_df), log))\n\n    @etl_skip()\n    def test_market_size_etl_accuracy_and_completeness(self):\n        # Every Tuesday 16:00 UTC time will refresh the data of last Full Week.\n        start_date, end_date = get_week_start_end_date(self.check_date_str)\n        date_list = get_date_list(start_date, end_date)\n        for date in date_list:\n            print \"************** {} *************\".format(date)\n            raw_df = MarketSizeRawData(self.spark).get(date)\n            unified_df = MarketSizeUnifiedData(self.spark).get(date)\n            db_df = MarketSizeDBData().get(date)\n\n            self._compare_df(raw_df, unified_df, log=\"raw / unified - {}\".format(date))\n            self._compare_df(unified_df, db_df, log=\"unified / db - {}\".format(date))\n        raise RuntimeError(date_list)\n\n    def test_market_size_etl_timelines(self):\n        # Every Tuesday 16:00 UTC time will refresh the data of last Full Week.\n        # E.g. 2020-02-11 17:00 the data of 2020-02-02 ~ 2020-02-08 will be ready\n        trigger_datetime = datetime.datetime.strptime(\"2020-02-11 17:00:00\", '%Y-%m-%d %H:%M:%S')\n        check_date_str_actual = self._get_check_date_from_routing_config(trigger_datetime).strftime(\"%Y-%m-%d\")\n        self.assertEqual(\"2020-02-08\", check_date_str_actual)\n\n    @etl_skip()\n    def test_market_size_led(self):\n        _, expected_led_date = get_week_start_end_date(self.check_date_str)\n        led_df = MarketSizeDBData().get_led()\n        for device_code in [\"ios-all\", \"android-all\", \"ios-tablet\", \"ios-phone\"]:\n            actual_led_date = led_df.loc[led_df.device_code == device_code].date.values[0].strftime(\"%Y-%m-%d\")\n            self.assertEqual(expected_led_date, actual_led_date,\n                             msg=\"current led for device : {} is {}, it should be {}\".format(\n                                 device_code, actual_led_date, expected_led_date))\n"]},{"cell_type":"code","execution_count":0,"id":"20200519-050328_46268726","metadata":{},"outputs":[],"source":["\n\nimport sys\nimport datetime\nimport traceback\nimport unittest\nfrom applications.db_check_v1.common.html_report_test_runner import HTMLTestRunner\n\n\ndef debug(case_list):\n    std_out_origin= sys.stdout\n    std_err_origin= sys.stderr\n    try:\n        suite =  unittest.TestSuite()\n        for case in case_list:\n            suite.addTest(case)\n        runner = unittest.TextTestRunner(verbosity=2, buffer=True)\n        runner.run(suite)\n    except Exception as ex:\n        print dir(ex)\n        print ex.message\n        traceback.print_exception(type(ex), ex, ex.__traceback__)\n    finally:\n        sys.stdout = std_out_origin\n        sys.stderr = std_err_origin\n    \ndef get_date_list2(begin_date, end_date, freq):\n    date_list = [x for x in list(pd.date_range(start=begin_date, end=end_date, freq=freq))]\n    return date_list\n\ntest_case_list = [ ] # pass \n\nbegin_date = datetime.datetime(2020, 01, 01)\nend_date = datetime.datetime(2020, 05, 31)\ndate_list = get_date_list2(begin_date, end_date, \"W-WED\")\n#date_list = [datetime.datetime(2020, 4, 8), datetime.datetime(2020, 2, 5), datetime.datetime(2020, 2, 12)]\nprint date_list\nfor t_date in date_list:\n    test_case_list.append(TestMarketSizeWeekly(trigger_datetime=t_date, methodName='test_market_size_etl_accuracy_and_completeness'))\n\n\ndebug(test_case_list)\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200520-012824_1513654833","metadata":{},"outputs":[],"source":["\n\nimport datetime\nimport unittest\n\nfrom aadatapipelinecore.core.monitoring.pipeline_monitor import running, fail, task_success\nfrom aadatapipelinecore.core.urn import Urn\nfrom aadatapipelinecore.core.utils.identifier import package_id\nfrom aadatapipelinecore.core.utils.spark import canned_spark, stop\nfrom aadatapipelinecore.core.utils import email\nfrom applications.db_check_v1.common.html_report_test_runner import HTMLTestRunner\n\n\ndef get_date_list(begin_date, end_date, freq):\n    date_list = [x for x in list(pd.date_range(start=begin_date, end=end_date, freq=freq))]\n    return date_list\n\ndef send_db_check_email(title, text_context, key=None):\n    default_recipients = ['tom@appannie.com']\n    email.send(title, text_context, default_recipients, sender='dev-qa-data-quality@appannie.com')\n\n\ndef send_message():\n    log_file = \"/tmp/db_check.log\"\n    with open(log_file, \"w\") as html_file:\n        suite = unittest.TestSuite()\n        \n        # begin_date = datetime.datetime(2020, 01, 01)\n        # end_date = datetime.datetime(2020, 05, 20)\n        #date_list = get_date_list(begin_date, end_date, \"W-WED\")\n\n        # date_list = [datetime.datetime(2020, 4, 1), datetime.datetime(2020, 2, 5), datetime.datetime(2020, 1, 29)]\n        date_list = [ datetime.datetime(2020, 1, 29)]\n        print date_list\n        for t_date in date_list:\n            suite.addTests([TestMarketSizeWeekly(trigger_datetime=t_date, methodName='test_market_size_etl_accuracy_and_completeness')])\n            \n\n        runner = HTMLTestRunner(\n            stream=html_file,\n            title='DB Test Report',\n            description='This db_check the report output by Tech Team.'\n        )\n\n        failed_count = 0\n        result_list = runner.run(suite).result\n        for result in result_list:\n            if result[0] == 1 or result[0] == 2:\n                failed_count += 1\n\n    with open(log_file, 'r') as html_file:\n        today = datetime.date.today()\n        str_today = today.strftime(\"%Y-%m-%d\")\n\n        title = \"Data Regression Check Report - \" + str_today + \" - \"\n        if failed_count == 0:\n            title += \"Passed\"\n        else:\n            title += \"Failed\"\n        send_db_check_email(title, html_file.read())\n\n\nsend_message()\nprint 123"]},{"cell_type":"code","execution_count":0,"id":"20200520-020941_72272056","metadata":{},"outputs":[],"source":["\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}