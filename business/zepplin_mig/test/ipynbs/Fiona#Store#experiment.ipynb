{"cells":[{"cell_type":"code","execution_count":0,"id":"20200526-115549_1764119205","metadata":{},"outputs":[],"source":["%%sh\n\naws s3 ls s3://b2c-prod-data-pipeline-qa/aa.store/result_store_unified_db_count/ --recursive --human --summarize | tail -30"]},{"cell_type":"code","execution_count":0,"id":"20200526-115634_1229338757","metadata":{},"outputs":[],"source":["\n\nspark.read.parquet(\"s3://b2c-prod-data-pipeline-qa/aa.store/result_store_unified_db_count_0430/\").createOrReplaceTempView(\"ha\")\nspark.sql(\"select * from ha order by test_date desc\").show(20, False)"]},{"cell_type":"code","execution_count":0,"id":"20200403-021209_2070119615","metadata":{},"outputs":[],"source":["\nfrom aadatapipelinecore.core.urn import Urn\nfrom aadatapipelinecore.core.pipeline import type_\nfrom applications.common.parser import SqlParser\nfrom applications.common.executor import SqlExecutor\nfrom applications.auto_pipeline.transform import _view\nclass DryRunSqlExecutor(SqlExecutor):\n    def _verify_tasks(self):\n        pass\ndef run(spark, raw_data, sql_text, dry_run=True):\n    urn = Urn(namespace=raw_data[\"namespace\"])\n    source_data_list = raw_data.pop(\"source\")\n    raw_data.update(raw_data.pop(\"options\"))\n    _view(spark, sql_text, None, source_data_list)\n    context = raw_data\n    tasks = SqlParser(spark, sql_text, context).parse()\n    if dry_run:\n        sql_executor = DryRunSqlExecutor\n    else:\n        sql_executor = SqlExecutor\n    sql_executor(urn, spark, tasks, type_.EventType.TRANSFORM, context).run()\nsql_text = \"\"\"\n\nWITH store_db AS (\n    SELECT\n        db_table(\n            engine=\"PG\",\n            database=\"AA_DAILY_EST\",\n            sql=\"select count(*) FROM store.store_est_fact_v2 WHERE granularity in ('daily') and date in ('2020-03-28') and est_free_app_download is not null \"\n        )\n);\n\n\"\"\"\nnamespace = \"aa.store.market-size.v1\"\ningest_msg = {\n    \"namespace\": \"aa.store.market-size.v1\",\n    \"job_type\": \"routine\",\n    \"options\":{},\n    \"source\": [\n        {\n            \"name\":\"rank_raw\",\n            \"data_encoding\": \"parquet\",\n            \"compression\": \"gzip\",\n            \"path\": [\"s3://b2c-prod-dca-store-estimates/store_estv2/APP_ESTIMATES_FINAL/version=2.0.0/range_type=DAY/date=2020-01-01/\"],\n        }\n    ]\n}\nrun(spark, ingest_msg, sql_text)\nspark.sql(\"select * from store_db\").show()\n\n# "]},{"cell_type":"code","execution_count":0,"id":"20200408-014927_2068309742","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql import types as T\nfrom pyspark.sql import functions as F\n\nfrom aadatapipelinecore.core.urn import Urn\nfrom aadatapipelinecore.core.pipeline import type_\nfrom applications.common.parser import SqlParser\nfrom applications.common.executor import SqlExecutor\nfrom applications.auto_pipeline.transform import _view\n\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nimport aaplproxy\n\nclass DryRunSqlExecutor(SqlExecutor):\n    def _verify_tasks(self):\n        pass\ndef run(spark, raw_data, sql_text, dry_run=True):\n    urn = Urn(namespace=raw_data[\"namespace\"])\n    source_data_list = raw_data.pop(\"source\")\n    raw_data.update(raw_data.pop(\"options\"))\n    _view(spark, sql_text, None, source_data_list)\n    context = raw_data\n    tasks = SqlParser(spark, sql_text, context).parse()\n    if dry_run:\n        sql_executor = DryRunSqlExecutor\n    else:\n        sql_executor = SqlExecutor\n    sql_executor(urn, spark, tasks, type_.EventType.TRANSFORM, context).run()\nsql_text =\"\"\"\n\n\n\nWITH domain_id_name_mapping AS (\n    SELECT\n        db_table(\n            engine=\"plproxy\",\n            database=\"aa\",\n            sql=\"SELECT domain_id AS domain_id, name AS domain_name FROM aa_domain_metadata WHERE is_disabled IN ('f') and sensitive_status IN (0)\"\n        )\n);\n\nWITH store_db AS (\n    SELECT\n        db_table(\n            engine=\"PG\",\n            database=\"AA_DAILY_EST\",\n            sql=\"select * from store.store_est_fact_v2 \"\n        )\n);\n\n\n\"\"\"\n\n\n\ntest_date='2020-03-24'\nnamespace = \"aa.store.market-size.v1\"\ningest_msg = {\n    \"namespace\": \"aa.store.market-size.v1\",\n    \"job_type\": \"routine\",\n    \"options\":{},\n    \"source\": [\n        {\n            \"name\":\"rank_raw\",\n            \"data_encoding\": \"parquet\",\n            \"compression\": \"gzip\",\n            \"path\": [\"s3://b2c-prod-dca-store-estimates/store_estv2/APP_ESTIMATES_FINAL/version=2.0.0/range_type=DAY/date={}/\".format(test_date)],\n        }\n    ]\n}\n\nrun(spark, ingest_msg, sql_text)\nspark.sql(\"select * from store_db\").show()\n\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200407-072917_1976861529","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql import types as T\nfrom pyspark.sql import functions as F\n\nfrom aadatapipelinecore.core.urn import Urn\nfrom aadatapipelinecore.core.pipeline import type_\nfrom applications.common.parser import SqlParser\nfrom applications.common.executor import SqlExecutor\nfrom applications.auto_pipeline.transform import _view\n\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nimport aaplproxy\n\nclass DryRunSqlExecutor(SqlExecutor):\n    def _verify_tasks(self):\n        pass\ndef run(spark, raw_data, sql_text, dry_run=True):\n    urn = Urn(namespace=raw_data[\"namespace\"])\n    source_data_list = raw_data.pop(\"source\")\n    raw_data.update(raw_data.pop(\"options\"))\n    _view(spark, sql_text, None, source_data_list)\n    context = raw_data\n    tasks = SqlParser(spark, sql_text, context).parse()\n    if dry_run:\n        sql_executor = DryRunSqlExecutor\n    else:\n        sql_executor = SqlExecutor\n    sql_executor(urn, spark, tasks, type_.EventType.TRANSFORM, context).run()\nsql_text =\"\"\"\n\n-- mapping feed as metrc in raw\nWITH feed_metric AS (\nselect *, 'free_app_download' as metric, \"ios-phone\" as device_code from rank_raw where  feed='0' and platform='ios'\nUNION ALL\nselect *, 'paid_app_download' as metric, \"ios-phone\" as device_code from rank_raw where  feed='1' and platform='ios'\nUNION ALL\nselect *, 'revenue' as metric , \"ios-phone\" as device_code from rank_raw where  feed='2' and platform='ios'\nUNION ALL\nselect *, 'free_app_download' as metric, \"ios-tablet\" as device_code from rank_raw where  feed='101' and platform='ios'\nUNION ALL\nselect *, 'paid_app_download' as metric, \"ios-tablet\" as device_code from rank_raw  where  feed='100' and platform='ios'\nUNION ALL\nselect *, 'revenue' as metric, \"ios-tablet\" as device_code from rank_raw  where  feed='102' and platform='ios'\nUNION ALL\nselect *, 'free_app_download' as metric, \"ios-all\" as device_code from rank_raw  where  feed='1000' and platform='ios'\nUNION ALL\nselect *, 'paid_app_download' as metric, \"ios-all\" as device_code from rank_raw  where  feed='1001' and platform='ios'\nUNION ALL\nselect *, 'revenue' as metric, \"ios-all\" as device_code from rank_raw  where  feed='1002' and platform='ios'\nUNION ALL\nselect *, 'free_app_download' as metric , \"android-all\" as device_code from rank_raw   where  feed='0' and platform='android'\nUNION ALL\nselect *, 'paid_app_download' as metric, \"android-all\" as device_code from rank_raw  where  feed='1' and platform='android'\nUNION ALL\nselect *, 'revenue' as metric,  \"android-all\" as device_code from rank_raw  where  feed='2' and platform='android'\n);\n\n\n-- select tested column from raw data\nWITH metric_raw_data AS (\nSELECT id, category_id as raw_category_id,rank,store_id as raw_store_id , metric,device_code,date , platform from feed_metric where store_id not in (3,4,5,6, 1002,1003, 1005,1004, 1006,1007)\n);\n\n\n-- group by and count data in raw data\nWITH group_by_raw AS (\nSELECT count(id) AS total_count , raw_category_id, raw_store_id, metric,device_code,date,platform from metric_raw_data where raw_store_id not in (3,4,5,6, 1002,1003, 1004, 1005, 1006,1007) group by raw_category_id, raw_store_id, metric,device_code,date, platform\n);\n\n\n-- pivot metric column\nWITH pivot_metric_rank_raw AS (\n\nSELECT \nfree_app_download,revenue, paid_app_download, raw_category_id,raw_store_id,device_code, platform,date\nFROM\n      group_by_raw\n PIVOT (\n    max(total_count) \n\tFOR metric IN ('free_app_download','revenue', 'paid_app_download')\n  )\n);\n\n\n\n\n-- select tested column from raw data\nWITH metric_raw_store_data AS (\nSELECT distinct id, est, store_id as raw_store_id , metric,device_code, date , platform from feed_metric where store_id not in (3,4,5,6, 1002,1003, 1005,1004, 1006,1007)\n\n);\n\n\n-- group by and count data in raw data\nWITH group_by_store_raw AS (\nSELECT count(est) AS total_count ,raw_store_id, metric,device_code,date,platform from metric_raw_store_data where raw_store_id not in (3,4,5,6,1002,1003, 1004, 1005, 1006,1007) group by raw_store_id, metric,device_code,date, platform\n);\n\n\n-- pivot metric column\nWITH pivot_metric_store_raw AS (\n\nSELECT \nfree_app_download,revenue, paid_app_download,raw_store_id,device_code, platform, date\nFROM\n      group_by_store_raw\n PIVOT (\n    max(total_count) \n\tFOR metric IN ('free_app_download','revenue', 'paid_app_download')\n  )\n);\n\n\n\n-- map raw with category\nWITH category_mapping_raw AS (\n\nSELECT * from ( select *, 'ios' as mapping_platform from category_mapping_deminsion_service where market_code='apple-store' \nUNION ALL select *, 'android' as mapping_platform from category_mapping_deminsion_service where market_code='google-play'\n ) as mapping right join pivot_metric_rank_raw on mapping.legacy_category_id=pivot_metric_rank_raw.raw_category_id and \nmapping.mapping_platform=pivot_metric_rank_raw.platform\n);\n\n\n-- map raw with rank country_code\nWITH country_category_mapping_rank_raw AS (\nselect date, raw_store_id, country_code,device_code,category_id,free_app_download,paid_app_download,revenue from country_code_mapping right join category_mapping_raw on country_code_mapping.country_code_store_id=category_mapping_raw.raw_store_id and country_code_mapping.market_code=category_mapping_raw.platform\n);\n\n\n\n-- map raw with store country_code\nWITH country_mapping_store_raw AS (\nselect date, raw_store_id, country_code,device_code,free_app_download,paid_app_download,revenue from country_code_mapping right join pivot_metric_store_raw on country_code_mapping.country_code_store_id=pivot_metric_store_raw.raw_store_id and country_code_mapping.market_code=pivot_metric_store_raw.platform\n);\n\n\n-- group by unified data\nWITH unified_group_data AS (\nselect count(app_id) as unified_count_app_id, count(free_app_download) as unified_count_free_app_download, count(paid_app_download) as unified_count_paid_app_download, count(revenue) as unified_count_revenue,\n  country_code as unified_country_code, device_code as unified_device_code, category_id as unified_category_id from ( select distinct  app_id, free_app_download, paid_app_download, revenue, country_code, device_code, category_id from  rank_unified ) as unified\ngroup by  category_id,  country_code,  device_code );\n\n\n-- group by unified data\nWITH unified_group_data_store AS (\nselect count(app_id) as unified_count_app_id, count(free_app_download) as unified_count_free_app_download, count(paid_app_download) as unified_count_paid_app_download, count(revenue) as unified_count_revenue,\n  country_code as unified_country_code, device_code as unified_device_code from ( select distinct  app_id, free_app_download, paid_app_download, revenue, country_code, device_code from  store_unified ) as unified\ngroup by   country_code,  device_code );\n\n\n\n\n-- compare raw vs unified data\nWITH compared_data_rank AS (\n    SELECT * from country_category_mapping_rank_raw left join unified_group_data on unified_group_data.unified_country_code==country_category_mapping_rank_raw.country_code and unified_group_data.unified_category_id==country_category_mapping_rank_raw.category_id and unified_group_data.unified_device_code==country_category_mapping_rank_raw.device_code\n);\n\nWITH miss_data_rank AS (\nselect * from compared_data_rank where unified_count_paid_app_download!=paid_app_download or unified_count_free_app_download != free_app_download  or unified_count_revenue != revenue or unified_count_app_id is null\n)\n\n\n\n-- compare raw vs unified data store\nWITH compared_store_data AS (\n    SELECT * from country_mapping_store_raw left join unified_group_data_store on unified_group_data_store.unified_country_code==country_mapping_store_raw.country_code and unified_group_data_store.unified_device_code==country_mapping_store_raw.device_code\n);\n\n\nWITH miss_data_store AS (\nselect * from compared_store_data where free_app_download!=unified_count_free_app_download or paid_app_download!=unified_count_paid_app_download or revenue!=unified_count_revenue or unified_count_app_id is null\n)\n\n\n\"\"\"\n\n\n\ntest_date='2020-03-01'\nnamespace = \"aa.store.market-size.v1\"\ningest_msg = {\n    \"namespace\": \"aa.store.market-size.v1\",\n    \"job_type\": \"routine\",\n    \"options\":{},\n    \"source\": [\n        {\n            \"name\":\"rank_raw\",\n            \"data_encoding\": \"parquet\",\n            \"compression\": \"gzip\",\n            \"path\": [\"s3://b2c-prod-dca-store-estimates/store_estv2/APP_ESTIMATES_FINAL/version=2.0.0/range_type=DAY/date={}/\".format(test_date)],\n        },        {\n            \"data_encoding\": \"parquet\",\n            \"compression\": \"gzip\",\n          \"name\":\"rank_unified\",\n            \"path\": [\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est-category-rank.v1/fact/granularity=daily/date={}\".format(test_date)],\n        },   \n        {\n            \"data_encoding\": \"parquet\",\n            \"compression\": \"gzip\",\n          \"name\":\"store_unified\",\n            \"path\": [\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/granularity=daily/date={}\".format(test_date)],\n        },\n        {\n            \"data_encoding\": \"parquet\",\n            \"compression\": \"gzip\",\n          \"name\":\"category_mapping_deminsion_service\",\n            \"path\": [\"s3://b2c-prod-data-pipeline-qa/aa.store/store_cateogry_mapping\"],\n        },   \n        {\n            \"data_encoding\": \"csv\",\n            \"compression\": \"gzip\",\n            \"name\":\"ios_country_mapping\",\n            \"data_schema\": [\n                            {\"name\":\"store_id\",\"type\":\"int\",\"nullable\": False},\n                            {\"name\":\"country_code\",\"type\":\"string\",\"nullable\": False},\n                            {\"name\":\"country_name\",\"type\":\"string\",\"nullable\": False}\n                            ],\n             \"csv_options\": {\n           'header': True,\n           'sep': '\\t',\n           'quote': '',\n           'encoding': 'utf-8',\n           'escape': ''\n           },\n\n            \"path\": [\"s3://b2c-prod-dca-store-estimates/store_back/dimension/IOS_COUNTRY_MAPPING\"],\n        },   \n        {\n            \"data_encoding\": \"csv\",\n            \"compression\": \"gzip\",\n            \"name\":\"android_country_mapping\",\n            \"data_schema\": [\n                            {\"name\":\"store_id\",\"type\":\"int\",\"nullable\": False},\n                            {\"name\":\"country_code\",\"type\":\"string\",\"nullable\": False},\n                            {\"name\":\"country_name\",\"type\":\"string\",\"nullable\": False}\n                            ],\n             \"csv_options\": {\n           'header': True,\n           'sep': '\\t',\n           'quote': '',\n           'encoding': 'utf-8',\n           'escape': ''\n           },\n\n            \"path\": [\"s3://b2c-prod-dca-store-estimates/store_back/dimension/ANDROID_COUNTRY_MAPPING\"],\n        }\n    ]\n}\nd1 = spark.read.csv(\"s3://b2c-prod-dca-store-estimates/store_back/dimension/IOS_COUNTRY_MAPPING\",\n                        sep=\"\\t\").withColumnRenamed(\"_c0\", \"store_id\").withColumnRenamed(\"_c1\",\n                                                                                         \"country_code\").withColumn(\n        \"market_code\", F.lit(\"ios\"))\nd2 = spark.read.csv(\"s3://b2c-prod-dca-store-estimates/store_back/dimension/ANDROID_COUNTRY_MAPPING\",\n                        sep=\"\\t\").withColumnRenamed(\"_c0\", \"store_id\").withColumnRenamed(\"_c1\",\n                                                                                         \"country_code\").withColumn(\n        \"market_code\", F.lit(\"android\"))\n\ncountry_code_df = d1.union(d2).cache()\ncountry_code_df = country_code_df.withColumnRenamed(\"store_id\", \"country_code_store_id\")\nprint 'country mapping table'\ncountry_code_df.show(2)\ncountry_code_df.createOrReplaceTempView(\"country_code_mapping\")\n\ncategory_mapping_table = spark.read.parquet(\n        \"s3://b2c-prod-data-pipeline-qa/aa.store/store_cateogry_mapping\")\ncategory_mapping_table.createOrReplaceTempView(\"category_mapping_deminsion_service\")\n\nrun(spark, ingest_msg, sql_text)\nspark.sql(\"select * from store_db\").show()\nresult1 = spark.sql(\"select * from miss_data_store\")\nresult2 = spark.sql(\"select * from miss_data_rank\")\n\nresult1.show()\nresult2.show()\n\n\n\n# s3://b2c-prod-data-pipeline-qa/aa.store/result_store_v1\n"]},{"cell_type":"code","execution_count":0,"id":"20200403-024217_1423429736","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql import types as T\nfrom pyspark.sql import functions as F\n\nfrom aadatapipelinecore.core.urn import Urn\nfrom aadatapipelinecore.core.pipeline import type_\nfrom applications.common.parser import SqlParser\nfrom applications.common.executor import SqlExecutor\nfrom applications.auto_pipeline.transform import _view\n\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nimport aaplproxy\n\nclass DryRunSqlExecutor(SqlExecutor):\n    def _verify_tasks(self):\n        pass\ndef run(spark, raw_data, sql_text, dry_run=True):\n    urn = Urn(namespace=raw_data[\"namespace\"])\n    source_data_list = raw_data.pop(\"source\")\n    raw_data.update(raw_data.pop(\"options\"))\n    _view(spark, sql_text, None, source_data_list)\n    context = raw_data\n    tasks = SqlParser(spark, sql_text, context).parse()\n    if dry_run:\n        sql_executor = DryRunSqlExecutor\n    else:\n        sql_executor = SqlExecutor\n    sql_executor(urn, spark, tasks, type_.EventType.TRANSFORM, context).run()\nsql_text = \"\"\"\n\nCREATE TABLE test_rank (\n    country_code text NOT NULL,\n    device_code int8 NOT NULL,\n    category_id text NOT NULL,\n    free_app_download text NOT NULL,\n    paid_app_download text NOT NULL,\n    revenue int4 NOT NULL,\n    date date NOT NULL,\n    PRIMARY KEY(country_code, device_code,category_id,free_app_download,paid_app_download,revenue)\n)\nPARTITION BY COLUMNS(date)\nWITH (\n    NAMESPACE = 'aa.store',\n    COALESCE = 1,\n    SAVEMODE = 'append',\n    DIMENSIONS = COLUMNS(country_code, device_code,category_id),\n    METRICS = COLUMNS(free_app_download,paid_app_download,revenue)\n);\n\n\n\n-- mapping feed as metrc in raw\nWITH feed_metric AS (\nselect *, 'free_app_download' as metric, \"ios-phone\" as device_code from rank_raw where  feed='0' and platform='ios'\nUNION ALL\nselect *, 'paid_app_download' as metric, \"ios-phone\" as device_code from rank_raw where  feed='1' and platform='ios'\nUNION ALL\nselect *, 'revenue' as metric , \"ios-phone\" as device_code from rank_raw where  feed='2' and platform='ios'\nUNION ALL\nselect *, 'free_app_download' as metric, \"ios-tablet\" as device_code from rank_raw where  feed='101' and platform='ios'\nUNION ALL\nselect *, 'paid_app_download' as metric, \"ios-tablet\" as device_code from rank_raw  where  feed='100' and platform='ios'\nUNION ALL\nselect *, 'revenue' as metric, \"ios-tablet\" as device_code from rank_raw  where  feed='102' and platform='ios'\nUNION ALL\nselect *, 'free_app_download' as metric, \"ios-all\" as device_code from rank_raw  where  feed='1000' and platform='ios'\nUNION ALL\nselect *, 'paid_app_download' as metric, \"ios-all\" as device_code from rank_raw  where  feed='1001' and platform='ios'\nUNION ALL\nselect *, 'revenue' as metric, \"ios-all\" as device_code from rank_raw  where  feed='1002' and platform='ios'\nUNION ALL\nselect *, 'free_app_download' as metric , \"android-all\" as device_code from rank_raw   where  feed='0' and platform='android'\nUNION ALL\nselect *, 'paid_app_download' as metric, \"android-all\" as device_code from rank_raw  where  feed='1' and platform='android'\nUNION ALL\nselect *, 'revenue' as metric,  \"android-all\" as device_code from rank_raw  where  feed='2' and platform='android'\n);\n\n\n\n\n-- select tested column from raw data\nWITH metric_raw_data AS (\nSELECT id, category_id as raw_category_id,rank, store_id as raw_store_id , metric,device_code,date , platform from feed_metric\n);\n\n\n-- group by and count data in raw data\nWITH group_by_raw AS (\nSELECT count(id) AS total_count , raw_category_id, raw_store_id, metric,device_code,date,platform from metric_raw_data where raw_store_id not in (0,3,4,5,6, 1000, 1003, 1005, 1006,1007)  group by raw_category_id, raw_store_id, metric,device_code,date, platform\n);\n\n\n-- pivot metric column\nWITH pivot_metric_raw AS (\n\nSELECT \nfree_app_download,revenue, paid_app_download, raw_category_id,raw_store_id,device_code, platform, date\nFROM\n      group_by_raw\n PIVOT (\n    max(total_count) \n\tFOR metric IN ('free_app_download', 'revenue', 'paid_app_download')\n  )\n);\n\n\n\n-- map raw with category\nWITH category_mapping_raw AS (\n\nSELECT * from ( select *, 'ios' as mapping_platform from category_mapping_deminsion_service where market_code='apple-store' \nUNION ALL select *, 'android' as mapping_platform from category_mapping_deminsion_service where market_code='apple-store'\n ) as mapping full outer join pivot_metric_raw on mapping.legacy_category_id=pivot_metric_raw.raw_category_id and \nmapping.mapping_platform=pivot_metric_raw.platform\n);\n\n\n\n-- union all platform with country_code mapping\n\nWITH country_code_mapping AS (\nselect *, 'android' as market_code from android_country_mapping \nUNION ALL select *, 'ios' market_code from ios_country_mapping\n);\n\n\n\n-- map raw with country_code\n\nWITH country_category_mapping_raw AS (\nselect date, country_code,device_code,category_id,free_app_download,paid_app_download,revenue from country_code_mapping full outer join category_mapping_raw on country_code_mapping.store_id=category_mapping_raw.raw_store_id and country_code_mapping.market_code=category_mapping_raw.platform\n);\n\n-- group by unified data\nWITH unified_group_data AS (\nselect count(app_id) as unified_count_app_id, count(free_app_download) as unified_count_free_app_download, count(paid_app_download) as unified_count_paid_app_download, count(revenue) as unified_count_revenue,\n  country_code as unified_country_code, device_code as unified_device_code, category_id as unified_category_id from ( select distinct  app_id, free_app_download, paid_app_download, revenue, country_code, device_code, category_id from  rank_unified ) as unified\ngroup by  category_id,  country_code,  device_code );\n\n\n\n-- compare raw vs unified data\nWITH compared_data AS (\n    SELECT * from country_category_mapping_raw left join unified_group_data on unified_group_data.unified_country_code==country_category_mapping_raw.country_code and unified_group_data.unified_category_id==country_category_mapping_raw.category_id and unified_group_data.unified_device_code==country_category_mapping_raw.device_code\n);\n\nWITH miss_data AS (\nselect * from compared_data where unified_count_paid_app_download!=paid_app_download or unified_count_free_app_download != free_app_download  or unified_count_revenue != revenue or unified_count_app_id is null\n)\n\n\"\"\"\n# PGPASSWORD='dNzWtSV3pKTx' psql -h 10.2.10.132  -U citus_bdp_usage_qa -d aa_citus_db -p 5432 << EOF \n# set search_path=store;\n\n# select * from store.store_est_fact_v2 where country_code='US' and app_id='835599320' and granularity='daily' and date='2020-03-28' ;\n\n# EOF\n\n# WITH domain_id_name_mapping AS (\n#     SELECT\n#         db_table(\n#             engine=\"plproxy\",\n#             database=\"aa\",\n#             sql=\"SELECT domain_id AS domain_id, name AS domain_name FROM aa_domain_metadata WHERE is_disabled IN ('f') and sensitive_status IN (0)\"\n#         )\n# );\n\n\n\n# WITH store_db AS (\n#     SELECT\n#         db_table(\n#             engine=\"CITUS\",\n#             database=\"AA_CITUS\",\n#             sql=\"select * from store.store_est_fact_v2 \"\n#         )\n# );\n\n\ntest_date='2020-03-24'\nnamespace = \"aa.store.market-size.v1\"\ningest_msg = {\n    \"namespace\": \"aa.store.market-size.v1\",\n    \"job_type\": \"routine\",\n    \"options\":{},\n    \"source\": [\n        {\n            \"name\":\"rank_raw\",\n            \"data_encoding\": \"parquet\",\n            \"compression\": \"gzip\",\n            \"path\": [\"s3://b2c-prod-dca-store-estimates/store_estv2/APP_ESTIMATES_FINAL/version=2.0.0/range_type=DAY/date={}/\".format(test_date)],\n        },        {\n            \"data_encoding\": \"parquet\",\n            \"compression\": \"gzip\",\n          \"name\":\"rank_unified\",\n            \"path\": [\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est-category-rank.v1/fact/granularity=daily/date={}\".format(test_date)],\n        },   \n        {\n            \"data_encoding\": \"parquet\",\n            \"compression\": \"gzip\",\n          \"name\":\"store_unified\",\n            \"path\": [\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/granularity=daily/date={}\".format(test_date)],\n        },\n        {\n            \"data_encoding\": \"parquet\",\n            \"compression\": \"gzip\",\n          \"name\":\"category_mapping_deminsion_service\",\n            \"path\": [\"s3://b2c-prod-data-pipeline-qa/aa.store/store_cateogry_mapping\"],\n        },   \n        {\n            \"data_encoding\": \"csv\",\n            \"compression\": \"gzip\",\n            \"name\":\"ios_country_mapping\",\n            \"data_schema\": [\n                            {\"name\":\"store_id\",\"type\":\"int\",\"nullable\": False},\n                            {\"name\":\"country_code\",\"type\":\"string\",\"nullable\": False},\n                            {\"name\":\"country_name\",\"type\":\"string\",\"nullable\": False}\n                            ],\n             \"csv_options\": {\n           'header': True,\n           'sep': '\\t',\n           'quote': '',\n           'encoding': 'utf-8',\n           'escape': ''\n           },\n\n            \"path\": [\"s3://b2c-prod-dca-store-estimates/store_back/dimension/IOS_COUNTRY_MAPPING\"],\n        },   \n        {\n            \"data_encoding\": \"csv\",\n            \"compression\": \"gzip\",\n            \"name\":\"android_country_mapping\",\n            \"data_schema\": [\n                            {\"name\":\"store_id\",\"type\":\"int\",\"nullable\": False},\n                            {\"name\":\"country_code\",\"type\":\"string\",\"nullable\": False},\n                            {\"name\":\"country_name\",\"type\":\"string\",\"nullable\": False}\n                            ],\n             \"csv_options\": {\n           'header': True,\n           'sep': '\\t',\n           'quote': '',\n           'encoding': 'utf-8',\n           'escape': ''\n           },\n\n            \"path\": [\"s3://b2c-prod-dca-store-estimates/store_back/dimension/ANDROID_COUNTRY_MAPPING\"],\n        }\n    ]\n}\nrun(spark, ingest_msg, sql_text)\nresult = spark.sql(\"select * from miss_data\")\n\n\nresult.write.format(\"delta\").save(\"s3://b2c-prod-data-pipeline-qa/aa.store/result_store_v1/\",mode=\"append\",\n            partitionBy=[\"date\"])\n\n\n# s3://b2c-prod-data-pipeline-qa/aa.store/result_store_v1\n"]},{"cell_type":"code","execution_count":0,"id":"20200402-094547_1222413895","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql import types as T\nfrom pyspark.sql import functions as F\n\nfrom aadatapipelinecore.core.urn import Urn\nfrom aadatapipelinecore.core.pipeline import type_\nfrom applications.common.parser import SqlParser\nfrom applications.common.executor import SqlExecutor\nfrom applications.auto_pipeline.transform import _view\n\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nimport aaplproxy\n\nclass DryRunSqlExecutor(SqlExecutor):\n    def _verify_tasks(self):\n        pass\ndef run(spark, raw_data, sql_text, dry_run=True):\n    urn = Urn(namespace=raw_data[\"namespace\"])\n    source_data_list = raw_data.pop(\"source\")\n    raw_data.update(raw_data.pop(\"options\"))\n    _view(spark, sql_text, None, source_data_list)\n    context = raw_data\n    tasks = SqlParser(spark, sql_text, context).parse()\n    if dry_run:\n        sql_executor = DryRunSqlExecutor\n    else:\n        sql_executor = SqlExecutor\n    sql_executor(urn, spark, tasks, type_.EventType.TRANSFORM, context).run()\nsql_text = \"\"\"\n-- mapping feed as metrc in raw\nWITH feed_metric_store AS (\nselect *, 'free_app_download' as metric, \"ios-phone\" as device_code from rank_raw where  feed='0' and platform='ios'\nUNION ALL\nselect *, 'paid_app_download' as metric, \"ios-phone\" as device_code from rank_raw where  feed='1' and platform='ios'\nUNION ALL\nselect *, 'revenue' as metric , \"ios-phone\" as device_code from rank_raw where  feed='2' and platform='ios'\nUNION ALL\nselect *, 'free_app_download' as metric, \"ios-tablet\" as device_code from rank_raw where  feed='101' and platform='ios'\nUNION ALL\nselect *, 'paid_app_download' as metric, \"ios-tablet\" as device_code from rank_raw  where  feed='100' and platform='ios'\nUNION ALL\nselect *, 'revenue' as metric, \"ios-tablet\" as device_code from rank_raw  where  feed='102' and platform='ios'\nUNION ALL\nselect *, 'free_app_download' as metric, \"ios-all\" as device_code from rank_raw  where  feed='1000' and platform='ios'\nUNION ALL\nselect *, 'paid_app_download' as metric, \"ios-all\" as device_code from rank_raw  where  feed='1001' and platform='ios'\nUNION ALL\nselect *, 'revenue' as metric, \"ios-all\" as device_code from rank_raw  where  feed='1002' and platform='ios'\nUNION ALL\nselect *, 'free_app_download' as metric , \"android-all\" as device_code from rank_raw   where  feed='0' and platform='android'\nUNION ALL\nselect *, 'paid_app_download' as metric, \"android-all\" as device_code from rank_raw  where  feed='1' and platform='android'\nUNION ALL\nselect *, 'revenue' as metric,  \"android-all\" as device_code from rank_raw  where  feed='2' and platform='android'\n);\n\n\n-- select tested column from raw data\nWITH metric_raw_store_data AS (\nSELECT distinct id, est, store_id as raw_store_id , metric,device_code,date , platform from feed_metric_store\n);\n\n\n-- group by and count data in raw data\nWITH group_by_store_raw AS (\nSELECT count(est) AS total_count ,raw_store_id, metric,device_code,date,platform from metric_raw_store_data where raw_store_id not in (0,3,4,5,6, 1000, 1003, 1005, 1006,1007) group by raw_store_id, metric,device_code,date, platform\n);\n\n\n-- pivot metric column\nWITH pivot_metric_store_raw AS (\n\nSELECT \nfree_app_download,revenue, paid_app_download,raw_store_id,device_code, platform\nFROM\n      group_by_store_raw\n PIVOT (\n    max(total_count) \n\tFOR metric IN ('free_app_download','revenue', 'paid_app_download')\n  )\n);\n\n\n-- union all platform with country_code mapping\n\nWITH country_code_mapping AS (\nselect *, 'android' as market_code from android_country_mapping \nUNION ALL select *, 'ios' market_code from ios_country_mapping\n);\n\n\n\n-- map raw with country_code\n\nWITH country_mapping_store_raw AS (\nselect country_code,device_code,free_app_download,paid_app_download,revenue from country_code_mapping full outer join pivot_metric_store_raw on country_code_mapping.store_id=pivot_metric_store_raw.raw_store_id and country_code_mapping.market_code=pivot_metric_store_raw.platform\n);\n\n\n\n-- group by unified data\nWITH unified_group_data_store AS (\nselect count(app_id) as unified_count_app_id, count(free_app_download) as unified_count_free_app_download, count(paid_app_download) as unified_count_paid_app_download, count(revenue) as unified_count_revenue,\n  country_code, device_code  from ( select distinct  app_id, free_app_download, paid_app_download, revenue, country_code, device_code from  store_unified ) as unified\ngroup by   country_code,  device_code );\n\n\n\n-- compare raw vs unified data\nWITH compared_store_data AS (\n    SELECT * from country_mapping_store_raw left join unified_group_data_store on unified_group_data_store.country_code==country_mapping_store_raw.country_code and unified_group_data_store.device_code==country_mapping_store_raw.device_code\n);\n\n\nWITH miss_data AS (\nselect * from compared_store_data where free_app_download!=unified_count_free_app_download or paid_app_download!=unified_count_paid_app_download or revenue!=unified_count_revenue or unified_count_app_id is null\n)\n\n\n\"\"\"\n\n\n# store_unified , rank_unified\nnamespace = \"aa.store.market-size.v1\"\ningest_msg = {\n    \"namespace\": \"aa.store.market-size.v1\",\n    \"job_type\": \"routine\",\n    \"options\":{},\n    \"source\": [\n        {\n            \"name\":\"rank_raw\",\n            \"data_encoding\": \"parquet\",\n            \"compression\": \"gzip\",\n            \"path\": [\"s3://b2c-prod-dca-store-estimates/store_estv2/APP_ESTIMATES_FINAL/version=2.0.0/range_type=DAY/date=2020-03-28/\"],\n        },        {\n            \"data_encoding\": \"parquet\",\n            \"compression\": \"gzip\",\n          \"name\":\"store_unified\",\n            \"path\": [\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/granularity=daily/date=2020-03-28\"],\n        },        {\n            \"data_encoding\": \"parquet\",\n            \"compression\": \"gzip\",\n          \"name\":\"category_mapping_deminsion_service\",\n            \"path\": [\"s3://b2c-prod-data-pipeline-qa/aa.store/store_cateogry_mapping\"],\n        }, \n        {\n            \"data_encoding\": \"parquet\",\n            \"compression\": \"gzip\",\n          \"name\":\"rank_unified\",\n            \"path\": [\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est-category-rank.v1/fact/granularity=daily/date=2020-03-28\"],\n        },\n        {\n            \"data_encoding\": \"csv\",\n            \"compression\": \"gzip\",\n            \"name\":\"ios_country_mapping\",\n            \"data_schema\": [\n                            {\"name\":\"store_id\",\"type\":\"int\",\"nullable\": False},\n                            {\"name\":\"country_code\",\"type\":\"string\",\"nullable\": False},\n                            {\"name\":\"country_name\",\"type\":\"string\",\"nullable\": False}\n                            ],\n             \"csv_options\": {\n           'header': True,\n           'sep': '\\t',\n           'quote': '',\n           'encoding': 'utf-8',\n           'escape': ''\n           },\n\n            \"path\": [\"s3://b2c-prod-dca-store-estimates/store_back/dimension/IOS_COUNTRY_MAPPING\"],\n        },   \n        {\n            \"data_encoding\": \"csv\",\n            \"compression\": \"gzip\",\n            \"name\":\"android_country_mapping\",\n            \"data_schema\": [\n                            {\"name\":\"store_id\",\"type\":\"int\",\"nullable\": False},\n                            {\"name\":\"country_code\",\"type\":\"string\",\"nullable\": False},\n                            {\"name\":\"country_name\",\"type\":\"string\",\"nullable\": False}\n                            ],\n             \"csv_options\": {\n           'header': True,\n           'sep': '\\t',\n           'quote': '',\n           'encoding': 'utf-8',\n           'escape': ''\n           },\n\n            \"path\": [\"s3://b2c-prod-dca-store-estimates/store_back/dimension/ANDROID_COUNTRY_MAPPING\"],\n        }\n    ]\n}\nrun(spark, ingest_msg, sql_text)\nspark.sql(\"select * from miss_data \").show()\n\n# spark.sql(\"select * from compared_data where unified_count_paid_app_download!=paid_app_download or unified_count_free_app_download != free_app_download  or unified_count_revenue != revenue\").show(2)\n\n# spark.sql(\"select * from store_db\").show(2)\n\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200409-035613_1541898848","metadata":{},"outputs":[],"source":["\nimport datetime\n\nstart = \"2020-01-01\"\nend = \"2020-01-03\"\nreal_date1 = datetime.date(*[int(x) for x in start.split('-')])\nreal_date2 = datetime.date(*[int(x) for x in end.split('-')])\ndate_range = real_date2 - real_date1\ndates = list()\nfor days in xrange(date_range.days):\n    dates.append(real_date1 + datetime.timedelta(days))\n\nest_list = [ \"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/granularity=daily/date={}\".format(test_date) for test_date in dates ]\nrank_list = [\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est-category-rank.v1/fact/granularity=daily/date={}\".format(test_date) for test_date in dates  ]\nprint est_list\nprint rank_list"]},{"cell_type":"code","execution_count":0,"id":"20200405-072613_40143000","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql import types as T\nfrom pyspark.sql import functions as F\nimport datetime\n\nfrom aadatapipelinecore.core.urn import Urn\nfrom aadatapipelinecore.core.pipeline import type_\nfrom applications.common.parser import SqlParser\nfrom applications.common.executor import SqlExecutor\nfrom applications.auto_pipeline.transform import _view\n\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nimport aaplproxy\n\nclass DryRunSqlExecutor(SqlExecutor):\n    def _verify_tasks(self):\n        pass\ndef run(spark, raw_data, sql_text, dry_run=True):\n    urn = Urn(namespace=raw_data[\"namespace\"])\n    source_data_list = raw_data.pop(\"source\")\n    raw_data.update(raw_data.pop(\"options\"))\n    _view(spark, sql_text, None, source_data_list)\n    context = raw_data\n    tasks = SqlParser(spark, sql_text, context).parse()\n    if dry_run:\n        sql_executor = DryRunSqlExecutor\n    else:\n        sql_executor = SqlExecutor\n    sql_executor(urn, spark, tasks, type_.EventType.TRANSFORM, context).run()\n\n\nstart='2010-07-04'\nend='2013-01-01'\nreal_date1 = datetime.date(*[int(x) for x in start.split('-')])\nreal_date2 = datetime.date(*[int(x) for x in end.split('-')])\ndate_range = real_date2 - real_date1\ndates = list()\nfor days in xrange(date_range.days):\n    dates.append(real_date1 + datetime.timedelta(days))\ndates.reverse()\n\n\ndef test_count(test_date):\n    # test_date = '2017-08-01'\n    namespace = \"aa.store.market-size.v1\"\n    \n    ingest_msg = {\n        \"namespace\": \"aa.store.market-size.v1\",\n        \"job_type\": \"routine\",\n        \"options\": {},\n        \"source\": [\n            {\n                \"data_encoding\": \"parquet\",\n                \"compression\": \"gzip\",\n                \"name\": \"store_unified\",\n                \"path\": [\n                    \"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/granularity=daily/date={}\".format(\n                        test_date)],\n                # \"path\": est_list,\n    \n            }, {\n                \"data_encoding\": \"parquet\",\n                \"compression\": \"gzip\",\n                \"name\": \"rank_unified\",\n                \"path\": [\n                    \"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est-category-rank.v1/fact/granularity=daily/date={}\".format(\n                        test_date)],\n                # \"path\": rank_list,\n    \n            }, {\n                \"data_encoding\": \"parquet\",\n                \"compression\": \"gzip\",\n                \"name\": \"category_mapping_deminsion_service\",\n                \"path\": [\"s3://b2c-prod-data-pipeline-qa/aa.store/store_cateogry_mapping\"],\n            },\n            {\n                \"data_encoding\": \"csv\",\n                \"compression\": \"gzip\",\n                \"name\": \"ios_country_mapping\",\n                \"data_schema\": [\n                    {\"name\": \"store_id\", \"type\": \"int\", \"nullable\": False},\n                    {\"name\": \"country_code\", \"type\": \"string\", \"nullable\": False},\n                    {\"name\": \"country_name\", \"type\": \"string\", \"nullable\": False}\n                ],\n                \"csv_options\": {\n                    'header': True,\n                    'sep': '\\t',\n                    'quote': '',\n                    'encoding': 'utf-8',\n                    'escape': ''\n                },\n    \n                \"path\": [\"s3://b2c-prod-dca-store-estimates/store_back/dimension/IOS_COUNTRY_MAPPING\"],\n            },\n            {\n                \"data_encoding\": \"csv\",\n                \"compression\": \"gzip\",\n                \"name\": \"android_country_mapping\",\n                \"data_schema\": [\n                    {\"name\": \"store_id\", \"type\": \"int\", \"nullable\": False},\n                    {\"name\": \"country_code\", \"type\": \"string\", \"nullable\": False},\n                    {\"name\": \"country_name\", \"type\": \"string\", \"nullable\": False}\n                ],\n                \"csv_options\": {\n                    'header': True,\n                    'sep': '\\t',\n                    'quote': '',\n                    'encoding': 'utf-8',\n                    'escape': ''\n                },\n    \n                \"path\": [\"s3://b2c-prod-dca-store-estimates/store_back/dimension/ANDROID_COUNTRY_MAPPING\"],\n            }\n        ]\n    }\n    \n    sql_text = \"\"\"\n    \n    \n    -- rank_unified,store_unified\n    WITH unified_data_test AS \n    ( \n                    SELECT          store_unified.country_code, \n                                    store_unified.device_code, \n                                    store_unified.free_app_download AS est_free_app_download , \n                                    store_unified.paid_app_download AS est_paid_app_download, \n                                    store_unified.revenue           AS est_revenue, \n                                    store_unified.revenue_iap       AS est_revenue_iap, \n                                    store_unified.revenue_non_iap   AS est_revenue_non_iap, \n                                    rank_unified.category_id, \n                                    rank_unified.app_id, \n                                    rank_unified.free_app_download, \n                                    rank_unified.paid_app_download, \n                                    rank_unified.revenue, \n                                    rank_unified.revenue_iap, \n                                    rank_unified.revenue_non_iap, \n                                    rank_unified.granularity, \n                                    rank_unified.date \n                    FROM            rank_unified \n                    FULL OUTER JOIN store_unified \n                    ON              rank_unified.app_id = store_unified.app_id \n                    AND             rank_unified.country_code = store_unified.country_code \n                    AND             rank_unified.device_code = store_unified.device_code \n                    AND             rank_unified.date = store_unified.date );\n    \n    \n    \n    WITH unified_rank_filter_data_free_app_download AS \n    ( \n           SELECT * \n           FROM   unified_data_test \n           WHERE ( ( ( \n                                free_app_download<=1000 \n                         AND    country_code!=\"WW\" ) \n                  OR     ( \n                                free_app_download<=4000 \n                         AND    country_code==\"WW\" ) ) \n           OR     ( ( \n                                paid_app_download<=1000 \n                         AND    country_code!=\"WW\" ) \n                  OR     ( \n                                paid_app_download<=4000 \n                         AND    country_code==\"WW\" ) ) \n           OR     ( ( \n                                revenue<=1000 \n                         AND    country_code!=\"WW\" ) \n                  OR     ( \n                                revenue<=4000 \n                         AND    country_code==\"WW\" ) ) )\n           AND    device_code!='ios-all'\n    );\n    \n    \n    \n           WITH unified_category_filter_data_free_app_download AS \n    ( \n           SELECT * ,\n           CASE WHEN (free_app_download > 1000 and country_code !='WW') or (free_app_download > 4000 and country_code =='WW' ) or (free_app_download is null or free_app_download <= 0) Then null else est_free_app_download END as est_free_app_download_category,\n           CASE WHEN (paid_app_download > 1000 and country_code !='WW') or (paid_app_download > 4000 and country_code =='WW' ) or (paid_app_download is null or paid_app_download <= 0) Then null else est_paid_app_download END as est_paid_app_download_category,\n           CASE WHEN (revenue > 1000 and country_code !='WW') or (revenue > 4000 and country_code =='WW') or (revenue is null or revenue <= 0) Then null else est_revenue  END as est_revenue_category\n           FROM   unified_rank_filter_data_free_app_download \n\n\n    );    \n\n    \n    \"\"\"\n\n\n    run(spark, ingest_msg, sql_text)\n    # current est test:\n    free_app_download_count = spark.sql(\n        \"select count(app_id) from (select distinct app_id, country_code, device_code, est_free_app_download from unified_rank_filter_data_free_app_download where est_free_app_download is not null ) as test\").take(\n        1)\n    paid_app_download_count = spark.sql(\n        \"select count(app_id) from (select distinct app_id, country_code, device_code, est_paid_app_download from unified_rank_filter_data_free_app_download where est_paid_app_download is not null ) as test\").take(\n        1)\n    revenue_count = spark.sql(\n        \"select count(app_id) from (select distinct app_id, country_code, device_code, est_revenue from unified_rank_filter_data_free_app_download where est_revenue is not null ) as test \").take(\n        1)\n        \n        \n\n    free_app_download_category_count = spark.sql(\n        \"select count(*) from (select app_id, country_code, device_code, category_id, est_free_app_download from unified_category_filter_data_free_app_download where est_free_app_download_category is not null ) as test\").take(\n        1)\n    paid_app_download_category_count = spark.sql(\n        \"select count(*) from (select app_id, country_code, device_code, category_id, est_paid_app_download from unified_category_filter_data_free_app_download where est_paid_app_download_category is not null ) as test\").take(\n        1)\n    revenue_category_count = spark.sql(\n        \"select count(*) from (select app_id, country_code, device_code, category_id, est_revenue from unified_category_filter_data_free_app_download where est_revenue_category is not null ) as test \").take(\n        1)\n    \n    import psycopg2\n    import datetime\n    \n    spark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\n    import aaplproxy\n    from aadatapipelinecore.core.urn import Urn\n    from aaplproxy.da.local_sqlrunner import LocalSqlRunner\n    from aadatapipelinecore.core.utils.module import application_settings\n    from pyspark.sql import Row\n    \n    \n    def citus_row_category(date, country_code, market_code, device_code, category_id, metric_name):\n        def get_data_in_citus(date, country_code, market_code, device_code, category_id, metric_name):\n            citus_dsn_ = (\n                \"dbname='{db}' user='{user}' password='{password}' \"\n                \"host='{host}' port='{port}'\".format(\n                    db=\"aa_store_db\",\n                    user=\"citus_bdp_prod_app_int_qa\",\n                    host=\"10.2.10.254\",\n                    password=\"wZw8cfBuuklIskVG\",\n                    port=5432\n                )\n            )\n            # sql_category = \"select * from ( select app_id,country_code,device_code,category_id, date,{} as estimate from  store.store_est_category_fact_v1 where granularity='daily' and date='{}' and device_code='{}' and {} is not null and country_code='{}' and category_id={} ) as category_count \".format(metric_name, date, device_code, metric_name, country_code, category_id )\n            # sql_est = \"select * from ( select app_id,country_code,device_code,date,{} as estimate from  store.store_est_fact_v3 where granularity='daily' and date='{}' and device_code='{}' and {} is not null and country_code='{}' ) as est_count \".format(metric_name, date, device_code, metric_name, country_code )\n            # sql_category=\"select * from store.store_est_category_fact_v1 limit 1\"\n            # sql_est = \"select app_id from ( select distinct app_id, country_code,device_code, est_free_app_download from store.store_est_fact_v1  where date='2019-08-01' and granularity='daily' and est_free_app_download is not null and country_code='WW' and device_code='ios-phone' ) as prod \"\n            # sql_est = \"select app_id from ( select distinct app_id, country_code,device_code, est_free_app_download from store.store_est_fact_v1  where date='2019-08-01' and granularity='daily' and est_free_app_download is not null ) as prod \"\n            sql_est_free = \"select count(*) from store.store_est_fact_v6 where date='{}' and granularity='daily' and est_free_app_download is not null \".format(\n                date)\n            sql_est_paid = \"select count(*) from store.store_est_fact_v6 where date='{}' and granularity='daily' and est_paid_app_download is not null \".format(\n                date)\n            sql_est_download = \"select count(*) from store.store_est_fact_v6 where date='{}' and granularity='daily' and est_revenue is not null \".format(\n                date)\n                \n            sql_category_free = \"select count(*) from store.store_est_category_fact_v6 where date='{}' and granularity='daily' and est_free_app_download is not null\".format(\n                date)\n            sql_category_paid = \"select count(*) from store.store_est_category_fact_v6 where date='{}' and granularity='daily' and est_paid_app_download is not null\".format(\n                date)\n            sql_category_revenue = \"select count(*) from store.store_est_category_fact_v6 where date='{}' and granularity='daily' and est_revenue is not null\".format(\n                date)\n                \n            sql_est_app_count = \"select count (distinct app_id) from store.store_est_fact_v6 where date='{}' and granularity='daily' \".format(date) ; \n            sql_category_app_count = \"select count (distinct app_id) from store.store_est_category_fact_v6 where date='{}' and granularity='daily' \".format(date) ; \n\n\n            sql_est_app_count = \"select count (distinct app_id) from store.store_est_fact_v6 where date='{}' and granularity='daily' \".format(date) ; \n            sql_category_app_count = \"select count (distinct app_id) from store.store_est_category_fact_v6 where date='{}' and granularity='daily' \".format(date) ; \n\n\n\n            # db_category_count_result = ''  # query(citus_dsn_, sql_category)\n    \n            query_list = [sql_est_free, sql_est_paid, sql_est_download]\n            data_est_count_result = [query(citus_dsn_, sql) for sql in query_list]\n            \n            query_list_category = [sql_category_free, sql_category_paid, sql_category_revenue]\n            data_category_count_result = [query(citus_dsn_, sql) for sql in query_list_category]\n\n            data_est_app_id_count_result = query(citus_dsn_, sql_est_app_count)\n            data_category_app_id_count_result = query(citus_dsn_, sql_category_app_count)\n\n    \n            # print 'running.....'\n            return data_category_count_result, data_est_count_result, data_est_app_id_count_result, data_category_app_id_count_result\n    \n        def query(dsn, sql):\n            with psycopg2.connect(dsn) as conn:\n                conn.autocommit = True\n                with conn.cursor() as cur:\n                    cur.execute(sql)\n                    result = cur.fetchall()\n                    conn.commit()\n            return result\n    \n        result_category, result_est, result_est_app_count, result_category_app_count = get_data_in_citus(date, country_code, market_code, device_code, category_id,\n                                                        metric_name)\n        return  [ Row(app_id=r[0]) for r in result_category], [Row(app_id=r[0]) for r in result_est], [Row(app_id=result_est_app_count[0])], [Row(app_id=result_category_app_count[0])]\n        # return [ Row(app_id=r[0], country_code=r[1], device_code=r[2], date=r[3], estimate=r[4]) for r in result_est ] , len(result)\n    \n    \n    db_test_result_category, db_test_result_est, db_est_count, db_category_count = citus_row_category(test_date, 'US', 'apple-store', 'ios-phone', 100000,\n                                        'est_free_app_download')\n    \n    unified_result = [free_app_download_count[0][0], paid_app_download_count[0][0], revenue_count[0][0]]\n    db_result = [compare_data[0][0] for compare_data in db_test_result_est]\n    \n    unified_category_result=[free_app_download_category_count[0][0], paid_app_download_category_count[0][0], revenue_category_count[0][0]]\n    db_category_result = [compare_data[0][0] for compare_data in db_test_result_category]\n    \n    # print unified_category_result\n    # print db_category_result\n    from datetime import datetime\n    df_write_result = spark.createDataFrame([('est', test_date.strftime(\"%Y-%m-%d\"), unified_result, db_result), \n                                            (\"category\", test_date.strftime(\"%Y-%m-%d\"), unified_category_result, db_category_result)], \n                                            schema=[\"type\",\"test_date\",\"unified\",\"db\"])\n\n    from aadatapipelinecore.core.utils.retry import retry\n    def write_test_result(df_write_result):\n        df_write_result.write.format(\"delta\").save(\"s3://b2c-prod-data-pipeline-qa/aa.store/result_store_unified_db_count_0430/\",\n                                          mode=\"append\",\n                                          partitionBy=[\"type\"])\n    retry(write_test_result,(df_write_result,),{},interval=10)\n    \n    \n    if unified_result == db_result:\n        print test_date, 'est pass'\n    else:\n        print test_date, 'est failed!!!!!'\n\n\n    if unified_category_result == db_category_result:\n        print test_date, 'category pass'\n    else:\n        print test_date, 'category failed!!!!!'\n\n\n    if db_est_count[0][0] == db_category_count[0][0]:\n        print test_date, 'app_count pass'\n    else:\n        print test_date, 'app_count failed!!!!!'\n\n\n\nsc.parallelize(map(test_count, dates), 1)\n\n# for x in dates:\n#     print x\n#     test_count(x)\n"]},{"cell_type":"code","execution_count":0,"id":"20200505-145908_1402168746","metadata":{},"outputs":[],"source":["%%sh\naws s3 ls s3://b2c-prod-data-pipeline-qa/aa.store/result_store_unified_db_count_0430/ | sort -n"]},{"cell_type":"code","execution_count":0,"id":"20200424-010522_1385281140","metadata":{},"outputs":[],"source":["/\n\nspark.read.parquet(\"s3://b2c-prod-data-pipeline-qa/aa.store/result_store_unified_db_count_0430/part-00004-7e709799-1b0f-4d4a-a301-cb218ade0f92-c000.snappy.parquet\").show()\n"]},{"cell_type":"code","execution_count":0,"id":"20200415-115319_505967324","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql import types as T\nfrom pyspark.sql import functions as F\nimport datetime\n\nfrom aadatapipelinecore.core.urn import Urn\nfrom aadatapipelinecore.core.pipeline import type_\nfrom applications.common.parser import SqlParser\nfrom applications.common.executor import SqlExecutor\nfrom applications.auto_pipeline.transform import _view\n\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nimport aaplproxy\n\nclass DryRunSqlExecutor(SqlExecutor):\n    def _verify_tasks(self):\n        pass\ndef run(spark, raw_data, sql_text, dry_run=True):\n    urn = Urn(namespace=raw_data[\"namespace\"])\n    source_data_list = raw_data.pop(\"source\")\n    raw_data.update(raw_data.pop(\"options\"))\n    _view(spark, sql_text, None, source_data_list)\n    context = raw_data\n    tasks = SqlParser(spark, sql_text, context).parse()\n    if dry_run:\n        sql_executor = DryRunSqlExecutor\n    else:\n        sql_executor = SqlExecutor\n    sql_executor(urn, spark, tasks, type_.EventType.TRANSFORM, context).run()\n\n\nstart='2020-03-02'\nend='2020-04-01'\nreal_date1 = datetime.date(*[int(x) for x in start.split('-')])\nreal_date2 = datetime.date(*[int(x) for x in end.split('-')])\ndate_range = real_date2 - real_date1\ndates = list()\nfor days in xrange(date_range.days):\n    dates.append(real_date1 + datetime.timedelta(days))\n\n\ndef test_count(test_date):\n    # test_date = '2017-08-01'\n    namespace = \"aa.store.market-size.v1\"\n    \n    ingest_msg = {\n        \"namespace\": \"aa.store.market-size.v1\",\n        \"job_type\": \"routine\",\n        \"options\": {},\n        \"source\": [\n            {\n                \"data_encoding\": \"parquet\",\n                \"compression\": \"gzip\",\n                \"name\": \"store_unified\",\n                \"path\": [\n                    \"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/granularity=daily/date={}\".format(\n                        test_date)],\n                # \"path\": est_list,\n    \n            }, {\n                \"data_encoding\": \"parquet\",\n                \"compression\": \"gzip\",\n                \"name\": \"rank_unified\",\n                \"path\": [\n                    \"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est-category-rank.v1/fact/granularity=daily/date={}\".format(\n                        test_date)],\n                # \"path\": rank_list,\n    \n            }, {\n                \"data_encoding\": \"parquet\",\n                \"compression\": \"gzip\",\n                \"name\": \"category_mapping_deminsion_service\",\n                \"path\": [\"s3://b2c-prod-data-pipeline-qa/aa.store/store_cateogry_mapping\"],\n            },\n            {\n                \"data_encoding\": \"csv\",\n                \"compression\": \"gzip\",\n                \"name\": \"ios_country_mapping\",\n                \"data_schema\": [\n                    {\"name\": \"store_id\", \"type\": \"int\", \"nullable\": False},\n                    {\"name\": \"country_code\", \"type\": \"string\", \"nullable\": False},\n                    {\"name\": \"country_name\", \"type\": \"string\", \"nullable\": False}\n                ],\n                \"csv_options\": {\n                    'header': True,\n                    'sep': '\\t',\n                    'quote': '',\n                    'encoding': 'utf-8',\n                    'escape': ''\n                },\n    \n                \"path\": [\"s3://b2c-prod-dca-store-estimates/store_back/dimension/IOS_COUNTRY_MAPPING\"],\n            },\n            {\n                \"data_encoding\": \"csv\",\n                \"compression\": \"gzip\",\n                \"name\": \"android_country_mapping\",\n                \"data_schema\": [\n                    {\"name\": \"store_id\", \"type\": \"int\", \"nullable\": False},\n                    {\"name\": \"country_code\", \"type\": \"string\", \"nullable\": False},\n                    {\"name\": \"country_name\", \"type\": \"string\", \"nullable\": False}\n                ],\n                \"csv_options\": {\n                    'header': True,\n                    'sep': '\\t',\n                    'quote': '',\n                    'encoding': 'utf-8',\n                    'escape': ''\n                },\n    \n                \"path\": [\"s3://b2c-prod-dca-store-estimates/store_back/dimension/ANDROID_COUNTRY_MAPPING\"],\n            }\n        ]\n    }\n    \n    sql_text = \"\"\"\n    \n    \n    -- rank_unified,store_unified\n    WITH unified_data_test AS \n    ( \n                    SELECT          store_unified.country_code, \n                                    store_unified.device_code, \n                                    store_unified.free_app_download AS est_free_app_download , \n                                    store_unified.paid_app_download AS est_paid_app_download, \n                                    store_unified.revenue           AS est_revenue, \n                                    store_unified.revenue_iap       AS est_revenue_iap, \n                                    store_unified.revenue_non_iap   AS est_revenue_non_iap, \n                                    rank_unified.category_id, \n                                    rank_unified.app_id, \n                                    rank_unified.free_app_download, \n                                    rank_unified.paid_app_download, \n                                    rank_unified.revenue, \n                                    rank_unified.revenue_iap, \n                                    rank_unified.revenue_non_iap, \n                                    rank_unified.granularity, \n                                    rank_unified.date \n                    FROM            rank_unified \n                    FULL OUTER JOIN store_unified \n                    ON              rank_unified.app_id = store_unified.app_id \n                    AND             rank_unified.country_code = store_unified.country_code \n                    AND             rank_unified.device_code = store_unified.device_code \n                    AND             rank_unified.date = store_unified.date );\n    \n    \n    \n    WITH unified_rank_filter_data_free_app_download AS \n    ( \n           SELECT * \n           FROM   unified_data_test \n           WHERE ( ( ( \n                                free_app_download<=1000 \n                         AND    country_code!=\"WW\" ) \n                  OR     ( \n                                free_app_download<=4000 \n                         AND    country_code==\"WW\" ) ) \n           OR     ( ( \n                                paid_app_download<=1000 \n                         AND    country_code!=\"WW\" ) \n                  OR     ( \n                                paid_app_download<=4000 \n                         AND    country_code==\"WW\" ) ) \n           OR     ( ( \n                                revenue<=1000 \n                         AND    country_code!=\"WW\" ) \n                  OR     ( \n                                revenue<=4000 \n                         AND    country_code==\"WW\" ) ) )\n           AND    device_code!='ios-all'\n\n    );\n    \n    \n       WITH unified_category_filter_data_free_app_download AS \n    ( \n           SELECT * ,\n           CASE WHEN (free_app_download > 1000 and country_code !='WW') or (free_app_download > 4000 and country_code =='WW' ) Then null else est_free_app_download END as est_free_app_download_category,\n           CASE WHEN (paid_app_download > 1000 and country_code !='WW') or (paid_app_download > 4000 and country_code =='WW' ) Then null else est_paid_app_download END as est_paid_app_download_category,\n           CASE WHEN (revenue > 1000 and country_code !='WW') or (revenue > 4000 and country_code =='WW') Then null else est_revenue  END as est_revenue_category\n           FROM   unified_rank_filter_data_free_app_download \n\n\n    );    \n\n    \n    \n    \n    \"\"\"\n    \n#     [9049417, 1914843, 5070231]\n# [8620540L, 1901239L, 4578835L]\n\n# [9049417, 1914843, 5070231]\n# [8620540L, 1901239L, 4578835L]\n\n\n    run(spark, ingest_msg, sql_text)\n \n        \n    # spark.sql(\n    #     \"select * from (select app_id, country_code, device_code, category_id, est_free_app_download from unified_rank_filter_data_free_app_download where est_free_app_download is not null ) as test\").show()\n    # free_app_download_category_count = spark.sql(\n    #     \"select * from (select app_id, country_code, device_code, category_id, est_free_app_download from unified_rank_filter_data_free_app_download where est_free_app_download is not null and category_id=100000 ) as test\").show(2000000)\n        \n    free_app_download_category_count = spark.sql(\n        \"select * from unified_category_filter_data_free_app_download where paid_app_download is null   \").show()\n\n    # paid_app_download_category_count = spark.sql(\n    #     \"select count(*) from (select app_id, country_code, device_code, category_id, est_paid_app_download from unified_rank_filter_data_free_app_download where est_paid_app_download is not null ) as test\").take(\n    #     1)\n    # revenue_category_count = spark.sql(\n    #     \"select count(*) from (select app_id, country_code, device_code, category_id, est_revenue from unified_rank_filter_data_free_app_download where est_revenue is not null ) as test \").take(\n    #     1)\n    \n    # import psycopg2\n    # import datetime\n    \n    # spark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\n    # import aaplproxy\n    # from aadatapipelinecore.core.urn import Urn\n    # from aaplproxy.da.local_sqlrunner import LocalSqlRunner\n    # from aadatapipelinecore.core.utils.module import application_settings\n    # from pyspark.sql import Row\n    \n    \n    # def citus_row_category(date, country_code, market_code, device_code, category_id, metric_name):\n    #     def get_data_in_citus(date, country_code, market_code, device_code, category_id, metric_name):\n    #         citus_dsn_ = (\n    #             \"dbname='{db}' user='{user}' password='{password}' \"\n    #             \"host='{host}' port='{port}'\".format(\n    #                 db=\"aa_store_db\",\n    #                 user=\"citus_bdp_prod_app_int_qa\",\n    #                 host=\"10.2.10.254\",\n    #                 password=\"wZw8cfBuuklIskVG\",\n    #                 port=5432\n    #             )\n    #         )\n\n    #         sql_category_free = \"select count(*) from store.store_est_category_fact_v1 where date='{}' and granularity='daily' and est_free_app_download  is not null and country_code='AE' and device_code='ios-phone' and category_id=100000\".format(\n    #             date)\n    #         # sql_category_paid = \"select count(*) from store.store_est_category_fact_v1 where date='{}' and granularity='daily' and est_paid_app_download is not null and country_code='AE' and device_code='ios-phone'\".format(\n    #         #     date)\n    #         # sql_category_revenue = \"select count(*) from store.store_est_category_fact_v1 where date='{}' and granularity='daily' and est_revenue is not null and country_code='AE' and device_code='ios-phone'\".format(\n    #         #     date)\n\n    #         # db_category_count_result = ''  # query(citus_dsn_, sql_category)\n    \n    #         # query_list = [sql_est_free, sql_est_paid, sql_est_download]\n    #         # data_est_count_result = [query(citus_dsn_, sql) for sql in query_list]\n            \n    #         # query_list_category = [sql_category_free, sql_category_paid, sql_category_revenue]\n    #         # data_category_count_result = [query(citus_dsn_, sql) for sql in query_list_category]\n    #         query_list_category = [sql_category_free]\n    #         data_category_count_result = [query(citus_dsn_, sql) for sql in query_list_category]\n\n    \n    #         print 'running.....'\n    #         return data_category_count_result, []\n    \n    #     def query(dsn, sql):\n    #         with psycopg2.connect(dsn) as conn:\n    #             conn.autocommit = True\n    #             with conn.cursor() as cur:\n    #                 cur.execute(sql)\n    #                 result = cur.fetchall()\n    #                 conn.commit()\n    #         return result\n    \n    #     result_category, result_est = get_data_in_citus(date, country_code, market_code, device_code, category_id,\n    #                                                     metric_name)\n    #     return  [ Row(app_id=r[0]) for r in result_category], [\"\"]\n    #     # return [ Row(app_id=r[0], country_code=r[1], device_code=r[2], date=r[3], estimate=r[4]) for r in result_est ] , len(result)\n    \n    \n    # db_test_result_category, db_test_result_est = citus_row_category(test_date, 'US', 'apple-store', 'ios-phone', 100000,\n    #                                     'est_free_app_download')\n    \n    # #unified_result = [free_app_download_count[0][0], paid_app_download_count[0][0], revenue_count[0][0]]\n    # #db_result = [compare_data[0][0] for compare_data in db_test_result_est]\n    \n    # unified_category_result=[free_app_download_category_count[0][0]]#, paid_app_download_category_count[0][0], revenue_category_count[0][0]]\n    # db_category_result = [compare_data[0][0] for compare_data in db_test_result_category]\n    # print unified_category_result\n    # print db_category_result\n    # # from datetime import datetime\n    # # df_write_result = spark.createDataFrame([(test_date.strftime(\"%Y-%m-%d\"), unified_result, db_result)], schema=[\"test_date\",\"unified\",\"db\"])\n\n    # # from aadatapipelinecore.core.utils.retry import retry\n    # # def write_test_result(df_write_result):\n    # #     df_write_result.write.format(\"delta\").save(\"s3://b2c-prod-data-pipeline-qa/aa.store/result_store_est_unified_db_count/\",\n    # #                                       mode=\"append\",\n    # #                                       partitionBy=[\"test_date\"])\n    # # retry(write_test_result,(df_write_result,),{},interval=10)\n    # # if unified_result == db_result:\n    # #     print test_date, 'est pass'\n    # # else:\n    # #     print test_date, 'est failed'\n\n\n    # if unified_category_result == db_category_result:\n    #     print test_date, 'category pass'\n    # else:\n    #     print test_date, 'category failed'\n\n\n\n\n\nfor x in dates:\n    test_count(x)\n\n\n# # spark.sql(\"select * from unified where app_id='1410134706' \").show()\n# # spark.sql(\"select * from db where app_id='1109868900' \").show()\n\n# spark.sql(\"select count(*) from db\").show(2)\n# spark.sql(\"select count(*) from unified_1\").show(2)\n\n\n\n    # def compared_category():\n    #     spark.sql(\"select * from (select app_id, country_code, device_code, category_id, est_free_app_download from unified_data_with_filter where est_free_app_download is not null ) as test\").show()\n    #     spark.sql(\"select count(app_id) from (select app_id, country_code, device_code, category_id, est_free_app_download from unified_data_with_filter where est_free_app_download is not null ) as test\").show()\n    #     df_unified = spark.sql(\"select distinct app_id from (select distinct app_id, country_code, device_code, free_app_download_count from unified_rank_filter_data_free_app_download where free_app_download_count is not null ) as test\").cache()\n    #     df_unified.createOrReplaceTempView(\"unified_1\")\n\n    #     spark.sql(\"select app_id from db except all select app_id from unified_1\").show()\n    #     spark.sql(\"select app_id from unified_1 except all select app_id from db\").show()\n\n# SET\n#   count  \n# ---------\n#  9729053\n# (1 row)\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200413-131818_1057308982","metadata":{},"outputs":[],"source":["\nIOS_STORE_COUNTRY_MAPPING = [\n    (0, 'WW'), (143575, 'AL'), (143563, 'DZ'), (143564, 'AO'), (143538, 'AI'),\n    (143540, 'AG'), (143505, 'AR'), (143524, 'AM'), (143460, 'AU'), (143445, 'AT'),\n    (143568, 'AZ'), (143539, 'BS'), (143559, 'BH'), (143541, 'BB'), (143565, 'BY'),\n    (143446, 'BE'), (143555, 'BZ'), (143576, 'BJ'), (143542, 'BM'), (143577, 'BT'),\n    (143556, 'BO'), (143525, 'BW'), (143503, 'BR'), (143543, 'VG'), (143560, 'BN'),\n    (143526, 'BG'), (143578, 'BF'), (143579, 'KH'), (143455, 'CA'), (143580, 'CV'),\n    (143544, 'KY'), (143581, 'TD'), (143483, 'CL'), (143465, 'CN'), (143501, 'CO'),\n    (143582, 'CG'), (143495, 'CR'), (143494, 'HR'), (143557, 'CY'), (143489, 'CZ'),\n    (143458, 'DK'), (143545, 'DM'), (143508, 'DO'), (143509, 'EC'), (143516, 'EG'),\n    (143506, 'SV'), (143518, 'EE'), (143583, 'FJ'), (143447, 'FI'), (143442, 'FR'),\n    (143584, 'GM'), (143443, 'DE'), (143573, 'GH'), (143448, 'GR'), (143546, 'GD'),\n    (143504, 'GT'), (143585, 'GW'), (143553, 'GY'), (143510, 'HN'), (143463, 'HK'),\n    (143482, 'HU'), (143558, 'IS'), (143467, 'IN'), (143476, 'ID'), (143449, 'IE'),\n    (143491, 'IL'), (143450, 'IT'), (143511, 'JM'), (143462, 'JP'), (143528, 'JO'),\n    (143517, 'KZ'), (143529, 'KE'), (143493, 'KW'), (143586, 'KG'), (143587, 'LA'),\n    (143519, 'LV'), (143497, 'LB'), (143588, 'LR'), (143520, 'LT'), (143451, 'LU'),\n    (143515, 'MO'), (143530, 'MK'), (143531, 'MG'), (143589, 'MW'), (143473, 'MY'),\n    (143532, 'ML'), (143521, 'MT'), (143590, 'MR'), (143533, 'MU'), (143468, 'MX'),\n    (143591, 'FM'), (143523, 'MD'), (143592, 'MN'), (143547, 'MS'), (143593, 'MZ'),\n    (143594, 'NA'), (143484, 'NP'), (143452, 'NL'), (143461, 'NZ'), (143512, 'NI'),\n    (143534, 'NE'), (143561, 'NG'), (143457, 'NO'), (143562, 'OM'), (143477, 'PK'),\n    (143595, 'PW'), (143485, 'PA'), (143597, 'PG'), (143513, 'PY'), (143507, 'PE'),\n    (143474, 'PH'), (143478, 'PL'), (143453, 'PT'), (143498, 'QA'), (143487, 'RO'),\n    (143469, 'RU'), (143598, 'ST'), (143479, 'SA'), (143535, 'SN'), (143599, 'SC'),\n    (143600, 'SL'), (143464, 'SG'), (143496, 'SK'), (143499, 'SI'), (143601, 'SB'),\n    (143472, 'ZA'), (143466, 'KR'), (143454, 'ES'), (143486, 'LK'), (143548, 'KN'),\n    (143549, 'LC'), (143550, 'VC'), (143554, 'SR'), (143602, 'SZ'), (143456, 'SE'),\n    (143459, 'CH'), (143470, 'TW'), (143603, 'TJ'), (143572, 'TZ'), (143475, 'TH'),\n    (143551, 'TT'), (143536, 'TN'), (143480, 'TR'), (143604, 'TM'), (143552, 'TC'),\n    (143537, 'UG'), (143492, 'UA'), (143481, 'AE'), (143444, 'GB'), (143441, 'US'),\n    (143514, 'UY'), (143566, 'UZ'), (143502, 'VE'), (143471, 'VN'), (143571, 'YE'),\n    (143605, 'ZW'),(143518, 'EE')]\nANDROID_STORE_COUNTRY_MAPPING = [\n    (17, 'AR'), (1, 'AU'), (35, 'AT'), (61, 'AZ'), (11, 'BE'), (18, 'BR'), (47, 'BG'),\n    (2, 'CA'), (13, 'CL'), (3, 'CN'), (52, 'CO'), (64, 'CR'), (80, 'HR'), (36, 'CZ'),\n     (38, 'DK'), (62, 'EC'), (33, 'EG'), (20, 'FI'), (6, 'FR'), (4, 'DE'), (46, 'GR'),\n   (16, 'HK'), (37, 'HU'), (19, 'IN'), (21, 'ID'), (39, 'IE'), (40, 'IL'), (8, 'IT'),\n   (9, 'JP'), (53, 'KZ'), (95, 'KE'), (50, 'KW'), (86, 'LV'), (65, 'LB'), (78, 'LT'),\n   (24, 'MY'), (26, 'MX'), (23, 'NL'), (41, 'NZ'), (74, 'NG'), (42, 'NO'), (54, 'PK'),\n     (56, 'PE'), (31, 'PH'), (28, 'PL'), (43, 'PT'), (84, 'PR'), (73, 'QA'), (44, 'RO'),\n    (22, 'RU'), (51, 'SA'), (32, 'SG'), (45, 'SK'), (14, 'ZA'), (27, 'KR'), (5, 'ES'),\n     (34, 'SE'), (12, 'CH'), (30, 'TW'), (29, 'TH'), (25, 'TR'), (48, 'UA'), (49, 'AE'),\n     (7, 'GB'), (10, 'US'), (15, 'VN'), (1000, 'WW')\n ]\n\nest_list=[\"est_free_app_download\", \"est_paid_app_download\", \"est_revenue\" ]\ndevice_code_list=['ios-phone','ios-tablet']\ndate_list=['2019-08-01']\nl1 = [[d, x[1], 'apple-store' , device_code, est] for x in IOS_STORE_COUNTRY_MAPPING for est in est_list for device_code in device_code_list for d in date_list]\nl2 = [ [d, x[1], 'google-play' , \"android-all\", est] for x in ANDROID_STORE_COUNTRY_MAPPING for est in est_list for d in date_list]\n\ntest_data_list = l1 + l2\n\nprint test_data_list"]},{"cell_type":"code","execution_count":0,"id":"20200413-014323_1310810513","metadata":{},"outputs":[],"source":["\n%sh\nPGPASSWORD='wZw8cfBuuklIskVG' psql -h 10.2.10.254  -U citus_bdp_prod_app_int_qa -d aa_store_db -p 5432 << EOF \nset search_path=store;\n\n--\\d+\n\n--select count(*) from store.store_est_fact_v1 where date='2017-08-01' and granularity='daily' and est_free_app_download is not null   ; \n--select count(*) from store.store_est_fact_v1 where date='2017-08-01' and granularity='daily' and est_paid_app_download is not null  ; \n--select count(*) from store.store_est_fact_v1 where date='2017-08-01' and granularity='daily' and est_revenue is not null ; \n-- select * from store.store_est_category_fact_v1 where date='2020-03-02' and granularity='daily' and device_code='ios-phone' and country_code='AE' and app_id=523365306 and  category_id=100000 limit 3 ; \n\n--select count (distinct app_id) from store.store_est_fact_v1 where date='2020-02-01' and granularity='weekly'   limit 3 ; \n\n\n-- select count (distinct date) from store.store_est_fact_v1 limit 5\n--select * from pg_stat_activity where query is not null limit 10;\n-- select distinct date from store_est_category_fact_v1 order by date asc limit 10\n-- select * from store.store_est_fact_v1 where date='2019-08-01' and est_free_app_download is not null limit 3;\n-- select country_code, count(*) as count_country from ( select distinct app_id, country_code,device_code, est_free_app_download from store.store_est_fact_v1  where date='2019-08-01' and granularity='daily' and est_free_app_download is not null  and device_code='ios-phone') as prod  group by country_code order by count_country asc\n\n-- select app_id from ( select distinct app_id, country_code,device_code, est_free_app_download from store.store_est_fact_v1  where date='2019-08-01' and granularity='daily' and est_free_app_download is not null  and device_code='ios-phone') as prod  group by country_code order by count_country asc\n--select count(*) from ( select distinct app_id, country_code,device_code, est_free_app_download from store.store_est_fact_v1  where date='2019-08-01' and granularity='daily' and est_free_app_download is not null and country_code='GD' and device_code='ios-phone'  ) as prod;\n\n--select count(*) from ( select distinct app_id, country_code,device_code, est_free_app_download from store.store_est_fact_v1  where date='2019-08-01' and granularity='daily' and est_free_app_download is not null  ) as prod;\n\n-- select count(*) from ( select distinct app_id, country_code,device_code, est_paid_app_download from store.store_est_fact_v1  where date='2019-08-01' and granularity='daily' and est_paid_app_download is not null  ) as prod;\n-- select count(*) from ( select distinct app_id, country_code,device_code, est_revenue from store.store_est_fact_v1  where date='2019-08-01' and granularity='daily' and est_revenue is not null  ) as prod;\n\n--select * from store.store_est_fact_v4 where device_code='' limit 10  ;\n--select * from store.store_est_category_fact_v4 where country_code='US' and category_id='100028' and app_id='966030322' and  granularity = 'daily' and date='2020-01-02';\n-- \\d+\n\nexplain (analyze true,buffers true)\nselect * from store.store_est_category_fact_v6 order by date desc limit 3 ; \n\n\nEOF\n"]},{"cell_type":"code","execution_count":0,"id":"20200413-070034_218765311","metadata":{},"outputs":[],"source":["\nimport psycopg2\nimport datetime\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nimport aaplproxy\nfrom aadatapipelinecore.core.urn import Urn\nfrom aaplproxy.da.local_sqlrunner import LocalSqlRunner\nfrom aadatapipelinecore.core.utils.module import application_settings\nfrom pyspark.sql import Row\n\ndef citus_row_category(date, country_code , market_code , device_code, category_id, metric_name):\n    def get_data_in_citus(date, country_code , market_code , device_code, category_id, metric_name):\n        citus_dsn_ = (\n            \"dbname='{db}' user='{user}' password='{password}' \"\n            \"host='{host}' port='{port}'\".format(\n                db=\"aa_store_db\",\n                user=\"citus_bdp_prod_app_int_qa\",\n                host=\"10.2.10.254\",\n                password=\"wZw8cfBuuklIskVG\",\n                port=5432\n            )\n        )\n        # sql_category = \"select * from ( select app_id,country_code,device_code,category_id, date,{} as estimate from  store.store_est_category_fact_v1 where granularity='daily' and date='{}' and device_code='{}' and {} is not null and country_code='{}' and category_id={} ) as category_count \".format(metric_name, date, device_code, metric_name, country_code, category_id )\n        # sql_est = \"select * from ( select app_id,country_code,device_code,date,{} as estimate from  store.store_est_fact_v3 where granularity='daily' and date='{}' and device_code='{}' and {} is not null and country_code='{}' ) as est_count \".format(metric_name, date, device_code, metric_name, country_code )\n        # sql_category=\"select * from store.store_est_category_fact_v1 limit 1\"\n        # sql_est = \"select app_id from ( select distinct app_id, country_code,device_code, est_free_app_download from store.store_est_fact_v1  where date='2019-08-01' and granularity='daily' and est_free_app_download is not null and country_code='WW' and device_code='ios-phone' ) as prod \"\n        # sql_est = \"select app_id from ( select distinct app_id, country_code,device_code, est_free_app_download from store.store_est_fact_v1  where date='2019-08-01' and granularity='daily' and est_free_app_download is not null ) as prod \"\n        # sql_est_free = \"select count(*) from store.store_est_fact_v1 where date='{}' and granularity='daily' and est_free_app_download is not null \".format(date)\n        # sql_est_paid = \"select count(*) from store.store_est_fact_v1 where date='{}' and granularity='daily' and est_paid_app_download is not null \".format(date)\n        # sql_est_download = \"select count(*) from store.store_est_fact_v1 where date='{}' and granularity='daily' and est_revenue is not null \".format(date)\n\n        db_category_count_result = '' #query(citus_dsn_, sql_category)\n        \n        query_list=[sql_est_free, sql_est_paid, sql_est_download]\n        data_est_count_result = [ query(citus_dsn_, sql) for sql in query_list ]\n        \n        print 'running.....'\n        return db_category_count_result , data_est_count_result\n\n    def query(dsn, sql):\n        with psycopg2.connect(dsn) as conn:\n            conn.autocommit = True\n            with conn.cursor() as cur:\n                cur.execute(sql)\n                result = cur.fetchall()\n                conn.commit()\n        return result\n    \n    result_category, result_est = get_data_in_citus(date, country_code , market_code , device_code, category_id, metric_name)\n    return [Row(app_id=r[0]) for r in result_est]\n    # return [ Row(app_id=r[0], country_code=r[1], device_code=r[2], date=r[3], estimate=r[4]) for r in result_est ] , len(result)\n\ndb_test_result = citus_row_category('2018-01-01', 'US' , 'apple-store' , 'ios-phone', 100000, 'est_free_app_download')\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200407-015214_1744037429","metadata":{},"outputs":[],"source":["\nfrom aadatapipelinecore.core.utils.spark import eject_all_caches\n\neject_all_caches(spark)\n"]},{"cell_type":"code","execution_count":0,"id":"20200415-065737_789921617","metadata":{},"outputs":[],"source":["%%sh\n\naws s3 ls s3://b2c-prod-data-pipeline-qa/aa.store/result_store_data_v2_2019-07-14/ | wc -l\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}