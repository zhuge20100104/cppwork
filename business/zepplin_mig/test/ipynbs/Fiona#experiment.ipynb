{"cells":[{"cell_type":"code","execution_count":0,"id":"20200314-065910_1208662314","metadata":{},"outputs":[],"source":["%%sh\naws s3 ls s3://aardvark-prod-dca-data/oss/GAME_CROSS_GENRE_KPI/version=1.0.0/range_type=MONTH/date=2019-07-31/\n \n\n\n\n "]},{"cell_type":"code","execution_count":0,"id":"20200314-060847_863024107","metadata":{},"outputs":[],"source":["\nspark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-usage/unified/usage.genre-cross.v1/fact/granularity=monthly/date=2019-07-31/part-00000-37b7762c-4c94-4290-a335-d1250c347d15.c000.gz.parquet\").show()\n\nspark.read.parquet(\"s3://aardvark-prod-pdx-mdm-to-int/genre_report/version=1.0.0/range_type=MONTH/date=2019-08-31/\").show()"]},{"cell_type":"code","execution_count":0,"id":"20200227-053953_748058085","metadata":{},"outputs":[],"source":["\nfrom applications.db_check_v1.common.constants import query, citus_settings\n\nsql = \"select date, count(1) from aso.aso_sov_search_ads_keyword_fact_v1 where date in (select distinct date FROM aso.aso_sov_search_ads_keyword_fact_v1  where granularity='daily' order by date desc ) group by date order by date;\"\n\nprint query(citus_settings(\"aa\"), sql)\n"]},{"cell_type":"code","execution_count":0,"id":"20200210-091214_1414497999","metadata":{},"outputs":[],"source":["\nfrom aadatapipelinecore.core.log import logger\n\nimport unittest\nfrom pyspark.sql.utils import AnalysisException\nfrom aadatapipelinecore.core.fs.device import s3\nfrom aadatapipelinecore.core.fs import Conf\n\nsource_path = 's3://b2c-prod-data-pipeline-unified-review/unified/review.v1/fact/process_granularity=monthly/'\ndest_path = 's3://b2c-prod-data-pipeline-unified-review/unified/review_bulk_json_month.v3/date={}'\n\ns3_bucket_list = s3.S3Bucket(Conf(bucket_name='b2c-prod-data-pipeline-unified-review'))\npath_list = s3_bucket_list.all(prefix=\"unified/review.v1/fact/process_granularity=monthly/\", depth_is_1=True)\nprint path_list[155]\nfor path in path_list[155:]:\n    print path.split(\"/\")[4].split(\"=\")[1]\n\n    count_1 = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-review/{}\".format(path)).where(\n        \"market_code in ('apple-store','google-play')\").select(\"review_id\").distinct().count()\n    new_path = path.split(\"/\")[4].split(\"=\")[1]\n    df = spark.read.json(dest_path.format(new_path)).cache()\n    count_2 = df.filter(\"index is not null\").count()\n    count_3 = df.filter(\"_identifier is not null\").count()\n\n    # print count_1\n    if count_1 == count_2 == count_3:\n        print 'pass', path, count_1\n        pass\n        # print 'pass', path\n    else:\n        print \"not equal!!!!!!\", count_1, count_2, count_3, path\n"]},{"cell_type":"code","execution_count":0,"id":"20200211-222521_1529681176","metadata":{},"outputs":[],"source":["%%sh\nPGPASSWORD='90H1O7a9c2PQj7SC' psql -h b2b-prod-datapipeline-meta-new.crlexxwtzodp.us-east-1.rds.amazonaws.com  -U aa_datapipeline -d pipeline_meta -p 5432 << EOF\nselect count(1), status from review_load_queue group by status;\nselect (max(update_time) - min(update_time)) / count(update_time) as avg_time_per_file from review_load_queue where create_time > '2020-02-11 03:00:00' and status = 'finished';\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20200207-152211_95293251","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql.functions import desc\n\ndup_list = spark.read.parquet('s3://b2c-prod-data-pipeline-unified-review/unified/review_load_temp/review_load_temp_v4/event_month=2017-06/').select('review_id','process_date','process_hour').distinct().groupBy(\"review_id\").agg({\"*\":\"count\"}).where(\"count(1)>1\").orderBy(\"count(1)\",ascending = False).take(10)\n\nfor x in dup_list:\n    result1 = spark.read.parquet('s3://b2c-prod-data-pipeline-unified-review/unified/review_load_temp/review_load_temp_v4/event_month=2017-06/').filter(\"review_id='{}'\".format(x[\"review_id\"])).groupBy(\"process_date\",\"process_hour\",\"time\").agg({\"*\":\"count\"}).orderBy(desc(\"time\"),desc(\"process_date\"),desc(\"process_hour\")).take(1)\n    result2 = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-review/unified/review_load_temp/review_agg_v3/event_month=2017-06/\").filter(\"review_id='{}'\".format(x[\"review_id\"])).take(1)\n    print result1,result2\n    if result1[0][\"process_date\"]==result2[0][\"process_date\"] and result1[0][\"process_hour\"]==result2[0][\"process_hour\"] and result1[0][\"time\"]==result2[0][\"time\"]  :\n        print 'pass' , x \n    else:\n        print 'failed!!!',result1, result2,x\n"]},{"cell_type":"code","execution_count":0,"id":"20200130-071914_1925283701","metadata":{},"outputs":[],"source":["\nprint sc.parallelize([1,2,3,4,5], 4).cache().map(lambda x:x+1).collect()"]},{"cell_type":"code","execution_count":0,"id":"20200206-113457_973470773","metadata":{},"outputs":[],"source":["\n\ntest_list = [['Hello', 'aworld'], ['I', 'am', 'fine']]\nfrom pyspark.sql import Row\n\ndf =spark.createDataFrame(list(map(lambda x : Row(words=x, anther='aha'), test_list)))\ndf.show()\n\nprint dir(df)\nprint vars(df)\nprint hasattr(df,'name')\n"]},{"cell_type":"code","execution_count":0,"id":"20200314-082553_151855781","metadata":{},"outputs":[],"source":["\nreview_row=set()\nreview_row.add(1)\nreview_row.add(2)\n\ndf=spark.createDataFrame([('2020-05-01', 'daily', len(review_row))],schema=[\"process_date\",\"granularity\",\"agg_count\"] )\ndf.coalesce(1).write.format(\"parquet\").save(\"s3://b2c-prod-data-pipeline-qa/aa.review.count/test.parquet\",mode=\"append\",  partitionBy=[\"process_date\"])\n\n# spark.read.parquet(\"s3://b2c-prod-data-pipeline-qa/aa.review.count/process_date=2020-05-01/part-00001-7c8e471b-0072-4031-9595-e27070423ad5.c000.snappy.parquet\").show()\n\n\nprint dir(df.write)\n"]},{"cell_type":"code","execution_count":0,"id":"20200314-082638_1928739384","metadata":{},"outputs":[],"source":["%%sh\naws s3 ls s3://b2c-prod-data-pipeline-qa/aa.review.count/process_date=2020-03-13/part-00000-c640f0dc-7a8c-4f2b-93b3-808a86c4be5d.c000.snappy.parquet | sort -n\n"]},{"cell_type":"code","execution_count":0,"id":"20200314-082707_515747144","metadata":{},"outputs":[],"source":["\nprint spark.read.parquet(\"s3://aardvark-prod-dca-data/oss/GAME_CROSS_GENRE_KPI/version=1.0.0/range_type=MONTH/date=2019-07-31/\").show() #groupBy(\"metric_name\").count().show(20,False)\n\n\n# +------------------------------+-----+\n# |metric_name                   |count|\n# +------------------------------+-----+\n# |shared_users                  |95247|\n# |related_category_UP           |95247|\n# |XGA                           |95247|\n# |selected_category_active_users|95247|\n# |selected_threshold            |95247|\n# |XUP                           |95247|\n# +------------------------------+-----+\n\n# spark.read.parquet(\"s3://b2c-prod-data-pipeline-qa/aa.review.count/process_date=2020-03-13/part-00000-1f4aa426-7ecd-492d-a818-90c710966871.c000.snappy.parquet\").show()"]},{"cell_type":"code","execution_count":0,"id":"20200314-095933_717616279","metadata":{},"outputs":[],"source":["\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}