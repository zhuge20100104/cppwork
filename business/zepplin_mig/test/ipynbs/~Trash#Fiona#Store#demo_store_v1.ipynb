{"cells":[{"cell_type":"code","execution_count":0,"id":"20200509-062612_820051250","metadata":{},"outputs":[],"source":["\n\ndef platform_feed_to_metric(platform, feed):\n    mapping = [\n        ['ios', 0, 'iphone_free'],\n        ['ios',1, 'iphone_paid'],\n        ['ios',2, 'iphone_revenue'],\n        ['ios',101,'ipad_free'],\n        ['ios',100,'ipad_paid'],\n        ['ios',102,'ipad_revenue'],\n        ['android',0,'est_free_app_download'],\n        ['android',1,'est_paid_app_download'],\n        ['android',2,'est_revenue'],\n    ]\n    return [x for x in mapping if (x[0], x[1]) == (platform, feed)][0][2]\n    \nplatform_feed_to_metric(\"ios\",0)"]},{"cell_type":"code","execution_count":0,"id":"20200509-054555_300641065","metadata":{},"outputs":[],"source":["\n\nimport datetime\nfrom pyspark.sql import types as T\nfrom pyspark.sql import functions as F\n\n\nstart_week = \"2015-01-01\"\nend_week = \"2015-02-01\"\n\nreal_date1 = datetime.date(*[int(x) for x in start_week.split('-')])\nreal_date2 = datetime.date(*[int(x) for x in end_week.split('-')])\ndate_range = real_date2 - real_date1\ndates = list()\nsar_list=list()\nfor days in xrange(date_range.days):\n    dates.append(str(real_date1 + datetime.timedelta(days)))\n\ndates_temp=list()\nsar_list=list()\nfor days in xrange(date_range.days):\n    dates_temp.append(real_date1 + datetime.timedelta(days))\n    if (real_date1 + datetime.timedelta(days)).weekday() == 5:\n        temp=list()\n        while dates_temp:\n            temp.append(dates_temp.pop())\n        sar_list.append(str(real_date1 + datetime.timedelta(days)))\n\n\ndaily_csv_schema = T.StructType(\n    [\n        T.StructField(\"store_id\", T.IntegerType(), True),\n        T.StructField(\"date\", T.StringType(), True),\n        T.StructField(\"platform_id\", T.IntegerType(), True),\n        T.StructField(\"vertical\", T.IntegerType(), True),\n        T.StructField(\"feed\", T.IntegerType(), True),\n        T.StructField(\"id\", T.LongType(), True),\n        T.StructField(\"est\", T.IntegerType(), True),\n        T.StructField(\"category\", T.IntegerType(), True),\n        T.StructField(\"rank\", T.IntegerType(), True)\n    ]\n)\n\n\n\nweekly_csv_schema = T.StructType(\n    [\n        T.StructField(\"id\", T.LongType(), True),\n        T.StructField(\"store_id\", T.IntegerType(), True),\n        T.StructField(\"category\", T.IntegerType(), True),\n        T.StructField(\"start_date\", T.StringType(), True),\n        T.StructField(\"end_date\", T.StringType(), True),\n        T.StructField(\"iphone_free\", T.IntegerType(), True),\n        T.StructField(\"iphone_paid\", T.IntegerType(), True),\n        T.StructField(\"iphone_revenue\", T.IntegerType(), True),\n        T.StructField(\"ipad_free\", T.LongType(), True),\n        T.StructField(\"ipad_paid\", T.IntegerType(), True),\n        T.StructField(\"ipad_revenue\", T.IntegerType(), True)\n    ]\n)\n \nmonthly_csv_schema = T.StructType(\n    [\n        T.StructField(\"id\", T.LongType(), True),\n        T.StructField(\"store_id\", T.IntegerType(), True),\n        T.StructField(\"category\", T.IntegerType(), True),\n        T.StructField(\"year\", T.StringType(), True),\n        T.StructField(\"month\", T.StringType(), True),\n        T.StructField(\"iphone_free\", T.IntegerType(), True),\n        T.StructField(\"iphone_paid\", T.IntegerType(), True),\n        T.StructField(\"iphone_revenue\", T.IntegerType(), True),\n        T.StructField(\"ipad_free\", T.LongType(), True),\n        T.StructField(\"ipad_paid\", T.IntegerType(), True),\n        T.StructField(\"ipad_revenue\", T.IntegerType(), True)\n    ]\n)\n       \n\nprint 'test date'\nprint dates\nprint sar_list\n \n\ndf_1 = spark.read.option(\"basePath\", \"s3://b2c-prod-dca-store-estimates/store_est/v_final/DAY/\").schema(daily_csv_schema).csv(\"s3://b2c-prod-dca-store-estimates/store_est/v_final/DAY/{%s}/ios/sbe_est_app/*/\" % \",\".join(dates), sep=\"\\t\").cache()\ndf_2 = spark.read.option(\"basePath\", \"s3://b2c-prod-dca-store-estimates/store_est/v_final/MONTH/\").schema(monthly_csv_schema).csv(\"s3://b2c-prod-dca-store-estimates/store_est/v_final/MONTH/{%s}/ios/sbe_est_app/*/\" % dates[-1], sep=\"\\t\").cache()\ndf_3 = spark.read.option(\"basePath\", \"s3://b2c-prod-dca-store-estimates/store_est/v_final/WEEK/\").schema(weekly_csv_schema).csv(\"s3://b2c-prod-dca-store-estimates/store_est/v_final/WEEK/{%s}/ios/sbe_est_app/*/\" % \",\".join(sar_list), sep=\"\\t\").cache()\n\ndf_1.createOrReplaceTempView(\"daily_data\")\ndf_2.createOrReplaceTempView(\"monthly_data\")\ndf_3.createOrReplaceTempView(\"weekly_data\")\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200509-055032_666102011","metadata":{},"outputs":[],"source":["\nspark.sql(\"select * from daily_data where id=378736412 and store_id=143462 and category=100 \").show(2)\nspark.sql(\"select * from weekly_data where id=378736412 and store_id=143462 and category=100 \").show()\nspark.sql(\"select * from monthly_data where id=378736412 and store_id=143462 and category=100 \").show()"]},{"cell_type":"code","execution_count":0,"id":"20200509-064746_1971241215","metadata":{},"outputs":[],"source":["\nnew_transfor_df = spark.sql('''\nSELECT\n  *\nFROM\n  (\n    SELECT\n      id,\n      Sum(est) AS est,\n      category,\n      store_id,\n      platform_id,\n      feed,\n      vertical\n    FROM\n      (\n        SELECT\n          DISTINCT d1.id,\n          d1.est,\n          d1.store_id,\n          d1.date,\n          d1.feed,\n          d1.vertical,\n          d1.platform_id,\n          d2.category\n        FROM\n          daily_data AS d1\n          JOIN daily_data AS d2 \n          ON d1.id = d2.id\n          AND d1.store_id = d2.store_id\n          AND d1.feed = d2.feed\n          AND d1.vertical = d2.vertical\n          AND d1.platform_id = d2.platform_id\n      ) AS t\n    WHERE\n      feed IN (\n        0,\n        1,\n        2,\n        101,\n        100,\n        102\n      )\n    GROUP BY\n      id,\n      store_id,\n      category,\n      platform_id,\n      vertical,\n      feed\n  ) PIVOT (\n    max(est) FOR feed IN (\n      0,\n      1,\n      2,\n      101,\n      100,\n      102\n    )\n  )\n''').withColumnRenamed(\"0\", platform_feed_to_metric('ios',0)).withColumnRenamed(\"1\", platform_feed_to_metric('ios',1)).withColumnRenamed(\"2\", platform_feed_to_metric('ios',2)).withColumnRenamed(\"101\", platform_feed_to_metric('ios',101)).withColumnRenamed(\"100\", platform_feed_to_metric('ios',100)).withColumnRenamed(\"102\", platform_feed_to_metric('ios',102)).na.fill(0).cache()\n                                                        \nnew_transfor_df.createOrReplaceTempView(\"transfer_new\")\n\nspark.sql(\"select * from transfer_new where id=585544408 and store_id=143496\").show()\n"]},{"cell_type":"code","execution_count":0,"id":"20200509-063707_1834077477","metadata":{},"outputs":[],"source":["\nprint spark.sql(\"select id, category, store_id, iphone_free, iphone_paid, iphone_revenue, ipad_free, ipad_paid, ipad_revenue from transfer_new except select id, category, store_id, iphone_free, iphone_paid, iphone_revenue, ipad_free, ipad_paid, ipad_revenue from monthly_data  order by iphone_paid desc \").show(200)\n\nprint spark.sql(\"select id, category, store_id, iphone_free, iphone_paid, iphone_revenue, ipad_free, ipad_paid, ipad_revenue from monthly_data where category =100 except select id, category, store_id, iphone_free, iphone_paid, iphone_revenue, ipad_free, ipad_paid, ipad_revenue from transfer_new   order by iphone_paid desc \").show(200)\n\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200509-063729_1489859326","metadata":{},"outputs":[],"source":["\nspark.sql(\"select * from daily_data where id=891453663 and store_id=143441 and date between '2015-01-03' and '2015-01-10' and feed = 1 and category in (100, 36) order by category desc \").show()\nspark.sql(\"select * from weekly_data where id=891453663 and store_id=143441 and category=100   \").show(2)\nspark.sql(\"select * from monthly_data where id=891453663 and store_id=143441  \").show()\n"]},{"cell_type":"code","execution_count":0,"id":"20200509-074427_2143608316","metadata":{},"outputs":[],"source":["\nprint spark.sql(\"select * from transfer_new where id=891453663 and store_id=143441\").show()"]},{"cell_type":"code","execution_count":0,"id":"20200509-074812_1099030586","metadata":{},"outputs":[],"source":["\n14237344.000/39529475.000"]},{"cell_type":"code","execution_count":0,"id":"20200509-074855_699895599","metadata":{},"outputs":[],"source":["\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}