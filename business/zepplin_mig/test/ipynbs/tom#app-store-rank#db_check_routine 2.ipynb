{"cells":[{"cell_type":"code","execution_count":0,"id":"20191202-102223_26950095","metadata":{},"outputs":[],"source":["\n\n# Copyright (c) 2018 App Annie Inc. All rights reserved.\n\n\"\"\"\nDB Check modules\n\"\"\"\nimport unittest\n\nimport datetime\nimport croniter\nfrom sqlalchemy.dialects.postgresql import psycopg2\nfrom aaintdatapipeline.application.app_qa.conf.settings import PRODUCT_SERVICE_ENDPOINT, \\\n    MICRO_SERVICE_ACCESS_ID, MICRO_SERVICE_SECRET_KEY, PG_AA_NAME, PG_AA_ACCESS_ID, PG_AA_HOSTS, PG_AA_SECRET_KEY, \\\n    PG_AA_AMAZON_NAME, PG_AA_AMAZON_ACCESS_ID, PG_AA_AMAZON_HOSTS, PG_AA_AMAZON_SECRET_KEY\nfrom aaintdatapipeline.core.utils import microservice\nfrom pyspark.sql import functions as F\n\nfrom copy import deepcopy\nfrom aaintdatapipeline.application.app_qa.common.db_check_utils import query\nfrom aaintdatapipeline.application.app_qa.conf.settings import CITUS_MKT_NAME\nfrom aaintdatapipeline.application.app_qa.conf.settings import CITUS_AA_CITUS_DB_NAME, \\\n    CITUS_AA_CITUS_DB_ACCESS_ID, CITUS_AA_CITUS_DB_HOSTS, CITUS_AA_CITUS_DB_SECRET_KEY\n# from aaintdatapipeline.application.app_qa.db_check_v1.pyspark_test import PySparkTest\nfrom aaintdatapipeline.core.conf import Conf\nfrom aaintdatapipeline.core.fs.device import S3Bucket, specified_bucket\nimport zlib\nimport pandas as pd\nimport pandas.io.sql as sqlio\nimport psycopg2\n\n# base_test.py\nimport os\nimport shutil\nimport unittest\n\nfrom aaintdatapipeline.core.conf.settings import ROOT\nfrom aaintdatapipeline.core.fs.device import meta_bucket, raw_bucket, unified_bucket\nfrom aaintdatapipeline.core.fs.device.bucket import unified_data_system_config_bucket\nfrom aaintdatapipeline.core.utils.commandline import env\nfrom aaintdatapipeline.core.utils.encode import activate_system_utf8\nfrom aaintdatapipeline.core.utils.spark import create_spark, eject_all_caches\n\n\nclass PipelineTest(unittest.TestCase):\n    routing_config = None\n    trigger_datetime = None\n    prev_etl_datetime = None\n\n    def __init__(self, methodName='runTest', trigger_datetime=None):\n        super(PipelineTest, self).__init__(methodName)\n        self.trigger_datetime = trigger_datetime or datetime.datetime.utcnow()\n        self.check_date_str = self._get_check_date_str_from_routing_config(self.trigger_datetime)\n        self.prev_etl_datetime = self._get_pre_etl_completed_date()\n\n    def setUp(self):\n        super(PipelineTest, self).setUp()\n        self._verify_config()\n\n    @classmethod\n    def setUpClass(cls):\n        super(PipelineTest, cls).setUpClass()\n        activate_system_utf8()\n        env(PYTHONIOENCODING='utf8')\n        cls.spark = create_spark()\n        cls.sc = cls.spark.sparkContext\n\n    def _verify_config(cls):\n        cls.assertIsNotNone(cls.routing_config)\n        cls.assertIsNotNone(cls.trigger_datetime)\n        cls.assertIsNotNone(cls.prev_etl_datetime)\n        cls.assertIsNotNone(cls.check_date_str)\n\n    def _get_check_date_str_from_routing_config(self, trigger_datetime):\n        \"\"\"\n        return the date of : <days_delta> ago from previous scheduled date&time of <cron_time>.\n        e.g.\n        config = (\"0 9 * * *\", 1), today is 2019-10-27 8:00\n        so previous scheduled date&time is 2019-10-26 9:00\n        will return \"2019-10-25\"\n\n        :param config: config format: (<cron_time>, <days_delta>)\n        :type config: tuple\n        the cron_time please refer to https://support.acquia.com/hc/en-us/articles/360004224494-Cron-time-string-format\n        the days_delta is the days ago from the expected date.\n        :return: date string of \"%Y-%m-%d\"\n        :type return: str\n        \"\"\"\n        schedule, days_delta = self.routing_config\n        # here use UTC now\n        cron = croniter.croniter(schedule, trigger_datetime)\n        date = cron.get_prev(datetime.datetime) - datetime.timedelta(days=days_delta)\n        return date.strftime(\"%Y-%m-%d\")\n\n    def _get_pre_etl_completed_date(self):\n        schedule, _ = self.routing_config\n        cron = croniter.croniter(schedule, self.trigger_datetime)\n        date = cron.get_prev(datetime.datetime)\n        return date\n\n\ndef rank_bucket(bucket_str):\n    \"\"\"\n    Get Bucket Object from bucket string\n    :param bucket_str: string like: s3://xxx.xxx\n    :type bucket_str: str\n    :return: bucket_object\n    :rtype: bucket_object\n    \"\"\"\n    conf = Conf(\n        bucket_name=bucket_str,\n        bucket_class=S3Bucket\n    )\n    return specified_bucket(conf)\n\n\nclass AppStoreRankRawData():\n    bucket_name = \"\"\n    bucket_path = \"\"\n    data_split_str = \"\"\n    rank_list_split_str = \"\"\n    rank_split_str = \"\"\n    accept_feeds = []\n    country_code_mapping = {}\n    category_id_mapping = {}\n    metric_mapping = {}\n    market_code = \"\"\n    filename_available = []\n\n    def get(self, date, country_code, category_id):\n        df = self.get_raw_data_by_date(date)\n        return df.loc[(df.country_code == country_code) & (df.category_id == category_id )]\n\n    def parse_mapping(self, df):\n        if self.country_code_mapping:\n            df = df.replace({\"country_code\": self.country_code_mapping})\n\n        if self.category_id_mapping:\n            df[\"category_id\"] = pd.to_numeric(df[\"category_id\"])\n            df = df.replace({\"category_id\": self.category_id_mapping})\n\n        if self.metric_mapping:\n            df[\"metric\"] = pd.to_numeric(df[\"metric\"])\n            df = df.replace({\"metric\": self.metric_mapping})\n        return df\n\n\n    def parse_df_to_unified_format(self, df):\n        columns = [\"code\", \"category_id\", \"country_code\",\n                   \"free_download\", \"paid_download\", \"revenue\", \"new_free_download\", \"new_paid_download\" ]\n        data_list = []\n        for index,row in df.iterrows():\n            if len(row.app_rank_list)==0:\n                continue\n            for index,app_id in enumerate(row.app_rank_list, start=1):\n                free_download = index if row.metric == 'free_download' else None\n                paid_download = index if row.metric == 'paid_download' else None\n                revenue = index if row.metric == 'revenue' else None\n                new_free_download = index if row.metric == 'new_free_download' else None\n                new_paid_download = index if row.metric == 'new_paid_download' else None\n                data_list.append([app_id, row.category_id, row.country_code,\n                               free_download, paid_download, revenue, new_free_download, new_paid_download])\n        new_df = pd.DataFrame(data_list, columns=columns)\n        aggregate_dict = { metric : 'min' for metric in APP_STORE_RANK_METRICS}\n        new_df = new_df.groupby(new_df['code'], as_index=False).aggregate(aggregate_dict).\\\n            reindex(columns=new_df.columns)\n        # code to app_ids\n        code_app_id_mapping = self.get_code_app_id_mapping(new_df.code.tolist())\n        new_df = new_df.merge(code_app_id_mapping, on='code', how=\"left\").rename(columns={'id':'app_id'})\n        return new_df\n\n    def get_unified_format(self, date):\n        df = self.get_raw_data_by_date(date)\n        return self.parse_df_to_unified_format(df)\n\n    def get_raw_data_by_date(self, date):\n        \"\"\"\n        :return: raw_data_frame\n        :rtype: list_of_dic\n        raw_data:\n        _________________________________________________________________________________\n        |    date    |   country_id   |  category_id  |   feed_id   |   rank (app_id)   |\n        |------------|----------------|---------------|-------------|-------------------|\n        | 2019-04-27 | 143441(bigint) |   6016 (int)  |   0 (int)   | 376510438(bigint) |\n        ---------------------------------------------------------------------------------\n        unified_data:\n        _____________________________________________________________________________________\n        |  country_code  |   category_id   |       app_id       | feed_name (free_download) |\n        |----------------|-----------------|--------------------|---------------------------|\n        |      'US'      | 100026 (bigint) | 376510438 (bigint) |    25 (int) (app_rank)    |\n        -------------------------------------------------------------------------------------\n        \"\"\"\n        path = \"{_bucket_path}/{_date}/23/\".format(_date=date, _bucket_path=self.bucket_path)\n        bucket = rank_bucket(self.bucket_name)\n        columns = ['date', 'country_code', 'category_id', 'metric', 'app_rank_list']\n\n        _raw_data_list = []\n        for filepath in bucket.list(path):\n            filename = filepath.replace(path, '')\n            if self.filename_available and filename not in self.filename_available:\n                continue\n            _raw_data = zlib.decompress(bucket.get(filepath))\n            for _line in _raw_data.splitlines():\n                line_data = _line.split(self.data_split_str)\n                app_rank_list = [rank_app for rank_app in line_data[4].split(self.rank_list_split_str) if\n                                 rank_app.strip() != '']\n                if self.rank_split_str:\n                    app_rank_list = [app_rank.split(self.rank_split_str)[1] for app_rank in app_rank_list]\n                line_data[4] = app_rank_list\n                _raw_data_list.append(line_data)\n        return self.parse_mapping(pd.DataFrame(_raw_data_list, columns=columns))\n\n\n    def get_code_app_id_mapping(self, code_ids):\n        return None\n\n    def get_rank_count_and_sum_by_date(self, date):\n        raw_df = self.get_raw_data_by_date(date)\n        raw_agg_df_list = []\n        for df_index, row in raw_df.iterrows():\n            if len(row.app_rank_list) == 0:\n                continue\n            _df = pd.DataFrame([[app_id, app_index] for app_index, app_id in enumerate(row.app_rank_list, start=1)],\n                              columns=[\"code\", \"rank\"])\n            aggregation_functions = {'rank': 'min'}\n            raw_agg_df = _df.groupby(_df['code'], as_index=False)\\\n                .aggregate(aggregation_functions)\\\n                .reindex(columns=_df.columns)\n            raw_agg_df_list.append(raw_agg_df)\n\n        raw_agg_df_all = pd.concat(raw_agg_df_list, ignore_index=True, sort=False)\n        app_id_mapping_df = self.get_code_app_id_mapping(list(set(raw_agg_df_all.code.tolist())))\n        if app_id_mapping_df is not None:\n            raw_agg_df_all = raw_agg_df_all.merge(app_id_mapping_df, on='code', how=\"left\")\n        raw_count = len(raw_agg_df_all[raw_agg_df_all.id.notnull()])\n        raw_sum = raw_agg_df_all[raw_agg_df_all.id.notnull()][\"rank\"].sum()\n        return raw_count, raw_sum\n\n# class IPhoneRaw(AppStoreRankRawData):\n#     bucket_name = \"prod_appannie_ios\"\n#     bucket_path = \"country-ranks\"\n#     data_split_str = \"\\t\"\n#     rank_list_split_str = \" \"\n#     accept_feeds = [0, 1, 2]\n#\n#\n# class IPadRaw(AppStoreRankRawData):\n#     bucket_name = \"prod_appannie_ios\"\n#     bucket_path = \"country-ranks\"\n#     data_split_str = \"\\t\"\n#     rank_list_split_str = \" \"\n\n\n# class MacRaw(AppStoreRankRawData):\n#     bucket_name = \"prod_appannie_ios\"\n#     bucket_path = \"mac/country-ranks\"\n#     data_split_str = \"\\t\"\n#     rank_list_split_str = \" \"\n\nMETRIC_MAPPING = {\n    'tv-os-tv': {\n        0: 'free_download',\n        1: 'paid_download',\n        2: 'revenue'\n    },\n    'amazon-store':{\n        'android-all':{\n            0: 'free_download',\n            1: 'paid_download',\n            3: 'new_free_download'\n        }\n    }\n\n}\nCOUNTRY_CODE_MAPPING = {\n    'ios': {143441: 'US', 143442: 'FR', 143443: 'DE', 143444: 'GB', 143445: 'AT',\n            143446: 'BE', 143447: 'FI', 143448: 'GR', 143449: 'IE', 143450: 'IT',\n            143451: 'LU', 143452: 'NL', 143453: 'PT', 143454: 'ES', 143455: 'CA',\n            143456: 'SE', 143457: 'NO', 143458: 'DK', 143459: 'CH', 143460: 'AU',\n            143461: 'NZ', 143462: 'JP', 143463: 'HK', 143464: 'SG', 143465: 'CN',\n            143466: 'KR', 143467: 'IN', 143468: 'MX', 143469: 'RU', 143470: 'TW',\n            143471: 'VN', 143472: 'ZA', 143473: 'MY', 143474: 'PH', 143475: 'TH',\n            143476: 'ID', 143477: 'PK', 143478: 'PL', 143479: 'SA', 143480: 'TR',\n            143481: 'AE', 143482: 'HU', 143483: 'CL', 143484: 'NP', 143485: 'PA',\n            143486: 'LK', 143487: 'RO', 143489: 'CZ', 143491: 'IL', 143492: 'UA',\n            143493: 'KW', 143494: 'HR', 143495: 'CR', 143496: 'SK', 143497: 'LB',\n            143498: 'QA', 143499: 'SI', 143501: 'CO', 143502: 'VE', 143503: 'BR',\n            143504: 'GT', 143505: 'AR', 143506: 'SV', 143507: 'PE', 143508: 'DO',\n            143509: 'EC', 143510: 'HN', 143511: 'JM', 143512: 'NI', 143513: 'PY',\n            143514: 'UY', 143515: 'MO', 143516: 'EG', 143517: 'KZ', 143518: 'EE',\n            143519: 'LV', 143520: 'LT', 143521: 'MT', 143523: 'MD', 143524: 'AM',\n            143525: 'BW', 143526: 'BG', 143528: 'JO', 143529: 'KE', 143530: 'MK',\n            143531: 'MG', 143532: 'ML', 143533: 'MU', 143534: 'NE', 143535: 'SN',\n            143536: 'TN', 143537: 'UG', 143538: 'AI', 143539: 'BS', 143540: 'AG',\n            143541: 'BB', 143542: 'BM', 143543: 'VG', 143544: 'KY', 143545: 'DM',\n            143546: 'GD', 143547: 'MS', 143548: 'KN', 143549: 'LC', 143550: 'VC',\n            143551: 'TT', 143552: 'TC', 143553: 'GY', 143554: 'SR', 143555: 'BZ',\n            143556: 'BO', 143557: 'CY', 143558: 'IS', 143559: 'BH', 143560: 'BN',\n            143561: 'NG', 143562: 'OM', 143563: 'DZ', 143564: 'AO', 143565: 'BY',\n            143566: 'UZ', 143568: 'AZ', 143571: 'YE', 143572: 'TZ', 143573: 'GH',\n            143575: 'AL', 143576: 'BJ', 143577: 'BT', 143578: 'BF', 143579: 'KH',\n            143580: 'CV', 143581: 'TD', 143582: 'CG', 143583: 'FJ', 143584: 'GM',\n            143585: 'GW', 143586: 'KG', 143587: 'LA', 143588: 'LR', 143589: 'MW',\n            143590: 'MR', 143591: 'FM', 143592: 'MN', 143593: 'MZ', 143594: 'NA',\n            143595: 'PW', 143597: 'PG', 143598: 'ST', 143599: 'SC', 143600: 'SL',\n            143601: 'SB', 143602: 'SZ', 143603: 'TJ', 143604: 'TM', 143605: 'ZW',\n            0: 'WW'},\n    'amazon-store':{\n        'android-all':{\n            'UK' : 'GB',\n        }\n    }\n}\nCATEGORY_ID_MAPPING = {\n    \"tv-os-tv\": {\n        36: 300000,\n        360: 300001,\n        6004: 300002,\n        6009: 300003,\n        6012: 300004,\n        6013: 300005,\n        6014: 300006,\n        6016: 300007,\n        6017: 300008\n    },\n    'amazon-store':{\n        'android-all': {\n        10: 720000,\n        6395703011: 720001,\n        6395710011: 720003,\n        6395709011: 720004,\n        6395711011: 720005,\n        6395712011: 720006,\n        6395713011: 720007,\n        6395702011: 720008,\n        6395714011: 720009,\n        6395715011: 720010,\n        6395716011: 720011,\n        6395717011: 720012,\n        6395720011: 720015,\n        6395726011: 720016,\n        6395718011: 720017,\n        6395727011: 720019,\n        6395729011: 720020,\n        6395745011: 720021,\n        6395728011: 720022,\n        6395730011: 720024,\n        6395731011: 720025,\n        6395732011: 720026,\n        6395733011: 720028,\n        6395734011: 720029,\n        6395735011: 720030,\n        6395736011: 720031,\n        6395737011: 720032,\n        6395738011: 720033,\n        6395747011: 720034,\n        6395744011: 720035,\n        8: 720000,\n        148152071: 720001,\n        148153071: 720003,\n        148154071: 720004,\n        148155071: 720005,\n        148156071: 720006,\n        148157071: 720007,\n        148158071: 720008,\n        148159071: 720009,\n        148160071: 720010,\n        148161071: 720011,\n        148162071: 720012,\n        148165071: 720013,\n        148163071: 720015,\n        148164071: 720016,\n        148166071: 720018,\n        148167071: 720019,\n        148168071: 720020,\n        148169071: 720021,\n        152899071: 720022,\n        148170071: 720024,\n        148171071: 720025,\n        148172071: 720026,\n        148173071: 720028,\n        148174071: 720029,\n        148175071: 720030,\n        148176071: 720031,\n        148177071: 720032,\n        148178071: 720033,\n        148180071: 720034,\n        148181071: 720035,\n        2: 720000,\n        1720677031: 720001,\n        1720683031: 720002,\n        1720684031: 720003,\n        1720685031: 720004,\n        1720686031: 720005,\n        1720687031: 720006,\n        1720688031: 720007,\n        1720689031: 720009,\n        1720690031: 720010,\n        1720691031: 720011,\n        1720692031: 720012,\n        1720693031: 720013,\n        1720712031: 720014,\n        1720694031: 720015,\n        1720700031: 720016,\n        1720701031: 720018,\n        1720702031: 720019,\n        1720703031: 720020,\n        1720704031: 720021,\n        1720705031: 720022,\n        1720706031: 720023,\n        1720707031: 720025,\n        1720708031: 720026,\n        1720714031: 720027,\n        1720709031: 720028,\n        1720710031: 720029,\n        1720711031: 720030,\n        1720713031: 720032,\n        1720724031: 720034,\n        1720725031: 720035,\n        3: 720000,\n        1726743031: 720001,\n        1726749031: 720002,\n        1726750031: 720003,\n        1726751031: 720004,\n        1726752031: 720005,\n        1726753031: 720006,\n        1726754031: 720007,\n        1726755031: 720009,\n        1726756031: 720010,\n        1726757031: 720011,\n        1726758031: 720012,\n        1726759031: 720013,\n        1726778031: 720014,\n        1726760031: 720015,\n        1726766031: 720016,\n        1726767031: 720018,\n        1726768031: 720019,\n        1726769031: 720020,\n        1726770031: 720021,\n        1726771031: 720022,\n        1726772031: 720023,\n        1726773031: 720025,\n        1726774031: 720026,\n        1726775031: 720028,\n        1726776031: 720029,\n        1726777031: 720030,\n        1726779031: 720032,\n        1726780031: 720033,\n        1726790031: 720034,\n        1726791031: 720035,\n        4: 720000,\n        1722761031: 720001,\n        1722767031: 720002,\n        1722768031: 720003,\n        1722769031: 720004,\n        1722770031: 720005,\n        1722771031: 720006,\n        1722772031: 720007,\n        1722773031: 720009,\n        1722774031: 720010,\n        1722775031: 720011,\n        1722776031: 720012,\n        1722777031: 720013,\n        1722796031: 720014,\n        1722778031: 720015,\n        1722784031: 720016,\n        1722785031: 720018,\n        1722786031: 720019,\n        1722787031: 720020,\n        1722788031: 720021,\n        1722789031: 720022,\n        1722790031: 720023,\n        1722791031: 720025,\n        1722792031: 720026,\n        1722793031: 720028,\n        1722794031: 720029,\n        1722795031: 720030,\n        1722797031: 720032,\n        1722798031: 720033,\n        1722808031: 720034,\n        1722809031: 720035,\n        5: 720000,\n        1725417031: 720001,\n        1725423031: 720002,\n        1725424031: 720003,\n        1725425031: 720004,\n        1725426031: 720005,\n        1725427031: 720006,\n        1725428031: 720007,\n        1725429031: 720009,\n        1725430031: 720010,\n        1725431031: 720011,\n        1725432031: 720012,\n        1725433031: 720013,\n        1725452031: 720014,\n        1725434031: 720015,\n        1725440031: 720016,\n        1725441031: 720018,\n        1725442031: 720019,\n        1725443031: 720020,\n        1725444031: 720021,\n        1725445031: 720022,\n        1725446031: 720023,\n        1725447031: 720025,\n        1725448031: 720026,\n        1725449031: 720028,\n        1725450031: 720029,\n        1725451031: 720030,\n        1725453031: 720032,\n        1725454031: 720033,\n        1725464031: 720034,\n        1725465031: 720035,\n        6: 720000,\n        2386858051: 720001,\n        2386869051: 720002,\n        2386864051: 720003,\n        2386865051: 720004,\n        2386866051: 720005,\n        2386867051: 720006,\n        2386868051: 720007,\n        2386870051: 720009,\n        2386871051: 720010,\n        2386872051: 720011,\n        2386873051: 720012,\n        2386874051: 720013,\n        2386892051: 720014,\n        2386875051: 720015,\n        2386881051: 720016,\n        2386882051: 720018,\n        2386883051: 720019,\n        2386884051: 720020,\n        2386885051: 720021,\n        2386894051: 720022,\n        2386886051: 720023,\n        2386887051: 720025,\n        2386888051: 720026,\n        2386889051: 720028,\n        2386890051: 720029,\n        2386891051: 720030,\n        2386893051: 720032,\n        2386895051: 720033,\n        2386905051: 720034,\n        2386906051: 720035,\n        7: 720000,\n        1710348031: 720001,\n        1710359031: 720002,\n        1710354031: 720003,\n        1710355031: 720004,\n        1710356031: 720005,\n        1710357031: 720006,\n        1710358031: 720007,\n        1710360031: 720009,\n        1710361031: 720010,\n        1710362031: 720011,\n        1710363031: 720012,\n        1710364031: 720013,\n        1710383031: 720014,\n        1710365031: 720015,\n        1710371031: 720016,\n        1710372031: 720018,\n        1710373031: 720019,\n        1710374031: 720020,\n        1710375031: 720021,\n        1710376031: 720022,\n        1710377031: 720023,\n        1710378031: 720025,\n        1710379031: 720026,\n        1710380031: 720028,\n        1710381031: 720029,\n        1710382031: 720030,\n        1710384031: 720032,\n        1710385031: 720033,\n        1710395031: 720034,\n        1710396031: 720035,\n        1: 720000,\n        2478833011: 720001,\n        2478832011: 720002,\n        2478840011: 720003,\n        2478839011: 720004,\n        2478841011: 720005,\n        2478842011: 720006,\n        2478843011: 720007,\n        2478844011: 720009,\n        2478845011: 720010,\n        2478846011: 720011,\n        2478847011: 720012,\n        2478867011: 720014,\n        2478849011: 720015,\n        2478855011: 720016,\n        3310778011: 720017,\n        2478858011: 720019,\n        2478860011: 720020,\n        2577638011: 720021,\n        2478859011: 720022,\n        2478861011: 720024,\n        2478862011: 720025,\n        2478863011: 720026,\n        2478864011: 720028,\n        2478865011: 720029,\n        2478866011: 720030,\n        2478868011: 720032,\n        2478869011: 720033,\n        3310683011: 720034,\n        2478875011: 720035\n        }\n    }\n}\n\n\nclass AppleTvRaw(AppStoreRankRawData):\n    bucket_name = \"prod_appannie_appletv\"\n    bucket_path = \"country-ranks\"\n    data_split_str = \",\"\n    rank_list_split_str = \" \"\n    rank_split_str = \"-\"\n    country_code_mapping = None\n    category_id_mapping = CATEGORY_ID_MAPPING['tv-os-tv']\n    metric_mapping = METRIC_MAPPING['tv-os-tv']\n\n    device_code = \"tv-os-tv\"\n    market_code = 'apple-store'\n    filename_available = [COUNTRY_CODE_MAPPING['ios'][id] for id in COUNTRY_CODE_MAPPING['ios']]\n\n    # this should be a product_service\n    def get_code_app_id_mapping(self, code_list):\n        sql_code_list = \"','\".join(code_list)\n        sql = \"select id,code from product where code in ('{}')\".format(sql_code_list)\n        conn = psycopg2.connect(aa_dsn)\n        df = sqlio.read_sql_query(sql, conn)\n        return df\n\n\nclass AmazonRaw(AppStoreRankRawData):\n    bucket_name = \"prod_appannie_amazon\"\n    bucket_path = \"country-ranks\"\n    data_split_str = \",\"\n    rank_list_split_str = \" \"\n    rank_split_str = \"-\"\n    device_code = \"android-all\"\n    market_code = 'amazon-store'\n\n    filename_available = ['FR', 'CN', 'CA', 'DE', 'JP', 'IT', 'US', 'UK', 'ES']\n\n    country_code_mapping = COUNTRY_CODE_MAPPING[market_code][device_code]\n    category_id_mapping = CATEGORY_ID_MAPPING[market_code][device_code]\n    metric_mapping = METRIC_MAPPING[market_code][device_code]\n\n    # this should be a product_service\n    def get_code_app_id_mapping(self, code_list):\n        sql_code_list = \"','\".join(code_list)\n        sql = \"select id,code from app where code in ('{}')\".format(sql_code_list)\n        conn = psycopg2.connect(aa_amazon_dsn)\n        df = sqlio.read_sql_query(sql, conn)\n        return df\n\n    def get_rank_count_and_sum_by_date(self, date):\n        raw_df = self.get_raw_data_by_date(date)\n        raw_agg_df_list = []\n        for df_index, row in raw_df.iterrows():\n            if len(row.app_rank_list) == 0:\n                continue\n            _df = pd.DataFrame([[app_id, app_index] for app_index, app_id in enumerate(row.app_rank_list, start=1)],\n                              columns=[\"code\", \"rank\"])\n            aggregation_functions = {'rank': 'min'}\n            raw_agg_df = _df.groupby(_df['code'], as_index=False)\\\n                .aggregate(aggregation_functions)\\\n                .reindex(columns=_df.columns)\n            raw_agg_df_list.append(raw_agg_df)\n\n        raw_agg_df_all = pd.concat(raw_agg_df_list, ignore_index=True, sort=False)\n        app_id_mapping_df = self.get_code_app_id_mapping(list(set(raw_agg_df_all.code.tolist())), aa_amazon_dsn)\n        raw_agg_df_all = raw_agg_df_all.merge(app_id_mapping_df, on='code', how=\"left\")\n        raw_count = len(raw_agg_df_all[raw_agg_df_all.id.notnull()])\n        raw_sum = raw_agg_df_all[raw_agg_df_all.id.notnull()][\"rank\"].sum()\n        return raw_count, raw_sum\n\n\n# class GooglePlayRaw(AppStoreRankRawData):\n#     bucket_name = \"prod_appannie_android\"\n#     bucket_path = \"country-ranks\"\n#     data_split_str = \",\"\n#     rank_list_split_str = \" \"\n#     accept_feeds = [0, 1, 2]\n\n\n# CONSTANTS\nAPP_STORE_RANK_METRICS = [\"free_download\", \"new_paid_download\", \"revenue\", \"paid_download\", \"new_free_download\"]\ncitus_dsn = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=CITUS_AA_CITUS_DB_NAME,\n        user=CITUS_AA_CITUS_DB_ACCESS_ID,\n        host=CITUS_AA_CITUS_DB_HOSTS[0][0],\n        password=CITUS_AA_CITUS_DB_SECRET_KEY,\n        port=CITUS_AA_CITUS_DB_HOSTS[0][1]\n    )\n)\naa_dsn = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_AA_NAME,\n        user=PG_AA_ACCESS_ID,\n        host=PG_AA_HOSTS[0][0],\n        password=PG_AA_SECRET_KEY,\n        port=PG_AA_HOSTS[0][1]\n    )\n)\n\naa_amazon_dsn = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_AA_AMAZON_NAME,\n        user=PG_AA_AMAZON_ACCESS_ID,\n        host=PG_AA_AMAZON_HOSTS[0][0],\n        password=PG_AA_AMAZON_SECRET_KEY,\n        port=PG_AA_AMAZON_HOSTS[0][1]\n    )\n)\n\n\n\n\nclass AppleTvUnified():\n    device_code = 'tv-os-tv'\n    s3_path = \"s3://b2c-prod-data-pipeline-unified-store-free/unified/app-tech.store.app-rank.v1/fact/\"\n\n    def get(self, date, country_code, category_id):\n        df = self.get_raw_df_by_date(date)\n        return df.filter(\"country_code='{country_code}' and category_id='{category_id}'\".format(\n            country_code=country_code, category_id=category_id)).toPandas()\n\n    def get_raw_df_by_date(self, date):\n        return spark.read.parquet(\"{}date={}/device_code={}/\".format(self.s3_path, date, self.device_code))\n\n    def get_rank_count_and_sum_by_date(self, date):\n        df = self.get_raw_df_by_date(date)\n        df_agg = df.filter('app_id is not null').agg(\n            F.count(\"free_download\").alias(\"free_download_count\"),\n            F.count(\"paid_download\").alias(\"paid_download_count\"),\n            F.count(\"revenue\").alias(\"revenue_count\"),\n            F.count(\"new_free_download\").alias(\"new_free_download_count\"),\n            F.count(\"new_paid_download\").alias(\"new_paid_download_count\"),\n            F.sum(\"free_download\").alias(\"free_download_sum\"),\n            F.sum(\"paid_download\").alias(\"paid_download_sum\"),\n            F.sum(\"revenue\").alias(\"revenue_sum\"),\n            F.sum(\"new_free_download\").alias(\"new_free_download_sum\"),\n            F.sum(\"new_paid_download\").alias(\"new_paid_download_sum\")\n        ).collect()\n\n        data = df_agg[0]\n        unified_count = sum([data.free_download_count, data.paid_download_count, data.revenue_count, data.new_free_download_count, data.new_paid_download_count])\n        unified_sum = sum([data.free_download_sum or 0, data.paid_download_sum or 0, data.revenue_sum or 0, data.new_free_download_sum or 0, data.new_paid_download_sum or 0])\n        return unified_count, unified_sum\n\n\nclass AmazonUnified(AppleTvUnified):\n    device_code = 'android-all'\n    s3_path = \"s3://b2c-prod-data-pipeline-unified-store-free/unified/app-tech.store.app-rank.v2/fact/\"\n\nclass AppleTvDB():\n    schema = \"store\"\n    table = \"store_app_rank_fact_v1\"\n    device_code = 'tv-os-tv'\n\n    def get(self, date, country_code, category_id):\n        sql = \"SELECT * from {schema}.{table} where date ='{date}' AND device_code='{device_code}' AND \" \\\n              \"country_code='{country_code}' AND category_id='{category_id}'\".format(\n            schema=self.schema, table=self.table, date=date, device_code=self.device_code,\n            country_code=country_code, category_id=category_id)\n        result = self.query_df(citus_dsn, sql)\n        return result\n\n    @staticmethod\n    def query(dsn, sql):\n        with psycopg2.connect(dsn) as conn:\n            conn.autocommit = True\n            with conn.cursor() as cur:\n                cur.execute(sql)\n                df = pd.DataFrame(cur.fetchall())\n                df.columns = cur.keys()\n                conn.commit()\n        return df\n\n    @staticmethod\n    def query_df(dsn, sql):\n        conn = psycopg2.connect(dsn)\n        df = sqlio.read_sql_query(sql, conn)\n        return df\n\nclass AmazonDB(AppleTvDB):\n    device_code = 'android-all'\n\n\n# CASES\n\nclass AppStoreRankDailyTest(PipelineTest):\n    routing_config = ('* 9 * * *', 1)\n\n    def test_apple_tv_etl_process(self):\n        country_code = 'US'\n        category_id = 300000\n        raw_df = AppleTvRaw().parse_df_to_unified_format(AppleTvRaw().get(self.check_date_str, country_code, category_id))\n        unified_df = AppleTvUnified().get(self.check_date_str, country_code, category_id)\n        db_df = AppleTvDB().get(self.check_date_str,  country_code, category_id)\n        for metric in APP_STORE_RANK_METRICS:\n            _raw_df = raw_df[pd.notnull(raw_df[metric])].sort_values(metric)\n            _unified_df = unified_df[pd.notnull(unified_df[metric])].sort_values(metric)\n            _db_df = db_df[pd.notnull(db_df[metric])].sort_values(metric)\n\n            data_app = {\n                'raw': _raw_df.app_id.tolist(),\n                'unified': _unified_df.app_id.tolist(),\n                'db': _db_df.app_id.tolist()\n            }\n\n            data_rank = {\n                'raw': _raw_df[metric].tolist(),\n                'unified': _unified_df[metric].tolist(),\n                'db': db_df[metric].tolist()\n            }\n\n            self.assertTrue(data_app['raw']==data_app['unified']==data_app['db'], msg=\"{}\".format(data_app))\n            self.assertTrue(data_rank['raw']==data_rank['unified']==data_rank['db'], msg=\"{}\".format(data_rank))\n\n    def test_amazon_etl_process(self):\n        country_code = 'US'\n        category_id = 720000\n        raw_df = AmazonRaw().parse_df_to_unified_format(AmazonRaw().get(self.check_date_str, country_code, category_id))\n        unified_df = AmazonUnified().get(self.check_date_str, country_code, category_id)\n\n        for metric in APP_STORE_RANK_METRICS:\n            _raw_df = raw_df[pd.notnull(raw_df[metric])].sort_values(metric)\n            _unified_df = unified_df[pd.notnull(unified_df[metric])].sort_values(metric)\n            # _db_df = db_df[pd.notnull(db_df[metric])].sort_values(metric)\n\n            data_app = {\n                'raw': _raw_df.app_id.tolist(),\n                'unified': _unified_df.app_id.tolist(),\n                # 'db': _db_df.app_id.tolist()\n                'db': []\n            }\n\n            data_rank = {\n                'raw': _raw_df[metric].tolist(),\n                'unified': _unified_df[metric].tolist(),\n                # 'db': db_df[metric].tolist()\n                'db': []\n            }\n\n            self.assertTrue(data_app['raw'] == data_app['unified'] == data_app['db'], msg=\"{}\".format(data_app))\n            self.assertTrue(data_rank['raw'] == data_rank['unified'] == data_rank['db'], msg=\"{}\".format(data_rank))\n\n    def test_amazon_completeness(self):\n        raw_count, raw_sum = AmazonRaw().get_rank_count_and_sum_by_date(self.check_date_str)\n        unified_count, unified_sum = AmazonUnified().get_rank_count_and_sum_by_date(self.check_date_str)\n\n        self.assertEqual(raw_count, unified_count)\n        self.assertEqual(raw_sum, unified_sum)\n\n    def test_apple_tv_completeness(self):\n        raw_count, raw_sum = AppleTvRaw().get_rank_count_and_sum_by_date(self.check_date_str)\n        unified_count, unified_sum = AppleTvUnified().get_rank_count_and_sum_by_date(self.check_date_str)\n\n        self.assertEqual(raw_count, unified_count)\n        self.assertEqual(raw_sum, unified_sum)\n\n\n\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20191212-075515_1422485429","metadata":{},"outputs":[],"source":["\n\n\nimport datetime\n\ndef logtime():\n    print datetime.datetime.now()\n\ndef get_sum_count_raw(date_str):\n    raw_reader = AmazonRaw()\n    raw_reader.category_id_mapping = None\n    raw_df = raw_reader.get_raw_data_by_date(date_str)\n\n    columns = [\"app_id\", \"category_id\", \"country_code\",\n               \"free_download\", \"paid_download\", \"revenue\", \"new_free_download\", \"new_paid_download\", ]\n\n    amazon_count = 0\n    amazon_count_dict = {}\n    amazon_sum = 0\n    df_new_list = []\n    for df_index,row in raw_df.iterrows():\n        # print df_index\n        country_code = row.country_code if row.country_code!='UK' else 'GB'\n        legacy_category_id = row.category_id\n        if len(row.app_rank_list)==0:\n            continue\n        if country_code not in amazon_count_dict:\n            amazon_count_dict[country_code] = {}\n        if legacy_category_id not in amazon_count_dict[country_code]:\n            amazon_count_dict[country_code][legacy_category_id] = 0\n        df = pd.DataFrame([[app_id,app_index] for app_index,app_id in enumerate(row.app_rank_list, start=1)], columns=[ \"code\", \"rank\"]) # if app_id in app_df_list\n        aggregation_functions = {'rank': 'min'}\n        df_new = df.groupby(df['code'],as_index=False).aggregate(aggregation_functions).reindex(columns=df.columns)\n        df_new_list.append(df_new)\n        continue # bellow for breakdown test\n        app_id_mapping_df =AmazonRaw().get_code_app_id_mapping(df_new.code.tolist(), aa_amazon_dsn)\n        df_new = df_new.merge(app_id_mapping_df, on='code', how=\"left\")\n        amazon_count += len(df_new[df_new.id.notnull()])\n        amazon_count_dict[country_code][legacy_category_id] += len(df_new[df_new.id.notnull()])\n        amazon_sum += df_new[df_new.id.notnull()][\"rank\"].sum()\n    \n    df_new = pd.concat(df_new_list, ignore_index=True, sort =False)\n    app_id_mapping_df =AmazonRaw().get_code_app_id_mapping(list(set(df_new.code.tolist())), aa_amazon_dsn)\n    df_new = df_new.merge(app_id_mapping_df, on='code', how=\"left\")\n    amazon_count = len(df_new[df_new.id.notnull()])\n    amazon_sum = df_new[df_new.id.notnull()][\"rank\"].sum()\n    \n    return amazon_count, amazon_sum, amazon_count_dict\n    \n\nprint get_sum_count_raw('2019-10-11')"]},{"cell_type":"code","execution_count":0,"id":"20191212-092347_1311464745","metadata":{},"outputs":[],"source":["\n#315541, 56075482\nfrom pyspark.sql import functions as F\n\n\ndef get_sum_count_unified(date_str):\n    df = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-free/unified/app-tech.store.app-rank.v2/fact/date={}/device_code=android-all/\".format(date_str))\n\n    ############## all 0-3 should be transformed, 2 is not load to db\n    df_unified = df.filter('app_id is not null').groupBy([\"country_code\",\"legacy_category_id\"]).agg(F.count(\"free_download\").alias(\"free_download_count\"),F.count(\"paid_download\").alias(\"paid_download_count\"), F.count(\"revenue\").alias(\"revenue_count\"), F.count(\"new_free_download\").alias(\"new_free_download_count\"), F.sum(\"free_download\").alias(\"free_download_sum\"),F.sum(\"paid_download\").alias(\"paid_download_sum\"),  F.sum(\"revenue\").alias(\"revenue_sum\"), F.sum(\"new_free_download\").alias(\"new_free_download_sum\")).collect()\n    \n    unified_count = 0\n    unified_sum = 0\n    \n    amazon_count_dict = {}\n    for data in df_unified:\n        country_code = data.country_code\n        legacy_category_id = str(data.legacy_category_id)\n        if country_code not in amazon_count_dict:\n            amazon_count_dict[country_code] = {}\n        if legacy_category_id not in amazon_count_dict[country_code]:\n            amazon_count_dict[country_code][legacy_category_id] = 0\n        amazon_count_dict[country_code][legacy_category_id] += sum([data.free_download_count, data.paid_download_count, data.new_free_download_count, data.revenue_count])\n        unified_count += sum([data.free_download_count, data.paid_download_count, data.new_free_download_count, data.revenue_count])\n        unified_sum += sum([data.free_download_sum or 0, data.paid_download_sum or 0, data.new_free_download_sum or 0, data.revenue_sum or 0])\n\n    return unified_count, unified_sum, amazon_count_dict\n\n\nget_sum_count_unified('2013-03-27')\n"]},{"cell_type":"code","execution_count":0,"id":"20191212-101457_536964973","metadata":{},"outputs":[],"source":["\n\ndef get_date_list(begin_date, end_date, freq):\n    date_list = [x.strftime('%Y-%m-%d') for x in list(pd.date_range(start=begin_date, end=end_date, freq=freq))]\n    return date_list\n\n# begin_date = datetime.datetime.strptime(\"2012-09-12\", '%Y-%m-%d')\n# end_date = datetime.datetime.strptime(\"2019-12-11\", '%Y-%m-%d')\n\n\nbegin_date = datetime.datetime.strptime(\"2012-09-12\", '%Y-%m-%d')\nend_date = datetime.datetime.strptime(\"2019-12-20\", '%Y-%m-%d')\n\nDATE_LIST = [\"2012-09-22\",\"2013-03-07\",\"2013-03-27\"]\n\n\nprint \"%table date\\tu_count\\tu_sum\"\n\nfor date_str in DATE_LIST:\n    try:\n        # r_count, r_sum, _ = get_sum_count_raw(date_str)\n        u_count, u_sum = AmazonUnified().get_rank_count_and_sum_by_date(date_str)\n        # count_diff = r_count - u_count\n        # sum_diff = r_sum - u_sum\n        # print \"{}\\t{}\\t{}\".format(date_str, count_diff, sum_diff)\n        print \"{}\\t{}\\t{}\".format(date_str, u_count, u_sum)\n    except Exception as e:\n        print \"{}\\t{}\\t{}\".format(date_str, -10, -10 )\n    "]},{"cell_type":"code","execution_count":0,"id":"20191215-005448_1139535710","metadata":{},"outputs":[],"source":["%%sh\n\naws s3 ls s3://b2c-prod-data-pipeline-unified-store-free/unified/app-tech.store.app-rank.v2/fact/\n"]},{"cell_type":"code","execution_count":0,"id":"20191215-105025_925735006","metadata":{},"outputs":[],"source":["%%sh\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}