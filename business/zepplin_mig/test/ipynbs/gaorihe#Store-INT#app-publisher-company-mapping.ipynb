{"cells":[{"cell_type":"code","execution_count":0,"id":"20200630-070624_1529031671","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql import types as T\nfrom pyspark.sql import functions as F\nfrom aadatapipelinecore.core.loader import pg, read as pg_read\nfrom aadatapipelinecore.core.urn import Urn\nfrom aadatapipelinecore.core.utils.identifier import atomic_id\nmarket_code = \"google-play\"\nupdate_date = \"2020-06-30\"\nPG_INTERFACE_IOS = {\"engine\": \"PG\", \"database\": \"aa\"}\nPG_INTERFACE_GP = {\"engine\": \"PG\", \"database\": \"aa_android\"}\nPUBLISHER_EVENT_SCHEMA = T.StructType([\n    T.StructField(\"id\", T.LongType(), False),\n    T.StructField(\"app_id\", T.LongType(), False),\n    T.StructField(\"store_id\", T.IntegerType(), False),\n    T.StructField(\"date\", T.StringType(), False),\n    T.StructField(\"old_value\", T.StringType(), False),\n    T.StructField(\"new_value\", T.StringType(), False),\n])\nurn = Urn(namespace=\"aa.store.app-event.v1\")\nsql = \"\"\"\n    SELECT id, app_id, store_id, date, old_value, new_value\n    FROM {table}\n    WHERE type = 33\n\"\"\"\nif market_code == \"apple-store\":\n    interface = PG_INTERFACE_IOS\n    sql = sql.format(table=\"aa_event\")\nelif market_code == \"google-play\":\n    interface = PG_INTERFACE_GP\n    sql = sql.format(table=\"event\")\nevent_rows = pg_read(\n    urn, interface, sql_param_pair=(sql,),\n    mode=pg.QueryMode.COPY,\n    dataframe_schema=PUBLISHER_EVENT_SCHEMA\n)\ndf = spark.createDataFrame(event_rows, PUBLISHER_EVENT_SCHEMA)\nprint df.count()\n# df.show(10, False)\npublisher_event_df = (\n    df\n    .withColumn(\"event_type\", F.lit(\"publisher_id\"))\n    .withColumn(\"market_code\", F.lit(market_code))\n    .withColumn(\"update_date\", F.lit(update_date))\n    .withColumn(\"_identifier\", F.lit(atomic_id()))\n)\nprint publisher_event_df.count()\npublisher_event_df.show(10, False)\npublisher_event_df.cache().createOrReplaceTempView(\"publisher_event\")\n"]},{"cell_type":"code","execution_count":0,"id":"20200602-071215_61380904","metadata":{},"outputs":[],"source":["\nfrom bdce.common.utils import update_application_code\nupdate_application_code(\n    spark, role=\"BDP-PROD-INT-DATAPIPELINE\", application_name=\"ap_aa_dna_mapping_log\"\n)"]},{"cell_type":"code","execution_count":0,"id":"20200610-032959_185769795","metadata":{},"outputs":[],"source":["\nimport json\nfrom aadatapipelinecore.core.fs.device import DynamoBucket\nfrom aadatapipelinecore.core.fs import Conf\napp_config_dynamo = DynamoBucket(Conf(bucket_name=\"B2C-PROD-DATA-PIPELINE_application_config\"))\n\nnamespace = \"aa.dna.mapping-log.v1\"\nconf = json.loads(app_config_dynamo.get([{\"id\": namespace}])[0][\"config\"])\nprint json.dumps(conf.get(namespace))\n\n# conf = {\n#     namespace: {\n#   \"schedule_module\": \"core.sched_datapipeline_workflow.DataPipelineScheduler\",\n#   \"amr\": {\n#     \"routine\": {\n#       \"default\": {\n#         \"is_multi_az\": \"false\",\n#         \"slave_instance_type\": \"r5.2xlarge\",\n#         \"safe_reserved_capacity\": 30,\n#         \"cluster_name\": \"zeppelin_cluster\",\n#         \"master_instance_type\": \"m4.xlarge\",\n#         \"retired_window\": 1800,\n#         \"bdp_version\": \"5.27.0\",\n#         \"node_count\":4,\n#         \"market\": \"spot\",\n#         \"category_name\": \"DATAPIPELINE_DNA_MAPPINGLOG-ADHOC-GAORIHE\"\n#       }\n#     }\n#   },\n#   \"pkg_name\": \"ap_aa_dna_mapping_log\",\n#   \"schedule_params\": {\n#     \"bypass_job_monitor\": True\n#   }\n# }\n# }\n\n# print json.dumps(conf.get(namespace))\n# app_config_dynamo.update({\"id\": namespace}, [{\"config\": json.dumps(conf)}])"]},{"cell_type":"code","execution_count":0,"id":"20200610-033523_504106901","metadata":{},"outputs":[],"source":["%python\nimport requests\nimport json\nimport time\n\nurl = \"https://6tx93muepa.execute-api.us-east-1.amazonaws.com/prod/ingest/bounded\"\nheaders = {\"Content-Type\": \"application/json\"}\n\njson_data = {\n  \"job_type\": \"routine\",\n  \"namespace\": \"aa.dna.mapping-log.v1\",\n  \"options\":{\n    \"date\":\"2020-06-29\"\n  },\n  \"source\": [{}]\n}\n\nprint json_data\n# response = requests.post(url, data=json.dumps(json_data), headers=headers)\n# print response.text"]},{"cell_type":"code","execution_count":0,"id":"20200525-035409_1342809383","metadata":{},"outputs":[],"source":["%%sh\nPGPASSWORD='TMV!PYT02X*w' psql -h 54.210.244.2  -U app_tomcat -d aa -p 5432 << EOF\n\nBEGIN;\n\nSELECT \n    *\n    --id, app_id, store_id, date, type, old_value, new_value\nFROM aa_event\nWHERE \n    type = 33\n    AND date >= '2020-06-15'\n    AND app_id = 350648885\nLIMIT 10\n;\n\nrollback;\n\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20200525-055942_1639731653","metadata":{},"outputs":[],"source":["%%sh\nPGPASSWORD='TMV!PYT02X*w' psql -h 54.210.244.2  -U app_tomcat -d aa_android -p 5433 << EOF\n\nBEGIN;\n\nSELECT \n    *\n    --count(1)\n    --id, app_id, store_id, date, type, old_value, new_value\nFROM event\nWHERE type = 33 and date='2020-01-01'\nLIMIT 10;\n\nrollback;\n\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20200525-032207_2139868375","metadata":{},"outputs":[],"source":["%%sh\nPGPASSWORD='TMV!PYT02X*w' psql -h 23.22.35.207  -U app_tomcat -d dna -p 5432 << EOF\n\nBEGIN;\n\nSELECT\n    *\n    --count(distinct company_id)\n    --product_id, unified_product_id, publisher_id, company_id, parent_company_id \nFROM in_app_dna_info_mapping\nWHERE product_id = 350648885\nORDER BY last_updated\nLIMIT 100\n;\n\nrollback;\n\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20200525-062127_342526467","metadata":{},"outputs":[],"source":["%%sh\nPGPASSWORD='TMV!PYT02X*w' psql -h 23.22.35.207  -U app_tomcat -d dna -p 5432 << EOF\n\nBEGIN;\n\nSELECT *\nFROM genre_id_product_mapping\nLIMIT 10\n;\n\n\nrollback;\n\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20200525-093834_75962177","metadata":{},"outputs":[],"source":["%%sh\n# universal_id: company_id\n# company_id: publisher_id\n\nPGPASSWORD='TMV!PYT02X*w' psql -h 23.22.35.207  -U app_tomcat -d dna -p 5432 << EOF\n\nBEGIN;\n\n--\\x\n\nSELECT *\nFROM dna_universal_company_mapping\nWHERE confirmed AND NOT disabled\nLIMIT 10\n;\n\n\n--SELECT count(1)\n--FROM dna_deleted_universal_company_mapping\n--LIMIT 1;\n\n\nrollback;\n\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20200525-060134_1979641453","metadata":{},"outputs":[],"source":["%%sh\nPGPASSWORD='TMV!PYT02X*w' psql -h 23.22.35.207  -U app_tomcat -d dna -p 5432 << EOF\n\nBEGIN;\n\nSELECT \n    id, universal_id, parent_id, start_date, end_date, created_time, last_updated_time, confirmed, disabled\nFROM dna_universal_company_parent\nWHERE\n    universal_id = 1000200000000143\n    --AND confirmed = True\n    AND disabled = False\nORDER BY start_date DESC\nLIMIT 10\n;\n\nrollback;\n\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20200622-122820_221048000","metadata":{},"outputs":[],"source":["%%sh\n+----------------+\n|      company_id|\n+----------------+\n|1000200000034103|\n|1000200000139906|\n|1000200000034104|\n+----------------+"]},{"cell_type":"code","execution_count":0,"id":"20200527-063128_3459805","metadata":{},"outputs":[],"source":["%%sh\nPGPASSWORD='2mHdFW6%#REu' psql -h internal-aa-prod-plproxy-internal-4-329644124.us-east-1.elb.amazonaws.com -p 7432 -U app_bdp_usage_qa -d dailyest << EOF\nSELECT  company_id, pub_id, company_type, date_range, date \n FROM plproxy.execute_select_nestloop(\\$proxy\\$ \n  SELECT company_id, pub_id, company_type, date_range, date\n    FROM pp.company_publisher_map_0\n    where company_id=1000200000333846 \n    LIMIT 100;\n     \\$proxy\\$) tbl (company_id BIGINT, pub_id BIGINT, company_type SMALLINT, date_range DATERANGE, date DATE)  LIMIT 100 ;\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20200527-063258_769868470","metadata":{},"outputs":[],"source":["%%sh\nPGPASSWORD='2mHdFW6%#REu' psql -h internal-aa-prod-plproxy-internal-4-329644124.us-east-1.elb.amazonaws.com -p 7432 -U app_bdp_usage_qa -d dailyest << EOF\n\nselect * \nfrom plproxy.execute_select_nestloop(\\$proxy\\$ \n\n    select *\n    from pp.company_publisher_map_1\n    limit 5\n\n\\$proxy\\$) tbl \n(company_id BIGINT, pub_id BIGINT, company_type SMALLINT, date_range DATERANGE, date DATE)\nlimit 100\n;\n\n\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20200622-101936_1227639048","metadata":{},"outputs":[],"source":["%%sh\nPGPASSWORD='PZQYyjRHCXZ23LVQ' psql -h 10.2.6.141  -U citus_bdp_prod_int_datapipeline -d aa_store_db -p 5432 << EOF\n\nBEGIN;\n\nSELECT *\nFROM dna.dna_mapping_log_4app_dim_v1\nWHERE\n    (start_date BETWEEN '2019-12-01' AND '2020-01-01' OR end_date BETWEEN '2019-12-01' AND '2020-01-01')\n    AND\n    (start_date != '1970-01-01' AND end_date IS NOT NULL)\n    AND company_id IS NOT NULL AND parent_company_id IS NOT NULL\nORDER BY app_id, start_date\nLIMIT 10\n;\n\n\nrollback;\n\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20200622-115303_1530579081","metadata":{},"outputs":[],"source":["%%sh\nPGPASSWORD='PZQYyjRHCXZ23LVQ' psql -h 10.2.6.141  -U citus_bdp_prod_int_datapipeline -d aa_store_db -p 5432 << EOF\n\nBEGIN;\n\nSELECT count(1) FROM (\n    SELECT \n        --distinct app_id, publisher_id\n        --distinct publisher_id, company_id\n        distinct company_id, parent_company_id\n    FROM dna.dna_mapping_log_4app_dim_v1\n    WHERE\n        (start_date BETWEEN '2019-12-01' AND '2020-01-01' OR end_date BETWEEN '2019-12-01' AND '2020-01-01')\n        AND\n        (start_date != '1970-01-01' AND end_date IS NOT NULL)\n) a\n;\n\nrollback;\n\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20200622-110654_2038056683","metadata":{},"outputs":[],"source":["%%sh\nPGPASSWORD='PZQYyjRHCXZ23LVQ' psql -h 10.2.6.141  -U citus_bdp_prod_int_datapipeline -d aa_store_db -p 5432 << EOF\n\nBEGIN;\n\nSELECT *\nFROM store.store_est_publisher_fact_v1\nLIMIT 10\n;\n\nrollback;\n\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20200602-065133_179685500","metadata":{},"outputs":[],"source":["%%sh\n# aws s3 ls s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est-cum.v1/fact/date=2020-04-18/   --recursive --human --summarize\n# aws s3 ls s3://b2c-prod-data-pipeline-unified-store-free/unified/store.app.v1/dimension/market_code=google-play/  --recursive --human --summarize\n\naws s3 ls s3://b2c-prod-data-pipeline-unified-dna/unified/dna.mapping-log.v1/dimension/_delta_log/\n# aws s3 ls s3://b2c-prod-data-pipeline-unified-dna/unified/dna.mapping-log.v1/dimension/update_date=${date}/  --recursive --human --summarize | sort\n\n# aws s3 ls s3://b2c-prod-data-pipeline-unified-dna/unified/dna.app-publisheer-mapping.v1/dimension/update_date=${date}/  --recursive --human --summarize | sort\n# aws s3 ls s3://b2c-prod-data-pipeline-unified-dna/unified/dna.publisher-company-mapping.v1/dimension/update_date=${date}/  --recursive --human --summarize | sort\n# aws s3 ls s3://b2c-prod-data-pipeline-unified-dna/unified/dna.company-parent-company-mapping.v1/dimension/update_date=${date}/  --recursive --human --summarize | sort\n\n# aws s3 ls s3://b2c-prod-data-pipeline-unified-store-free/_obsolete/store.app-event.v1/fact/update_date=  --recursive --human --summarize"]},{"cell_type":"code","execution_count":0,"id":"20200611-053922_519081963","metadata":{},"outputs":[],"source":["%%sh\naws s3 cp s3://b2c-prod-data-pipeline-unified-dna/unified/dna.mapping-log.v1/dimension/_delta_log/${json_file}.json - | head -n 20"]},{"cell_type":"code","execution_count":0,"id":"20200611-024219_80220135","metadata":{},"outputs":[],"source":["\nmapping_df = (\n    spark\n    .read\n    .format(\"delta\")\n    .option(\"versionAsOf\", \"6\")\n    .load(\"s3://b2c-prod-data-pipeline-unified-dna/unified/dna.mapping-log.v1/dimension/\")\n    .where(\"update_date = '2020-06-22'\")\n    .select([\"app_id\", \"publisher_id\", \"company_id\", \"parent_company_id\", \"start_date\", \"end_date\"])\n    .orderBy([\"app_id\", \"start_date\"])\n)\nprint mapping_df.count()\nmapping_df.show(10, False)\nmapping_df.cache().createOrReplaceTempView(\"mapping_log\")"]},{"cell_type":"code","execution_count":0,"id":"20200623-102033_1975534946","metadata":{},"outputs":[],"source":["\nmapping_df.where(\"publisher_id IS NULL\").show(10, False)\nmapping_df.where(\"app_id = 350648885\").show(10, False)"]},{"cell_type":"code","execution_count":0,"id":"20200623-110255_1992186383","metadata":{},"outputs":[],"source":["\nmapping_df.where(\"app_id = 281889893\").show(10, False)"]},{"cell_type":"code","execution_count":0,"id":"20200623-071049_1717286040","metadata":{},"outputs":[],"source":["\nprint mapping_df.select(\"app_id\").distinct().count()\nprint mapping_df.select([\"app_id\", \"start_date\"]).distinct().count()\nprint mapping_df.where(\"start_date = '1970-01-01' AND end_date IS NULL\").count()"]},{"cell_type":"code","execution_count":0,"id":"20200622-073638_645654165","metadata":{},"outputs":[],"source":["\ndate_validate = spark.sql(\"\"\"\nSELECT * FROM (\n    SELECT\n        app_id, start_date, end_date,\n        lag(start_date, -1) over (partition by app_id order by start_date) next_start_date\n    FROM mapping_log\n) a\nWHERE\n    next_start_date IS NOT NULL AND next_start_date != DATE_ADD(end_date, 1)\n    --app_id = 331677319\n\"\"\")\nprint date_validate.count()\ndate_validate.show(10, False)"]},{"cell_type":"code","execution_count":0,"id":"20200623-075747_1127866053","metadata":{},"outputs":[],"source":["\nmapping_df.where(\"app_id = 331677319\").show(10, False)"]},{"cell_type":"code","execution_count":0,"id":"20200622-073957_2045673366","metadata":{},"outputs":[],"source":["\napp_df = (\n    spark\n    .read\n    .format(\"delta\")\n    .load(\"s3://b2c-prod-data-pipeline-unified-dna/unified/dna.app-publisher-mapping.v1/dimension/\")\n    .where(\"update_date = '2020-06-22'\")\n    .select([\"app_id\", \"publisher_id\", \"start_date\", \"end_date\"])\n    .orderBy([\"app_id\", \"start_date\"])\n)\nprint app_df.count()\napp_df.show(10, False)\napp_df.cache().createOrReplaceTempView(\"app_mapping\")"]},{"cell_type":"code","execution_count":0,"id":"20200623-073123_1247671495","metadata":{},"outputs":[],"source":["\nprint app_df.select(\"app_id\").distinct().count()"]},{"cell_type":"code","execution_count":0,"id":"20200623-072927_1681633300","metadata":{},"outputs":[],"source":["\npublisher_df = (\n    spark\n    .read\n    .format(\"delta\")\n    .load(\"s3://b2c-prod-data-pipeline-unified-dna/unified/dna.publisher-company-mapping.v1/dimension/\")\n    .where(\"update_date = '2020-06-22'\")\n    .select([\"publisher_id\", \"company_id\"])\n    .orderBy([\"publisher_id\"])\n)\nprint publisher_df.count()\npublisher_df.show(10, False)\npublisher_df.cache().createOrReplaceTempView(\"publisher_company_mapping\")"]},{"cell_type":"code","execution_count":0,"id":"20200622-080538_1207832505","metadata":{},"outputs":[],"source":["\ncompany_df = (\n    spark\n    .read\n    .format(\"delta\")\n    .load(\"s3://b2c-prod-data-pipeline-unified-dna/unified/dna.company-parent-company-mapping.v1/dimension/\")\n    .where(\"update_date = '2020-06-22'\")\n    .select([\"company_id\", \"parent_company_id\", \"start_date\", \"end_date\"])\n    .orderBy([\"company_id\", \"start_date\"])\n)\nprint company_df.count()\ncompany_df.show(10, False)\ncompany_df.cache().createOrReplaceTempView(\"company_parent_mapping\")"]},{"cell_type":"code","execution_count":0,"id":"20200622-074111_592433671","metadata":{},"outputs":[],"source":["\napp_cum = (\n    spark\n    .read\n    .format(\"delta\")\n    .load(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-cum.v1/fact/\")\n    .where(\"date = '2020-04-18'\")\n    .select([\"app_id\"])\n)\nprint app_cum.count()\napp_cum.show(10, False)\napp_cum.cache().createOrReplaceTempView(\"app_cum\")"]},{"cell_type":"code","execution_count":0,"id":"20200623-073552_569495746","metadata":{},"outputs":[],"source":["\n# apps that in app-publisher mapping, but not in final mapping\napp_diff = spark.sql(\"\"\"\nSELECT * \nFROM app_mapping\nWHERE app_id IN (\n    SELECT app_pub_mapping_app_id AS app_id\n    FROM (\n        SELECT final.app_id AS final_mapping_app_id, mid.app_id AS app_pub_mapping_app_id\n        FROM mapping_log AS final\n        FULL JOIN app_mapping AS mid\n        ON final.app_id = mid.app_id\n    ) a\n    WHERE final_mapping_app_id IS NULL\n)\n\"\"\")\nprint app_diff.count()\napp_diff.show(10, False)"]},{"cell_type":"code","execution_count":0,"id":"20200623-074110_357311379","metadata":{},"outputs":[],"source":["\napp_diff.cache().createOrReplaceTempView(\"app_diff\")\ndf = spark.sql(\"\"\"\nSELECT final.*\nFROM app_diff AS diff\nJOIN final_mapping AS final\nON diff.app_id = final.app_id\n\"\"\")\nprint df.count()\ndf.show(10, False)"]},{"cell_type":"code","execution_count":0,"id":"20200623-084029_871608638","metadata":{},"outputs":[],"source":["\ndf.where(\"end_date IS NOT NULL\").show(10, False)"]},{"cell_type":"code","execution_count":0,"id":"20200623-080800_1158151982","metadata":{},"outputs":[],"source":["\nfrom aadatapipelinecore.core.urn import Urn\nfrom applications.common.test import read_unified_dataframe\n\nSYS_VIEWS = {\n    \"uds_view_dna_app_publisher_map\": {\n        \"urn\": Urn(namespace=\"aa.dna.app-publisher-mapping.v1\", data_type=\"dimension\"),\n        \"test_data\": [\n            {\n                \"date\": \"2020-04-18\",\n                \"app_id\": 1001\n            }\n        ]\n    }\n}\n\n\ndef init_single_view(spark, view):\n    from aadatapipelinecore.core.log import logger\n    urn = SYS_VIEWS[view][\"urn\"]\n    sql_where = SYS_VIEWS[view].get(\"partition_sql_where\", \" 1=1 \")\n    is_delta_lake = SYS_VIEWS[view].get(\"is_delta_lake\", True)\n    is_snapshot = SYS_VIEWS[view].get(\"is_snapshot\", False)\n    logger.info(\"view {} sql where is {}\".format(view, sql_where))\n    read_unified_dataframe(urn, spark, sql_where, is_delta_lake, is_snapshot).createOrReplaceTempView(view)\n\nview = \"uds_view_dna_app_publisher_map\"\ninit_single_view(spark, view)"]},{"cell_type":"code","execution_count":0,"id":"20200623-081146_640268803","metadata":{},"outputs":[],"source":["\nspark.sql(\"select count(1) from uds_view_dna_app_publisher_map\").show()\nspark.sql(\"select count(distinct app_id) from uds_view_dna_app_publisher_map\").show()\nspark.sql(\"select * from uds_view_dna_app_publisher_map limit 10\").show(10, False)"]},{"cell_type":"code","execution_count":0,"id":"20200623-081812_906613831","metadata":{},"outputs":[],"source":["\nspark.sql(\"\"\"\n    SELECT app_id, publisher_id, start_date, end_date\n    FROM uds_view_dna_app_publisher_map\n    WHERE update_date = '2020-06-22'\n\"\"\").cache().createOrReplaceTempView(\"app_publisher_mapping\")"]},{"cell_type":"code","execution_count":0,"id":"20200623-082055_616542191","metadata":{},"outputs":[],"source":["\nspark.sql(\"\"\"\n    SELECT a.app_id, a.publisher_id, b.company_id, a.start_date, a.end_date\n    FROM app_publisher_mapping AS a\n    LEFT JOIN publisher_company_mapping AS b\n    ON a.publisher_id = b.publisher_id\n\"\"\").cache().createOrReplaceTempView(\"app_company_mapping\")"]},{"cell_type":"code","execution_count":0,"id":"20200623-082131_1402426668","metadata":{},"outputs":[],"source":["\nspark.sql(\"\"\"\n    SELECT DISTINCT\n        b.app_id, a.company_id, a.parent_company_id, a.start_date, a.end_date\n    FROM app_company_mapping AS b\n    LEFT JOIN company_parent_mapping AS a\n    ON\n        a.company_id = b.company_id\n        AND (\n            a.start_date BETWEEN b.start_date AND b.end_date\n            OR a.end_date BETWEEN b.start_date AND b.end_date\n            OR (b.start_date IS NULL AND a.start_date <= b.end_date)\n            OR (b.end_date IS NULL AND a.end_date >= b.start_date)\n            OR (b.start_date IS NULL AND b.end_date IS NULL)\n        )\n\"\"\").cache().createOrReplaceTempView(\"app_parent_company_mapping\")"]},{"cell_type":"code","execution_count":0,"id":"20200623-083258_1039918647","metadata":{},"outputs":[],"source":["\nspark.sql(\"\"\"\n    SELECT DISTINCT app_id, date FROM (\n        SELECT app_id, CASE WHEN start_date IS NULL THEN '1970-01-01' ELSE start_date END AS date FROM app_company_mapping\n        UNION\n        SELECT app_id, DATE_ADD(end_date, 1) AS date FROM app_company_mapping\n        UNION\n        SELECT app_id, CASE WHEN start_date IS NULL THEN '1970-01-01' ELSE start_date END AS date FROM app_parent_company_mapping\n        UNION\n        SELECT app_id, DATE_ADD(end_date, 1) AS date FROM app_parent_company_mapping\n    ) a\n    WHERE date IS NOT NULL\n    ORDER BY app_id, date\n\"\"\").cache().createOrReplaceTempView(\"all_dates\")"]},{"cell_type":"code","execution_count":0,"id":"20200623-083455_1176722476","metadata":{},"outputs":[],"source":["\nspark.sql(\"\"\"\n    SELECT app_id, date AS start_date, date_add(lead(date, 1) over (partition by app_id order by date), -1) AS end_date\n    FROM all_dates\n    --UNION\n    --SELECT app_id, null AS start_date, date_add(first_value(date) over (partition by app_id order by date), -1) AS end_date\n    --FROM all_dates\n\"\"\").cache().createOrReplaceTempView(\"all_date_range\")"]},{"cell_type":"code","execution_count":0,"id":"20200623-083549_687826848","metadata":{},"outputs":[],"source":["\nspark.sql(\"\"\"\n    SELECT\n        company.app_id, company.publisher_id, company.company_id, parent.parent_company_id,\n        --CASE WHEN company.start_date IS NULL THEN '1970-01-01' ELSE company.start_date END AS start_date,\n        company.start_date,\n        company.end_date,\n        '2020-06-23' AS update_date\n    FROM\n        (\n            SELECT\n                range.app_id, map.publisher_id, map.company_id, range.start_date, range.end_date\n            FROM all_date_range AS range\n            LEFT JOIN app_company_mapping AS map\n            ON\n                map.app_id = range.app_id\n                AND (range.start_date >= map.start_date OR map.start_date IS NULL)\n                AND (range.end_date <= map.end_date OR map.end_date IS NULL)\n        ) AS company\n        LEFT JOIN company_parent_mapping AS parent\n        ON\n            company.company_id = parent.company_id\n            AND (company.start_date >= parent.start_date OR parent.start_date IS NULL)\n            AND (company.end_date <= parent.end_date OR parent.end_date IS NULL)\n\"\"\").cache().createOrReplaceTempView(\"final_mapping\")"]},{"cell_type":"code","execution_count":0,"id":"20200623-081929_1794249251","metadata":{},"outputs":[],"source":["\nspark.sql(\"select * from final_mapping where app_id = 285735373\").show(10, False)\nspark.sql(\"select * from final_mapping where app_id = 331677319\").show(10, False)\n# spark.sql(\"select count(1) from all_dates\").show(10, False)"]},{"cell_type":"code","execution_count":0,"id":"20200623-092958_268309264","metadata":{},"outputs":[],"source":["\nspark.sql(\"select count(1) from final_mapping where start_date IS NULL\").show(10, False)"]},{"cell_type":"code","execution_count":0,"id":"20200623-083701_602221579","metadata":{},"outputs":[],"source":["\nspark.sql(\"select count(1) from final_mapping\").show(10, False)\nspark.sql(\"select count(distinct app_id) from final_mapping\").show(10, False)\nspark.sql(\"select count(1) from final_mapping WHERE start_date = '1970-01-01' AND end_date IS NULL\").show(10, False)"]},{"cell_type":"code","execution_count":0,"id":"20200623-092408_509683162","metadata":{},"outputs":[],"source":["\nspark.sql(\"select * from final_mapping WHERE publisher_id IS NULL\").show(10, False)\nspark.sql(\"select * from app_publisher_mapping WHERE publisher_id IS NULL\").show(10, False)"]},{"cell_type":"code","execution_count":0,"id":"20200623-083746_999914112","metadata":{},"outputs":[],"source":["\ncheck = spark.sql(\"\"\"\nSELECT * FROM (\n    SELECT\n        app_id, start_date, end_date,\n        lag(start_date, -1) over (partition by app_id order by start_date) next_start_date\n    FROM mapping_log\n) a\nWHERE\n    next_start_date IS NOT NULL AND next_start_date != DATE_ADD(end_date, 1)\n    --app_id = 331677319\n\"\"\")\nprint check.count()\ncheck.show(10, False)"]},{"cell_type":"code","execution_count":0,"id":"20200618-100313_1685419797","metadata":{},"outputs":[],"source":["\nmapping_df.where(\"app_id = 20600007740853\").show(10, False)\nmapping_df.where(\"app_id = 20600006822910\").show(10, False)\nmapping_df.where(\"app_id = 1466586824\").show(10, False)"]},{"cell_type":"code","execution_count":0,"id":"20200618-101341_1701414687","metadata":{},"outputs":[],"source":["\nspark.sql(\"\"\"\nSELECT \n    DISTINCT publisher_id, company_id\nFROM historical_mapping\nWHERE \n    publisher_id IN (542280115, 20200003115819)\n\"\"\").show()"]},{"cell_type":"code","execution_count":0,"id":"20200618-102259_1324127742","metadata":{},"outputs":[],"source":["\nmapping_df.where(\"parent_company_id = 1000200000031106\").where(\"start_date < '2018-06-15'\").show(100, False)"]},{"cell_type":"code","execution_count":0,"id":"20200618-111823_484798097","metadata":{},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":0,"id":"20200617-090113_72273508","metadata":{},"outputs":[],"source":["\nprint mapping_df.where(\"app_id IS NULL\").count()\nprint mapping_df.select(\"app_id\").distinct().count()\n# print publisher_df.select(\"app_id\").distinct().count()"]},{"cell_type":"code","execution_count":0,"id":"20200617-065956_1142037439","metadata":{},"outputs":[],"source":["\npublisher_df = (\n    spark.read.format(\"delta\")\n    .load(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-publisher-mapping.v1/dimension/\")\n    .where(\"update_date = '2020-06-15'\")\n    .select([\"app_id\", \"publisher_id\", \"start_date\", \"end_date\"])\n    .orderBy([\"app_id\", \"start_date\"])\n)\nprint publisher_df.count()\npublisher_df.show(10, False)\npublisher_df.cache().createOrReplaceTempView(\"publisher_df\")"]},{"cell_type":"code","execution_count":0,"id":"20200617-090006_1621424571","metadata":{},"outputs":[],"source":["\nprint publisher_df.select(\"app_id\").distinct().count()"]},{"cell_type":"code","execution_count":0,"id":"20200617-070047_925374352","metadata":{},"outputs":[],"source":["\npublisher_df.where(\"end_date = '2014-04-08' AND start_date IS NULL\").show(10, False)"]},{"cell_type":"code","execution_count":0,"id":"20200615-115831_1294471506","metadata":{},"outputs":[],"source":["\ncompany_df = (\n    spark.read.format(\"delta\")\n    .load(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.company-parent-company-mapping.v1/dimension/\")\n    .where(\"update_date = '2020-06-15'\")\n    .select([\"company_id\", \"parent_company_id\", \"start_date\", \"end_date\"])\n    .orderBy([\"company_id\", \"start_date\"])\n)\nprint company_df.count()\ncompany_df.show(10, False)\ncompany_df.cache().createOrReplaceTempView(\"parent_mapping\")"]},{"cell_type":"code","execution_count":0,"id":"20200616-021743_2025683954","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql import types as T\nfrom pyspark.sql import functions as F\nfrom aadatapipelinecore.core.loader import pg, read as pg_read\nfrom aadatapipelinecore.core.urn import Urn\nfrom aadatapipelinecore.core.utils.identifier import atomic_id\n\nupdate_date = \"2020-06-16\"\n\ninterface = {\"engine\": \"PG\", \"database\": \"dna\"}\n\nDNA_PUBLISHER_COMPANY_SCHEMA = T.StructType([\n    T.StructField(\"universal_id\", T.LongType(), False),\n    T.StructField(\"company_id\", T.LongType(), False),\n    T.StructField(\"last_updated\", T.StringType(), False),\n])\n\nurn = Urn(namespace=\"aa.store.dna-company.v1\")\nsql = \"\"\"\n    SELECT DISTINCT universal_id, company_id, last_updated_time as last_updated\n    FROM {table}\n    WHERE confirmed AND NOT disabled\n\"\"\".format(table = \"dna_universal_company_mapping\")\n\ndna_rows = pg_read(\n    urn, interface, sql_param_pair=(sql,),\n    mode=pg.QueryMode.COPY,\n    dataframe_schema=DNA_PUBLISHER_COMPANY_SCHEMA\n)\ndf = spark.createDataFrame(dna_rows, DNA_PUBLISHER_COMPANY_SCHEMA)\n\nprint df.count()\n\ndna_publisher_df = (\n    df\n    .withColumnRenamed(\"company_id\", \"publisher_id\")\n    .withColumnRenamed(\"universal_id\", \"company_id\")\n    .withColumn(\"update_date\", F.lit(update_date))\n    .withColumn(\"_identifier\", F.lit(atomic_id()))\n)\nprint dna_publisher_df.count()\ndna_publisher_df.show(10, False)\ndna_publisher_df.cache().createOrReplaceTempView(\"dna_df\")"]},{"cell_type":"code","execution_count":0,"id":"20200616-022824_315858985","metadata":{},"outputs":[],"source":["\nleft = spark.sql(\"\"\"\n    SELECT a.app_id, a.publisher_id, b.company_id, a.start_date, a.end_date\n    FROM publisher_mapping AS a\n    LEFT JOIN dna_df AS b\n    ON a.publisher_id = b.publisher_id\n\"\"\")\nprint left.count()\nleft.show(10, False)\nleft.cache().createOrReplaceTempView(\"app_company_mapping\")"]},{"cell_type":"code","execution_count":0,"id":"20200616-053937_1201650489","metadata":{},"outputs":[],"source":["\napp_parent_company = spark.sql(\"\"\"\n    SELECT b.app_id, a.company_id, a.parent_company_id, a.start_date, a.end_date\n    FROM parent_mapping AS a\n    JOIN app_company_mapping AS b\n    ON\n        a.company_id = b.company_id\n        AND (\n            a.start_date BETWEEN b.start_date AND b.end_date\n            OR a.end_date BETWEEN b.start_date AND b.end_date\n            OR (b.start_date IS NULL AND a.start_date <= b.end_date)\n            OR (b.end_date IS NULL AND a.end_date >= b.start_date)\n        )\n\"\"\")\napp_parent_company.cache().createOrReplaceTempView(\"app_parent_company\")\nall_dates = spark.sql(\"\"\"\nSELECT DISTINCT app_id, date FROM (\n    SELECT app_id, start_date AS date FROM app_company_mapping WHERE company_id IS NOT NULL\n    UNION\n    SELECT app_id, DATE_ADD(end_date, 1) AS date FROM app_company_mapping WHERE company_id IS NOT NULL\n    UNION \n    SELECT app_id, start_date AS date FROM app_parent_company\n    UNION\n    SELECT app_id, DATE_ADD(end_date, 1) AS date FROM app_parent_company\n) a\nWHERE date IS NOT NULL\nORDER BY app_id, date\n\"\"\")\nprint all_dates.count()\nall_dates.show(10, False)\nall_dates.cache().createOrReplaceTempView(\"all_dates\")"]},{"cell_type":"code","execution_count":0,"id":"20200616-063112_1419304371","metadata":{},"outputs":[],"source":["\nall_date_range = spark.sql(\"\"\"\nSELECT app_id, date AS start_date, date_add(lead(date, 1) over (partition by app_id order by date), -1) AS end_date\nFROM all_dates\nUNION\nSELECT app_id, null AS start_date, date_add(first_value(date) over (partition by app_id order by date), -1) AS end_date\nFROM all_dates\n\"\"\")\nprint all_date_range.count()\nall_date_range.show(10, False)\nall_date_range.cache().createOrReplaceTempView(\"all_date_range\")"]},{"cell_type":"code","execution_count":0,"id":"20200616-064240_1920158742","metadata":{},"outputs":[],"source":["\napp_parent_company.where(\"app_id = 281889893\").orderBy(\"start_date\").show(10, False)\n\n# app_company_mapping\nleft.where(\"app_id = 281889893\").orderBy(\"start_date\").show(10, False)\n\n# parent_mapping\ncompany_df.where(\"company_id IN (1000200000003452, 1000200000003455)\").show(10, False)"]},{"cell_type":"code","execution_count":0,"id":"20200616-101101_1377326659","metadata":{},"outputs":[],"source":["\n# 281889893, 319581197\n# new_app_company_mapping.where(\"app_id = 319581197\").orderBy(\"start_date\").show(10, False)\nresult.where(\"app_id = 281889893\").orderBy(\"start_date\").show(10, False)"]},{"cell_type":"code","execution_count":0,"id":"20200616-060312_85809239","metadata":{},"outputs":[],"source":["\nall_dates.where(\"app_id = 319581197\").orderBy(\"date\").show(10, False)\nall_date_range.where(\"app_id = 319581197\").orderBy(\"start_date\").show(10, False)"]},{"cell_type":"code","execution_count":0,"id":"20200616-093932_1692408180","metadata":{},"outputs":[],"source":["\n# all_date_range - range\n+---------+----------+----------+\n|app_id   |start_date|end_date  |\n+---------+----------+----------+\n|319581197|null      |2014-07-06|\n|319581197|2014-07-07|2015-06-18|\n|319581197|2015-06-19|2018-01-31|\n|319581197|2018-02-01|2020-01-22|\n|319581197|2020-01-23|null      |\n+---------+----------+----------+\n\n# app_company_mapping - map\n+---------+------------+----------------+----------+----------+\n|app_id   |publisher_id|company_id      |start_date|end_date  |\n+---------+------------+----------------+----------+----------+\n|319581197|304712583   |1000200000034131|null      |2015-06-18|\n|319581197|978181908   |1000200000034131|2015-06-19|2020-01-22|\n|319581197|304712583   |1000200000034131|2020-01-23|null      |\n+---------+------------+----------------+----------+----------+"]},{"cell_type":"code","execution_count":0,"id":"20200616-145717_2032245343","metadata":{},"outputs":[],"source":["\nnew_app_company_mapping = spark.sql(\"\"\"\n        SELECT\n            map.app_id, map.publisher_id, map.company_id, range.start_date, range.end_date\n        FROM all_date_range AS range\n        LEFT JOIN app_company_mapping AS map\n        ON\n            map.app_id = range.app_id \n            AND \n            ( \n                (range.start_date >= map.start_date OR map.start_date IS NULL)\n                AND (range.end_date <= map.end_date OR map.end_date IS NULL)\n            )\n\"\"\")"]},{"cell_type":"code","execution_count":0,"id":"20200616-053002_1738941367","metadata":{},"outputs":[],"source":["\n# all_date_range\n# app_company_mapping\n# parent_mapping\n\nresult = spark.sql(\"\"\"\nSELECT \n    company.app_id, company.publisher_id, company.company_id, parent.parent_company_id, company.start_date, company.end_date\nFROM\n    (\n        SELECT\n            map.app_id, map.publisher_id, map.company_id, range.start_date, range.end_date\n        FROM all_date_range AS range\n        LEFT JOIN app_company_mapping AS map\n        ON\n            map.app_id = range.app_id \n            AND \n            (range.start_date >= map.start_date OR map.start_date IS NULL)\n            AND (range.end_date <= map.end_date OR map.end_date IS NULL)\n    ) AS company\n    LEFT JOIN parent_mapping AS parent\n    ON\n        company.company_id = parent.company_id \n        AND (company.start_date >= parent.start_date OR parent.start_date IS NULL)\n        AND (company.end_date <= parent.end_date OR parent.end_date IS NULL)\n\"\"\")\nprint result.count()\nresult.show(10, False)"]},{"cell_type":"code","execution_count":0,"id":"20200616-023213_740786891","metadata":{},"outputs":[],"source":["\nvalidate = spark.sql(\"\"\"\nSELECT * FROM (\n    SELECT\n        app_id, start_date, end_date,\n        lag(start_date, -1) over (partition by app_id order by start_date) next_start_date\n    FROM app_company_mapping\n) a\nWHERE\n    next_start_date IS NOT NULL AND next_start_date != DATE_ADD(end_date, 1)\n    --app_id = 331677319\n\"\"\")\nprint validate.count()\nvalidate.show(10, False)"]},{"cell_type":"code","execution_count":0,"id":"20200611-093420_1781477050","metadata":{},"outputs":[],"source":["%%sh\naws s3 ls s3://b2c-prod-data-pipeline-unified-store-free/_obsolete/store.app-event.v1/fact/ --recursive"]},{"cell_type":"code","execution_count":0,"id":"20200611-092501_1394799239","metadata":{},"outputs":[],"source":["\nevent = (\n    spark\n    .read\n    .option(\"basePath\", \"s3://b2c-prod-data-pipeline-unified-store-free/_obsolete/store.app-event.v1/fact/\")\n    .parquet(\"s3://b2c-prod-data-pipeline-unified-store-free/_obsolete/store.app-event.v1/fact/update_date=2020-06-11/\")\n    .select([\"market_code\", \"id\", \"app_id\", \"store_id\", \"date\", \"old_value\", \"new_value\"])\n)\nprint event.count()\nevent.show(10, False)\nevent.cache().createOrReplaceTempView(\"event\")"]},{"cell_type":"code","execution_count":0,"id":"20200611-134227_1767492529","metadata":{},"outputs":[],"source":["\nspark.sql(\"\"\"\nSELECT * FROM event\nWHERE\n    app_id = 20600009608756\n    AND date = '2019-06-17 07:00:00+00'\nORDER BY id DESC\n\"\"\").show(10, False)"]},{"cell_type":"code","execution_count":0,"id":"20200611-092652_504902098","metadata":{},"outputs":[],"source":["\nt = spark.sql(\"\"\"\nSELECT * FROM (\n    SELECT market_code, app_id, store_id, date, count(1) AS count\n    FROM event\n    GROUP BY market_code, app_id, store_id, date\n) a\nWHERE count > 1\nORDER BY count DESC\n\"\"\")\nprint t.count()\nt.show(100, False)"]},{"cell_type":"code","execution_count":0,"id":"20200602-075142_469117768","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql import types as T\nfrom pyspark.sql import functions as F\nfrom aadatapipelinecore.core.loader import pg, read as pg_read\nfrom aadatapipelinecore.core.urn import Urn\nfrom aadatapipelinecore.core.utils.identifier import atomic_id\n\nmarket_code = \"google-play\"\nupdate_date = \"2020-06-11\"\n\n\nPG_INTERFACE_IOS = {\"engine\": \"PG\", \"database\": \"aa\"}\nPG_INTERFACE_GP = {\"engine\": \"PG\", \"database\": \"aa_android\"}\n\nPUBLISHER_EVENT_SCHEMA = T.StructType([\n    T.StructField(\"id\", T.LongType(), False),\n    T.StructField(\"app_id\", T.LongType(), False),\n    T.StructField(\"store_id\", T.IntegerType(), False),\n    T.StructField(\"date\", T.StringType(), False),\n    T.StructField(\"old_value\", T.StringType(), False),\n    T.StructField(\"new_value\", T.StringType(), False),\n])\n\nurn = Urn(namespace=\"aa.store.app-event.v1\")\nsql = \"\"\"\n    SELECT id, app_id, store_id, date, old_value, new_value\n    FROM {table}\n    WHERE type = 33\n\"\"\"\n\nif market_code == \"apple-store\":\n    interface = PG_INTERFACE_IOS\n    sql = sql.format(table=\"aa_event\")\nelif market_code == \"google-play\":\n    interface = PG_INTERFACE_GP\n    sql = sql.format(table=\"event\")\n\nevent_rows = pg_read(\n    urn, interface, sql_param_pair=(sql,),\n    mode=pg.QueryMode.COPY,\n    dataframe_schema=PUBLISHER_EVENT_SCHEMA\n)\ndf = spark.createDataFrame(event_rows, PUBLISHER_EVENT_SCHEMA)\n\nprint df.count()\n# df.show(10, False)\n\n\npublisher_event_df = (\n    df\n    .withColumn(\"event_type\", F.lit(\"publisher_id\"))\n    .withColumn(\"market_code\", F.lit(market_code))\n    .withColumn(\"update_date\", F.lit(update_date))\n    .withColumn(\"_identifier\", F.lit(atomic_id()))\n)\nprint publisher_event_df.count()\npublisher_event_df.show(10, False)\npublisher_event_df.cache().createOrReplaceTempView(\"publisher_event\")"]},{"cell_type":"code","execution_count":0,"id":"20200608-060149_1482379157","metadata":{},"outputs":[],"source":["\n# publisher_event_df.coalesce(2).write.parquet(\n    \"s3://b2c-prod-data-pipeline-unified-store-free/_obsolete/store.app-event.v1/fact/\",\n    mode=\"append\",\n    compression=\"gzip\",\n    partitionBy=[\"update_date\", \"market_code\", \"event_type\"]\n\n)"]},{"cell_type":"code","execution_count":0,"id":"20200615-122607_1456146564","metadata":{},"outputs":[],"source":["%%sh\naws s3 ls s3://b2c-prod-data-pipeline-unified-store-free/_obsolete/store.app-event.v1/fact/update_date="]},{"cell_type":"code","execution_count":0,"id":"20200602-094149_1343008035","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql.functions import lit\n\npublisher_event = (\n    spark.read\n    .option(\"basePath\", \"s3://b2c-prod-data-pipeline-unified-store-free/_obsolete/store.app-event.v1/fact/\")\n    .parquet(\"s3://b2c-prod-data-pipeline-unified-store-free/_obsolete/store.app-event.v1/fact/update_date={date}/\".format(date=\"2020-06-11\"))\n    .drop(\"_identifier\")\n)\nprint publisher_event.count()\npublisher_event.show(10, False)\npublisher_event.cache().createOrReplaceTempView(\"publisher_event\")"]},{"cell_type":"code","execution_count":0,"id":"20200603-021435_567138434","metadata":{},"outputs":[],"source":["\ndf = spark.sql(\"\"\"\n    SELECT\n        market_code, app_id, date, old_value, new_value,\n        ROW_NUMBER() OVER (PARTITION BY app_id ORDER BY date) AS rn\n    FROM (\n        SELECT DISTINCT\n            'apple-store' AS market_code, app_id, date_format(date, 'yyyy-MM-dd') AS date,\n            FIRST_VALUE(old_value) OVER (PARTITION BY app_id, date_format(date, 'yyyy-MM-dd') ORDER BY id ASC) AS old_value,\n            FIRST_VALUE(new_value) OVER (PARTITION BY app_id, date_format(date, 'yyyy-MM-dd') ORDER BY id DESC) AS new_value\n        FROM publisher_event\n    ) AS a\n    WHERE\n        old_value != new_value\n\"\"\")\nprint df.count()\ndf.show(10, False)\ndf.cache().createOrReplaceTempView(\"agg_publisher_event\")"]},{"cell_type":"code","execution_count":0,"id":"20200603-093716_1811233875","metadata":{},"outputs":[],"source":["\nspark.sql(\"\"\"\n    SELECT a.market_code, a.app_id, a.new_value AS publisher_id, a.date AS start_date, DATE_ADD(b.date, -1) AS end_date\n    FROM agg_publisher_event AS a\n    LEFT JOIN agg_publisher_event AS b\n    ON\n        a.app_id = b.app_id\n        AND a.rn + 1 = b.rn\n    UNION ALL\n    SELECT market_code, app_id, old_value AS publisher_id, NULL AS start_date, DATE_ADD(date, -1) AS end_date\n    FROM agg_publisher_event\n    WHERE rn = 1\n\"\"\").cache().createOrReplaceTempView(\"publisher_change_log\")"]},{"cell_type":"code","execution_count":0,"id":"20200616-154908_1579342825","metadata":{},"outputs":[],"source":["\nspark.sql(\"\"\"\n    SELECT\n        market_code,\n        app_id,\n        new_value AS publisher_id,\n        date AS start_date,\n        DATE_ADD(LAG(date, 1) OVER (PARTITION BY app_id ORDER BY date DESC), -1) AS end_date\n    FROM agg_publisher_event\n    UNION ALL\n    SELECT DISTINCT\n        market_code,\n        app_id,\n        FIRST_VALUE(old_value) OVER (PARTITION BY app_id ORDER BY date) AS publisher_id,\n        NULL AS start_date,\n        DATE_ADD(FIRST_VALUE(date) OVER (PARTITION BY app_id ORDER BY date), -1) AS end_date\n    FROM agg_publisher_event\n\"\"\").cache().createOrReplaceTempView(\"publisher_change_log\")"]},{"cell_type":"code","execution_count":0,"id":"20200615-131222_2061949234","metadata":{},"outputs":[],"source":["\nspark.sql(\"select * from publisher_change_log where app_id = 319581197\").orderBy(\"start_date\").show(10, False)"]},{"cell_type":"code","execution_count":0,"id":"20200616-155557_528111378","metadata":{},"outputs":[],"source":["\ndf.where(\"app_id = 319581197\").orderBy(\"date\").show(10, False)"]},{"cell_type":"code","execution_count":0,"id":"20200603-090144_1080520511","metadata":{},"outputs":[],"source":["\na\n+-----------+---------+----------+---------+---------+---+\n|market_code|app_id   |date      |old_value|new_value|rn |\n+-----------+---------+----------+---------+---------+---+\n|apple-store|319581197|2015-06-19|304712583|978181908|1  |\n|apple-store|319581197|2020-01-23|978181908|304712583|2  |\n+-----------+---------+----------+---------+---------+---+\n\n+---------+-----------+------------+------------+----------+----------+\n|app_id   |market_code|event_type  |publisher_id|start_date|end_date  |\n+---------+-----------+------------+------------+----------+----------+\n|319581197|apple-store|publisher_id|304712583   |null      |2015-06-18|\n|319581197|apple-store|publisher_id|978181908   |2015-06-19|2020-01-22|\n|319581197|apple-store|publisher_id|304712583   |2020-01-23|null      |\n+---------+-----------+------------+------------+----------+----------+"]},{"cell_type":"code","execution_count":0,"id":"20200603-091139_240469076","metadata":{},"outputs":[],"source":["\nt1 = spark.sql(\"\"\"\nSELECT app_id, date, old_value, new_value, ROW_NUMBER() OVER (PARTITION BY app_id ORDER BY date) AS rn\nFROM agg_publisher_event\n\"\"\")\nt1.cache().createOrReplaceTempView(\"t\")\n\ntest = spark.sql(\"\"\"\nSELECT a.app_id, a.new_value AS publisher_id, a.date AS start_date, b.date AS end_date\nFROM t AS a\nLEFT JOIN t AS b\nON\n    a.app_id = b.app_id\n    AND a.rn + 1 = b.rn\nUNION ALL\nSELECT app_id, old_value AS publisher_id, NULL AS start_date, date AS end_date\nFROM t\nWHERE rn = 1\n\"\"\").orderBy([\"app_id\", \"start_date\"])\nprint test.count()\ntest.show(10, False)\ntest.cache().createOrReplaceTempView(\"publisher_change_log\")"]},{"cell_type":"code","execution_count":0,"id":"20200603-064145_478969195","metadata":{},"outputs":[],"source":["\npublisher_mapping = spark.sql(\"\"\"\nSELECT\n    app_id, publisher_id, start_date, end_date\nFROM publisher_change_log\nUNION ALL\nSELECT \n    app_id, publisher_id, NULL AS start_date, NULL AS end_date\nFROM publisher_df\nWHERE\n    app_id NOT IN (\n        SELECT DISTINCT app_id\n        FROM publisher_change_log\n    )\n\"\"\")\nprint publisher_mapping.count()\npublisher_mapping.show(10, False)"]},{"cell_type":"code","execution_count":0,"id":"20200608-064559_1517928003","metadata":{},"outputs":[],"source":["\n(\n    # publisher_mapping\n    .coalesce(10)\n    .write\n    .format(\"delta\")\n    .mode(\"append\")\n    .save(\"s3://b2c-prod-data-pipeline-unified-store-free/unified/store.app-publisher-mapping.v1/dimension/\")\n)"]},{"cell_type":"code","execution_count":0,"id":"20200603-083405_204993009","metadata":{},"outputs":[],"source":["\ndiff = publisher_mapping.where(\"is_publisher_same = False AND start_date < '2020-06-01'\")\nprint diff.count()\n\ndiff.select([\"market_code\", \"status\"]).groupby([\"market_code\", \"status\"]).count().orderBy([\"market_code\", \"status\"]).show(10, False)\ndiff.show(10, False)"]},{"cell_type":"code","execution_count":0,"id":"20200604-032151_525791206","metadata":{},"outputs":[],"source":["\npublisher_diff = spark.sql(\"\"\"\nSELECT DISTINCT\n    detail.market_code, detail.app_id, detail.status, detail.publisher_id, change.event_type, change.date, change.new_value,\n    CASE WHEN detail.publisher_id = change.new_value THEN True ELSE False END AS is_publisher_same\nFROM (\n    SELECT market_code, app_id, event_type, update_time AS date, new_value\n    FROM (\n        SELECT *, ROW_NUMBER() OVER (PARTITION BY app_id, market_code, event_type ORDER BY update_time DESC, id DESC) AS rn\n        FROM (\n            SELECT id, app_id, market_code, event_type, date_format(date, 'yyyy-MM-dd') AS date, date AS update_time, old_value, new_value\n            FROM publisher_event\n        ) a\n    ) b\n    WHERE rn = 1\n) AS change\nJOIN\n(\n    SELECT DISTINCT market_code, app_id, status, publisher_id\n    FROM publisher_df\n) AS detail\nON\n    change.app_id = detail.app_id\n\"\"\").where(\"is_publisher_same = False AND date <= '2020-06-01'\").orderBy([\"market_code\", \"date\"])\nprint publisher_diff.count()\npublisher_diff.show(10, False)"]},{"cell_type":"code","execution_count":0,"id":"20200603-063507_158179789","metadata":{},"outputs":[],"source":["%%sh\nPGPASSWORD='TMV!PYT02X*w' psql -h 54.210.244.2  -U app_tomcat -d aa_android -p 5433 << EOF\n\nBEGIN;\n\nSELECT id, name, company_id, status\nFROM app\nWHERE \n    id = 20600009608756\nLIMIT 10\n;\n\nSELECT *\nFROM event\nWHERE \n    app_id = 20600009608756 AND type = 33\n    AND date < '2019-06-20'\nORDER BY id DESC\nLIMIT 100\n;\n\nrollback;\n\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20200602-070614_1933358429","metadata":{},"outputs":[],"source":["%%sh\nPGPASSWORD='TMV!PYT02X*w' psql -h 54.210.244.2  -U app_tomcat -d aa -p 5432 << EOF\n\nBEGIN;\n\nSELECT id, name, company_id, status\nFROM aa_app\nWHERE \n    id = 328171271\nLIMIT 10\n;\n\nSELECT *\nFROM aa_event\nWHERE \n    app_id = 328171271 AND type = 33\nORDER BY date DESC\nLIMIT 10\n;\n\n\\d aa_event\n\nEND;\n\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20200603-101641_239870440","metadata":{},"outputs":[],"source":["%%sh\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}