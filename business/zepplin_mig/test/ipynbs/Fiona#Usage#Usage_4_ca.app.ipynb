{"cells":[{"cell_type":"code","execution_count":0,"id":"20191213-063416_1094235821","metadata":{},"outputs":[],"source":["%%sh\nPGPASSWORD='2mHdFW6%#REu' psql -h internal-aa-prod-plproxy-internal-2-31838298.us-east-1.elb.amazonaws.com -U app_bdp_usage_qa -d cohort -p 7432 << EOF \n\nSELECT device_id,store_id,date,app_id,kpi,estimate,seg_app_id\n  FROM plproxy.execute_select_nestloop(\\$proxy\\$select device_id,store_id,date,app_id,kpi,estimate,seg_app_id from ca.app_monthly_1001_1_201802\n \\$proxy\\$) t (device_id SMALLINT,store_id INT,date DATE,app_id BIGINT,kpi SMALLINT, estimate FLOAT, seg_app_id BIGINT)  limit 3;\n\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20191213-063540_1894212481","metadata":{},"outputs":[],"source":["\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\n\nfrom aaintdatapipeline.application.app_qa.db_check_v1.constants import pg_settings\nfrom aaintdatapipeline.core.urn import Urn\nfrom aaintdatapipeline.application.app_qa.conf import settings\nfrom aaintdatapipeline.core.loader.plproxy import build_db_settings\nfrom aaplproxy.connection import ClusterConnection\nimport unittest\nimport datetime\nfrom dateutil.relativedelta import relativedelta\nimport psycopg2\n\nANDROID_COUNTRY_ID_CODES = { 1: 'AU', 2: 'CA', 3: 'CN', 4: 'DE', 5: 'ES', 6: 'FR', 7: 'GB', 8: 'IT', 9: 'JP', 10: 'US', 11: 'BE', 12: 'CH', 13: 'CL', 14: 'ZA', 15: 'VN', 16: 'HK', 17: 'AR', 18: 'BR', 19: 'IN', 20: 'FI', 21: 'ID', 22: 'RU', 23: 'NL', 24: 'MY', 25: 'TR', 26: 'MX', 27: 'KR', 28: 'PL', 29: 'TH', 30: 'TW', 31: 'PH', 32: 'SG', 33: 'EG', 34: 'SE', 35: 'AT', 36: 'CZ', 37: 'HU', 38: 'DK', 39: 'IE', 40: 'IL', 41: 'NZ', 42: 'NO', 43: 'PT', 44: 'RO', 45: 'SK', 46: 'GR', 47: 'BG', 48: 'UA', 49: 'AE', 50: 'KW', 51: 'SA', 52: 'CO', 65: 'LB', 56: 'PE', 80: 'HR', 54: 'PK', 62: 'EC', 73: 'QA', 102: 'MO', 103: 'LU', 53: 'KZ', 1000: 'WW' }\n\n\n# IOS_COUNTRY_ID_CODES={143460:'AU',143455:'CA',143465:'CN',143443:'DE',143454:'ES'}\n\nIOS_COUNTRY_ID_CODES={143460:'AU',143455:'CA',143465:'CN',143443:'DE',143454:'ES',143442:'FR',143444:'GB',143450:'IT',143462:'JP',143441:'US',143446:'BE',143459:'CH',143483:'CL',143472:'ZA',143471:'VN',143463:'HK',143505:'AR',143503:'BR',143467:'IN',143447:'FI',143476:'ID',143469:'RU',143452:'NL',143473:'MY',143480:'TR',143468:'MX',143466:'KR',143478:'PL',143475:'TH',143470:'TW',143474:'PH',143464:'SG',143516:'EG',143456:'SE',143445:'AT',143489:'CZ',143482:'HU',143458:'DK',143449:'IE',143491:'IL',143461:'NZ',143457:'NO',143453:'PT',143487:'RO',143496:'SK',143448:'GR',143526:'BG',143492:'UA',143481:'AE',143493:'KW',143479:'SA',143501:'CO',143451:'LU',143497:'LB',143515:'MO',143507:'PE',143494:'HR',143477:'PK',143509:'EC',143498:'QA',0:'WW'}\n\ndef get_device_list(device):\n    if device=='ios':\n        return ['2001','2002']\n    else:\n        return ['1001','1002']\n\ndef get_month_list():\n    result = []\n    today = datetime.date(2019, 10, 1) \n    current = datetime.date(2013, 1, 1)    \n    while current <= today:\n        month_data_raw=datetime.datetime.strftime(current,'%Y-%m')\n        month_data_leg_db=datetime.datetime.strftime(current,'%Y%m')\n        result.append((month_data_raw, month_data_leg_db ))\n        current += relativedelta(months=1)    \n    return result\n    \n    \ndef pg_settings(urn, sql, granularity, schema):\n    result = {}\n    db_settings = build_db_settings(urn, schema)\n    connection = ClusterConnection(db_settings)\n    master_runner = connection.master_runner\n    rows, _ = master_runner.select(sql)\n    result[granularity] = rows\n    return result\n\n\nurn = Urn(\n    namespace='app-qa.db-validation.v1',\n    owner='app_qa'\n)\n\npath=\"s3://b2c-prod-data-pipeline-unified-usage/unified/app-tech.usage.legacy-ca_app.v1/fact/granularity={raw_granularity}/month={raw_month}/device_id={device}/store_id={sid}/\"\n\n\nimport traceback\ndef check_ca_app_dump_data(store_id_list, device_id_list, _granularity):\n    t = unittest.TestCase('run')\n    for id in store_id_list:\n        for device in device_id_list:\n            for m in get_month_list():\n                # print id, device, m[0] \n                try:\n                    weekly_basic = \"\"\"\n                        SELECT app_id_count FROM plproxy.execute_select_nestloop($$select count(app_id) from ca.app_{granularity}_{device_id}_{store_id}_{month} $$) t (app_id_count BIGINT)\n                    \"\"\".format(device_id=device,store_id=id, month=m[1], granularity=_granularity)\n                    granularity_ = _granularity.capitalize()\n                    result = pg_settings(urn, weekly_basic, granularity_,'usage')\n                    l = [int(x[0]) for x in result[granularity_]]\n                    if sum(l)==0:\n                        pass\n                        # print 'the table is empty  - device:{}  store_id:{} month:{}'.format(device, id, m[0])\n                    else:\n                        dump_data_path=path.format(device=device, raw_month=m[0], sid=id, raw_granularity=_granularity)\n                        dump_count=spark.read.parquet(dump_data_path).count()\n                        t.assertEqual(dump_count, sum(l), \"{}:{} ~ raw: {} ~ dumped data: {},device:{},  store_id:{} , month: {}\".format(granularity_, m[0], sum(l), dump_count, device, id , m))\n                except psycopg2.ProgrammingError : \n                    pass\n                    # traceback.print_exc()\n                    # print(e)\n                    #  print 'the table is not existed - granularity {}, device:{}  store_id:{} month:{}'.format(granularity_, device, id, m[0])\n                \n\ncheck_ca_app_dump_data(IOS_COUNTRY_ID_CODES, get_device_list('ios'),'monthly')\ncheck_ca_app_dump_data(ANDROID_COUNTRY_ID_CODES, get_device_list('android'),'monthly')\ncheck_ca_app_dump_data(IOS_COUNTRY_ID_CODES, get_device_list('ios'),'weekly')\ncheck_ca_app_dump_data(ANDROID_COUNTRY_ID_CODES, get_device_list('android'),'weekly')\nprint 'pass'\n\n"]},{"cell_type":"code","execution_count":0,"id":"20191223-085744_1792171529","metadata":{},"outputs":[],"source":["\nimport unittest\nimport datetime\nfrom dateutil.relativedelta import relativedelta\nfrom pyspark.sql.utils import AnalysisException\nfrom pyspark.sql.functions import count\nfrom pyspark.sql import Row\n\nkpi_mapping={1:\"est_average_active_users\", 2: \"est_average_session_per_user\", 3:\"est_average_session_duration\", 4:\"est_install_penetration\", 5:\"est_average_active_days\", 6:\"est_percentage_active_days\", 7:\"est_average_bytes_per_user\" , 8:\"est_average_time_per_user\", 9:\"est_cross_product_usage_penetration\", 10:\"est_open_rate\",11:\"est_total_time\", 12:\"est_share_of_category_time\",14:\"est_total_sessions\", 15:\"est_share_of_category_session\", 17:\"est_average_bytes_per_session\", 18:\"est_share_of_category_bytes\", 20:\"est_percent_of_wifi_total\", 21:\"est_mb_per_second\", 22:\"est_panel_size\", 23:\"est_installs\", 24:\"est_average_active_users_country_share\", 25:\"est_installs_country_share\", 26:\"est_audience_index\", 27:\"est_audience_percentage\",28:\"est_cross_product_affinity\"}\n\nANDROID_COUNTRY_ID_CODES = { 1: 'AU', 2: 'CA', 3: 'CN', 4: 'DE', 5: 'ES', 6: 'FR', 7: 'GB', 8: 'IT', 9: 'JP', 10: 'US', 11: 'BE', 12: 'CH', 13: 'CL', 14: 'ZA', 15: 'VN', 16: 'HK', 17: 'AR', 18: 'BR', 19: 'IN', 20: 'FI', 21: 'ID', 22: 'RU', 23: 'NL', 24: 'MY', 25: 'TR', 26: 'MX', 27: 'KR', 28: 'PL', 29: 'TH', 30: 'TW', 31: 'PH', 32: 'SG', 33: 'EG', 34: 'SE', 35: 'AT', 36: 'CZ', 37: 'HU', 38: 'DK', 39: 'IE', 40: 'IL', 41: 'NZ', 42: 'NO', 43: 'PT', 44: 'RO', 45: 'SK', 46: 'GR', 47: 'BG', 48: 'UA', 49: 'AE', 50: 'KW', 51: 'SA', 52: 'CO', 65: 'LB', 56: 'PE', 80: 'HR', 54: 'PK', 62: 'EC', 73: 'QA', 102: 'MO', 103: 'LU', 53: 'KZ', 1000: 'WW' }\n\n\nIOS_COUNTRY_ID_CODES={143460:'AU',143455:'CA',143465:'CN',143443:'DE',143454:'ES',143442:'FR',143444:'GB',143450:'IT',143462:'JP',143441:'US',143446:'BE',143459:'CH',143483:'CL',143472:'ZA',143471:'VN',143463:'HK',143505:'AR',143503:'BR',143467:'IN',143447:'FI',143476:'ID',143469:'RU',143452:'NL',143473:'MY',143480:'TR',143468:'MX',143466:'KR',143478:'PL',143475:'TH',143470:'TW',143474:'PH',143464:'SG',143516:'EG',143456:'SE',143445:'AT',143489:'CZ',143482:'HU',143458:'DK',143449:'IE',143491:'IL',143461:'NZ',143457:'NO',143453:'PT',143487:'RO',143496:'SK',143448:'GR',143526:'BG',143492:'UA',143481:'AE',143493:'KW',143479:'SA',143501:'CO',143451:'LU',143497:'LB',143515:'MO',143507:'PE',143494:'HR',143477:'PK',143509:'EC',143498:'QA',0:'WW'}\n\ndef get_device_list(device):\n    if device=='ios':\n        return {\"2001\":\"ios-phone\",\"2002\":\"ios-tablet\"}\n    else:\n        return {\"1001\":\"android-phone\" ,\"1002\":\"android-tablet\"}\n\n\ndef last_day_of_month(check_month):\n    next_month = check_month.replace(day=28) + datetime.timedelta(days=4)  \n    return next_month - datetime.timedelta(days=next_month.day)\n\n\ndef get_month_list():\n    result = []\n    today = datetime.date(2019, 10, 1) \n    current = datetime.date(2013, 1, 1)    \n    while current <= today:\n        month_data_raw=datetime.datetime.strftime(current,'%Y-%m')\n        month_data_leg_db=datetime.datetime.strftime(current,'%Y%m')\n        result.append((month_data_raw, month_data_leg_db,current  ))\n        current += relativedelta(months=1)  \n    return result\n\n\ndef get_path_date_list(granularity):\n    df_date = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-usage/unified/app-tech.usage.legacy-ca_app.v1//fact/granularity={}/\".format(granularity)).select('date').dropDuplicates()\n    collect_date= df_date.collect()\n    print collect_date\n    date_list = [(x[0][:7],x[0]) for x in collect_date]\n\n    return date_list\n    \n    \nimport traceback\ndef check_ca_data_count(store_id_list, device_id_list, _granularity, date_list):\n    t = unittest.TestCase('run')\n    for id,country_code in store_id_list.items():\n        for device,device_code in device_id_list.items():\n            for m in date_list:\n                raw_count_with_KPI=''\n                # print id, device, m[0] , m[1]\n                try:\n                    raw_path=\"s3://b2c-prod-data-pipeline-unified-usage/unified/app-tech.usage.legacy-ca_app.v1/fact/granularity={raw_granularity}/month={raw_month}/device_id={raw_device_id}/store_id={raw_store_id}/\"\n                    unified_path=\"s3://b2c-prod-data-pipeline-unified-usage/unified/app-tech.usage.cross-apps.v1/fact/granularity={unified_granularity}/date={unified_date}/\"\n                    raw_path_parse=raw_path.format(raw_device_id=device,raw_store_id=id, raw_month=m[0], raw_granularity=_granularity)\n                    raw_count_with_KPI=spark.read.parquet(raw_path_parse).select(\"kpi\",\"app_id\",\"seg_app_id\").distinct().groupBy(\"kpi\").agg(count(\"kpi\")).collect()\n                    # print raw_count_with_KPI\n                except AnalysisException as e: \n                    pass\n                    # print e\n                    break\n                    # traceback.print_exc()\n                # print 'raw count', raw_count\n                for row in raw_count_with_KPI:\n                    # print 'row _ test', row[\"kpi\"], row[\"count(kpi)\"]\n                    unified_path_parse=unified_path.format(unified_date=m[1], unified_granularity=_granularity)\n                    unified_count= spark.read.parquet(unified_path_parse).filter(\"device_code='{}' and country_code='{}'\".format(device_code,country_code)).filter(\"{} is not null\".format(kpi_mapping[row[\"kpi\"]])).select(kpi_mapping[row[\"kpi\"]]).count()\n                    # print 'unified count' , unified_count\n                    t.assertEqual(row[\"count(kpi)\"], unified_count, \" raw: {} ~ unified data: {},device:{},  store_id:{} , month: {}, KPI {}\".format(row[\"count(kpi)\"], unified_count, device, id , m, row[\"kpi\"]))\ngraularity_list=[\"monthly\"]\nfor graularity in graularity_list:\n    check_ca_data_count(IOS_COUNTRY_ID_CODES, get_device_list('ios'),graularity, get_path_date_list(graularity))\n    check_ca_data_count(ANDROID_COUNTRY_ID_CODES, get_device_list('android'),graularity, get_path_date_list(graularity))\nprint 'pass'\n\n"]},{"cell_type":"code","execution_count":0,"id":"20191223-090056_1432964083","metadata":{},"outputs":[],"source":["%%sh\n\naws s3 ls s3://b2c-prod-data-pipeline-unified-usage/unified/app-tech.usage.legacy-ca_app.v1/fact/granularity=monthly/month=2013-01/device_id=1001/\n\n "]},{"cell_type":"code","execution_count":0,"id":"20191223-090401_1945194294","metadata":{},"outputs":[],"source":["%%sh\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}