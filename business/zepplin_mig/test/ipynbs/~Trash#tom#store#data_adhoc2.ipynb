{"cells":[{"cell_type":"code","execution_count":0,"id":"20200224-075331_1680050164","metadata":{},"outputs":[],"source":["\n\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nimport pandas as pd\npd.set_option('expand_frame_repr', False)\nimport boto3\nfrom datetime import datetime\nimport pandas as pd\nfrom pyspark.sql import functions as F\nfrom applications.db_check_v1.common.constants import COUNTRY_CODE_MAPPING_BY_MARKET_CODE as COUNTRY_CODE_MAPPING\nfrom conf.settings import *\nfrom applications.db_check_v1.common.db_check_utils import query_df\nimport pandas as pd\n\ndaily_est_dsn =(\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_DAILY_EST_NAME,\n        user=PG_DAILY_EST_ACCESS_ID,\n        host=PG_DAILY_EST_HOSTS[0][0],\n        password=PG_DAILY_EST_SECRET_KEY,\n        port=PG_DAILY_EST_HOSTS[0][1]\n    )\n)\n\n\ndef get_date_list(start_date, end_date, freq=\"D\"):\n    date_list = [x.strftime('%Y-%m-%d') for x in list(pd.date_range(start=start_date, end=end_date, freq=freq))]\n    return date_list\n\n\ndef compare(date):\n    sql = \"\"\"\nselect distinct(app_id) from plproxy.execute_select_nestloop($proxy$ \n    select distinct(app_id)\n    from aa.app_store_daily_estimate_{}\n    where \n        date = '{}'\n$proxy$) tbl (app_id BIGINT);\n\"\"\"\n    print datetime.today()\n    db_df = []\n    for device in [0,1,2]:\n        db_device_df = query_df(daily_est_dsn, sql.format(device, date))\n        db_df = db_device_df if len(db_df)==0 else pd.concat([db_df, db_device_df])\n    db_df = db_df.drop_duplicates()\n    print datetime.today()\n    unified_df = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/granularity=daily/date={}/\".format(date)).select(\"app_id\").distinct().toPandas()\n    print datetime.today()\n    \n    \n    diff_df =db_df.merge(unified_df, indicator=True, how='left')\n    diff_df = diff_df.loc[diff_df[\"_merge\"] != \"both\"]\n    \n    sql = \"\"\"\nselect app_id,feed_id,store_id,estimate from plproxy.execute_select_nestloop($proxy$ \n    select app_id,feed_id,store_id,estimate\n    from aa.app_store_daily_estimate_{}\n    where \n        date = '{}' AND app_id in ({})\n$proxy$) tbl(app_id BIGINT,feed_id SMALLINT,store_id INT, estimate INT);\n\"\"\" \n    print len(diff_df)\n    diff_app_id = [str(x) for x in diff_df.app_id.tolist()]\n    print sql.format(1, date, \",\".join(diff_app_id))\n    db_df = query_df(daily_est_dsn, sql.format(1, date, \",\".join(diff_app_id)))\n    print db_df.store_id.unique()\n\n    \n    print datetime.today()\n    if len(diff_df) ==  0:\n        return \"{};PASS\".format(date)\n    else:\n        return \"{};FAIL; {} {} {}\".format(date, len(unified_df),len(db_df), diff_df.app_id.tolist()[0:5])\n        \n        \ndef write_log(strobj, s3obj):\n    s3obj.put(Body=str(strobj))\n"]},{"cell_type":"code","execution_count":0,"id":"20200224-084344_1389857395","metadata":{},"outputs":[],"source":["\ns3 = boto3.resource('s3')\ns3object = s3.Object('b2c-prod-data-pipeline-qa', 'tom/all3/regression1.txt')\nlog = [] \n\n# 2010-09-02/   2020-02-21\ndate_list =get_date_list('2019-07-14', '2019-09-10')\nfor date in date_list:\n    temp_log = \"\"\n    # compare(date)\n    try:\n        temp_log = compare(date)\n        print temp_log\n    except Exception, e:\n        temp_log = \"{}; ERROR; {}\".format(date, e.message)\n        print temp_log\n        print \n    log.append(temp_log)\n    write_log(log, s3object)"]},{"cell_type":"code","execution_count":0,"id":"20200224-081351_451881994","metadata":{},"outputs":[],"source":["%%sh\n\nPGPASSWORD='2mHdFW6%#REu' psql -h internal-aa-prod-plproxy-internal-4-329644124.us-east-1.elb.amazonaws.com -U app_bdp_usage_qa -d dailyest -p 7432 << EOF \n\nselect app_id,feed_id,store_id,estimate from plproxy.execute_select_nestloop(\\$proxy\\$ \n    select app_id,feed_id,store_id,estimate\n    from aa.app_store_daily_estimate_1\n    where \n        date = '2019-09-01' AND app_id in (985896290, 470074597, 497708025, 720245280, 540041963, 391329860, 829641544, 1148468242, 928368430, 859604306, 1046307415 )\n\\$proxy\\$) tbl (app_id BIGINT,feed_id SMALLINT,store_id INT, estimate INT);\n\nEOF\n"]},{"cell_type":"code","execution_count":0,"id":"20200224-075344_1475384151","metadata":{},"outputs":[],"source":["%%sh\n\nPGPASSWORD='2mHdFW6%#REu' psql -h internal-aa-prod-plproxy-internal-4-329644124.us-east-1.elb.amazonaws.com -U app_bdp_usage_qa -d dailyest -p 7432 << EOF \n\nselect app_id,feed_id,store_id,estimate from plproxy.execute_select_nestloop(\\$proxy\\$ \n    select app_id,feed_id,store_id,estimate\n    from aa.app_store_daily_estimate_1\n    where \n        date = '2019-09-01' AND app_id in (985896290, 470074597, 497708025, 720245280, 540041963, 391329860, 829641544, 1148468242, 928368430, 859604306, 1046307415 )\n    limit 5\n\\$proxy\\$) tbl (app_id BIGINT,feed_id SMALLINT,store_id INT, estimate INT);\n\nEOF\n"]},{"cell_type":"code","execution_count":0,"id":"20200224-080251_794901579","metadata":{},"outputs":[],"source":["\n\ndef get_date_list(start_date, end_date, freq=\"D\"):\n    date_list = [x.strftime('%Y-%m-%d') for x in list(pd.date_range(start=start_date, end=end_date, freq=freq))]\n    return date_list\n\ndate_list = get_date_list(\"2019-07-14\", \"2020-02-24\")\n\nfor date in date_list:\n    df = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/granularity=daily/date={}/\".format(date))\n    unifie_count = df.select(\"app_id\").distinct().count()\n\n    df = spark.read.parquet(\"s3://b2c-prod-dca-store-estimates/store_estv2/APP_ESTIMATES_FINAL/version=2.0.0/range_type=DAY/date={}/\".format(date))\n    raw_count= df.select(\"id\").distinct().count()\n    \n    if unifie_count!=raw_count:\n        print \"{}; Fail; {};{}\".format(date, raw_count, unifie_count)\n    else:\n        print \"{}; Pass\".format(date)"]},{"cell_type":"code","execution_count":0,"id":"20200224-081152_1812451018","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql import types as T\nimport pandas as pd\n\nEST_SCHEMA = T.StructType(\n[\n    T.StructField(\"country_code\", T.StringType(), True),\n    T.StructField(\"date\", T.StringType(), True),\n    T.StructField(\"device_code\", T.StringType(), True),\n    T.StructField(\"granularity\", T.StringType(), True),\n    T.StructField(\"free_app_download\", T.StringType(), True),  \n    T.StructField(\"app_id\", T.StringType(), True),\n    T.StructField(\"paid_app_download\", T.StringType(), True),\n    T.StructField(\"revenue\", T.StringType(), True),\n    T.StructField(\"revenue_iap\", T.StringType(), True)    ]\n)\n    \ndef get_date_list(start_date, end_date, freq=\"D\"):\n    date_list = [x.strftime('%Y-%m-%d') for x in list(pd.date_range(start=start_date, end=end_date, freq=freq))]\n    return date_list\n\ndate_list = get_date_list(\"2016-10-24\", \"2017-12-31\")\n# date_list = get_date_list(\"2010-08-02\", \"2019-07-13\")\n\nfor date in date_list:\n    unified_df = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/granularity=daily/date={}/\".format(date)).select(\"app_id\").distinct()\n    unifie_count = unified_df.count()\n    # unified_df.write.parquet(\"s3://b2c-prod-data-pipeline-qa/tom/store/unified/date={}/\".format(date))\n    \n\n    raw_df = spark.read.option(\"delimiter\", \"\\t\").csv(\"s3://b2c-prod-dca-store-estimates/store_est/v_final/DAY/{}/*/sbe_est_app/*/\".format(date)).select(\"_c5\").distinct()\n    raw_count= raw_df.count()\n    # raw_df.write.parquet(\"s3://b2c-prod-data-pipeline-qa/tom/store/raw/date={}/\".format(date))\n\n    \n    if unifie_count!=raw_count:\n        print \"{}; Fail; {};{}\".format(date, raw_count, unifie_count)\n    else:\n        print \"{}; Pass\".format(date)"]},{"cell_type":"code","execution_count":0,"id":"20200225-002544_141371372","metadata":{},"outputs":[],"source":["\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}