{"cells":[{"cell_type":"code","execution_count":0,"id":"20200928-004423_1835085611","metadata":{},"outputs":[],"source":["\nimport psycopg2\nimport datetime\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nimport aaplproxy\nfrom aadatapipelinecore.core.urn import Urn\nfrom aaplproxy.da.local_sqlrunner import LocalSqlRunner\nfrom aadatapipelinecore.core.utils.module import application_settings\nfrom pyspark.sql import Row\nfrom pyspark.sql.types import *\nfrom pyspark.sql import functions as F\ndef citus_row(start,end):\n    def get_data_in_citus(start,end):\n        citus_dsn_ = (\n            \"dbname='{db}' user='{user}' password='{password}' \"\n            \"host='{host}' port='{port}'\".format(\n                db=\"aa_citus_db\",\n                user=\"citus_bdp_usage_qa\",\n                host=\"10.2.10.132\",\n                password=\"dNzWtSV3pKTx\",\n                port=5432\n            )\n        )\n        count_sql = \"SELECT category_id,CAST(SUM(est_market_size_download)AS bigint)AS sum_est_market_size_download,CAST(SUM(est_market_size_revenue) AS bigint)AS sum_est_market_size_revenue, count(1) FROM store.store_market_size_fact_v1 WHERE date >='{}' AND date<='{}' group by category_id order by category_id desc \".format(start,end)\n        db_data = query(citus_dsn_, count_sql)\n        return db_data\n    def query(dsn, sql):\n        with psycopg2.connect(dsn) as conn:\n            conn.autocommit = True\n            with conn.cursor() as cur:\n                cur.execute(sql)\n                result = cur.fetchall()\n                conn.commit()\n        return result\n    result = get_data_in_citus(start,end)\n    return [Row(category_id=r[0],sum_est_market_size_download=r[1], sum_est_market_size_revenue=r[2], count=r[3]) for r in result]\ndef generate_citus_result(spark, citus_data):\n    schema = StructType([\n    StructField(\"category_id\", StringType(), True),\n    StructField(\"sum_est_market_size_download\", LongType(), True),\n    StructField(\"sum_est_market_size_revenue\", LongType(), True),\n    StructField(\"count\", LongType(), True)\n    ])\n    df_3 = spark.createDataFrame(citus_data, schema)\n    df_3.createOrReplaceTempView(\"citus_data\")\n    return spark.sql(\"select * from citus_data\")\nprint(\"================online=======================\")\nonline_df = generate_citus_result(spark,citus_row(\"2020-08-01\",\"2020-08-31\"))\nonline_df.show()\nprint(\"================ADL=========================\")\nsample_data_df=spark.read.format(\"parquet\").load(\"s3://b2c-prod-data-pipeline-unified-store-paid/_obselete/snowflake_v1/store.market-download-revenue.v1/fact/\")\nsample_data_df.createOrReplaceTempView(\"sample_data\")\nspark.sql(\"SELECT SUM(est_market_size_download) as sum_est_market_size_download, SUM(est_market_size_revenue) as sum_est_market_size_revenue,count(1) FROM sample_data \").show()\ntest_sample_data_df =spark.sql(\"select category_id,SUM(est_market_size_download) as sum_est_market_size_download, SUM(est_market_size_revenue) as sum_est_market_size_revenue,count(1) FROM sample_data group by category_id order by category_id desc\")\ntest_sample_data_df.show()\nprint(\"column test (except all)\")\ntest_sample_data_df.exceptAll(online_df).createOrReplaceTempView(\"test_sample_data\")\nspark.sql(\"select * from test_sample_data order by category_id desc \").show()"]},{"cell_type":"code","execution_count":0,"id":"20200928-083933_1831420405","metadata":{},"outputs":[],"source":["\n\n\nraw_data_df = spark.read.format(\"delta\").load(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.market-size.v1/fact/\").where(\" granularity='daily' and date >= '2020-08-01' and date <= '2020-08-31'\").cache()\nraw_data_df.createOrReplaceTempView(\"raw_data\")\n# spark.sql(\"select * from raw_data\").show()\n# spark.sql(\"select app_price_type_id, category_id, country_code, device_code, purchase_type_id, granularity, date, count(1) as count_number from raw_data group by app_price_type_id, category_id, country_code, device_code, purchase_type_id, granularity, date order by count_number desc\").show()\n# spark.sql(\"select * from raw_data where category_id=400027 and country_code = 'WW' and device_code ='android-all' and  purchase_type_id = 12 and app_price_type_id=0 \").show()\n\nspark.sql(\"select date, sum(est_market_size_download), sum(est_market_size_revenue), count(1) from (select distinct app_price_type_id, category_id, country_code, device_code, purchase_type_id, granularity, date, est_market_size_download, est_market_size_revenue from raw_data  ) as temp group by date order by date desc\").show(50,False)\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200928-084700_1695552392","metadata":{},"outputs":[],"source":["%%sh\nPGPASSWORD='dNzWtSV3pKTx' psql -h 10.2.10.132 -U citus_bdp_usage_qa -d aa_citus_db -p 5432 << EOF \nselect date,count(1), sum(est_market_size_download)as download, sum(est_market_size_revenue) as revenue FROM store.store_market_size_fact_v1  WHERE date between '2020-08-01' AND '2020-08-31' group by date order by date desc;\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20200928-043004_728818454","metadata":{},"outputs":[],"source":["\nimport psycopg2\nimport datetime\n# spark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nimport aaplproxy\nfrom aadatapipelinecore.core.urn import Urn\nfrom aaplproxy.da.local_sqlrunner import LocalSqlRunner\nfrom aadatapipelinecore.core.utils.module import application_settings\nfrom pyspark.sql import Row\nfrom pyspark.sql.types import *\nfrom pyspark.sql import functions as F\ndef citus_row(start,end):\n    def get_data_in_citus(start,end):\n        citus_dsn_ = (\n            \"dbname='{db}' user='{user}' password='{password}' \"\n            \"host='{host}' port='{port}'\".format(\n                db=\"aa_citus_db\",\n                user=\"citus_bdp_usage_qa\",\n                host=\"10.2.10.132\",\n                password=\"dNzWtSV3pKTx\",\n                port=5432\n            )\n        )\n        count_sql = \"SELECT device_code,country_code,category_id,app_price_type_id,purchase_type_id,granularity,est_market_size_download,est_market_size_revenue,count(distinct(app_price_type_id, purchase_type_id,category_id,device_code,country_code,date,granularity)) FROM store.store_market_size_fact_v1 WHERE date >='{}' AND date<='{}'and device_code= 'android-all'  GROUP BY device_code,country_code,category_id,app_price_type_id,purchase_type_id,category_id,granularity,est_market_size_download,est_market_size_revenue\".format(start,end)\n        db_data = query(citus_dsn_, count_sql)\n        return db_data\n    def query(dsn, sql):\n        with psycopg2.connect(dsn) as conn:\n            conn.autocommit = True\n            with conn.cursor() as cur:\n                cur.execute(sql)\n                result = cur.fetchall()\n                conn.commit()\n        return result\n    result = get_data_in_citus(start,end)\n    return [Row(device_code=r[0], country_code=r[1], category_id=r[2],app_price_type_id=r[3],purchase_type_id=r[4],granularity=r[5],est_market_size_download=r[6],est_market_size_revenue=r[7],count=r[8]) for r in result]\ndef generate_citus_result(spark, citus_data):\n    schema = StructType([\n    StructField(\"device_code\", StringType(), True),\n    StructField(\"country_code\", StringType(), True),\n    StructField(\"category_id\", LongType(), True),\n    StructField(\"app_price_type_id\",  LongType(), True),\n    StructField(\"purchase_type_id\",  LongType(), True),\n    StructField(\"granularity\", StringType(), True),\n    StructField(\"est_market_size_download\", LongType(), True),\n    StructField(\"est_market_size_revenue\", LongType(), True),\n    StructField(\"count\", LongType(), True)\n    ])\n    df_3 = spark.createDataFrame(citus_data, schema)\n    df_3.createOrReplaceTempView(\"citus_data\")\n    return spark.sql(\"select * from citus_data\")\nprint(\"================online=======================\")\nonline_df = generate_citus_result(spark,citus_row(\"2020-08-01\",\"2020-08-01\"))\nonline_df.createOrReplaceTempView(\"online_data\")\n\nonline_df.show()\nprint(\"================ADL=========================\")\n# sample_data_df=spark.read.format(\"parquet\").load(\"s3://b2c-prod-data-pipeline-unified-store-paid/_obselete/snowflake_v1/store.market-download-revenue.v1/fact/\")\n# sample_data_df.createOrReplaceTempView(\"sample_data\")\n# spark.sql(\"SELECT device_code,count(1),SUM(est_market_size_download) as sum_est_market_size_download, SUM(est_market_size_revenue) as sum_est_market_size_revenue FROM sample_data where date='2020-08-01' group by device_code\").show()\n\nraw_data_df = spark.read.format(\"delta\").load(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.market-size.v1/fact/\").where(\" granularity='daily' and date >= '2020-08-01' and date <= '2020-08-01'\")\nraw_data.createOrReplaceTempView(\"raw_data\")\nnew_raw_data_df = spark.sql(\"select  device_code,country_code,category_id,app_price_type_id,purchase_type_id,granularity,est_market_size_download,est_market_size_revenue,count(1) from raw_data where date = '2020-08-01' and device_code='android-all' group by device_code,country_code,category_id,app_price_type_id,purchase_type_id,granularity,est_market_size_download,est_market_size_revenue \")\nprint(\"new raw data\")\nnew_raw_data_df.show()\nprint(\"except\")\ndf2= new_raw_data_df.exceptAll(online_df).cache()\ndf2.show()\ndf2.createOrReplaceTempView(\"df2_data\")\n# spark.sql(\"select distinct category_id from df2_data\").show()\n\n# spark.sql(\"Select * from raw_data where date = '2020-08-01' and device_code='android-all' and category_id = 400027 group by_identifier,app_price_type_id,category_id,country_code,est_market_size_download,est_market_size_revenue,purchase_type_id,granularity,date,device_code\").show()"]},{"cell_type":"code","execution_count":0,"id":"20200928-083321_290205902","metadata":{},"outputs":[],"source":["\nspark.sql('''\nselect * from raw_data WHERE date between '2020-08-01' AND '2020-08-01' and category_id=400027 and country_code='NL' and app_price_type_id = 1 and purchase_type_id =10\n''').show()"]},{"cell_type":"code","execution_count":0,"id":"20200928-065928_1872975602","metadata":{},"outputs":[],"source":["%%sh\nPGPASSWORD='dNzWtSV3pKTx' psql -h 10.2.10.132 -U citus_bdp_usage_qa -d aa_citus_db -p 5432 << EOF \nSELECT * FROM store.store_market_size_fact_v1  WHERE date between '2020-08-01' AND '2020-08-01' and category_id=400027 and country_code='NL' and app_price_type_id = 1 and purchase_type_id =10  limit 3;\nEOF"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}