{"cells":[{"cell_type":"code","execution_count":0,"id":"20200930-040210_647150897","metadata":{},"outputs":[],"source":["\nimport psycopg2\nimport datetime\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nimport aaplproxy\nfrom aadatapipelinecore.core.urn import Urn\nfrom aaplproxy.da.local_sqlrunner import LocalSqlRunner\nfrom aadatapipelinecore.core.utils.module import application_settings\nfrom pyspark.sql import Row\nfrom pyspark.sql.types import *\nfrom pyspark.sql import functions as F\nios_feed = {1: \"0,1,2,100,101,102\"}\nandroid_feed = {0: \"0,1,2\"}\ndef citus_row(start,end):\n    def get_data_in_citus(start,end):\n        citus_dsn_ = (\n            \"dbname='{db}' user='{user}' password='{password}' \"\n            \"host='{host}' port='{port}'\".format(\n                db=\"aa_store_db\",\n                user=\"citus_bdp_prod_app_int_qa\",\n                host=\"10.2.6.141\",\n                password=\"wZw8cfBuuklIskVG\",\n                port=5432\n            )\n        )\n        sql = \"select device_code, cast(sum(est_free_app_download) as bigint) as est_free_app_download, cast(sum(est_paid_app_download) as bigint) as est_paid_app_download, cast(sum(est_revenue) as bigint) as est_revenue from store.store_est_publisher_fact_v2 where date>='{}' and date<='{}' group by device_code\".format(start,end)\n        db_data = query(citus_dsn_, sql)\n        return db_data\n    def query(dsn, sql):\n        with psycopg2.connect(dsn) as conn:\n            conn.autocommit = True\n            with conn.cursor() as cur:\n                cur.execute(sql)\n                result = cur.fetchall()\n                conn.commit()\n        return result\n    result = get_data_in_citus(start, end)\n    return [Row(device_code=r[0], sum_est_free_app_download=r[1], sum_est_paid_app_download=r[2],\n                sum_est_revenue=r[3]) for r in result]\ndef generate_citus_result(spark, citus_data):\n    schema = StructType([\n    StructField(\"device_code\",  StringType(), True),\n    StructField(\"sum_est_free_app_download\", LongType(), True),\n    StructField(\"sum_est_paid_app_download\", LongType(), True),\n    StructField(\"sum_est_revenue\", LongType(), True)])\n    df_3 = spark.createDataFrame(citus_data, schema)\n    df_3.createOrReplaceTempView(\"citus_data\")\n    return spark.sql(\"select * from citus_data order by device_code desc\")\nprint(\"=============Online============\")\nonline_data_df = generate_citus_result(spark,citus_row(\"2020-08-01\",\"2020-08-01\"))\nonline_data_df.show()\nprint(\"=============sampleData============\")\nsample_data_df = spark.read.format(\"parquet\").load(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.publisher-download-revenue.v1/fact/\")\nsample_data_df.createOrReplaceTempView(\"sample_data\")\nresult_df = spark.sql(\"\"\"\n     select device_code,\n            sum(est_free_app_download) as sum_est_free_app_download,\n            sum(est_paid_app_download) as sum_est_paid_app_download,\n            sum(est_revenue) as sum_est_revenue\n    from sample_data\n    group by device_code\n\"\"\")\n\nprint(sample_data_df.count())\nonline_data_df.exceptAll(result_df).show()\nresult_df.exceptAll(online_data_df).show()"]},{"cell_type":"code","execution_count":0,"id":"20200930-060103_675572367","metadata":{},"outputs":[],"source":["\nimport psycopg2\nimport datetime\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nimport aaplproxy\nfrom aadatapipelinecore.core.urn import Urn\nfrom aaplproxy.da.local_sqlrunner import LocalSqlRunner\nfrom aadatapipelinecore.core.utils.module import application_settings\nfrom pyspark.sql import Row\nfrom pyspark.sql.types import *\nfrom pyspark.sql import functions as F\nios_feed = {1: \"0,1,2,100,101,102\"}\nandroid_feed = {0: \"0,1,2\"}\ndef citus_row(start,end):\n    def get_data_in_citus(start,end):\n        citus_dsn_ = (\n            \"dbname='{db}' user='{user}' password='{password}' \"\n            \"host='{host}' port='{port}'\".format(\n                db=\"aa_store_db\",\n                user=\"citus_bdp_prod_app_int_qa\",\n                host=\"10.2.6.141\",\n                password=\"wZw8cfBuuklIskVG\",\n                port=5432\n            )\n        )\n        sql = \"select publisher_id, cast(sum(est_free_app_download) as bigint) as est_free_app_download, cast(sum(est_paid_app_download) as bigint) as est_paid_app_download, cast(sum(est_revenue) as bigint) as est_revenue from store.store_est_publisher_fact_v2 where date>='{}' and date<='{}' group by publisher_id\".format(start,end)\n        db_data = query(citus_dsn_, sql)\n        return db_data\n    def query(dsn, sql):\n        with psycopg2.connect(dsn) as conn:\n            conn.autocommit = True\n            with conn.cursor() as cur:\n                cur.execute(sql)\n                result = cur.fetchall()\n                conn.commit()\n        return result\n    result = get_data_in_citus(start, end)\n    return [Row(publisher_id=r[0], sum_est_free_app_download=r[1], sum_est_paid_app_download=r[2],\n                sum_est_revenue=r[3]) for r in result]\ndef generate_citus_result(spark, citus_data):\n    schema = StructType([\n    StructField(\"publisher_id\",  LongType(), True),\n    StructField(\"sum_est_free_app_download\", LongType(), True),\n    StructField(\"sum_est_paid_app_download\", LongType(), True),\n    StructField(\"sum_est_revenue\", LongType(), True)])\n    df_3 = spark.createDataFrame(citus_data, schema)\n    df_3.createOrReplaceTempView(\"citus_data\")\n    return spark.sql(\"select * from citus_data order by publisher_id desc\")\nprint(\"=============Online============\")\nonline_data_df = generate_citus_result(spark,citus_row(\"2020-08-01\",\"2020-08-01\"))\nprint(\"=============sampleData============\")\nsample_data_df = spark.read.format(\"parquet\").load(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.publisher-download-revenue.v1/fact/\")\nsample_data_df.createOrReplaceTempView(\"sample_data\")\nresult_df = spark.sql(\"\"\"\n     select publisher_key,\n            sum(est_free_app_download) as sum_est_free_app_download,\n            sum(est_paid_app_download) as sum_est_paid_app_download,\n            sum(est_revenue) as sum_est_revenue\n    from sample_data\n    where device_code = 'android-all' or device_code = 'ios-tablet' or device_code = 'ios-phone' \n    group by publisher_key\n\"\"\")\n\nprint(sample_data_df.count())\nonline_data_df.exceptAll(result_df).show()\nresult_df.exceptAll(online_data_df).show()"]},{"cell_type":"code","execution_count":0,"id":"20200930-062817_1257128098","metadata":{},"outputs":[],"source":["\nresult_df.where(\"publisher_key = 20200003671279\").show()"]},{"cell_type":"code","execution_count":0,"id":"20200930-035808_352613808","metadata":{},"outputs":[],"source":["\nraw_data = spark.read.format(\"delta\").load(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est-publisher-dna-log.v1/fact/\").where(\" granularity='daily' and date = '2020-08-01'\")\nsample_data = spark.read.format(\"parquet\").load(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.publisher-download-revenue.v1/fact/\")\nraw_data.createOrReplaceTempView(\"raw_data\")\nsample_data.createOrReplaceTempView(\"sample_data\")\n\nprint(\"result_view\")\nresult1_df = spark.sql(\"\"\"\n    select device_code,\n           sum(est_paid_app_download) as sum_est_paid_app_download,\n           sum(est_free_app_download) as sum_est_free_app_download,\n           sum(est_in_app_purchase_revenue) as sum_est_in_app_purchase_revenue,\n           sum(est_non_in_app_purchase_revenue) as sum_est_non_in_app_purchase_revenue,\n           sum(est_revenue) as sum_est_revenue\n    from sample_data\n    group by device_code\n\"\"\")\nprint(\"result_data\")\nresult1_df.show()\nspark.sql(\"\"\"\n    select sum(coalesce(est_free_app_download, 0) + coalesce(est_paid_app_download, 0)) as sum_est_paid_app_download,\n           sum(est_download)\n    from sample_data\n\"\"\").show()\nprint(\"raw_data\")\nraw1_df = spark.sql(\"\"\"\n    select device_code,\n           sum(est_paid_app_download) as sum_est_paid_app_download,\n           sum(est_free_app_download) as sum_est_free_app_download,\n           sum(est_revenue_iap) as sum_est_in_app_purchase_revenue,\n           sum(est_revenue_non_iap) as sum_est_non_in_app_purchase_revenue,\n           sum(est_revenue) as sum_est_revenue\n    from raw_data\n    group by device_code\n\"\"\")\nprint(\"raw_data\")\nraw1_df.show()\nprint(\"exceptAll \")\nraw1_df.exceptAll(result1_df).show()\nresult1_df.exceptAll(raw1_df).show()\nprint(\"sample_data_count\")\nspark.sql(\"\"\"\n    select device_code, count(1) as count\n    from sample_data\n    group by device_code\n\"\"\").show()\nprint(\"raw_data_count\")\nspark.sql(\"\"\"\n    select device_code, count(1) as count\n    from raw_data\n    group by device_code\n\"\"\").show()\n"]},{"cell_type":"code","execution_count":0,"id":"20200930-063913_1492257657","metadata":{},"outputs":[],"source":["%%sh\nPGPASSWORD='wZw8cfBuuklIskVG' psql -h 10.2.6.141 -U citus_bdp_prod_app_int_qa -d aa_store_db -p 5432 << EOF \nSELECT * from store.store_est_publisher_fact_v2 where publisher_id=20200003671279 and date='2020-08-01' limit 1;\nEOF\n"]},{"cell_type":"code","execution_count":0,"id":"20200930-064056_83943297","metadata":{},"outputs":[],"source":["\nimport psycopg2\nimport datetime\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nimport aaplproxy\nfrom aadatapipelinecore.core.urn import Urn\nfrom aaplproxy.da.local_sqlrunner import LocalSqlRunner\nfrom aadatapipelinecore.core.utils.module import application_settings\nfrom pyspark.sql import Row\nfrom pyspark.sql.types import *\nfrom pyspark.sql import functions as F\nios_feed = {1: \"0,1,2,100,101,102\"}\nandroid_feed = {0: \"0,1,2\"}\ndef citus_row(start,end):\n    def get_data_in_citus(start,end):\n        citus_dsn_ = (\n            \"dbname='{db}' user='{user}' password='{password}' \"\n            \"host='{host}' port='{port}'\".format(\n                db=\"aa_store_db\",\n                user=\"citus_bdp_prod_app_int_qa\",\n                host=\"10.2.6.141\",\n                password=\"wZw8cfBuuklIskVG\",\n                port=5432\n            )\n        )\n        sql = \"select country_code, cast(sum(est_free_app_download) as bigint) as est_free_app_download, cast(sum(est_paid_app_download) as bigint) as est_paid_app_download, cast(sum(est_revenue) as bigint) as est_revenue from store.store_est_publisher_fact_v2 where date>='{}' and date<='{}' group by country_code\".format(start,end)\n        db_data = query(citus_dsn_, sql)\n        return db_data\n    def query(dsn, sql):\n        with psycopg2.connect(dsn) as conn:\n            conn.autocommit = True\n            with conn.cursor() as cur:\n                cur.execute(sql)\n                result = cur.fetchall()\n                conn.commit()\n        return result\n    result = get_data_in_citus(start, end)\n    return [Row(country_code=r[0], sum_est_free_app_download=r[1], sum_est_paid_app_download=r[2],\n                sum_est_revenue=r[3]) for r in result]\ndef generate_citus_result(spark, citus_data):\n    schema = StructType([\n    StructField(\"country_code\",  StringType(), True),\n    StructField(\"sum_est_free_app_download\", LongType(), True),\n    StructField(\"sum_est_paid_app_download\", LongType(), True),\n    StructField(\"sum_est_revenue\", LongType(), True)])\n    df_3 = spark.createDataFrame(citus_data, schema)\n    df_3.createOrReplaceTempView(\"citus_data\")\n    return spark.sql(\"select * from citus_data order by country_code desc\")\nprint(\"=============Online============\")\nonline_data_df = generate_citus_result(spark,citus_row(\"2020-08-01\",\"2020-08-01\"))\nprint(\"=============sampleData============\")\nsample_data_df = spark.read.format(\"parquet\").load(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.publisher-download-revenue.v1/fact/\")\nsample_data_df.createOrReplaceTempView(\"sample_data\")\nresult_df = spark.sql(\"\"\"\n     select country_code,\n            sum(est_free_app_download) as sum_est_free_app_download,\n            sum(est_paid_app_download) as sum_est_paid_app_download,\n            sum(est_revenue) as sum_est_revenue\n    from sample_data\n    where device_code = 'android-all' or device_code = 'ios-tablet' or device_code = 'ios-phone' \n    group by country_code\n\"\"\")\n\nprint(sample_data_df.count())\nonline_data_df.exceptAll(result_df).show()\nresult_df.exceptAll(online_data_df).show()"]},{"cell_type":"code","execution_count":0,"id":"20200930-064655_135168411","metadata":{},"outputs":[],"source":["\nimport psycopg2\nimport datetime\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nimport aaplproxy\nfrom aadatapipelinecore.core.urn import Urn\nfrom aaplproxy.da.local_sqlrunner import LocalSqlRunner\nfrom aadatapipelinecore.core.utils.module import application_settings\nfrom pyspark.sql import Row\nfrom pyspark.sql.types import *\nfrom pyspark.sql import functions as F\nios_feed = {1: \"0,1,2,100,101,102\"}\nandroid_feed = {0: \"0,1,2\"}\ndef citus_row(start,end):\n    def get_data_in_citus(start,end):\n        citus_dsn_ = (\n            \"dbname='{db}' user='{user}' password='{password}' \"\n            \"host='{host}' port='{port}'\".format(\n                db=\"aa_store_db\",\n                user=\"citus_bdp_prod_app_int_qa\",\n                host=\"10.2.6.141\",\n                password=\"wZw8cfBuuklIskVG\",\n                port=5432\n            )\n        )\n        sql = \"select category_id, cast(sum(est_free_app_download) as bigint) as est_free_app_download, cast(sum(est_paid_app_download) as bigint) as est_paid_app_download, cast(sum(est_revenue) as bigint) as est_revenue from store.store_est_publisher_fact_v2 where date>='{}' and date<='{}' group by category_id\".format(start,end)\n        db_data = query(citus_dsn_, sql)\n        return db_data\n    def query(dsn, sql):\n        with psycopg2.connect(dsn) as conn:\n            conn.autocommit = True\n            with conn.cursor() as cur:\n                cur.execute(sql)\n                result = cur.fetchall()\n                conn.commit()\n        return result\n    result = get_data_in_citus(start, end)\n    return [Row(category_id=r[0], sum_est_free_app_download=r[1], sum_est_paid_app_download=r[2],\n                sum_est_revenue=r[3]) for r in result]\ndef generate_citus_result(spark, citus_data):\n    schema = StructType([\n    StructField(\"category_id\",  StringType(), True),\n    StructField(\"sum_est_free_app_download\", LongType(), True),\n    StructField(\"sum_est_paid_app_download\", LongType(), True),\n    StructField(\"sum_est_revenue\", LongType(), True)])\n    df_3 = spark.createDataFrame(citus_data, schema)\n    df_3.createOrReplaceTempView(\"citus_data\")\n    return spark.sql(\"select * from citus_data order by category_id desc\")\nprint(\"=============Online============\")\nonline_data_df = generate_citus_result(spark,citus_row(\"2020-08-01\",\"2020-08-01\"))\nprint(\"=============sampleData============\")\nsample_data_df = spark.read.format(\"parquet\").load(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.publisher-download-revenue.v1/fact/\")\nsample_data_df.createOrReplaceTempView(\"sample_data\")\nresult_df = spark.sql(\"\"\"\n     select category_key,\n            sum(est_free_app_download) as sum_est_free_app_download,\n            sum(est_paid_app_download) as sum_est_paid_app_download,\n            sum(est_revenue) as sum_est_revenue\n    from sample_data\n    where device_code = 'android-all' or device_code = 'ios-tablet' or device_code = 'ios-phone' \n    group by category_key\n\"\"\")\n\nprint(sample_data_df.count())\nonline_data_df.exceptAll(result_df).show()\nresult_df.exceptAll(online_data_df).show()"]},{"cell_type":"code","execution_count":0,"id":"20200930-065237_1978433005","metadata":{},"outputs":[],"source":["\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}