{"cells":[{"cell_type":"code","execution_count":0,"id":"20200215-023313_402741034","metadata":{},"outputs":[],"source":["\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nimport pandas as pd\npd.set_option('expand_frame_repr', False)\n"]},{"cell_type":"code","execution_count":0,"id":"20200220-101736_801990351","metadata":{},"outputs":[],"source":["\nfrom bdce.common.utils import update_application_code\nupdate_application_code(\n    spark, role=\"BDP-PROD-APP-INT-QA\", application_name=\"aa-int-qa-db-check-debug\"\n)\nspark.sparkContext.addPyFile(\"/tmp/zeppelin_application_code/libs/python/dependencies.zip\")\nspark.sparkContext.addPyFile(\"/tmp/zeppelin_application_code/code.zip\")\n"]},{"cell_type":"code","execution_count":0,"id":"20200215-021257_199790659","metadata":{},"outputs":[],"source":["%%sh\n\n\n\n\nPGPASSWORD='2mHdFW6%#REu' psql -h internal-aa-prod-plproxy-internal-4-329644124.us-east-1.elb.amazonaws.com -U app_bdp_usage_qa -d dailyest -p 7432 << EOF \nselect sum(count_a) from plproxy.execute_select_nestloop(\\$proxy\\$ \n    select count(*) as count_a\n    from aa.app_store_daily_estimate\n    where\n        date = '2019-01-01'\n\\$proxy\\$) tbl (count_a SMALLINT);\n\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20200220-011634_572571448","metadata":{},"outputs":[],"source":["%%sh\n\nselect device_id, store_id, date, genre_id, modifier_id, download, revenue from plproxy.execute_select_nestloop($proxy$ \n    select device_id, store_id, date, genre_id, modifier_id, download, revenue\n    from aa.genre_store_daily_estimate\n    where \n        date = '2020-01-01'\n    limit 5\n$proxy$) tbl (device_id SMALLINT, store_id INT, date DATE , genre_id BIGINT, modifier_id BIGINT, download BIGINT, revenue BIGINT);\n"]},{"cell_type":"code","execution_count":0,"id":"20200219-063041_1722219105","metadata":{},"outputs":[],"source":["%%sh\n\n#\\d+ aa.genre_store_daily_estimate_1000_2020\n\n\nPGPASSWORD='2mHdFW6%#REu' psql -h internal-aa-prod-plproxy-internal-4-329644124.us-east-1.elb.amazonaws.com -U app_bdp_usage_qa -d dailyest -p 7432 << EOF \n\\d+ aa.genre_store_daily_estimate;\nselect device_id, store_id, date, genre_id, modifier_id, download, revenue from plproxy.execute_select_nestloop(\\$proxy\\$ \n    select device_id, store_id, date, genre_id, modifier_id, download, revenue\n    from aa.genre_store_daily_estimate\n    where \n        date = '2020-01-01'\n    limit 5\n\\$proxy\\$) tbl (device_id SMALLINT, store_id INT, date DATE, genre_id BIGINT, modifier_id BIGINT, download BIGINT, revenue BIGINT);\n\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20200711-083504_176671307","metadata":{},"outputs":[],"source":["%%sh\n\n# aws s3 cp s3://b2c-prod-data-pipeline-qa/aa.store.game_iq/genre_min_count.json /tmp/genre_min_count.json\ncat  /tmp/genre_min_count.json\n"]},{"cell_type":"code","execution_count":0,"id":"20200711-083655_961308083","metadata":{},"outputs":[],"source":["%%sh\n\nPGPASSWORD='2mHdFW6%#REu' psql -h internal-aa-prod-plproxy-internal-4-329644124.us-east-1.elb.amazonaws.com -U app_bdp_usage_qa -d dailyest -p 7432 << EOF \n\nselect date,count(distinct(genre_id)) from plproxy.execute_select_nestloop(\\$proxy\\$ \n    select date,genre_id\n    from aa.genre_store_daily_estimate\n    where \n        date between '2019-01-01' and '2019-12-31'\n        \n    group by date, genre_id\n\\$proxy\\$) tbl ( date DATE, genre_id BIGINT) group by date;\n\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20200215-022754_1053623002","metadata":{},"outputs":[],"source":["%%sh\n\nPGPASSWORD='2mHdFW6%#REu' psql -h 10.2.26.136 -U app_bdp_usage_qa -d dna -p 6432 << EOF \n\nselect * from dna_genre_id_product_mapping where product_id=1427744264 limit 10;\nselect count (*) from dna_genre_id_product_mapping;\n\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20200215-023038_1187630552","metadata":{},"outputs":[],"source":["\n\n\nfrom conf.settings import PG_DNA_NAME, PG_DNA_ACCESS_ID, PG_DNA_HOSTS, PG_DNA_SECRET_KEY\nfrom applications.db_check_v1.common.db_check_utils import query_df\n\ndna_dsn = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_DNA_NAME,\n        user=PG_DNA_ACCESS_ID,\n        host=PG_DNA_HOSTS[0][0],\n        password=PG_DNA_SECRET_KEY,\n        port=PG_DNA_HOSTS[0][1]\n    )\n)\nmapping_df_unified = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-dna/unified/dna.genre_id_product_mapping.v1/dimension/\").toPandas()\nsql = 'SELECT * FROM dna_genre_id_product_mapping'\nmapping_df_raw = query_df(dna_dsn, sql)\n\nmapping_df_raw['created_time'] = mapping_df_raw['created_time'].dt.strftime('%Y-%m-%d')\nmapping_df_raw['last_updated_time'] = mapping_df_raw['last_updated_time'].dt.strftime('%Y-%m-%d')\nmapping_df_raw['genre_id'] = [str(map(int, l))  if l else 'None' for l in mapping_df_raw['genre_id']]\nmapping_df_raw['modifier_id'] = [str(map(int, l)) if l else 'None' for l in mapping_df_raw['modifier_id']]\n\nmapping_df_unified['genre_id'] = mapping_df_unified['genre_id'].astype(\"str\")\nmapping_df_unified['modifier_id'] = mapping_df_unified['modifier_id'].astype(\"str\")\nprint mapping_df_raw\nprint mapping_df_unified\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200215-023112_1024930936","metadata":{},"outputs":[],"source":["\n\ndef _compare_df(df1, df2, on=None):\n    for diff_type in [\"left\", \"right\"]:\n        diff_df = df1.merge(df2, indicator=True, how=diff_type, on=on)  # .loc[lambda x : x['_merge']!='both']\n        diff_df = diff_df.loc[diff_df[\"_merge\"] != \"both\"]\n        if len(diff_df) != 0:\n            print diff_type\n            print diff_df\n\n\n# print mapping_df_raw.genre_id.dtypes\n# print '*'*100\n# print mapping_df_unified.genre_id.dtypes\n# print mapping_df_raw\n# print mapping_df_unified\n\n_compare_df(mapping_df_raw, mapping_df_unified, on=[\"product_id\", \"genre_id\"]) # \"modifier_id\",\"last_updated_time\",  \"created_time\", \"created_by\", \"last_updated_by\", \"comments\", \nprint \"pass\"\n"]},{"cell_type":"code","execution_count":0,"id":"20200216-112743_175745113","metadata":{},"outputs":[],"source":["\n\ndf_unified_test = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-dna/unified/dna.genre_id_product_mapping.v1/dimension/\")\n\n\ndf_unified_test.filter(\"product_id=20600012164188\").show(10)"]},{"cell_type":"code","execution_count":0,"id":"20200313-044717_662114014","metadata":{},"outputs":[],"source":["%%sh\n\nPGPASSWORD='2mHdFW6%#REu' psql -h 10.2.26.136 -U app_bdp_usage_qa -d dna -p 6432 << EOF \n\nselect * from dna_genre_id_product_mapping where product_id=20600012164188 limit 10;\nselect count (*) from dna_genre_id_product_mapping;\n\nEOF\n"]},{"cell_type":"code","execution_count":0,"id":"20200711-092839_2113384055","metadata":{},"outputs":[],"source":["%%sh\naws s3 ls s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.genre-est.v1/fact/granularity=daily/date=2019-04-01/"]},{"cell_type":"code","execution_count":0,"id":"20200216-085331_1632162512","metadata":{},"outputs":[],"source":["\n\n#est_unified_df = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.genre-est.v1/fact/granularity=daily/date=2019-04-01/\")\n#est_unified_df.show()\n\nest_unified_df.select(\"genre_id\").distinct().count()\n# print est_unified_df\n# print set(est_unified_df.device_code.tolist())\n# print set(est_unified_df.country_code.tolist())\n# print set(est_unified_df.genre_id.tolist())\n# print set(est_unified_df.modifier_id.tolist())\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200216-091415_1262335089","metadata":{},"outputs":[],"source":["\nstore_est_unified_df = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/granularity=daily/date=2019-12-27/\")\nmapping_df_unified = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-dna/unified/dna.genre_id_product_mapping.v1/dimension/\")\n\ntransformed_mapping_df = mapping_df_unified.select([\"product_id\", \"genre_id\"]).withColumn('genre_id', F.explode('genre_id'))\ntransformed_store_est_unified_df = store_est_unified_df.select([\"app_id\", \"device_code\", \"country_code\", \"free_app_download\", \"paid_app_download\", \"revenue\"]).withColumnRenamed(\"app_id\", \"product_id\")\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200220-030025_860355775","metadata":{},"outputs":[],"source":["\n\nfrom conf.settings import *\nfrom applications.db_check_v1.common.db_check_utils import query_df\nimport pandas as pd\npd.set_option('expand_frame_repr', False)\n\ndate = \"2020-01-01\"\nsql = \"\"\"\nselect device_id, store_id, date, genre_id, modifier_id, download, revenue from plproxy.execute_select_nestloop($proxy$ \n    select device_id, store_id, date, genre_id, modifier_id, download, revenue\n    from aa.genre_store_daily_estimate\n    where \n        date = '{}'\n$proxy$) tbl (device_id SMALLINT, store_id INT, date DATE , genre_id BIGINT, modifier_id BIGINT, download BIGINT, revenue BIGINT);\n\n\"\"\".format(date)\ndaily_est_dsn =(\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_DAILY_EST_NAME,\n        user=PG_DAILY_EST_ACCESS_ID,\n        host=PG_DAILY_EST_HOSTS[0][0],\n        password=PG_DAILY_EST_SECRET_KEY,\n        port=PG_DAILY_EST_HOSTS[0][1]\n    )\n)\n\ndb_df = query_df(daily_est_dsn, sql)\nest_unified_df = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.genre-est.v1/fact/granularity=daily/date={}/\".format(date)).toPandas()\n\n\ndef _compare_df(df1, df2):\n    for diff_type in [\"left\", \"right\"]:\n        diff_df = df1.merge(df2, indicator=True, how=diff_type)  # .loc[lambda x : x['_merge']!='both']\n        diff_df = diff_df.loc[diff_df[\"_merge\"] != \"both\"]\n        if len(diff_df) != 0:\n            print diff_df\n            print diff_type\n\n\nprint db_df\nprint est_unified_df"]},{"cell_type":"code","execution_count":0,"id":"20200220-030914_542264115","metadata":{},"outputs":[],"source":["\n\nfrom applications.db_check_v1.common.constants import COUNTRY_CODE_MAPPING_BY_MARKET_CODE as COUNTRY_CODE_MAPPING\n\nDEVICE_CODE_MAPPING_BY_DEVICE_ID = {\n    'google-play':{\n        1000: \"android-all\",\n        1001: \"android-phone\",\n        1002: \"android-tablet\",\n    },\n    'apple-store': {\n        2000: \"ios-all\",\n        2001: \"ios-phone\",\n        2002: \"ios-tablet\"\n    }\n}\n\n\nDEVICE_CODE_MAPPING = DEVICE_CODE_MAPPING_BY_DEVICE_ID\n\ndb_df.loc[db_df['device_id'].isin(DEVICE_CODE_MAPPING['google-play'])] = db_df.loc[db_df['device_id'].isin(DEVICE_CODE_MAPPING['google-play'])].replace({\"device_id\": DEVICE_CODE_MAPPING['google-play']})\ndb_df.loc[db_df['device_id'].isin(DEVICE_CODE_MAPPING['apple-store'])] = db_df.loc[db_df['device_id'].isin(DEVICE_CODE_MAPPING['apple-store'])].replace({\"device_id\": DEVICE_CODE_MAPPING['apple-store']})\n\ndb_df = db_df.replace({\"store_id\": COUNTRY_CODE_MAPPING['google-play']})\ndb_df = db_df.replace({\"store_id\": COUNTRY_CODE_MAPPING['apple-store']})\n\ndb_df = db_df.rename(columns={'store_id': 'country_code'}).rename(columns={'device_id': 'device_code'}).rename(columns={'device_id': 'device_code'}).rename(columns={'device_id': 'device_code'})\n\nest_unified_df[\"modifier_id\"] = 100000\n\n_compare_df(est_unified_df, db_df)\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200220-102416_1238068796","metadata":{},"outputs":[],"source":["\n\nprint est_unified_df.dtypes\nprint db_df.dtypes"]},{"cell_type":"code","execution_count":0,"id":"20200220-094800_1122459294","metadata":{},"outputs":[],"source":["\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200216-093116_1017638639","metadata":{},"outputs":[],"source":["\ntransformed_store_est_unified_df.show(5)\ntransformed_mapping_df.show(5)\ntransformed_store_est_unified_df.withColumn('total_col', transformed_store_est_unified_df.free_app_download + transformed_store_est_unified_df.paid_app_download).filter(\"free_app_download=0 or paid_app_download=0\").show(5)\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200216-100922_1158256973","metadata":{},"outputs":[],"source":["\n\nfrom pyspark.sql import functions as F\n\ngiq_df = transformed_store_est_unified_df.join(transformed_mapping_df, transformed_mapping_df.product_id == transformed_store_est_unified_df.product_id, how='inner').groupBy([\"device_code\", \"country_code\", \"genre_id\"]).agg({\n            \"free_app_download\": \"sum\",\n            \"paid_app_download\": \"sum\",\n            \"revenue\": \"sum\",\n        }).withColumnRenamed(\"sum(free_app_download)\", \"free_app_download\").withColumnRenamed(\"sum(paid_app_download)\", \"paid_app_download\").withColumnRenamed(\"sum(revenue)\", \"revenue\")\n\n\ngiq_df = giq_df.fillna({\"free_app_download\":0, \"paid_app_download\":0})\n# giq_df = giq_df.withColumn(\"download\", F.when(giq_df.free_app_download + giq_df.paid_app_download>0, giq_df.free_app_download + giq_df.paid_app_download).otherwise(F.lit(None)))\ngiq_df = giq_df.withColumn(\"download\", giq_df.free_app_download + giq_df.paid_app_download)\n\n\n\n\n\n\n# def replace(column, value):\n#     return when(column != value, column).otherwise(lit(None))\n\n# giq_df.withColumn(\"download\", replace(col(\"y\"), \"bar\")).show()\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200216-115700_355569301","metadata":{},"outputs":[],"source":["\ns1=giq_df.select([\"device_code\", \"country_code\", \"genre_id\", \"download\", \"revenue\"])\ns2=est_unified_df.select([\"device_code\", \"country_code\", \"genre_id\", \"download\", \"revenue\"])\n\ndiff = s1.union(s2).subtract(s1.intersect(s2))\ndiff.show()\n\n\n\nprint diff.count()\nprint s1.count()\nprint s2.count()\n\n# |  ios-phone|          NA|     207|       8|   null|\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200216-122042_634115454","metadata":{},"outputs":[],"source":["\n\nimport pandas as pd\n\nmapping_df_unified = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-dna/unified/dna.genre_id_product_mapping.v1/dimension/\")\ntransformed_mapping_df = mapping_df_unified.select([\"product_id\", \"genre_id\"]).withColumn('genre_id', F.explode('genre_id'))\n\ndef compare(date):\n    #collect\n    store_est_unified_df = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/granularity=daily/date={}/\".format(date))\n    est_unified_df = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.genre-est.v1/fact/granularity=daily/date={}/\".format(date))\n    \n    #transform\n    transformed_store_est_unified_df = store_est_unified_df.select([\"app_id\", \"device_code\", \"country_code\", \"free_app_download\", \"paid_app_download\", \"revenue\"]).withColumnRenamed(\"app_id\", \"product_id\")\n    giq_df = transformed_store_est_unified_df.join(transformed_mapping_df, transformed_mapping_df.product_id == transformed_store_est_unified_df.product_id, how='inner').groupBy([\"device_code\", \"country_code\", \"genre_id\"]).agg({\n            \"free_app_download\": \"sum\",\n            \"paid_app_download\": \"sum\",\n            \"revenue\": \"sum\",\n        }).withColumnRenamed(\"sum(free_app_download)\", \"free_app_download\").withColumnRenamed(\"sum(paid_app_download)\", \"paid_app_download\").withColumnRenamed(\"sum(revenue)\", \"revenue\")\n    giq_df = giq_df.fillna({\"free_app_download\":0, \"paid_app_download\":0})\n    giq_df = giq_df.withColumn(\"download\", giq_df.free_app_download + giq_df.paid_app_download)\n\n    #compare\n    s1=giq_df.select([\"device_code\", \"country_code\", \"genre_id\", \"download\", \"revenue\"])\n    s2=est_unified_df.select([\"device_code\", \"country_code\", \"genre_id\", \"download\", \"revenue\"])\n\n    diff = s1.union(s2).subtract(s1.intersect(s2))\n    if diff.count()>0:\n        print \"{}: FAIL\".format(date)\n        print diff.show(2)\n    else:\n        print  \"{}: PASS\".format(date)\n    \n    \ndef get_date_list(start_date, end_date, freq=\"D\"):\n    date_list = [x.strftime('%Y-%m-%d') for x in list(pd.date_range(start=start_date, end=end_date, freq=freq))]\n    return date_list\n\n\ndate_list = get_date_list(\"2010-07-04/\", \"2020-02-08/\")\nfor date in date_list:\n    try:\n        compare(date)\n    except Exception, e:\n        print \"{}: ERROR\".format(date) \n\n"]},{"cell_type":"code","execution_count":0,"id":"20200220-110920_585528898","metadata":{},"outputs":[],"source":["\n\nimport pandas as pd\nfrom pyspark.sql import functions as F\n\n\nDEVICE_CODE_MAPPING_BY_DEVICE_ID = {\n    'google-play':{\n        1000: \"android-all\",\n        1001: \"android-phone\",\n        1002: \"android-tablet\",\n    },\n    'apple-store': {\n        2000: \"ios-all\",\n        2001: \"ios-phone\",\n        2002: \"ios-tablet\"\n    }\n}\nDEVICE_CODE_MAPPING = DEVICE_CODE_MAPPING_BY_DEVICE_ID\n\ndaily_est_dsn =(\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_DAILY_EST_NAME,\n        user=PG_DAILY_EST_ACCESS_ID,\n        host=PG_DAILY_EST_HOSTS[0][0],\n        password=PG_DAILY_EST_SECRET_KEY,\n        port=PG_DAILY_EST_HOSTS[0][1]\n    )\n)\n\nmapping_df_unified = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-dna/unified/dna.genre_id_product_mapping.v1/dimension/\")\ntransformed_mapping_df = mapping_df_unified.select([\"product_id\", \"genre_id\"]).withColumn('genre_id', F.explode('genre_id'))\n\ndef compare(date):\n    #collect\n    store_est_unified_df = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/granularity=daily/date={}/\".format(date))\n    est_unified_df = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.genre-est.v1/fact/granularity=daily/date={}/\".format(date))\n    \n    #transform\n    transformed_store_est_unified_df = store_est_unified_df.select([\"app_id\", \"device_code\", \"country_code\", \"free_app_download\", \"paid_app_download\", \"revenue\"]).withColumnRenamed(\"app_id\", \"product_id\")\n    giq_df = transformed_store_est_unified_df.join(transformed_mapping_df, transformed_mapping_df.product_id == transformed_store_est_unified_df.product_id, how='inner').groupBy([\"device_code\", \"country_code\", \"genre_id\"]).agg({\n            \"free_app_download\": \"sum\",\n            \"paid_app_download\": \"sum\",\n            \"revenue\": \"sum\",\n        }).withColumnRenamed(\"sum(free_app_download)\", \"free_app_download\").withColumnRenamed(\"sum(paid_app_download)\", \"paid_app_download\").withColumnRenamed(\"sum(revenue)\", \"revenue\")\n    giq_df = giq_df.fillna({\"free_app_download\":0, \"paid_app_download\":0})\n    giq_df = giq_df.withColumn(\"download\", F.when(giq_df.free_app_download + giq_df.paid_app_download>0, giq_df.free_app_download + giq_df.paid_app_download).otherwise(F.lit(None)))\n\n    #compare\n    s1=giq_df.select([\"device_code\", \"country_code\", \"genre_id\", \"download\", \"revenue\"])\n    s2=est_unified_df.select([\"device_code\", \"country_code\", \"genre_id\", \"download\", \"revenue\"])\n\n    diff = s1.union(s2).subtract(s1.intersect(s2))\n    \n    ##########################\n    # DB & UNIFIED LAYER TEST\n    from applications.db_check_v1.common.constants import COUNTRY_CODE_MAPPING_BY_MARKET_CODE as COUNTRY_CODE_MAPPING\n    from conf.settings import *\n    from applications.db_check_v1.common.db_check_utils import query_df\n    import pandas as pd\n\n    sql = \"\"\"\nselect device_id, store_id, date, genre_id, modifier_id, download, revenue from plproxy.execute_select_nestloop($proxy$ \n    select device_id, store_id, date, genre_id, modifier_id, download, revenue\n    from aa.genre_store_daily_estimate\n    where \n        date = '{}'\n$proxy$) tbl (device_id SMALLINT, store_id INT, date DATE , genre_id BIGINT, modifier_id BIGINT, download BIGINT, revenue BIGINT);\"\"\".format(date)\n\n    db_df = query_df(daily_est_dsn, sql)\n\n    db_df.loc[db_df['device_id'].isin(DEVICE_CODE_MAPPING['google-play'])] = db_df.loc[db_df['device_id'].isin(DEVICE_CODE_MAPPING['google-play'])].replace({\"device_id\": DEVICE_CODE_MAPPING['google-play']})\n    db_df.loc[db_df['device_id'].isin(DEVICE_CODE_MAPPING['apple-store'])] = db_df.loc[db_df['device_id'].isin(DEVICE_CODE_MAPPING['apple-store'])].replace({\"device_id\": DEVICE_CODE_MAPPING['apple-store']})\n\n    db_df = db_df.replace({\"store_id\": COUNTRY_CODE_MAPPING['google-play']})\n    db_df = db_df.replace({\"store_id\": COUNTRY_CODE_MAPPING['apple-store']})\n\n    db_df = db_df.rename(columns={'store_id': 'country_code'}).rename(columns={'device_id': 'device_code'}).rename(columns={'device_id': 'device_code'}).rename(columns={'device_id': 'device_code'})\n\n    est_unified_df = est_unified_df.toPandas()\n    est_unified_df[\"modifier_id\"] = 100000\n\n    diff_db = _compare_df(est_unified_df, db_df)\n    \n    if diff.count()>0:\n        print \"{}: FAIL UNIFIED\".format(date)\n        diff.show(2)\n    elif len(diff_db)>0:\n        print \"{}: FAIL DB\".format(date)\n        print diff_db\n    else:\n        print  \"{}: PASS\".format(date)\n    \n    \ndef get_date_list(start_date, end_date, freq=\"D\"):\n    date_list = [x.strftime('%Y-%m-%d') for x in list(pd.date_range(start=start_date, end=end_date, freq=freq))]\n    return date_list\n\ndef _compare_df(df1, df2):\n    for diff_type in [\"left\", \"right\"]:\n        diff_df = df1.merge(df2, indicator=True, how=diff_type)  # .loc[lambda x : x['_merge']!='both']\n        diff_df = diff_df.loc[diff_df[\"_merge\"] != \"both\"]\n        if len(diff_df) != 0:\n            print diff_type\n            return diff_df\n    return []\n\ndate_list = get_date_list(\"2010-07-04/\", \"2020-02-15/\")\nfor date in date_list:\n    try:\n        compare(date)\n    except Exception, e:\n        print \"{}: ERROR\".format(date)\n        print e.message\n\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200216-122944_1611377973","metadata":{},"outputs":[],"source":["%md\n\n1. fill na > 0逻辑, download有, 但是 revenue没有. 所以会出现 download =0 , revenue=null的情况\n2. 正在跑\n"]},{"cell_type":"code","execution_count":0,"id":"20200216-121335_296724452","metadata":{},"outputs":[],"source":["\n\nsql = \"device_code='ios-phone' and country_code='NA' and genre_id=207\"\ns1.filter(sql).show()\ns2.filter(sql).show()\n"]},{"cell_type":"code","execution_count":0,"id":"20200216-094454_592749310","metadata":{},"outputs":[],"source":["\n\nimport pandas as pd\n\ntest_df1 = pd.DataFrame({'id': [1,2,3], 'download':[1,2,3]})\ntest_df2 = pd.DataFrame({'id': [1,1,2,3,4], 'id2':[11,111,22,33,44], 'nickname':['aa','aa','bb','cc','dd']})\n\n\nresult_df = test_df1.merge(test_df2, on='id', how='outer')\n\nprint result_df\n"]},{"cell_type":"code","execution_count":0,"id":"20200216-095511_571202517","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql import Row\nimport pyspark.sql.functions as F \n\n\ndf = spark.createDataFrame( [Row(1, [1,2,3])], ['id', 'genre_id'])\ndf.show()\ndf = df.withColumn('genre_id', F.explode('genre_id'))\ndf.show()\n"]},{"cell_type":"code","execution_count":0,"id":"20200215-023242_558555763","metadata":{},"outputs":[],"source":["%%sh\n\naws s3 ls s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.genre-est.v1/fact/granularity=daily/\n# aws s3 ls s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/granularity=daily/date=2019-12-27/\n\n#                           PRE app-tech.store.app-est.v1/\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200216-085248_996121247","metadata":{},"outputs":[],"source":["%%sh\n# aws s3 ls s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.genre-est.v1/fact/granularity=daily/\naws s3 ls s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/\n \naws s3 ls s3://b2c-prod-data-pipeline-unified-store-paid/unified/\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200728-111433_1772851819","metadata":{},"outputs":[],"source":["%%sh\n\nPGPASSWORD='2mHdFW6%#REu' psql -h 10.2.26.136 -U app_bdp_usage_qa -d dna -p 6432 << EOF \n\nselect * from dna_genre_id_product_mapping where product_id=20600012164188 limit 10;\nselect count (*) from dna_genre_id_product_mapping;\n\nEOF\n\n    \n"]},{"cell_type":"code","execution_count":0,"id":"20200221-042209_675973824","metadata":{},"outputs":[],"source":["\n\ndf = spark.read.jdbc(\"jdbc:postgresql://10.2.26.136:6432/dna\", \"dna_genre_id_product_mapping\", properties={\"user\": \"app_bdp_usage_qa\", \"password\": \"2mHdFW6%#REu\"})\n\ndf.createOrReplaceTempView(\"dna_genre_id_product_mapping\")\n\nsqlDF = spark.sql(\"SELECT * FROM dna_genre_id_product_mapping LIMIT 10\")\nsqlDF.show()\n"]},{"cell_type":"code","execution_count":0,"id":"20200728-111610_1285520367","metadata":{},"outputs":[],"source":["%%sh\n\naws s3 ls s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.genre-est.v1/fact/granularity=daily/date=2020-07-18/\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200728-113019_1043269170","metadata":{},"outputs":[],"source":["%%sh\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}