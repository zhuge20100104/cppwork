{"cells":[{"cell_type":"code","execution_count":0,"id":"20200221-094002_550824437","metadata":{},"outputs":[],"source":["\n\n\ndate=\"2020-01-08\"\ndf = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/granularity=daily/date={}/device_code=android-all/\".format(date))\nprint df.filter(\"app_id==20600009602008 \").show(20)\n"]},{"cell_type":"code","execution_count":0,"id":"20200221-094059_966324824","metadata":{},"outputs":[],"source":["\n\n\ndate=\"2020-01-01\"\ndf = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/_obselete/store.app-est.v1/fact/granularity=daily/date={}/device_code=ios-all/\".format(date))\nprint df.filter(\"app_id=20600010387037\").show(20)\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200221-105456_1879457197","metadata":{},"outputs":[],"source":["\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nimport pandas as pd\npd.set_option('expand_frame_repr', False)\n"]},{"cell_type":"code","execution_count":0,"id":"20200221-095559_370956130","metadata":{},"outputs":[],"source":["\n\nimport pandas as pd\nfrom pyspark.sql import functions as F\nfrom applications.db_check_v1.common.constants import COUNTRY_CODE_MAPPING_BY_MARKET_CODE as COUNTRY_CODE_MAPPING\nfrom conf.settings import *\nfrom applications.db_check_v1.common.db_check_utils import query_df\nimport pandas as pd\n\ndaily_est_dsn =(\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_DAILY_EST_NAME,\n        user=PG_DAILY_EST_ACCESS_ID,\n        host=PG_DAILY_EST_HOSTS[0][0],\n        password=PG_DAILY_EST_SECRET_KEY,\n        port=PG_DAILY_EST_HOSTS[0][1]\n    )\n)\n\n\ndef get_date_list(start_date, end_date, freq=\"D\"):\n    date_list = [x.strftime('%Y-%m-%d') for x in list(pd.date_range(start=start_date, end=end_date, freq=freq))]\n    return date_list\n\n\ndef compare(date):\n    sql = \"\"\"\nselect distinct(app_id) from plproxy.execute_select_nestloop($proxy$ \n    select distinct(app_id)\n    from aa.app_store_daily_estimate_0\n    where \n        date = '{}'\n$proxy$) tbl (app_id BIGINT);\n\"\"\".format(date)\n\n    db_df = query_df(daily_est_dsn, sql)\n    unified_df = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/granularity=daily/date={}/device_code=android-all/\".format(date)).select(\"app_id\").distinct().toPandas()\n\n    u_list = unified_df.app_id.unique()\n    d_list = db_df.app_id.unique()\n    diff_list =  [x for x in  d_list if x not in u_list ]\n     \n    if len(diff_list) ==  0:\n        print \"{} PASS\".format(date)\n    else:\n        print \"{} FAIL\".format(date)\n        print \"{} {} {}\".format(len(u_list), len(d_list), diff_list[0:5])\n        # print len(u_list)\n        # print len(d_list)\n        # # print [x for x in  u_list if x not in d_list ]\n        # print [x for x in  d_list if x not in u_list ]\n        # print '*' * 200\n        \n\n\ndate_list = get_date_list(\"2019-11-01\", \"2020-02-21\")\nfor date in date_list:\n    # compare(date)\n    try:\n        compare(date)\n    except Exception, e:\n        print \"{}: ERROR\".format(date)\n        print e.message\n"]},{"cell_type":"code","execution_count":0,"id":"20200221-105503_2049552696","metadata":{},"outputs":[],"source":["\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}