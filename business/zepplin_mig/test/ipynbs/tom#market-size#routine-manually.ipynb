{"cells":[{"cell_type":"code","execution_count":0,"id":"20200208-025344_1682238072","metadata":{},"outputs":[],"source":["\n\nimport datetime\nimport psycopg2\nfrom contextlib import closing\ndbinfo = {\n    'NAME': 'dailyest',\n    'USER': 'app_bdp_usage_qa',\n    'PASSWORD': '2mHdFW6%#REu',\n    'HOST': 'internal-aa-prod-plproxy-internal-4-329644124.us-east-1.elb.amazonaws.com',\n    'PORT': 7432,\n}\nconn = psycopg2.connect(\"\"\"\n            dbname={dbname} user={user} host={host} port={port} password={passwd}\n            \"\"\".format(dbname=dbinfo['NAME'], user=dbinfo['USER'], passwd=dbinfo['PASSWORD'],\n                       host=dbinfo['HOST'], port=dbinfo['PORT']))\ndef select(stmt, params):\n    with closing(conn.cursor()) as cur:\n        cur.execute(stmt, params)\n        rows = cur.fetchall()\n        cnt = cur.rowcount\n    return rows, cnt\n\n\nsql = \"\"\"select device_id, date, store_id, kpi, category_id, app_type_id, purchase_type_id, estimate from plproxy.execute_select_nestloop($proxy$ select device_id, date, store_id, kpi, category_id, app_type_id, purchase_type_id, estimate from ms.market_size_daily_estimate_1000 where date = '2020-01-10' and purchase_type_id=12 and app_type_id=2 and store_id=14 and category_id in (65) $proxy$) tbl (device_id SMALLINT, date DATE, store_id INT, kpi SMALLINT, category_id INT, app_type_id SMALLINT, purchase_type_id SMALLINT, estimate BIGINT);\"\"\"\nrows, _ = select(sql, None)\nprint len(rows)\n\nfor row in rows:\n    print row\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200210-041014_582896329","metadata":{},"outputs":[],"source":["%%sh\n\nPGPASSWORD='2mHdFW6%#REu' psql -h internal-aa-prod-plproxy-internal-4-329644124.us-east-1.elb.amazonaws.com -U app_bdp_usage_qa -d dailyest -p 7432 << EOF \nselect device_id, date, store_id, kpi, category_id, app_type_id, purchase_type_id, estimate from plproxy.execute_select_nestloop(\\$proxy\\$ \n    select device_id, date, store_id, kpi, category_id, app_type_id, purchase_type_id, estimate\n    from ms.market_size_daily_estimate_1000 \n    where \n        date = '2020-01-10' and \n        purchase_type_id=12 and \n        app_type_id=2 and \n        store_id=14 and \n        category_id in (65) \n\\$proxy\\$) tbl (device_id SMALLINT, date DATE, store_id INT, kpi SMALLINT, category_id INT, app_type_id SMALLINT, purchase_type_id SMALLINT, estimate BIGINT);\nEOF\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200207-023007_1224286779","metadata":{},"outputs":[],"source":["%%sh\ndate\n# SELECT sum(est_market_size_download) as est_market_size_download ,sum(est_market_size_revenue) as est_market_size_revenue FROM store.store_market_size_fact_v1  WHERE app_price_type_id=2 AND purchase_type_id=12 AND country_code='US' AND category_id=100020 AND device_code='ios-all' AND date between '2010-01-10' AND '2020-01-10';\n\nPGPASSWORD='dNzWtSV3pKTx' psql -h 10.2.10.132 -U citus_bdp_usage_qa -d aa_citus_db -p 5432 << EOF \n\n-- SELECT date,count(*),count(distinct(app_price_type_id, purchase_type_id,category_id,device_code,country_code,date,granularity)) FROM store.store_market_size_fact_v1  WHERE date between '2019-12-01' AND '2019-12-31' GROUP BY date;\n\n\\d+ store.store_market_size_latest_date_v1;\n\nEOF\n\ndate\n\n#category_id=400070\n# device_code=\"android-all\"\n# country_code=\"ZA\"\n# app_price_type_id=2\n# purchase_type_id=12\n"]},{"cell_type":"code","execution_count":0,"id":"20200207-024638_419356960","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql.functions import lit, udf\nfrom pyspark.sql.types import (\n    ArrayType, BooleanType, LongType, IntegerType,\n    StringType, StructType, StructField\n)\nschema = StructType([\n    StructField(\"store_id\", IntegerType(), False),\n    StructField(\"date\", StringType(), False),\n    StructField(\"platform_id\", IntegerType(), False),\n    StructField(\"device\", StringType(), False),\n    StructField(\"data_type\", StringType(), False),\n    StructField(\"price_type\", IntegerType(), False),\n    StructField(\"purchase_type\", IntegerType(), False),\n    StructField(\"category_id\", IntegerType(), False),\n    StructField(\"estimate\", LongType(), False)\n])\n# sample unified data:\n# spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.market-size.v1/fact/granularity=daily/date=2020-01-10/\").filter(\"country_code='US' and app_price_type_id=0 and purchase_type_id=10 and device_code='android-all' and category_id=400002\").show()\n# raw data\nprint spark.read.csv(\"s3://b2c-prod-dca-store-estimates/store_est/v_final/DAY/2020-01-10/ios/market_size/*\", schema=schema, sep='\\t').show(1)\n# print spark.read.csv([\"s3://b2c-prod-dca-store-estimates/store_est/v_final/DAY/2020-01-10/android/market_size/*\", \"s3://b2c-prod-dca-store-estimates/store_est/v_final/DAY/2020-01-10/ios/market_size/*\"], schema=schema, sep='\\t').count()\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200207-025517_1199195064","metadata":{},"outputs":[],"source":["\n%md\n\n# Test Case List\n\n1. ETL Accuracy\n    - 数据读取过程: \n    - 数据mapping过程\n    - 数据清洗过程\n        -- 在transform过程只保留原始category数据, (清洗掉了预聚合的catetory级别数据)\n        -- 清洗掉 DF 预定义的store 数据. 比如ios原始数据中, store_id=3/4/5的数据\n    - 数据pivot过程: 窄表变宽表\n    - 数据ETL结束时\n        -- 生成 LED\n        -- 生成 Data Range Table\n2. ETL completness\n    - sum & count (2020-01-12 ~ now)\n3. ETL timeliness\n    - check with yiming about ETL completed time\n4. Coverage (DF)\n    - Country, Device, Coverage - add cases\n\n\n# progress:\n1. 查看为什么transform结果不对, 比较两个dataframe\n2. 继续, 直到数据完全匹配\n\n# issue list:\n1. historical, unified layer : category_id 是string类型, 应该是int\n2. routine unified data 中有脏数据, from IOS> store_id = 3/4/5\n3. 2020-01-10 数据 在QA data和 historical data之间 不匹配: \n\nDA: Iris\n"]},{"cell_type":"code","execution_count":0,"id":"20200207-100727_2100263628","metadata":{},"outputs":[],"source":["\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nimport pandas as pd\npd.set_option('expand_frame_repr', False)\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200207-100534_1520056263","metadata":{},"outputs":[],"source":[" \n\n\nfrom bdce.common.utils import update_application_code\nupdate_application_code(\n    spark, role=\"BDP-PROD-APP-INT-QA\", application_name=\"aa-int-qa-db-check-debug\"\n)\nspark.sparkContext.addPyFile(\"/tmp/zeppelin_application_code/libs/python/dependencies.zip\")\n"]},{"cell_type":"code","execution_count":0,"id":"20200207-075305_1430324376","metadata":{},"outputs":[],"source":["\n# Copyright (c) 2018 App Annie Inc. All rights reserved.\n# pylint: disable=E1101,C0412\n\n\"\"\"\nDB Check modules\n\"\"\"\n\nimport datetime\nfrom applications.db_check_v1.common.base_test import PipelineTest\nfrom applications.db_check_v1.common.db_check_utils import query_df, etl_skip\nfrom pyspark.sql.types import LongType, IntegerType, StringType, StructType, StructField\nfrom applications.db_check_v1.common.constants import COUNTRY_CODE_MAPPING_BY_MARKET_CODE as COUNTRY_CODE_MAPPING, \\\n    CATEGORY_ID_MAPPING_BY_MARLKET_AND_DEVICE_CODE as CATEGORY_ID_MAPPING\nfrom applications.db_check_v1.common.utils import get_week_start_end_date\nfrom applications.db_check_v1.cases.store.market_size_v1.constants import MARKET_SIZE_DSN\nimport pandas as pd\n\nclass MarketSizeRawData(object):\n    raw_s3_path = \"s3://b2c-prod-dca-store-estimates/store_estv2/MARKET_SIZE_ESTIMATES_FINAL/\" \\\n                  \"version=2.0.0/range_type=DAY/date={date}/\"\n    device_code_mapping = {\n        \"0google-play\": \"android-all\",\n        \"1ios\": \"ios-all\",\n        \"1ipad\": \"ios-tablet\",\n        \"1iphone\": \"ios-phone\",\n    }\n\n    metric_mapping = {\n        \"downloads\": \"est_market_size_download\",\n        \"revenue\": \"est_market_size_revenue\"\n    }\n\n    dimension_mapping = {\n        \"price_type\": \"app_price_type_id\",\n        \"purchase_type\": \"purchase_type_id\"\n    }\n\n    def __init__(self, spark):\n        self.spark = spark\n\n    def get(self, date):\n        df = self._get_raw_data_by_date(date)\n        df = self._parse_mapping(df)\n        df = self._parse_unified_format(df)\n        # df = self._data_clean_up(df)\n        return df\n\n    def _data_clean_up(self, df):\n        # clean unknown mapping\n        category_id_list = list(set(CATEGORY_ID_MAPPING[\"apple-store\"][\"ios-all\"].values() +\n                                    CATEGORY_ID_MAPPING[\"google-play\"][\"android-all\"].values()))\n\n        country_code_list = list(set(COUNTRY_CODE_MAPPING[\"apple-store\"].values() +\n                                     COUNTRY_CODE_MAPPING[\"google-play\"].values()))\n\n        df = df[(df['category_id'].isin(category_id_list)) & (df['country_code'].isin(country_code_list))]\n        return df\n\n    def _parse_mapping(self, df):\n        # country_code mapping\n        df.loc[df[\"platform_id\"] == 0] = df.loc[df[\"platform_id\"] == 0].\\\n            replace({\"store_id\": COUNTRY_CODE_MAPPING[\"google-play\"]})\n        df.loc[df[\"platform_id\"] == 1] = df.loc[df[\"platform_id\"] == 1].\\\n            replace({\"store_id\": COUNTRY_CODE_MAPPING[\"apple-store\"]})\n        df = df.rename(columns={'store_id': 'country_code'})\n\n        # category_id mapping\n        df.loc[df[\"platform_id\"] == 0] = df.loc[df[\"platform_id\"] == 0].\\\n            replace({\"category_id\": CATEGORY_ID_MAPPING[\"google-play\"][\"android-all\"]})\n        df.loc[df[\"platform_id\"] == 1] = df.loc[df[\"platform_id\"] == 1].\\\n            replace({\"category_id\": CATEGORY_ID_MAPPING[\"apple-store\"][\"ios-all\"]})\n\n        # device_code mapping\n        df[\"device_code\"] = df[\"platform_id\"].astype(str) + df[\"device\"]\n        df = df.replace({\"device_code\": self.device_code_mapping})\n        return df\n\n    def _parse_unified_format(self, df):\n        df = df.rename(columns=self.dimension_mapping)\n        df = df.pivot_table(index=[\"app_price_type_id\", \"purchase_type_id\", \"category_id\",\n                                   \"device_code\", \"country_code\"], columns='data_type', values='estimate')\n        df.reset_index(inplace=True)\n        df.columns.name = None\n        df = df.rename(columns=self.metric_mapping)\n        return df\n\n    def _get_raw_data_by_date(self, date):\n        \"\"\"\n        +--------+----------+-----------+-----------+---------+----------+-------------+-----------+--------+\n        |store_id|      date|platform_id|     device|data_type|price_type|purchase_type|category_id|estimate|\n        +--------+----------+-----------+-----------+---------+----------+-------------+-----------+--------+\n        |      10|2020-01-10|          0|google-play|downloads|         1|           10|          1|11981138|\n        +--------+----------+-----------+-----------+---------+----------+-------------+-----------+--------+\n        \"\"\"\n        schema = StructType([\n            StructField(\"store_id\", IntegerType(), False),\n            StructField(\"date\", StringType(), False),\n            StructField(\"platform_id\", IntegerType(), False),\n            StructField(\"device\", StringType(), False),\n            StructField(\"data_type\", StringType(), False),\n            StructField(\"price_type\", IntegerType(), False),\n            StructField(\"purchase_type\", IntegerType(), False),\n            StructField(\"category_id\", IntegerType(), False),\n            StructField(\"estimate\", LongType(), False)\n        ])\n        raw_df = self.spark.read.parquet(self.raw_s3_path.format(date=date))\n        return raw_df.toPandas()\n\n    def get_rank_count_and_sum_by_date(self, date):\n        pass\n        # return raw_count, raw_sum\n\n\nclass MarketSizeUnifiedData(object):\n    unified_s3_path = \"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.market-size.v1/fact/\" \\\n                      \"granularity=daily/date={}/\"\n\n    def __init__(self, spark):\n        self.spark = spark\n\n    def get(self, date):\n        unified_df = self.spark.read.parquet(self.unified_s3_path.format(date)).toPandas()\n        unified_df = unified_df.drop([\"_identifier\"], axis=1)\n        return unified_df\n\n\nclass MarketSizeDBData(object):\n    def get(self, date):\n        sql = \"SELECT * FROM store.store_market_size_fact_v1  WHERE date='{}'\".format(date)\n        return query_df(MARKET_SIZE_DSN, sql)\n\n\nclass TestMarketSizeDaily(PipelineTest):\n    # Every Tuesday 16:00 UTC time will refresh the data of last Full Week.\n    routing_config = ('* 16 * * 2', 3)\n\n    def _compare_df(self, df1, df2):\n        for diff_type in [\"left\", \"right\"]:\n            diff_df = df1.merge(df2, indicator=True, how=diff_type)  # .loc[lambda x : x['_merge']!='both']\n            diff_df = diff_df.loc[diff_df[\"_merge\"] != \"both\"]\n            if len(diff_df) != 0:\n                print diff_type\n                print diff_df.country_code.unique()\n                print diff_df.category_id.unique()\n                print diff_df.device_code.unique()\n            self.assertEqual(len(diff_df), 0)\n\n    # @etl_skip(routing_config)\n    def test_market_size_etl_accuracy_and_completeness(self):\n        # Every Tuesday 16:00 UTC time will refresh the data of last Full Week.\n        start_date, end_date = get_week_start_end_date(self.check_date_str)\n        date_list = get_date_list(start_date, end_date)\n        for date in date_list:\n            print date\n            raw_df = MarketSizeRawData(self.spark).get(date)\n            unified_df = MarketSizeUnifiedData(self.spark).get(date)\n            db_db = MarketSizeDBData().get(date)\n\n            self._compare_df(raw_df, unified_df)\n            self._compare_df(unified_df, db_db)\n\n    def test_market_size_etl_timelines(self):\n        # Every Tuesday 16:00 UTC time will refresh the data of last Full Week.\n        # E.g. 2020-02-11 17:00 the data of 2020-02-02 ~ 2020-02-08 will be ready\n        trigger_datetime = datetime.datetime.strptime(\"2020-02-11 17:00:00\", '%Y-%m-%d %H:%M:%S')\n        check_date_str_actual = self._get_check_date_from_routing_config(trigger_datetime).strftime(\"%Y-%m-%d\")\n        self.assertEqual(\"2020-02-08\", check_date_str_actual)\n\n\ndef get_date_list(start_date, end_date, freq=\"D\"):\n    date_list = [x.strftime('%Y-%m-%d') for x in list(pd.date_range(start=start_date, end=end_date, freq=freq))]\n    return date_list\n"]},{"cell_type":"code","execution_count":0,"id":"20200211-061600_1445661098","metadata":{},"outputs":[],"source":["\n\nfrom datetime import datetime\ndef get_date_list(begin_date, end_date, freq):\n    date_list = [x.strftime('%Y-%m-%d') for x in list(pd.date_range(start=begin_date, end=end_date, freq=freq))]\n    return date_list\n\n\nbegin_date = datetime(2020, 01, 01)\nend_date = datetime(2020, 02, 8)\n\nDATE_GRANULARITY_MAPPINGLIST = {\n    \"daily\": get_date_list(begin_date, end_date, \"D\"),\n    \"weekly\": get_date_list(begin_date, end_date, \"W-SAT\"),\n    \"monthly\": get_date_list(begin_date, end_date, \"M\")\n}\n"]},{"cell_type":"code","execution_count":0,"id":"20200218-025142_1844292398","metadata":{},"outputs":[],"source":["\n\ndate = \"2019-12-08\"\nlegacy_raw_df = MarketSizeRawData(spark)._get_raw_data_by_date(date)\nraw_df = MarketSizeRawData(spark).get(date)"]},{"cell_type":"code","execution_count":0,"id":"20200218-025316_522492770","metadata":{},"outputs":[],"source":["\n\nraw_df.        \ncategory_id_list = list(set(CATEGORY_ID_MAPPING[\"apple-store\"][\"ios-all\"].values() +\n                                    CATEGORY_ID_MAPPING[\"google-play\"][\"android-all\"].values()))\n\n        country_code_list = list(set(COUNTRY_CODE_MAPPING[\"apple-store\"].values() +\n                                     COUNTRY_CODE_MAPPING[\"google-play\"].values()))\n\n        df = df[(df['category_id'].isin(category_id_list)) & (df['country_code'].isin(country_code_list))]\n"]},{"cell_type":"code","execution_count":0,"id":"20200211-082622_57536812","metadata":{},"outputs":[],"source":["\n\n# legacy_raw_df = MarketSizeRawData(spark)._get_raw_data_by_date(\"2020-01-01\")\n# print legacy_raw_df.loc[(legacy_raw_df[\"category_id\"]==36) & (legacy_raw_df[\"device\"]!=\"google-play\")]\nprint raw_df.loc[(raw_df[\"category_id\"]==100000) & (raw_df[\"device_code\"]!=\"android-all\")]\n"]},{"cell_type":"code","execution_count":0,"id":"20200207-101218_1638908096","metadata":{},"outputs":[],"source":["\n\nfrom applications.db_check_v1.cases.store.app_rank_v1.constants import citus_dsn\nfrom applications.db_check_v1.common.db_check_utils import query_df\nfrom datetime import datetime\ndate_list = DATE_GRANULARITY_MAPPINGLIST[\"daily\"]\ndate_list = [\"2020-01-09\", \"2020-01-10\", \"2020-01-29\"]\n\n\nfor date in date_list:\n    print '*'*100\n    print date\n    start=datetime.today()\n    # legacy_raw_df = MarketSizeRawData(spark)._get_raw_data_by_date(date)\n    raw_df = MarketSizeRawData(spark).get(date)\n\n    # unified_df =  spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.market-size.v1/fact/granularity=daily/date={}/\".format(date)).toPandas()\n    # unified_df = unified_df.drop([\"_identifier\"], axis=1)\n    \n    # legacy_unified_df = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/app-tech.store.market-size.v1/fact/granularity=daily/date={}/\".format(date)).toPandas()\n    # legacy_unified_df = legacy_unified_df.drop([\"_identifier\"], axis=1)\n    # legacy_unified_df[\"category_id\"] = pd.to_numeric(legacy_unified_df[\"category_id\"])\n    \n    sql = \"SELECT * FROM store.store_market_size_fact_v1  WHERE date='{}'\".format(date)\n    db_df = query_df(citus_dsn, sql)\n\n    print datetime.today() - start\n\n\n    df1= raw_df\n    # df2= unified_df\n    # df2= legacy_unified_df\n    df2= db_df\n    for diff_type in [\"left\", \"right\"]:\n        diff_df = df1.merge(df2,indicator = True, how=diff_type)#.loc[lambda x : x['_merge']!='both']\n        diff_df = diff_df.loc[ diff_df[\"_merge\"]!=\"both\"]\n        if len(diff_df)!=0:\n            print len(df1)\n            print len(df2)\n            print diff_type\n            print len(diff_df)\n            print diff_df\n            print diff_df.country_code.unique()\n            print diff_df.category_id.unique()\n            print diff_df.device_code.unique()\n"]},{"cell_type":"code","execution_count":0,"id":"20200207-130042_812589505","metadata":{},"outputs":[],"source":["\n\n\n# print raw_df.loc[raw_df[\"est_market_size_revenue\"]==15017778.5]\n# print unified_df.loc[unified_df[\"est_market_size_revenue\"]==15017778.5]\n# print legacy_raw_df\n\ndate = \"2020-01-01\"\n\n# legacy_raw_df = MarketSizeRawData(spark)._get_raw_data_by_date(date)\nraw_df = MarketSizeRawData(spark).get(date)\n\nunified_df =  spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.market-size.v1/fact/granularity=daily/date={}/\".format(date)).toPandas()\n# unified_df = unified_df.drop([\"_identifier\"], axis=1)\n\n# legacy_unified_df = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/app-tech.store.market-size.v1/fact/granularity=daily/date={}/\".format(date)).toPandas()\n# legacy_unified_df = legacy_unified_df.drop([\"_identifier\"], axis=1)\n# legacy_unified_df[\"category_id\"] = pd.to_numeric(legacy_unified_df[\"category_id\"])\n\n\n#        app_price_type_id  purchase_type_id  category_id  device_code country_code  est_market_size_download  est_market_size_revenue        date granularity  _disable_idx_4_query      _merge\n# 183842                  1                11       400007  android-all           CN                      69.0                      NaN  2020-01-09       daily                     0  right_only\n\ncategory_id=400007\ndevice_code=\"android-all\"\ncountry_code=\"CN\"\napp_price_type_id=1\npurchase_type_id=12\n\n# print legacy_raw_df.loc[(legacy_raw_df[\"category_id\"]==44) & (legacy_raw_df[\"device\"]==\"google-play\")  &  (legacy_raw_df[\"store_id\"]==3)  & (legacy_raw_df[\"price_type\"]==app_price_type_id)  & (legacy_raw_df[\"purchase_type\"]==purchase_type_id)]\nprint legacy_raw_df.loc[(legacy_raw_df[\"category_id\"]==44) & (legacy_raw_df[\"store_id\"]==3)]\n\n\nprint raw_df.loc[(raw_df[\"category_id\"]==category_id) & (raw_df[\"device_code\"]==device_code) & (raw_df[\"country_code\"]==country_code) & (raw_df[\"app_price_type_id\"]==app_price_type_id) & (raw_df[\"purchase_type_id\"]==purchase_type_id) ]\n\n\n# print unified_df.loc[(unified_df[\"category_id\"]==category_id) & (unified_df[\"device_code\"]==device_code) & (unified_df[\"country_code\"]==country_code) & (unified_df[\"app_price_type_id\"]==app_price_type_id) & (unified_df[\"purchase_type_id\"]==purchase_type_id) ]\n\n\n# print legacy_unified_df.loc[(legacy_unified_df[\"category_id\"]==category_id) & (legacy_unified_df[\"device_code\"]==device_code) & (legacy_unified_df[\"country_code\"]==country_code) & (legacy_unified_df[\"app_price_type_id\"]==app_price_type_id) & (legacy_unified_df[\"purchase_type_id\"]==purchase_type_id) ]\n\n\nprint \"(1000, datetime.date(2020, 1, 10), 14, 1, 65, 2, 12, 188L)\"\n# print legacy_unified_df\n# print raw_df\n# print diff_df.country_code.unique()\n# print diff_df.category_id.unique()\n# print diff_df.device_code.unique()\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200215-043343_601649260","metadata":{},"outputs":[],"source":["\n\nprint raw_df"]},{"cell_type":"code","execution_count":0,"id":"20200214-044820_1257269720","metadata":{},"outputs":[],"source":["%%sh\n# SELECT * FROM store.store_market_size_fact_v1  WHERE category_id=400007 AND app_price_type_id=1 AND purchase_type_id=12 AND country_code='CN' AND device_code='android-all' AND date = '2020-01-09'\n\nPGPASSWORD='dNzWtSV3pKTx' psql -h 10.2.10.132 -U citus_bdp_usage_qa -d aa_citus_db -p 5432 << EOF \nSELECT count(*) FROM store.store_market_size_fact_v1  WHERE date = '2020-01-30'\n\nEOF\n"]},{"cell_type":"code","execution_count":0,"id":"20200207-102150_1616331121","metadata":{},"outputs":[],"source":["\n# tom_df = tom_df.drop([\"date\"], axis=1)\n# unified_df = unified_df.drop([\"_identifier\"], axis=1)\n# legacy_unified_df = legacy_unified_df.drop([\"_identifier\"], axis=1)\npd.set_option('expand_frame_repr', False)\n\n# print raw_df.dtypes\n# print unified_df.dtypes\n# print legacy_unified_df.dtypes\n\n\n# print raw_df\n# print unified_df\n# print legacy_unified_df\n\ndf1= raw_df\ndf2= unified_df\n# df2= legacy_unified_df\n\ndiff_df = df1.merge(df2,indicator = True, how='left', on=[\"app_price_type_id\",  \"purchase_type_id\",  \"category_id\",  \"device_code\", \"country_code\", \"est_market_size_download\", \"est_market_size_revenue\" ])#.loc[lambda x : x['_merge']!='both']\n# print df2[ ~df2.isin(df1)].dropna()\n\ndiff_df = diff_df.loc[ diff_df[\"_merge\"]!=\"both\"]\n\nprint diff_df\nprint diff_df.country_code.unique()\nprint diff_df.category_id.unique()\nprint diff_df.device_code.unique()"]},{"cell_type":"code","execution_count":0,"id":"20200207-132458_525033164","metadata":{},"outputs":[],"source":["%%sh\n\n\naws s3 ls s3://b2c-prod-dca-store-estimates/store_est/v_final/DAY/2020-01-10/ios/market_size/143443/\naws s3 ls s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.market-size.v1/fact/granularity=daily/date=2020-01-10/\n"]},{"cell_type":"code","execution_count":0,"id":"20200207-024355_1951106438","metadata":{},"outputs":[],"source":["%%sh\n# aws s3 ls s3://b2c-prod-dca-store-estimates/store_est/v_final/DAY/2020-02-01/ios/market_size/143441/\n# aws s3 ls s3://b2c-prod-dca-store-estimates/store_est/v_final/DAY/2020-02-08/android/market_size/3/\n# aws s3 ls s3://b2c-prod-dca-store-estimates/store_estv2/MARKET_SIZE_ESTIMATES_FINAL/version=2.0.0/range_type=DAY/date=2020-01-13/platform=android/\naws s3 ls s3://b2c-prod-dca-store-estimates/store_estv2/MARKET_SIZE_ESTIMATES_FINAL/version=2.0.0/range_type=DAY/date=2020-02-15/\n\naws s3 ls s3://b2c-prod-data-pipeline-raw-store-paid/\necho '***************************************************************************************'\n# aws s3 ls s3://b2c-prod-dca-store-estimates/store_est/v_final/DAY/2020-02-01/android/market_size/1/\n# aws s3 ls s3://b2c-prod-data-pipeline-unified-store-paid/unified/app-tech.store.market-size.v1/fact/granularity=daily/\n# aws s3 ls s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.market-size.v1/fact/granularity=daily/\n"]},{"cell_type":"code","execution_count":0,"id":"20200208-020656_120777918","metadata":{},"outputs":[],"source":["\n\n\"\"\"\n+--------+----------+-----------+-----------+---------+----------+-------------+-----------+--------+\n|store_id|      date|platform_id|     device|data_type|price_type|purchase_type|category_id|estimate|\n+--------+----------+-----------+-----------+---------+----------+-------------+-----------+--------+\n|      10|2020-01-10|          0|google-play|downloads|         1|           10|          1|11981138|\n+--------+----------+-----------+-----------+---------+----------+-------------+-----------+--------+\n    \"\"\"\nschema = StructType([\n    StructField(\"store_id\", IntegerType(), False),\n    StructField(\"date\", StringType(), False),\n    StructField(\"platform_id\", IntegerType(), False),\n    StructField(\"device\", StringType(), False),\n    StructField(\"data_type\", StringType(), False),\n    StructField(\"price_type\", IntegerType(), False),\n    StructField(\"purchase_type\", IntegerType(), False),\n    StructField(\"category_id\", IntegerType(), False),\n    StructField(\"estimate\", LongType(), False)\n])\ns3_path = \"s3://b2c-prod-dca-store-estimates/store_est/v_final/DAY/2020-01-09/android/market_size/3/\"\ndebug_raw_df = spark.read.csv(s3_path, schema=schema, sep='\\t').toPandas()\n\nprint debug_raw_df.loc[ (debug_raw_df[\"category_id\"]==44)]\n\nprint  debug_raw_df"]},{"cell_type":"code","execution_count":0,"id":"20200208-020919_171935550","metadata":{},"outputs":[],"source":["\nfrom aadatapipelinecore.core.fs import Conf\nfrom aadatapipelinecore.core.fs.device import S3Bucket, specified_bucket\n\nfrom applications.db_check_v1.common.constants import COUNTRY_CODE_MAPPING_BY_MARKET_CODE as COUNTRY_CODE_MAPPING, \\\n    CATEGORY_ID_MAPPING_BY_MARLKET_AND_DEVICE_CODE as CATEGORY_ID_MAPPING\n\n\nconf = Conf(\n    bucket_name=\"b2c-prod-dca-store-estimates\",\n    bucket_class=S3Bucket\n)\nbucket = specified_bucket(conf)\n\ndate_list = [\"2020-01-10\", \"2019-01-10\", \"2018-01-10\"]\n\nfor store in [\"ios\", \"android\"]:\n    for date in date_list:\n        path = \"store_est/v_final/DAY/{date}/{store}/market_size/\".format(date=date, store=store)\n        print \"*\" * 100\n        print path\n        for filepath in bucket.list(path, depth_is_1=True):\n            # print filepath\n            filename = filepath.replace(path, '').replace(\"/\", '')\n            country_id_list = COUNTRY_CODE_MAPPING[\"apple-store\"].keys() if store==\"ios\" else COUNTRY_CODE_MAPPING[\"google-play\"].keys()\n            country_id_list = [str(country) for country in country_id_list]\n            if filename not in country_id_list:\n                print \"{filename} should not in {path}\".format(filename=filename, path=path)\n                \n    \n \n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200208-023653_1800154508","metadata":{},"outputs":[],"source":["\n\nspark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.market-size.v1/fact/granularity=daily/date=2020-01-10/\").printSchema()\n\nspark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/app-tech.store.market-size.v1/fact/granularity=daily/date=2020-01-10/\").printSchema()"]},{"cell_type":"code","execution_count":0,"id":"20200210-040711_1922762321","metadata":{},"outputs":[],"source":["\n\n       app_price_type_id  category_id country_code  device_code  est_market_size_download  est_market_size_revenue  purchase_type_id\n56749                  2       400070           ZA  android-all                     191.0                      NaN                12"]},{"cell_type":"code","execution_count":0,"id":"20200214-065004_621186325","metadata":{},"outputs":[],"source":["%%sh\n\n%%sh\n\nPGPASSWORD='2mHdFW6%#REu' psql -h internal-aa-prod-plproxy-internal-4-329644124.us-east-1.elb.amazonaws.com -U app_bdp_usage_qa -d dailyest -p 7432 << EOF \nselect device_id, date, store_id, kpi, category_id, app_type_id, purchase_type_id, estimate from plproxy.execute_select_nestloop(\\$proxy\\$ \n    select device_id, date, store_id, kpi, category_id, app_type_id, purchase_type_id, estimate\n    from ms.market_size_daily_estimate_1000 \n    where \n        date = '2020-01-10' and \n        purchase_type_id=12 and \n        app_type_id=2 and \n        store_id=14 and \n        category_id in (65) \n\\$proxy\\$) tbl (device_id SMALLINT, date DATE, store_id INT, kpi SMALLINT, category_id INT, app_type_id SMALLINT, purchase_type_id SMALLINT, estimate BIGINT);\nEOF\n\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}