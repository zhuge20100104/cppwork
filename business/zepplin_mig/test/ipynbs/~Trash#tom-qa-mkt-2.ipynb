{"cells":[{"cell_type":"code","execution_count":0,"id":"20190819-160220_2074858506","metadata":{},"outputs":[],"source":["\n\nfrom itertools import product\nimport datetime\nimport psycopg2\nfrom contextlib import closing\nimport time\n\nGP_COUNTRY_CODE = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 61, 64, 65, 74, 78, 80, 84, 86, 95, 1000]\nIOS_COUNTRY_CODE = [0, 143441, 143442, 143443, 143444, 143445, 143446, 143447, 143448, 143449, 143450, 143451, 143452, 143453, 143454, 143455, 143456, 143457, 143458, 143459, 143460, 143461, 143462, 143463, 143464, 143465, 143466, 143467, 143468, 143469, 143470, 143471, 143472, 143473, 143474, 143475, 143476, 143477, 143478, 143479, 143480, 143481, 143482, 143483, 143484, 143485, 143486, 143487, 143489, 143491, 143492, 143493, 143494, 143495, 143496, 143497, 143498, 143499, 143501, 143502, 143503, 143504, 143505, 143506, 143507, 143508, 143509, 143510, 143511, 143512, 143513, 143514, 143515, 143516, 143517, 143518, 143519, 143520, 143521, 143523, 143524, 143525, 143526, 143528, 143529, 143530, 143531, 143532, 143533, 143534, 143535, 143536, 143537, 143538, 143539, 143540, 143541, 143542, 143543, 143544, 143545, 143546, 143547, 143548, 143549, 143550, 143551, 143552, 143553, 143554, 143555, 143556, 143557, 143558, 143559, 143560, 143561, 143562, 143563, 143564, 143565, 143566, 143568, 143571, 143572, 143573, 143575, 143576, 143577, 143578, 143579, 143580, 143581, 143582, 143583, 143584, 143585, 143586, 143587, 143588, 143589, 143590, 143591, 143592, 143593, 143594, 143595, 143597, 143598, 143599, 143600, 143601, 143602, 143603, 143604, 143605]\nGP_DEVICE_ID = [1001, 1002, 1000]\nIOS_DEVICE_ID = [2001, 2002, 2000]\nGRANULARIY = [\"weekly\", \"monthly\"]\nNETWORK = [1, 203, 324, 101, 136, 201, 202, 171, 109, 110, 111, 112, 200, 114, 116, 142, 311, 121, 316, 325]\nDATE = ['201501', '201502', '201503', '201504', '201505', '201506', '201507', '201508', '201509', '201510', '201511', '201512', '201601', '201602', '201603', '201604', '201605', '201606', '201607', '201608', '201609', '201610', '201611', '201612', '201701', '201702', '201703', '201704', '201705', '201706', '201707', '201708', '201709', '201710', '201711', '201712', '201801', '201802', '201803', '201804', '201805', '201806', '201807', '201808', '201809', '201810', '201811', '201812', '201901', '201902', '201903', '201904']\n\ndbinfo = {'NAME': 'mkt_est', 'USER': 'app_bdp_usage_qa', 'PASSWORD': '2mHdFW6%#REu', 'HOST': '10.2.6.27', 'PORT': 5433}\ndblist = [('10.2.6.27', 5433), ('10.2.6.245', 5434), ('10.2.6.42', 5435), ('10.2.6.148', 5436), ('10.2.6.49', 5437), ('10.2.6.52', 5438), ('10.2.6.187', 5439), ('10.2.6.254', 5440)]\n\ntime = time.strftime('%Y-%m-%d_%H-%M-%S',time.localtime(time.time()))\nlog_filename = '/tmp/db_{time}.log'.format(time=time)\nprint log_filename\n\ndef select(sql):\n    conn = psycopg2.connect(dbname=dbinfo['NAME'], user=dbinfo['USER'], password=dbinfo['PASSWORD'],host=dbinfo['HOST'], port=dbinfo['PORT'])\n    with closing(conn.cursor()) as cur:\n        cur.execute(sql)\n        rows = cur.fetchall()\n        cnt = cur.rowcount\n    return rows, cnt\n\ndef get_key_product_list(granularity=False, device_id=False, store_id=False, network_id=False):\n    granularity_list = GRANULARIY if granularity else [None]\n    device_id_list = GP_DEVICE_ID + IOS_DEVICE_ID if device_id else [None]\n    store_id_list = GP_COUNTRY_CODE + IOS_COUNTRY_CODE if store_id else [None]\n    network_id_list = NETWORK if network_id else [None]\n    product_list = []\n    for g, d, s, n in product(granularity_list, device_id_list, store_id_list, network_id_list):\n        if (d in GP_DEVICE_ID and s in IOS_COUNTRY_CODE) or (d in IOS_DEVICE_ID and s in GP_COUNTRY_CODE):\n            continue\n        product_list.append((g,d,s,n))\n    return product_list\n\ndef write_to_file(filename, str):\n    with open(filename,'a') as file_object:\n        file_object.write(str)\n\n\ndef check_mkt_data(table_name, table_keys, is_facet, **kw):\n    sql_where = \"creative_id <= 90100006099406\" if \"creative_id\" in table_keys else \"date < '2019-05-01'\"\n    for granularity,device_id,store_id, network_id in get_key_product_list(**kw):\n        # SQL RESULT\n        result = 0\n        error_result = 0\n        sql_table = \"{granularity}{table_name}{device_id}{store_id}\".format(\n            table_name=table_name + \"_\",\n            device_id=str(device_id) + \"_\" if device_id else \"\",\n            store_id=str(store_id) if store_id else \"\",\n            granularity=str(granularity) + \"_\" if granularity else \"\")\n        # print sql_table\n        for host, port in dblist:\n            dbinfo['HOST'] = host\n            dbinfo['PORT'] = port\n            try:\n                sql =  \"SELECT COUNT(DISTINCT ({table_keys}) ) FROM mkt.{sql_table} WHERE {sql_where}\".format(\n                    table_keys=table_keys, sql_table=sql_table, sql_where=sql_where)\n                r, _ = select(sql)\n                result += r[0][0]\n            except Exception, e:\n                print e.message\n                error_result=e.message.replace('\\n', '\\\\n')\n                if \"does not exist\" in error_result:\n                    error_result = 0\n        # S3 RESULT\n        s3_result = 0\n        error_s3_result = 0\n        s3_path = \"s3://b2c-prod-data-pipeline-unified-market/unified/app-tech.market.legacy-{table_name}.v1/{fact}/{granularity}{device_id}{store_id}\".format(\n            table_name=table_name, fact='fact' if is_facet else 'dimension',\n            granularity = \"granularity={}/\".format(granularity) if granularity else \"\",\n            device_id = \"device_id={}/\".format(device_id) if device_id else \"\",\n            store_id = \"store_id={}/\".format(store_id)) if store_id else \"\"\n        # print s3_path\n        try:\n            s3_result = spark.read.parquet(s3_path).count()\n        except Exception, e:\n            error_s3_result = 0\n\n        result_str = \"{},{},{}\\n\".format(sql_table, result or error_result,s3_result or error_s3_result)\n        write_to_file(log_filename, result_str)\n        # print result_str\n        # return\n\n# check_mkt_data(\"meta_creative\", \"device_id, store_id, network_id, creative_id, ad_app_id, first_seen, last_seen\", is_facet=False, device_id=True, store_id=True )\n# TBD check_mkt_data(\"meta_creative_pub\", \"device_id , store_id , date , network_id , creative_id , ad_app_id , pub_app_id\", is_facet=False, device_id=True, store_id=True )\n# TBD check_mkt_data(\"meta_creative_campaign\", \"device_id , store_id , date , network_id , creative_id , ad_app_id , campaign_id\", is_facet=False, device_id=True, store_id=True )\n\n# TBD check_mkt_data(\"creative_estimate\", \"device_id , store_id , date , network_id , ad_app_id , creative_id , kpi, estimate\", is_facet=True, granularity=True, device_id=True, store_id=True )\n# TBD check_mkt_data(\"creative_detail_estimate\", \"device_id , store_id , date , network_id , ad_app_id , creative_id , kpi, id_list\", is_facet=True, granularity=True, device_id=True, store_id=True )\n# TBD check_mkt_data(\"creative_ad_estimate\", \"device_id , store_id , date , network_id , ad_app_id , creative_id , estimate\", is_facet=True, granularity=True, device_id=True, store_id=True )\n\ncheck_mkt_data(\"ad_app_estimate\", \"device_id , store_id , network_id , date , ad_app_id , estimate , kpi\",  is_facet=True, granularity=True,device_id=True, store_id=True )\ncheck_mkt_data(\"ad_app_detail_estimate\", \"device_id , store_id , network_id , date , ad_app_id , id_list , kpi\",  is_facet=True, granularity=True,device_id=True, store_id=True )\ncheck_mkt_data(\"ad_app_pub_app_estimate\", \"device_id , store_id , date , network_id , ad_app_id , pub_app_id , estimate, kpi\",  is_facet=True, granularity=True,device_id=True, store_id=True )\n# TBD check_mkt_data(\"pub_app_ad_app_estimate\", \"device_id , store_id , date , network_id , ad_app_id , pub_app_id , estimate, kpi\",  is_facet=True, granularity=True,device_id=True, store_id=True )\n# NOT READY check_mkt_data(\"pub_app_ad_app_detail_estimate\", \"device_id , store_id , date , network_id , ad_app_id , pub_app_id , id_list, kpi\",  is_facet=True, granularity=True,device_id=True, store_id=True )\ncheck_mkt_data(\"ad_app_pub_estimate\", \"device_id , store_id , date , network_id , ad_app_id , pub_id , estimate, kpi\",  is_facet=True, granularity=True,device_id=True, store_id=True )\ncheck_mkt_data(\"pub_app_estimate\", \"device_id , store_id , date , network_id , pub_app_id , estimate, kpi\",  is_facet=True, granularity=True,device_id=True, store_id=True )\ncheck_mkt_data(\"pub_app_detail_estimate\", \"device_id , store_id , date , network_id , pub_app_id , id_list ,kpi\",  is_facet=True, granularity=True,device_id=True, store_id=True )\n\n#  ???? no date or creative id check_mkt_data(\"pub_app_ad_app_date_range_estimate\", \"device_id , store_id , network_id , pub_app_id , ad_app_id , first_seen , last_seen\", is_facet=False, device_id=True, store_id=True )\n\ncheck_mkt_data(\"creative_category\", \"device_id , store_id , category_id , creative_id , ad_app_id , date , rank , network_id\",  is_facet=True, granularity=True,device_id=True, store_id=True )\ncheck_mkt_data(\"ad_app_category\", \"device_id , store_id , category_id , ad_app_id , date , rank , network_id\",  is_facet=True, granularity=True,device_id=True, store_id=True )\ncheck_mkt_data(\"pub_app_category\", \"device_id , store_id , category_id , pub_app_id , date , rank , network_id\",  is_facet=True, granularity=True,device_id=True, store_id=True )\ncheck_mkt_data(\"adpo_estimate\", \"device_id , store_id , network_id , category_id , date , kpi , estimate\",  is_facet=True, granularity=True,device_id=True, store_id=True )\ncheck_mkt_data(\"adpo_detail_estimate\", \"device_id , store_id , network_id , category_id , date , kpi , estimate\",  is_facet=True, granularity=True,device_id=True, store_id=True )\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20190820-050947_964942055","metadata":{},"outputs":[],"source":["\n\nfrom itertools import product\nimport datetime\nimport threading\n\nimport psycopg2\nfrom contextlib import closing\nimport time\n\nGP_COUNTRY_CODE = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 61, 64, 65, 74, 78, 80, 84, 86, 95, 1000]\nIOS_COUNTRY_CODE = [0, 143441, 143442, 143443, 143444, 143445, 143446, 143447, 143448, 143449, 143450, 143451, 143452, 143453, 143454, 143455, 143456, 143457, 143458, 143459, 143460, 143461, 143462, 143463, 143464, 143465, 143466, 143467, 143468, 143469, 143470, 143471, 143472, 143473, 143474, 143475, 143476, 143477, 143478, 143479, 143480, 143481, 143482, 143483, 143484, 143485, 143486, 143487, 143489, 143491, 143492, 143493, 143494, 143495, 143496, 143497, 143498, 143499, 143501, 143502, 143503, 143504, 143505, 143506, 143507, 143508, 143509, 143510, 143511, 143512, 143513, 143514, 143515, 143516, 143517, 143518, 143519, 143520, 143521, 143523, 143524, 143525, 143526, 143528, 143529, 143530, 143531, 143532, 143533, 143534, 143535, 143536, 143537, 143538, 143539, 143540, 143541, 143542, 143543, 143544, 143545, 143546, 143547, 143548, 143549, 143550, 143551, 143552, 143553, 143554, 143555, 143556, 143557, 143558, 143559, 143560, 143561, 143562, 143563, 143564, 143565, 143566, 143568, 143571, 143572, 143573, 143575, 143576, 143577, 143578, 143579, 143580, 143581, 143582, 143583, 143584, 143585, 143586, 143587, 143588, 143589, 143590, 143591, 143592, 143593, 143594, 143595, 143597, 143598, 143599, 143600, 143601, 143602, 143603, 143604, 143605]\nGP_DEVICE_ID = [1001, 1002, ] # todo 1000\nIOS_DEVICE_ID = [2001, 2002, ] # todo 2000\nGRANULARIY = [\"weekly\", \"monthly\"]\nNETWORK = [1, 203, 324, 101, 136, 201, 202, 171, 109, 110, 111, 112, 200, 114, 116, 142, 311, 121, 316, 325]\nMONTH = ['201501', '201502', '201503', '201504', '201505', '201506', '201507', '201508', '201509', '201510', '201511', '201512', '201601', '201602', '201603', '201604', '201605', '201606', '201607', '201608', '201609', '201610', '201611', '201612', '201701', '201702', '201703', '201704', '201705', '201706', '201707', '201708', '201709', '201710', '201711', '201712', '201801', '201802', '201803', '201804', '201805', '201806', '201807', '201808', '201809', '201810', '201811', '201812', '201901', '201902', '201903', '201904']\n\ndbinfo = {'NAME': 'mkt_est', 'USER': 'app_bdp_usage_qa', 'PASSWORD': '2mHdFW6%#REu', 'HOST': '10.2.6.27', 'PORT': 5433}\ndblist = [('10.2.6.27', 5433), ('10.2.6.245', 5434), ('10.2.6.42', 5435), ('10.2.6.148', 5436), ('10.2.6.49', 5437), ('10.2.6.52', 5438), ('10.2.6.187', 5439), ('10.2.6.254', 5440)]\n\ndef select(sql):\n    conn = psycopg2.connect(dbname=dbinfo['NAME'], user=dbinfo['USER'], password=dbinfo['PASSWORD'],host=dbinfo['HOST'], port=dbinfo['PORT'])\n    with closing(conn.cursor()) as cur:\n        cur.execute(sql)\n        rows = cur.fetchall()\n        cnt = cur.rowcount\n    return rows, cnt\n\ndef get_key_product_list(granularity=False, device_id=False, store_id=False, network_id=False, month=False):\n    granularity_list = GRANULARIY if granularity else [None]\n    device_id_list = GP_DEVICE_ID + IOS_DEVICE_ID if device_id else [None]\n    store_id_list = GP_COUNTRY_CODE + IOS_COUNTRY_CODE if store_id else [None]\n    network_id_list = NETWORK if network_id else [None]\n    month_list = MONTH if month else [None]\n    product_list = []\n    for g, d, s, n, m in product(granularity_list, device_id_list, store_id_list, network_id_list, month_list):\n        if (d in GP_DEVICE_ID and s in IOS_COUNTRY_CODE) or (d in IOS_DEVICE_ID and s in GP_COUNTRY_CODE):\n            continue\n        product_list.append((g,d,s,n, m))\n    return product_list\n\ndef write_to_file(filename, str):\n    with open(filename,'a') as file_object:\n        file_object.write(str)\n\ndef check_mkt_data(table_name, table_keys, is_facet):\n    timestamp = time.strftime('%Y-%m-%d_%H-%M-%S', time.localtime(time.time()))\n    log_filename = '/tmp/db_{}_{}.log'.format(timestamp, threading.currentThread().name)\n    print log_filename\n    while (len(key_product_list) > 0):\n        time_start = time.time()\n        granularity, device_id, store_id, network_id, month = key_product_list.pop()\n        sql_where = \"creative_id <= 90100006099406\" if \"creative_id\" in table_keys else \"date < '2019-05-01'\"\n        # SQL RESULT\n        result = 0\n        error_result = 0\n        sql_table = \"{granularity}{table_name}{device_id}{store_id}{network_id}{month}\".format(\n            table_name=table_name + \"_\",\n            device_id=str(device_id) + \"_\" if device_id else \"\",\n            store_id=str(store_id) + \"_\" if store_id else \"\",\n            granularity=str(granularity) + \"_\" if granularity else \"\",\n            month = str(month) + \"_\" if month else \"\",\n            network_id = str(network_id) + \"_\" if  network_id else \"\").rstrip('_')\n        # print sql_table\n        for host, port in dblist:\n            dbinfo['HOST'] = host\n            dbinfo['PORT'] = port\n            try:\n                sql =  \"SELECT COUNT(DISTINCT ({table_keys}) ) FROM mkt.{sql_table} WHERE {sql_where}\".format(\n                    table_keys=table_keys, sql_table=sql_table, sql_where=sql_where)\n                r, _ = select(sql)\n                result += r[0][0]\n            except Exception, e:\n                # print e.message\n                error_result=e.message.replace('\\n', '\\\\n')\n                if \"does not exist\" in error_result:\n                    error_result = 0\n        # S3 RESULT\n        s3_result = 0\n        error_s3_result = 0\n        s3_path = \"s3://b2c-prod-data-pipeline-unified-market/unified/app-tech.market.legacy-{table_name}.v1/{fact}/{month}{granularity}{device_id}{store_id}{network_id}\".format(\n            table_name=table_name, fact='fact' if is_facet else 'dimension',\n            month = \"month={}/\".format(str('-'.join([month[:4], month[-2:]]))) if month else \"\",\n            granularity = \"granularity={}/\".format(granularity) if granularity else \"\",\n            device_id = \"device_id={}/\".format(device_id) if device_id else \"\",\n            store_id = \"store_id={}/\".format(store_id) if store_id else \"\",\n            network_id = \"network_id={}/\".format(network_id) if network_id else \"\")\n        try:\n            s3_result = spark.read.parquet(s3_path).count()\n            # print s3_path\n        except Exception, e:\n            error_s3_result = 0\n\n        time_end = time.time()\n        result_str = \"{},{},{},{}\\n\".format(sql_table, result or error_result,s3_result or error_s3_result, int(time_end-time_start))\n        write_to_file(log_filename, result_str)\n\n\nprint len(get_key_product_list(device_id=True, store_id=True, network_id=True, month=True))\n\nthread_count = 10\n# key_product_list = [(None, \"2002\",\"143441\",\"1\",\"201712\")] # DEBUG granularity, device_id, store_id, network_id, month\nkey_product_list = get_key_product_list(device_id=True, network_id=True, store_id=True, month=True)\n\nthread_group = []\nfor index in range(0,thread_count):\n    t = threading.Thread(\n        name=\"thread-{}\".format(index),\n        target=check_mkt_data,\n        args=(\n        \"meta_creative_pub\", \"device_id , store_id , date , network_id , creative_id , ad_app_id , pub_app_id\", True))\n    thread_group.append(t)\n    t.start()\n\nfor t in thread_group:\n    t.join()\n\n\n# # check_mkt_data(\"meta_creative\", \"device_id, store_id, network_id, creative_id, ad_app_id, first_seen, last_seen\", is_facet=False, device_id=True, store_id=True )\n# # TBD check_mkt_data(\"meta_creative_pub\", \"device_id , store_id , date , network_id , creative_id , ad_app_id , pub_app_id\", is_facet=False, device_id=True, store_id=True )\n# # TBD check_mkt_data(\"meta_creative_campaign\", \"device_id , store_id , date , network_id , creative_id , ad_app_id , campaign_id\", is_facet=False, device_id=True, store_id=True )\n#\n# # TBD check_mkt_data(\"creative_estimate\", \"device_id , store_id , date , network_id , ad_app_id , creative_id , kpi, estimate\", is_facet=True, granularity=True, device_id=True, store_id=True )\n# # TBD check_mkt_data(\"creative_detail_estimate\", \"device_id , store_id , date , network_id , ad_app_id , creative_id , kpi, id_list\", is_facet=True, granularity=True, device_id=True, store_id=True )\n# # TBD check_mkt_data(\"creative_ad_estimate\", \"device_id , store_id , date , network_id , ad_app_id , creative_id , estimate\", is_facet=True, granularity=True, device_id=True, store_id=True )\n#\n# check_mkt_data(\"ad_app_estimate\", \"device_id , store_id , network_id , date , ad_app_id , estimate , kpi\",  is_facet=True, granularity=True,device_id=True, store_id=True )\n# check_mkt_data(\"ad_app_detail_estimate\", \"device_id , store_id , network_id , date , ad_app_id , id_list , kpi\",  is_facet=True, granularity=True,device_id=True, store_id=True )\n# check_mkt_data(\"ad_app_pub_app_estimate\", \"device_id , store_id , date , network_id , ad_app_id , pub_app_id , estimate, kpi\",  is_facet=True, granularity=True,device_id=True, store_id=True )\n# # TBD check_mkt_data(\"pub_app_ad_app_estimate\", \"device_id , store_id , date , network_id , ad_app_id , pub_app_id , estimate, kpi\",  is_facet=True, granularity=True,device_id=True, store_id=True )\n# # NOT READY check_mkt_data(\"pub_app_ad_app_detail_estimate\", \"device_id , store_id , date , network_id , ad_app_id , pub_app_id , id_list, kpi\",  is_facet=True, granularity=True,device_id=True, store_id=True )\n# check_mkt_data(\"ad_app_pub_estimate\", \"device_id , store_id , date , network_id , ad_app_id , pub_id , estimate, kpi\",  is_facet=True, granularity=True,device_id=True, store_id=True )\n# check_mkt_data(\"pub_app_estimate\", \"device_id , store_id , date , network_id , pub_app_id , estimate, kpi\",  is_facet=True, granularity=True,device_id=True, store_id=True )\n# check_mkt_data(\"pub_app_detail_estimate\", \"device_id , store_id , date , network_id , pub_app_id , id_list ,kpi\",  is_facet=True, granularity=True,device_id=True, store_id=True )\n#\n# #  ???? no date or creative id check_mkt_data(\"pub_app_ad_app_date_range_estimate\", \"device_id , store_id , network_id , pub_app_id , ad_app_id , first_seen , last_seen\", is_facet=False, device_id=True, store_id=True )\n#\n# check_mkt_data(\"creative_category\", \"device_id , store_id , category_id , creative_id , ad_app_id , date , rank , network_id\",  is_facet=True, granularity=True,device_id=True, store_id=True )\n# check_mkt_data(\"ad_app_category\", \"device_id , store_id , category_id , ad_app_id , date , rank , network_id\",  is_facet=True, granularity=True,device_id=True, store_id=True )\n# check_mkt_data(\"pub_app_category\", \"device_id , store_id , category_id , pub_app_id , date , rank , network_id\",  is_facet=True, granularity=True,device_id=True, store_id=True )\n# check_mkt_data(\"adpo_estimate\", \"device_id , store_id , network_id , category_id , date , kpi , estimate\",  is_facet=True, granularity=True,device_id=True, store_id=True )\n# check_mkt_data(\"adpo_detail_estimate\", \"device_id , store_id , network_id , category_id , date , kpi , estimate\",  is_facet=True, granularity=True,device_id=True, store_id=True )\n#\n#\n"]},{"cell_type":"code","execution_count":0,"id":"20190819-160255_1604498648","metadata":{},"outputs":[],"source":["%%sh\n\n# 459680\n# export FILE=\"/tmp/db_2019-08-20_05-53-35*\"\n# cat $FILE | grep -v '0,0,'\n#echo $(((wc -l $FILE)/459680))\n# wc -l $FILE\n# cat $FILE | grep '2002_143441_1_201712'\n\n# -rw-r--r--  1 hadoop   hadoop   125910 Aug 19 23:16 db_2019-08-19_17-54-37.log\n# -rw-r--r--  1 hadoop   hadoop   126089 Aug 19 23:20 db_2019-08-19_17-54-37.log\n# -rw-r--r--  1 hadoop   hadoop   153486 Aug 20 01:52 db_2019-08-19_17-54-37.log\n# ls $FILE\n\n# cat  /tmp/db_2019-08-20_05-53-35_thread-0.log | grep -v '0,0,'\n#  cat /tmp/db_2019-08-20_05-53-35_thread-1.log | grep -v '0,0,'\n# cat /tmp/db_2019-08-20_05-53-35_thread-2.log | grep -v '0,0,'\n# cat /tmp/db_2019-08-20_05-53-35_thread-3.log | grep -v '0,0,'\n# cat /tmp/db_2019-08-20_05-53-35_thread-4.log | grep -v '0,0,'\n# cat /tmp/db_2019-08-20_05-53-35_thread-5.log | grep -v '0,0,'\ncat /tmp/db_2019-08-20_05-53-35_thread-6.log | grep -v '0,0,'\ncat /tmp/db_2019-08-20_05-53-35_thread-7.log | grep -v '0,0,'\ncat /tmp/db_2019-08-20_05-53-35_thread-8.log | grep -v '0,0,'\ncat /tmp/db_2019-08-20_05-53-35_thread-9.log | grep -v '0,0,'\n\n"]},{"cell_type":"code","execution_count":0,"id":"20190820-051427_1619245652","metadata":{},"outputs":[],"source":["%%sh\nls -al /tmp/\n\n\nfor VARIABLE in 0 1 2 3 4 5 6 7 8 9\ndo\n\texport LOGFILE=\"/tmp/db_2019-08-20_05-41-11_thread-\"$VARIABLE\".log\"\n    rm $LOGFILE  & mkdir -p $LOGFILE\ndone\n"]},{"cell_type":"code","execution_count":0,"id":"20190820-051540_433807240","metadata":{},"outputs":[],"source":["\n\nfrom itertools import product\nimport threading\n\nimport psycopg2\nfrom contextlib import closing\nimport time\n\nGP_COUNTRY_CODE = [1000, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 61, 64, 65, 74, 78, 80, 84, 86, 95]\nIOS_COUNTRY_CODE = [0, 143441, 143442, 143443, 143444, 143445, 143446, 143447, 143448, 143449, 143450, 143451, 143452, 143453, 143454, 143455, 143456, 143457, 143458, 143459, 143460, 143461, 143462, 143463, 143464, 143465, 143466, 143467, 143468, 143469, 143470, 143471, 143472, 143473, 143474, 143475, 143476, 143477, 143478, 143479, 143480, 143481, 143482, 143483, 143484, 143485, 143486, 143487, 143489, 143491, 143492, 143493, 143494, 143495, 143496, 143497, 143498, 143499, 143501, 143502, 143503, 143504, 143505, 143506, 143507, 143508, 143509, 143510, 143511, 143512, 143513, 143514, 143515, 143516, 143517, 143518, 143519, 143520, 143521, 143523, 143524, 143525, 143526, 143528, 143529, 143530, 143531, 143532, 143533, 143534, 143535, 143536, 143537, 143538, 143539, 143540, 143541, 143542, 143543, 143544, 143545, 143546, 143547, 143548, 143549, 143550, 143551, 143552, 143553, 143554, 143555, 143556, 143557, 143558, 143559, 143560, 143561, 143562, 143563, 143564, 143565, 143566, 143568, 143571, 143572, 143573, 143575, 143576, 143577, 143578, 143579, 143580, 143581, 143582, 143583, 143584, 143585, 143586, 143587, 143588, 143589, 143590, 143591, 143592, 143593, 143594, 143595, 143597, 143598, 143599, 143600, 143601, 143602, 143603, 143604, 143605]\nGP_DEVICE_ID = [1001, 1002, 1000]\nIOS_DEVICE_ID = [2001, 2002, 2000]\nGRANULARIY = [\"monthly\", \"weekly\"]\nNETWORK = [1, 203, 324, 101, 136, 201, 202, 171, 109, 110, 111, 112, 200, 114, 116, 142, 311, 121, 316, 325]\nMONTH = ['201904', '201501', '201502', '201503', '201504', '201505', '201506', '201507', '201508', '201509', '201510', '201511', '201512', '201601', '201602', '201603', '201604', '201605', '201606', '201607', '201608', '201609', '201610', '201611', '201612', '201701', '201702', '201703', '201704', '201705', '201706', '201707', '201708', '201709', '201710', '201711', '201712', '201801', '201802', '201803', '201804', '201805', '201806', '201807', '201808', '201809', '201810', '201811', '201812', '201901', '201902', '201903']\n\ndbinfo = {'NAME': 'mkt_est', 'USER': 'app_bdp_usage_qa', 'PASSWORD': '2mHdFW6%#REu', 'HOST': '10.2.6.27', 'PORT': 5433}\ndblist = [('10.2.6.27', 5433), ('10.2.6.245', 5434), ('10.2.6.42', 5435), ('10.2.6.148', 5436), ('10.2.6.49', 5437), ('10.2.6.52', 5438), ('10.2.6.187', 5439), ('10.2.6.254', 5440)]\n\ndef select(sql):\n    conn = psycopg2.connect(dbname=dbinfo['NAME'], user=dbinfo['USER'], password=dbinfo['PASSWORD'],host=dbinfo['HOST'], port=dbinfo['PORT'])\n    with closing(conn.cursor()) as cur:\n        cur.execute(sql)\n        rows = cur.fetchall()\n        cnt = cur.rowcount\n    return rows, cnt\n\ndef get_key_product_list(granularity=False, device_id=False, store_id=False, network_id=False, month=False):\n    granularity_list = GRANULARIY if granularity else [None]\n    device_id_list = GP_DEVICE_ID + IOS_DEVICE_ID if device_id else [None]\n    store_id_list = GP_COUNTRY_CODE + IOS_COUNTRY_CODE if store_id else [None]\n    network_id_list = NETWORK if network_id else [None]\n    month_list = MONTH if month else [None]\n    product_list = []\n    for g, d, s, n, m in product(granularity_list, device_id_list, store_id_list, network_id_list, month_list):\n        if (d in GP_DEVICE_ID and s in IOS_COUNTRY_CODE) or (d in IOS_DEVICE_ID and s in GP_COUNTRY_CODE):\n            continue\n        product_list.append((g,d,s,n, m))\n    return product_list\n\ndef write_to_file(filename, str):\n    with open(filename,'a') as file_object:\n        file_object.write(str)\n\ndef get_where(table_keys):\n    where_condition = []\n    if \"creative_id\" in table_keys:\n        where_condition.append(\"creative_id <= 90100006099406\")\n    if \"kpi\" in table_keys:\n        where_condition.append( \"kpi IS NOT NULL\")\n    if \"update_date\" in table_keys:\n        where_condition.append(\"update_date < '2019-05-01'\")\n    elif \"date\" in table_keys:\n        where_condition.append(\"date < '2019-05-01'\")\n    if len(where_condition)==0:\n        return \"TRUE\"\n    else:\n        return \" AND \".join(where_condition)\n\n\n\ndef _check_mkt_data_thread(table_name, table_keys, is_facet):\n    timestamp = time.strftime('%Y-%m-%d_%H-%M-%S', time.localtime(time.time()))\n    log_filename = '/tmp/db_test/{}_{}_{}.log'.format(table_name, timestamp, threading.currentThread().name)\n    print log_filename\n    while (len(key_product_list) > 0):\n        time_start = time.time()\n        keys_tuple = key_product_list.pop()\n        granularity, device_id, store_id, network_id, month = keys_tuple\n        sql_where=get_where(table_keys)\n        # SQL RESULT\n        result = 0\n        error_result = 0\n        sql_table = \"{granularity}{table_name}{device_id}{store_id}{network_id}{month}\".format(\n            table_name=table_name + \"_\",\n            device_id=str(device_id) + \"_\" if device_id else \"\",\n            store_id=str(store_id) + \"_\" if store_id else \"\",\n            granularity=str(granularity) + \"_\" if granularity else \"\",\n            month = str(month) + \"_\" if month else \"\",\n            network_id = str(network_id) + \"_\" if  network_id else \"\").rstrip('_')\n        # print sql_table\n        for host, port in dblist:\n            dbinfo['HOST'] = host\n            dbinfo['PORT'] = port\n            try:\n                sql =  \"SELECT COUNT(DISTINCT ({table_keys}) ) FROM mkt.{sql_table} WHERE {sql_where}\".format(\n                    table_keys=table_keys, sql_table=sql_table, sql_where=sql_where)\n                r, _ = select(sql)\n                result += r[0][0]\n            except Exception, e:\n                # print e.message\n                error_result=e.message.replace('\\n', '\\\\n')\n                if \"does not exist\" in error_result:\n                    error_result = 0\n                    continue\n                key_product_list.append(keys_tuple)\n        # S3 RESULT\n        s3_result = 0\n        error_s3_result = 0\n        s3_path = \"s3://b2c-prod-data-pipeline-unified-market/unified/app-tech.market.legacy-{table_name}.v1/{fact}/{month}{granularity}{device_id}{store_id}{network_id}\".format(\n            table_name=table_name, fact='fact' if is_facet else 'dimension',\n            month = \"month={}/\".format(str('-'.join([month[:4], month[-2:]]))) if month else \"\",\n            granularity = \"granularity={}/\".format(granularity) if granularity else \"\",\n            device_id = \"device_id={}/\".format(device_id) if device_id else \"\",\n            store_id = \"store_id={}/\".format(store_id) if store_id else \"\",\n            network_id = \"network_id={}/\".format(network_id) if network_id else \"\")\n        try:\n            s3_result = spark.read.parquet(s3_path).count()\n            # print s3_path\n        except Exception, e:\n            error_s3_result = 0\n\n        time_end = time.time()\n        result_str = \"{},{},{},{},{}\\n\".format(table_name, sql_table, result or error_result,s3_result or error_s3_result, int(time_end-time_start))\n        write_to_file(log_filename, result_str)\n\n\n# print len(get_key_product_list(device_id=True, store_id=True, network_id=True, month=True))\n\nthread_count = 10\n# key_product_list = [(None, \"2002\",\"143441\",\"1\",\"201712\")] # DEBUG granularity, device_id, store_id, network_id, month\nkey_product_list = []\n\n\ndef check_mkt_data(table_name, table_keys, is_facet, **kw):\n    thread_group = []\n    global key_product_list\n    key_product_list = get_key_product_list(**kw)\n    print len(key_product_list)\n    for index in range(0,thread_count):\n        t = threading.Thread(\n            name=\"thread-{}\".format(index),\n            target=_check_mkt_data_thread,\n            args=(table_name, table_keys, is_facet))\n        thread_group.append(t)\n        t.start()\n\n    for t in thread_group:\n        t.join()\n\n\n\n\n#\ncheck_mkt_data(\"adpo_estimate\", \"device_id , store_id , network_id , category_id , date , kpi , estimate\",  is_facet=True, granularity=True,device_id=True, )\ncheck_mkt_data(\"adpo_detail_estimate\", \"device_id , store_id , network_id , category_id , date , kpi , estimate\",  is_facet=True, granularity=True,device_id=True)\n\n"]},{"cell_type":"code","execution_count":0,"id":"20190820-145106_913706551","metadata":{},"outputs":[],"source":["%%sh\ndate\nls -al /tmp/db_test/*\n# wl -c /tmp/db_test/*\ncat /tmp/db_test/* | grep -v '0,0,'\n# mkdir -p /tmp/db_test/\n# rm -rf /tmp/db_test/*\n\n# for VARIABLE in 0 1 2 3 4 5 6 7 8 9\n# do\n# \texport LOGFILE=\"/tmp/db_new_ad_app_estimate_2019-08-20_15-14-55_thread-\"$VARIABLE\".log\"\n#     rm $LOGFILE  & mkdir -p $LOGFILE\n# done\n"]},{"cell_type":"code","execution_count":0,"id":"20190820-151349_1689297292","metadata":{},"outputs":[],"source":["%%sh\n\n\ncat /tmp/db_test/adpo_detail_estimate_2019-08-21_06-18-18_thread-0.log\n"]},{"cell_type":"code","execution_count":0,"id":"20190821-113330_756346451","metadata":{},"outputs":[],"source":["%%sh\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}