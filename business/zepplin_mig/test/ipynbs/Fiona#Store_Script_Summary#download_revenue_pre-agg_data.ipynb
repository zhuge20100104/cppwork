{"cells":[{"cell_type":"code","execution_count":0,"id":"20200626-062744_1642085984","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql.functions import sum\nfrom pyspark.sql.functions import desc\nfrom aadatapipelinecore.core.urn import Urn\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\n\nimport psycopg2\nfrom pyspark.sql import Row\nfrom dateutil.relativedelta import relativedelta\nfrom aaplproxy.connection import ClusterConnection\nfrom conf import settings\nfrom aadatapipelinecore.core.loader.plproxy import build_db_settings\nimport datetime as d\nimport datetime\nfrom datetime import timedelta\n\n\ntest_result = []\nPG_AA_HOSTS = [('10.2.6.141', 5432)]\nPG_AA_NAME = 'aa_store_db'\nPG_AA_ACCESS_ID = 'citus_bdp_prod_app_int_qa'\nPG_AA_SECRET_KEY = 'wZw8cfBuuklIskVG'\n\naa_dsn = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_AA_NAME,\n        user=PG_AA_ACCESS_ID,\n        host=PG_AA_HOSTS[0][0],\n        password=PG_AA_SECRET_KEY,\n        port=PG_AA_HOSTS[0][1]\n    )\n)\n\nurn = Urn(\n    namespace=\"app-qa.db-check.v1\",\n    owner=\"app_qa\"\n)\ndaily_sql = \"\"\"select count(1), \n            sum(est_free_app_download), \n            sum(est_paid_app_download), \n            sum(est_revenue)\n            from \n    (select app_id, device_code, country_code, category_id, \n            sum(est_free_app_download) as est_free_app_download, \n            sum(est_paid_app_download) as est_paid_app_download,\n            sum(est_revenue) as est_revenue\n            from store.store_est_category_fact_v1\n            where date between '{}' and '{}'\n            group by\n            app_id,\n            device_code,\n            country_code,\n            category_id) as t;\n\"\"\"\n\nsql = \"\"\"select count(1), \n        sum(est_free_app_download), \n        sum(est_paid_app_download), \n        sum(est_revenue)\n        from store.store_est_category_t_{}_fact_v1 \n        where date between '{}' and '{}' and granularity='{}';\"\"\"\n\n\ndef query(dsn, sql):\n    with psycopg2.connect(dsn) as conn:\n        conn.autocommit = True\n        with conn.cursor() as cur:\n            cur.execute(sql)\n            result = cur.fetchall()\n            conn.commit()\n    return result\n\n\ndict_test = {'weekly': ['2010-07-10', '2020-06-20'],\n             'monthly': ['2010-07-31', '2020-04-30'],\n             'quarterly' : ['2010-09-30', '2020-03-31'],\n             'yearly' : ['2010-12-31', '2019-12-31']\n}\n\n\ndef last_day_of_month(check_month):\n    next_month = check_month.replace(day=28) + datetime.timedelta(days=4)\n    return next_month - datetime.timedelta(days=next_month.day)\n\n\ndef get_date_range(date_list, granularity):\n    result = []\n    start = datetime.datetime.strptime(date_list[0], '%Y-%m-%d')\n    end = datetime.datetime.strptime(date_list[1], '%Y-%m-%d')\n    if granularity == 'weekly':\n        while start <= end:\n            date_row = datetime.datetime.strftime(start, '%Y-%m-%d')\n            result.append(date_row)\n            start += relativedelta(weeks=1)\n    elif granularity == 'monthly':\n        while start <= end:\n            start = last_day_of_month(start)\n            date_row = datetime.datetime.strftime(start, '%Y-%m-%d')\n            result.append(date_row)\n            start += relativedelta(months=1)\n    elif granularity == 'quarterly':\n        while start <= end:\n            start = last_day_of_month(start)\n            date_row = datetime.datetime.strftime(start, '%Y-%m-%d')\n            result.append(date_row)\n            start += relativedelta(months=3)\n    elif granularity == 'yearly':\n        while start <= end:\n            date_row = datetime.datetime.strftime(start, '%Y-%m-%d')\n            result.append(date_row)\n            start += relativedelta(months=12)\n    # print result\n    return result\n\n\ndef check_store_unified_db_completeness(date_list, graularity):\n    for date in date_list:\n        end = date\n        if graularity == 'weekly':\n            start = datetime.datetime.strptime(date, '%Y-%m-%d') - relativedelta(weeks=1) + relativedelta(days=1)\n            start = datetime.datetime.strftime(start, '%Y-%m-%d')\n        elif graularity == 'monthly':\n            start = date[:7] + str('-01')\n        elif graularity == 'quarterly':\n            start = datetime.datetime.strptime(date, '%Y-%m-%d') - relativedelta(months=2)\n            start = datetime.datetime.strftime(start, '%Y-%m') + str('-01')\n        elif graularity == 'yearly':\n            start = date[:4] + str('-01-01')\n        print start, end\n        unified_result = query(aa_dsn, daily_sql.format(start, end))\n        db_result = query(aa_dsn, sql.format(graularity[0], date, date, graularity))\n        # print date\n        # print unified_result[0][0]\n        # print db_result\n        if unified_result[0][0] == db_result[0][0] and unified_result[0][1] == db_result[0][1] and unified_result[0][2] == db_result[0][2] and unified_result[0][3] == db_result[0][3]:\n            print \"Completeness Test PASS! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n        else:\n            test_result.append(date)\n            print \"Completeness Test FAIL!!!!! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n\n\n\n\nkey = 'weekly'\nvalue = ['2020-08-08', '2020-08-15', '2020-08-22', '2020-08-29']\nfor d in value:\n    print d\n    check_store_unified_db_completeness(get_date_range([d,d], key), key)\nprint test_result"]},{"cell_type":"code","execution_count":0,"id":"20200626-070719_1015342940","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql.functions import sum\nfrom pyspark.sql.functions import desc\nfrom aadatapipelinecore.core.urn import Urn\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\n\nimport psycopg2\nfrom pyspark.sql import Row\nfrom dateutil.relativedelta import relativedelta\nfrom aaplproxy.connection import ClusterConnection\nfrom conf import settings\nfrom aadatapipelinecore.core.loader.plproxy import build_db_settings\nimport datetime as d\nimport datetime\nfrom datetime import timedelta\n\n\ntest_result = []\nPG_AA_HOSTS = [('10.2.6.141', 5432)]\nPG_AA_NAME = 'aa_store_db'\nPG_AA_ACCESS_ID = 'citus_bdp_prod_app_int_qa'\nPG_AA_SECRET_KEY = 'wZw8cfBuuklIskVG'\n\naa_dsn = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_AA_NAME,\n        user=PG_AA_ACCESS_ID,\n        host=PG_AA_HOSTS[0][0],\n        password=PG_AA_SECRET_KEY,\n        port=PG_AA_HOSTS[0][1]\n    )\n)\n\nurn = Urn(\n    namespace=\"app-qa.db-check.v1\",\n    owner=\"app_qa\"\n)\ndaily_category_sql = \"\"\"select count(1), \n            sum(est_free_app_download), \n            sum(est_paid_app_download), \n            sum(est_revenue)\n            from \n    (select app_id, device_code, country_code, category_id, \n            sum(est_free_app_download) as est_free_app_download, \n            sum(est_paid_app_download) as est_paid_app_download,\n            sum(est_revenue) as est_revenue\n            from store.store_est_category_fact_v1\n            where date between '{}' and '{}'\n            group by\n            app_id,\n            device_code,\n            country_code,\n            category_id) as t;\n\"\"\"\n\nsql = \"\"\"select count(1), \n        sum(est_free_app_download), \n        sum(est_paid_app_download), \n        sum(est_revenue)\n        from store.store_est_category_t_{}_fact_v1 \n        where date between '{}' and '{}' and granularity='{}';\"\"\"\n\n\ndef query(dsn, sql):\n    with psycopg2.connect(dsn) as conn:\n        conn.autocommit = True\n        with conn.cursor() as cur:\n            cur.execute(sql)\n            result = cur.fetchall()\n            conn.commit()\n    return result\n\n\ndict_test = {'weekly': ['2010-07-10', '2020-06-20'],\n             'monthly': ['2010-07-31', '2020-04-30'],\n             'quarterly' : ['2010-09-30', '2020-03-31'],\n             'yearly' : ['2010-12-31', '2019-12-31']\n}\n\n\ndef last_day_of_month(check_month):\n    next_month = check_month.replace(day=28) + datetime.timedelta(days=4)\n    return next_month - datetime.timedelta(days=next_month.day)\n\n\ndef get_date_range(date_list, granularity):\n    result = []\n    start = datetime.datetime.strptime(date_list[0], '%Y-%m-%d')\n    end = datetime.datetime.strptime(date_list[1], '%Y-%m-%d')\n    if granularity == 'weekly':\n        while start <= end:\n            date_row = datetime.datetime.strftime(start, '%Y-%m-%d')\n            result.append(date_row)\n            start += relativedelta(weeks=1)\n    elif granularity == 'monthly':\n        while start <= end:\n            start = last_day_of_month(start)\n            date_row = datetime.datetime.strftime(start, '%Y-%m-%d')\n            result.append(date_row)\n            start += relativedelta(months=1)\n    elif granularity == 'quarterly':\n        while start <= end:\n            start = last_day_of_month(start)\n            date_row = datetime.datetime.strftime(start, '%Y-%m-%d')\n            result.append(date_row)\n            start += relativedelta(months=3)\n    elif granularity == 'yearly':\n        while start <= end:\n            date_row = datetime.datetime.strftime(start, '%Y-%m-%d')\n            result.append(date_row)\n            start += relativedelta(months=12)\n    # print result\n    return result\n\n\ndef check_store_category_db_completeness(date_list, graularity):\n    for date in date_list:\n        end = date\n        if graularity == 'weekly':\n            start = datetime.datetime.strptime(date, '%Y-%m-%d') - relativedelta(weeks=1) + relativedelta(days=1)\n            start = datetime.datetime.strftime(start, '%Y-%m-%d')\n        elif graularity == 'monthly':\n            start = date[:7] + str('-01')\n        elif graularity == 'quarterly':\n            start = datetime.datetime.strptime(date, '%Y-%m-%d') - relativedelta(months=2)\n            start = datetime.datetime.strftime(start, '%Y-%m') + str('-01')\n        elif graularity == 'yearly':\n            start = date[:4] + str('-01-01')\n        print start, end\n        unified_result = query(aa_dsn, daily_category_sql.format(start, end))\n        db_result = query(aa_dsn, sql.format(graularity[0], date, date, graularity))\n        # print date\n        # print unified_result[0][0]\n        # print db_result\n        if unified_result[0][0] == db_result[0][0] and unified_result[0][1] == db_result[0][1] and unified_result[0][2] == db_result[0][2] and unified_result[0][3] == db_result[0][3]:\n            print \"Completeness Test PASS! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n        else:\n            test_result.append(date)\n            print \"Completeness Test FAIL!!!!! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n\n\n\n\nkey = 'yearly'\nvalue = ['2019-12-31']\nfor d in value:\n    print d\n    check_store_category_db_completeness(get_date_range([d,d], key), key)\nprint test_result"]},{"cell_type":"code","execution_count":0,"id":"20200627-070247_1033684748","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql.functions import sum\nfrom pyspark.sql.functions import desc\nfrom aadatapipelinecore.core.urn import Urn\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\n\nimport psycopg2\nfrom pyspark.sql import Row\nfrom dateutil.relativedelta import relativedelta\nfrom aaplproxy.connection import ClusterConnection\nfrom conf import settings\nfrom aadatapipelinecore.core.loader.plproxy import build_db_settings\nimport datetime as d\nimport datetime\nfrom datetime import timedelta\n\n\ntest_result = []\nPG_AA_HOSTS = [('10.2.6.141', 5432)]\nPG_AA_NAME = 'aa_store_db'\nPG_AA_ACCESS_ID = 'citus_bdp_prod_app_int_qa'\nPG_AA_SECRET_KEY = 'wZw8cfBuuklIskVG'\n\naa_dsn = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_AA_NAME,\n        user=PG_AA_ACCESS_ID,\n        host=PG_AA_HOSTS[0][0],\n        password=PG_AA_SECRET_KEY,\n        port=PG_AA_HOSTS[0][1]\n    )\n)\n\nurn = Urn(\n    namespace=\"app-qa.db-check.v1\",\n    owner=\"app_qa\"\n)\ndaily_sql = \"\"\"select count(1), \n            sum(est_free_app_download), \n            sum(est_paid_app_download), \n            sum(est_revenue)\n            from \n    (select app_id, device_code, country_code, \n            sum(est_free_app_download) as est_free_app_download, \n            sum(est_paid_app_download) as est_paid_app_download,\n            sum(est_revenue) as est_revenue\n            from store.store_est_fact_v2\n            where date between '{}' and '{}'\n            group by\n            app_id,\n            device_code,\n            country_code) as t;\n\"\"\"\n\nsql = \"\"\"select count(1), \n        sum(est_free_app_download), \n        sum(est_paid_app_download), \n        sum(est_revenue)\n        from store.store_est_t_{}_fact_v2 \n        where date between '{}' and '{}' and granularity='{}';\"\"\"\n\n\ndef query(dsn, sql):\n    with psycopg2.connect(dsn) as conn:\n        conn.autocommit = True\n        with conn.cursor() as cur:\n            cur.execute(sql)\n            result = cur.fetchall()\n            conn.commit()\n    return result\n\n\ndict_test = {'weekly': ['2010-07-10', '2020-06-20'],\n             'monthly': ['2010-07-31', '2020-06-30'],\n             'quarterly' : ['2010-09-30', '2020-06-30'],\n             'yearly' : ['2010-12-31', '2019-12-31']\n}\n\n\ndef last_day_of_month(check_month):\n    next_month = check_month.replace(day=28) + datetime.timedelta(days=4)\n    return next_month - datetime.timedelta(days=next_month.day)\n\n\ndef get_date_range(date_list, granularity):\n    result = []\n    start = datetime.datetime.strptime(date_list[0], '%Y-%m-%d')\n    end = datetime.datetime.strptime(date_list[1], '%Y-%m-%d')\n    if granularity == 'weekly':\n        while start <= end:\n            date_row = datetime.datetime.strftime(start, '%Y-%m-%d')\n            result.append(date_row)\n            start += relativedelta(weeks=1)\n    elif granularity == 'monthly':\n        while start <= end:\n            start = last_day_of_month(start)\n            date_row = datetime.datetime.strftime(start, '%Y-%m-%d')\n            result.append(date_row)\n            start += relativedelta(months=1)\n    elif granularity == 'quarterly':\n        while start <= end:\n            start = last_day_of_month(start)\n            date_row = datetime.datetime.strftime(start, '%Y-%m-%d')\n            result.append(date_row)\n            start += relativedelta(months=3)\n    elif granularity == 'yearly':\n        while start <= end:\n            date_row = datetime.datetime.strftime(start, '%Y-%m-%d')\n            result.append(date_row)\n            start += relativedelta(months=12)\n    # print result\n    return result\n\n\ndef check_store_unified_db_completeness(date_list, graularity):\n    for date in date_list:\n        end = date\n        if graularity == 'weekly':\n            start = datetime.datetime.strptime(date, '%Y-%m-%d') - relativedelta(weeks=1) + relativedelta(days=1)\n            start = datetime.datetime.strftime(start, '%Y-%m-%d')\n        elif graularity == 'monthly':\n            start = date[:7] + str('-01')\n        elif graularity == 'quarterly':\n            start = datetime.datetime.strptime(date, '%Y-%m-%d') - relativedelta(months=2)\n            start = datetime.datetime.strftime(start, '%Y-%m') + str('-01')\n        elif graularity == 'yearly':\n            start = date[:4] + str('-01-01')\n        print start, end\n        unified_result = query(aa_dsn, daily_sql.format(start, end))\n        db_result = query(aa_dsn, sql.format(graularity[0], date, date, graularity))\n        # print date\n        # print unified_result[0][0]\n        # print db_result\n        if  unified_result[0][1] == db_result[0][1] and unified_result[0][2] == db_result[0][2] and unified_result[0][3] == db_result[0][3]:\n            print \"Completeness Test PASS! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n        else:\n            test_result.append(date)\n            print \"Completeness Test FAIL!!!!! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n\n\n\n\nkey = 'quarterly'\n# value = ['2016-12-31','2015-06-30', '2012-09-30', '2013-03-31', '2018-03-31'] \n# value = ['2012-12-01','2016-10-22', '2013-05-11', '2013-06-08', '2015-05-02', '2012-07-14', '2013-03-30', '2017-02-04' ,'2018-01-20']\n# value = ['2012-12-31','2016-10-31', '2013-05-31', '2013-06-30', '2015-05-31', '2012-07-31', '2013-03-31', '2017-02-28' ,'2018-01-31']\nvalue = [ '2020-03-31','2020-06-30' ]\nfor d in value:\n    print d\n    check_store_unified_db_completeness(get_date_range([d,d], key), key),\nprint test_result"]},{"cell_type":"code","execution_count":0,"id":"20200626-063222_999292074","metadata":{},"outputs":[],"source":["%%sh\nPGPASSWORD='wZw8cfBuuklIskVG' psql -h 10.2.6.141  -U citus_bdp_prod_app_int_qa -d aa_store_db -p 5432 << EOF \nset search_path=store;\nselect count(1), \n        sum(est_free_app_download) + sum(est_paid_app_download), \n        sum(est_revenue) from store_est_fact_v2 where date between '2018-01-01' and '2018-12-31' and granularity='daily'   limit 5 ;\n        \nselect count(1), \n        sum(est_free_app_download) + sum(est_paid_app_download), \n        sum(est_revenue), sum(est_organic_download) + sum(est_paid_download) from store_est_t_y_fact_v2 where date between '2018-01-01' and '2018-12-31' limit 5 ;\n\nEOF\n\n\n\nPGPASSWORD='wZw8cfBuuklIskVG' psql -h 10.2.6.141  -U citus_bdp_prod_app_int_qa -d aa_store_db -p 5432 << EOF \nset search_path=store;\n-- select * from store_est_fact_v1 where date between '2020-03-31' and '2020-06-20' and app_id In (1512799121) and country_code='US' order by date desc limit 5 ;\nselect count(1) from store_est_t_w_fact_v1 where date between '2012-08-12' and '2012-08-18' ;\nselect  count(1) from store_est_category_t_w_fact_v1 where date between '2012-08-12' and '2012-08-18' ;\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20200626-065336_1711250920","metadata":{},"outputs":[],"source":["%%sh\nPGPASSWORD='wZw8cfBuuklIskVG' psql -h 10.2.6.141  -U citus_bdp_prod_app_int_qa -d aa_store_db -p 5432 << EOF \nset search_path=store;\n\nSELECT column_name, data_type FROM information_schema.columns where  table_schema='store' and TABLE_NAME = 'store_est_fact_v2';\n\n-- select * from store_est_fact_v1 where date between '2020-03-31' and '2020-06-20' and app_id In (1512799121) and country_code='US' order by date desc limit 5 ;\n-- select count(1) from store_est_t_w_fact_v1 where date between '2012-08-12' and '2012-08-18' ;\n-- select  count(1) from store_est_category_t_w_fact_v1 where date between '2012-08-12' and '2012-08-18' ;\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20200715-071948_532615629","metadata":{},"outputs":[],"source":["%%sh\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}