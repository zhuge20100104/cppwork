{"cells":[{"cell_type":"code","execution_count":0,"id":"20200514-013946_1625055414","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql.types import StructType, StructField, StringType, IntegerType\nimport pandas as pd\n\ndef get_date_list(start_date, end_date, freq=\"D\"):\n    import pandas as pd\n    \"\"\"\n    freq:   D: calendar day frequency\n            M: month end frequency\n            MS: month start frequency\n            A, Y: year end frequency\n            AS, YS: year start frequency\n    \"\"\"\n    date_list = [x.strftime('%Y-%m-%d') for x in list(pd.date_range(start=start_date, end=end_date, freq=freq))]\n    return date_list\n    \ndates = get_date_list('2010-07-04', '2010-07-31', freq='D')    # >> ['2010-07-04', '2010-07-05', '2010-07-06']\ndates = dates + get_date_list('2010-08-01', '2020-04-18', freq='D')\n# dates = dates + get_date_list('2010-08-01', '2010-09-30', freq='D')\nprint dates\n# mapping:  ios-phone,    ios-all,     ios-tablet,  free_app_download=2, facebook\napp_list = ['377194688', '364709193', '379174209',  '339739007',         '284882215', '20600000025034', '20600000357382', '20600000246936', '20600000009072']\ndevice_code = ['ios-phone','ios-tablet','ios-all', 'android-all']    # exclude 'android-all'\ncountries = ['WW', 'US']\n# app = [\n#     ('377194688', 'ios-phone', 'WW'),\n#     ('364709193', 'ios-all', 'US'),\n#     ('379174209', 'ios-tablet', 'US'),\n#     ('339739007', 'ios-phone', 'WW'),\n#     ('284882215', 'ios-all', 'WW'),    # facebook\n#     ('20600000025034', 'android-all', 'WW'),\n#     ('20600000357382', 'android-all', 'WW'),\n#     ('20600000246936', 'android-all', 'WW'),\n#     ('20600000348221', 'android-all', 'TH'),\n#     ('20600000009072', 'android-all', 'WW')\n#     ]\n\ndef main_test(dates, app_list, device_code, countries):\n    where_clause = \"app_id in ({}) and device_code in ('{}') and country_code in ('{}')\".format(\",\".join(map(str,app_list)),   \"','\".join(device_code), \"','\".join(countries) )\n    # where_clause = \"app_id={} and device_code={} and country_code={}\".format(app_id, device_code, country_code)\n    # >> \"app_id in (377194688,364709193,379174209,339739007,284882215) and device_code in ('ios-phone','ios-tablet','ios-all') and country_code in ('WW','US')\"\n    print where_clause\n\n    concat_list = []\n    for date in dates:\n    # for app_id, device_code, country_code in app:\n        # where_clause = \"app_id='{}' and device_code='{}' and country_code='{}'\".format(app_id, device_code, country_code)\n        unified_data = spark.read.option(\"basePath\", \"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/granularity=daily/\")\\\n        .parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/granularity=daily/date={}/\".format(date))\\\n        .where(where_clause).select('app_id', 'device_code', 'country_code', 'free_app_download', 'paid_app_download', 'revenue').toPandas()\n        \n        concat_list.append(unified_data)\n        \n    temp_df = pd.concat(concat_list).groupby(['app_id', 'device_code', 'country_code'], sort=True).sum(level=['free_app_download', 'paid_app_download', 'revenue'])\n    \n    # fetch data from cumulative\n    # cum_concat_list = []\n    # for app_id, device_code, country_code in app:\n    # where_clause = \"app_id='{}' and device_code='{}' and country_code='{}'\".format(app_id, device_code, country_code)\n    cum_df = spark.read.format('delta').load(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est-cum.v1/fact/date={}/\".format(dates[-1])).where(where_clause).select('app_id', 'device_code', 'country_code', 'free_app_download', 'paid_app_download', 'revenue').toPandas()\n    # cum_concat_list.append(cum_df)\n    # cum_temp_df = pd.concat(cum_concat_list).groupby(['app_id', 'device_code', 'country_code'], sort=True).sum(level=['free_app_download', 'paid_app_download', 'revenue'])\n    cum_temp_df = cum_df.groupby(['app_id', 'device_code', 'country_code'], sort=True).sum(level=['free_app_download', 'paid_app_download', 'revenue'])\n    return temp_df, cum_temp_df\n\ntemp_df, cum_temp_df = main_test(dates, app_list, device_code, countries)\n# print temp_df\n# print cum_temp_df\n\n# compare\nimport numpy as np\ndef temp_log_to_s3(log, name, file_format):\n    import boto3\n    import json\n    s3 = boto3.resource('s3')\n    s3object = s3.Object('b2c-prod-data-pipeline-qa', 'zidong/aa.store.cum/{}.{}'.format(name, file_format))\n    if file_format == 'json':\n        s3object.put(Body=json.dumps(log))\n        return json.dumps(log)\n    else:\n        s3object.put(Body=str(log))    \n        return log\n\n# print sorted(list(temp_df['free_app_download'])) == sorted(list(cum_df['free_app_download']))\n\n# joined_df = temp_df.merge(cum_df, on=['app_id', 'device_code', 'country_code'])\n# print joined_df.T\n\ndef _compare_df(df1, df2, on=None):\n    for diff_type in [\"left\", \"right\"]:\n        diff_df = df1.merge(df2, indicator=True, how=diff_type, on=on)  # .loc[lambda x : x['_merge']!='both']\n        print diff_df\n        diff_df = diff_df.loc[diff_df[\"_merge\"] != \"both\"]\n        print diff_df.empty\n        if not diff_df.empty:\n            print diff_type\n            print diff_df\n    temp_log_to_s3(diff_df, 'diff_df', 'csv')\n\n# temp_df['free_app_download'] = [np.nan if i==5 else i for i in temp_df['free_app_download']]\n# temp_df['free_app_download'] = [i if str(i).isdigit() else 0 for i in temp_df['free_app_download']]\n# print [i.__repr__() for i in temp_df['free_app_download']]\n\ntemp_df[temp_df['free_app_download'].isnull()] = 0\n# temp_df[temp_df['paid_app_download'].isnull()] = 0\n# temp_df[temp_df['revenue'].isnull()] = 0\n\n# cum_temp_df['free_app_download'] = [0 if l is None else l for l in cum_temp_df['free_app_download']]\n# cum_temp_df['paid_app_download'] = [0 if l is None else l for l in cum_temp_df['paid_app_download']]\n# cum_temp_df['revenue'] = [0 if l is None else l for l in cum_temp_df['revenue']]\n# print temp_df\n\n_compare_df(temp_df, cum_temp_df, on=['app_id', 'device_code', 'country_code', 'free_app_download'])\n# diff_df = cum_temp_df.merge(temp_df, indicator=True, how='left', on=['app_id'])\n# print diff_df.T\n\ntest_df = temp_df.reset_index()\n# temp_df.drop(['index'], axis=1, inplace=True)\nprint test_df\n# # save\nspark.createDataFrame(test_df).write.parquet(\"s3://b2c-prod-data-pipeline-qa/zidong/aa.store.cum/store_cum_sample_result/\", mode=\"overwrite\")\nspark.read.parquet(\"s3://b2c-prod-data-pipeline-qa/zidong/aa.store.cum/store_cum_sample_result/\").show(100)\n\n# # # compare\n# import numpy as np\n# def temp_log_to_s3(log, name, file_format):\n#     import boto3\n#     import json\n#     s3 = boto3.resource('s3')\n#     s3object = s3.Object('b2c-prod-data-pipeline-qa', 'zidong/aa.store.cum/{}.{}'.format(name, file_format))\n#     if file_format == 'json':\n#         s3object.put(Body=json.dumps(log))\n#         return json.dumps(log)\n#     else:\n#         s3object.put(Body=str(log))    \n#         return log\n\n# # print sorted(list(temp_df['free_app_download'])) == sorted(list(cum_df['free_app_download']))\n\n# # joined_df = temp_df.merge(cum_df, on=['app_id', 'device_code', 'country_code'])\n# # print joined_df.T\n\n# def _compare_df(df1, df2, on=None):\n#     for diff_type in [\"left\", \"right\"]:\n#         diff_df = df1.merge(df2, indicator=True, how=diff_type, on=on)  # .loc[lambda x : x['_merge']!='both']\n#         diff_df = diff_df.loc[diff_df[\"_merge\"] != \"both\"]\n#         print diff_df.empty\n#         if not diff_df.empty:\n#             print diff_type\n#             print diff_df\n#     print \"diff_df\", diff_df\n    \n\n# # temp_df['free_app_download'] = [np.nan if i==5 else i for i in temp_df['free_app_download']]\n# # temp_df['free_app_download'] = [i if str(i).isdigit() else 0 for i in temp_df['free_app_download']]\n# # print [i.__repr__() for i in temp_df['free_app_download']]\n\n# temp_df[temp_df['free_app_download'].isnull()] = 0\n# temp_df[temp_df['paid_app_download'].isnull()] = 0\n# temp_df[temp_df['revenue'].isnull()] = 0\n\n# cum_temp_df['free_app_download'] = [0 if l is None else l for l in cum_temp_df['free_app_download']]\n# cum_temp_df['paid_app_download'] = [0 if l is None else l for l in cum_temp_df['paid_app_download']]\n# cum_temp_df['revenue'] = [0 if l is None else l for l in cum_temp_df['revenue']]\n# # cum_temp_df.set_index(['app_id', 'device_code', 'country_code'])\n# print temp_df\n\n# _compare_df(temp_df, cum_temp_df, on=['app_id', 'device_code', 'country_code', 'free_app_download', 'paid_app_download', 'revenue'])\n# # diff_df = cum_temp_df.merge(temp_df, indicator=True, how='left', on=['app_id'])\n# # print diff_df.T"]},{"cell_type":"code","execution_count":0,"id":"20200514-014042_206392651","metadata":{},"outputs":[],"source":["\ndf = spark.read.parquet(\"s3://b2c-prod-data-pipeline-qa/zidong/aa.store.cum/store_cum_sample_result/\")\ndf.write.parquet(\"s3://b2c-prod-data-pipeline-qa/aa.store.app-est-cum.v1/store_cum_sample_result/\", mode=\"overwrite\")"]},{"cell_type":"code","execution_count":0,"id":"20200514-075450_968519465","metadata":{},"outputs":[],"source":["%%sh\naws s3 ls s3://b2c-prod-data-pipeline-qa/aa.store.app-est-cum.v1/\n"]},{"cell_type":"code","execution_count":0,"id":"20200514-093259_312277896","metadata":{},"outputs":[],"source":["\nimport pandas as pd\n\ndef get_date_list(start_date, end_date, freq=\"D\"):\n    import pandas as pd\n    \"\"\"\n    freq:   D: calendar day frequency\n            M: month end frequency\n            MS: month start frequency\n            A, Y: year end frequency\n            AS, YS: year start frequency\n    \"\"\"\n    date_list = [x.strftime('%Y-%m-%d') for x in list(pd.date_range(start=start_date, end=end_date, freq=freq))]\n    return date_list\n\n\n# cum_dates = get_date_list('2010-07-04', '2010-07-31', freq='D') + \\\n#             get_date_list('2010-08-31', '2020-03-31', freq='M') + \\\n#             get_date_list('2020-04-01', '2020-04-18', freq='D')  # prod\n# cum_dates = get_date_list('2010-07-04', '2010-07-31', freq='D') + \\\n# get_date_list('2010-08-31', '2011-09-30', freq='M')       # test monthly\n# cum_dates = get_date_list('2010-07-04', '2010-07-10', freq='D')\n# store_dates = get_date_list('2010-07-04', '2020-04-18', freq='D')  # prod\n# store_dates = get_date_list('2010-07-04', '2011-09-30', freq='D')     # test monthly\nstore_dates = get_date_list('2010-07-04', '2010-08-31', freq='D')\n\nbase_path = \"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/\"\n\nfrom pyspark.sql.types import StructType, StructField, StringType, IntegerType\n\nschema = StructType([StructField(\"app_id\", StringType(), True)])\nprev_df = spark.createDataFrame([], schema=schema)\n\n\npaths = []\nprint store_dates[0]\nfor i in range(len(store_dates)):\n    path = base_path + \"granularity=daily/date=\" + store_dates[i] + \"/\"\n    paths.append(path)\n# print paths\n\ndf = spark.read.option('basePath', base_path).parquet(*paths).select('app_id').distinct()\n\n# compare\ncum_df = spark.read.format('delta').load(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est-cum.v1/fact/\").where(\"date='{}'\".format(store_dates[-1])).select('app_id').distinct()\nexcept_df = df.subtract(cum_df)\nif except_df.first():\n    print \"failed date:\", cum_date\nprint \"SUCCESSED\"\n\n# save\ndf.write.parquet(\"s3://b2c-prod-data-pipeline-qa/aa.store.app-est-cum.v1/store_cum_completeness_result/\", mode=\"overwrite\")"]},{"cell_type":"code","execution_count":0,"id":"20200515-022007_380971251","metadata":{},"outputs":[],"source":["\nspark.read.parquet(\"s3://b2c-prod-data-pipeline-qa/aa.store.app-est-cum.v1/store_cum_completeness_result/\").show(10)"]},{"cell_type":"code","execution_count":0,"id":"20200515-022635_1873463097","metadata":{},"outputs":[],"source":["\nimport pandas as pd\n\ndef get_date_list(start_date, end_date, freq=\"D\"):\n    import pandas as pd\n    \"\"\"\n    freq:   D: calendar day frequency\n            M: month end frequency\n            MS: month start frequency\n            A, Y: year end frequency\n            AS, YS: year start frequency\n    \"\"\"\n    date_list = [x.strftime('%Y-%m-%d') for x in list(pd.date_range(start=start_date, end=end_date, freq=freq))]\n    return date_list\n\n\n# cum_dates = get_date_list('2010-07-04', '2010-07-31', freq='D') + \\\n#             get_date_list('2010-08-31', '2020-03-31', freq='M') + \\\n#             get_date_list('2020-04-01', '2020-04-18', freq='D')  # prod\n# cum_dates = get_date_list('2010-07-04', '2010-07-31', freq='D') + \\\n# get_date_list('2010-08-31', '2011-09-30', freq='M')       # test monthly\n# cum_dates = get_date_list('2010-07-04', '2010-07-10', freq='D')\n# store_dates = get_date_list('2010-07-04', '2020-04-18', freq='D')  # prod\n# store_dates = get_date_list('2010-07-04', '2011-09-30', freq='D')     # test monthly\nstore_dates = get_date_list('2010-07-04', '2010-08-31', freq='D')\n\nbase_path = \"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/\"\n\ndf = spark.read.option('basePath', base_path).parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/granularity=daily/date=2010-0[7-8]*/\").select('app_id').distinct()\n\n# compare\ncum_df = spark.read.format('delta').load(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est-cum.v1/fact/\").where(\"date='{}'\".format(store_dates[-1])).select('app_id').distinct()\nexcept_df = df.subtract(cum_df)\nif except_df.first():\n    print \"failed date:\", cum_date\nprint \"SUCCESSED\"\n\n# save\ndf.write.parquet(\"s3://b2c-prod-data-pipeline-qa/aa.store.app-est-cum.v1/store_cum_completeness_result/\", mode=\"overwrite\")"]},{"cell_type":"code","execution_count":0,"id":"20200515-025814_1206351531","metadata":{},"outputs":[],"source":["\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}