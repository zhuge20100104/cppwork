{"cells":[{"cell_type":"code","execution_count":0,"id":"20200215-023313_402741034","metadata":{},"outputs":[],"source":["\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nimport pandas as pd\npd.set_option('expand_frame_repr', False)\n"]},{"cell_type":"code","execution_count":0,"id":"20200215-021257_199790659","metadata":{},"outputs":[],"source":["%%sh\n\n\naws s3 ls s3://b2c-prod-data-pipeline-unified-dna/unified/dna.genre_id_product_mapping.v1/dimension/\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200215-022754_1053623002","metadata":{},"outputs":[],"source":["%%sh\n\nPGPASSWORD='2mHdFW6%#REu' psql -h 10.2.26.136 -U app_bdp_usage_qa -d dna -p 6432 << EOF \n\nselect * from dna_genre_id_product_mapping where product_id=1427744264 limit 10;\nselect count (*) from dna_genre_id_product_mapping;\n\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20200215-023038_1187630552","metadata":{},"outputs":[],"source":["\n\n\nfrom conf.settings import PG_DNA_NAME, PG_DNA_ACCESS_ID, PG_DNA_HOSTS, PG_DNA_SECRET_KEY\nfrom applications.db_check_v1.common.db_check_utils import query_df\n\ndna_dsn = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_DNA_NAME,\n        user=PG_DNA_ACCESS_ID,\n        host=PG_DNA_HOSTS[0][0],\n        password=PG_DNA_SECRET_KEY,\n        port=PG_DNA_HOSTS[0][1]\n    )\n)\nmapping_df_unified = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-dna/unified/dna.genre_id_product_mapping.v1/dimension/\").toPandas()\nsql = 'SELECT * FROM dna_genre_id_product_mapping'\nmapping_df_raw = query_df(dna_dsn, sql)\n\nmapping_df_raw['created_time'] = mapping_df_raw['created_time'].dt.strftime('%Y-%m-%d')\nmapping_df_raw['last_updated_time'] = mapping_df_raw['last_updated_time'].dt.strftime('%Y-%m-%d')\nmapping_df_raw['genre_id'] = [str(map(int, l))  if l else 'None' for l in mapping_df_raw['genre_id']]\nmapping_df_raw['modifier_id'] = [str(map(int, l)) if l else 'None' for l in mapping_df_raw['modifier_id']]\n\nmapping_df_unified['genre_id'] = mapping_df_unified['genre_id'].astype(\"str\")\nmapping_df_unified['modifier_id'] = mapping_df_unified['modifier_id'].astype(\"str\")\nprint mapping_df_raw\nprint mapping_df_unified\n"]},{"cell_type":"code","execution_count":0,"id":"20200215-023112_1024930936","metadata":{},"outputs":[],"source":["\n\ndef _compare_df(df1, df2, on=None):\n    for diff_type in [\"left\", \"right\"]:\n        diff_df = df1.merge(df2, indicator=True, how=diff_type, on=on)  # .loc[lambda x : x['_merge']!='both']\n        diff_df = diff_df.loc[diff_df[\"_merge\"] != \"both\"]\n        if len(diff_df) != 0:\n            print diff_type\n            print diff_df\n\n\n# print mapping_df_raw.genre_id.dtypes\n# print '*'*100\n# print mapping_df_unified.genre_id.dtypes\n# print mapping_df_raw\n# print mapping_df_unified\n\n_compare_df(mapping_df_raw, mapping_df_unified, on=[\"product_id\", \"created_time\", \"created_by\", \"last_updated_time\", \"last_updated_by\", \"comments\", \"modifier_id\", \"genre_id\"])\nprint \"pass\"\n"]},{"cell_type":"code","execution_count":0,"id":"20200216-112743_175745113","metadata":{},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":0,"id":"20200216-085331_1632162512","metadata":{},"outputs":[],"source":["\n\nest_unified_df = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.genre-est.v1/fact/granularity=daily/date=2019-12-27/\")\nest_unified_df.show()\n# print est_unified_df\n# print set(est_unified_df.device_code.tolist())\n# print set(est_unified_df.country_code.tolist())\n# print set(est_unified_df.genre_id.tolist())\n# print set(est_unified_df.modifier_id.tolist())\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200216-091415_1262335089","metadata":{},"outputs":[],"source":["\nstore_est_unified_df = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/granularity=daily/date=2019-12-27/\")\nmapping_df_unified = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-dna/unified/dna.genre_id_product_mapping.v1/dimension/\")\n\ntransformed_mapping_df = mapping_df_unified.select([\"product_id\", \"genre_id\"]).withColumn('genre_id', F.explode('genre_id'))\ntransformed_store_est_unified_df = store_est_unified_df.select([\"app_id\", \"device_code\", \"country_code\", \"free_app_download\", \"paid_app_download\", \"revenue\"]).withColumnRenamed(\"app_id\", \"product_id\")\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200216-093116_1017638639","metadata":{},"outputs":[],"source":["\ntransformed_store_est_unified_df.show(5)\ntransformed_mapping_df.show(5)\ntransformed_store_est_unified_df.withColumn('total_col', transformed_store_est_unified_df.free_app_download + transformed_store_est_unified_df.paid_app_download).filter(\"free_app_download=0 or paid_app_download=0\").show(5)\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200216-100922_1158256973","metadata":{},"outputs":[],"source":["\n\nfrom pyspark.sql import functions as F\n\ngiq_df = transformed_store_est_unified_df.join(transformed_mapping_df, transformed_mapping_df.product_id == transformed_store_est_unified_df.product_id, how='inner').groupBy([\"device_code\", \"country_code\", \"genre_id\"]).agg({\n            \"free_app_download\": \"sum\",\n            \"paid_app_download\": \"sum\",\n            \"revenue\": \"sum\",\n        }).withColumnRenamed(\"sum(free_app_download)\", \"free_app_download\").withColumnRenamed(\"sum(paid_app_download)\", \"paid_app_download\").withColumnRenamed(\"sum(revenue)\", \"revenue\")\n\n\ngiq_df = giq_df.fillna({\"free_app_download\":0, \"paid_app_download\":0})\n# giq_df = giq_df.withColumn(\"download\", F.when(giq_df.free_app_download + giq_df.paid_app_download>0, giq_df.free_app_download + giq_df.paid_app_download).otherwise(F.lit(None)))\ngiq_df = giq_df.withColumn(\"download\", giq_df.free_app_download + giq_df.paid_app_download)\n\n\n\n\n\n\n# def replace(column, value):\n#     return when(column != value, column).otherwise(lit(None))\n\n# giq_df.withColumn(\"download\", replace(col(\"y\"), \"bar\")).show()\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200216-115700_355569301","metadata":{},"outputs":[],"source":["\ns1=giq_df.select([\"device_code\", \"country_code\", \"genre_id\", \"download\", \"revenue\"])\ns2=est_unified_df.select([\"device_code\", \"country_code\", \"genre_id\", \"download\", \"revenue\"])\n\ndiff = s1.union(s2).subtract(s1.intersect(s2))\ndiff.show()\n\n\n\nprint diff.count()\nprint s1.count()\nprint s2.count()\n\n# |  ios-phone|          NA|     207|       8|   null|\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200216-122042_634115454","metadata":{},"outputs":[],"source":["\n\nimport pandas as pd\n\nmapping_df_unified = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-dna/unified/dna.genre_id_product_mapping.v1/dimension/\")\ntransformed_mapping_df = mapping_df_unified.select([\"product_id\", \"genre_id\"]).withColumn('genre_id', F.explode('genre_id'))\n\ndef compare(date):\n    #collect\n    store_est_unified_df = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/granularity=daily/date={}/\".format(date))\n    est_unified_df = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.genre-est.v1/fact/granularity=daily/date={}/\".format(date))\n    \n    #transform\n    transformed_store_est_unified_df = store_est_unified_df.select([\"app_id\", \"device_code\", \"country_code\", \"free_app_download\", \"paid_app_download\", \"revenue\"]).withColumnRenamed(\"app_id\", \"product_id\")\n    giq_df = transformed_store_est_unified_df.join(transformed_mapping_df, transformed_mapping_df.product_id == transformed_store_est_unified_df.product_id, how='inner').groupBy([\"device_code\", \"country_code\", \"genre_id\"]).agg({\n            \"free_app_download\": \"sum\",\n            \"paid_app_download\": \"sum\",\n            \"revenue\": \"sum\",\n        }).withColumnRenamed(\"sum(free_app_download)\", \"free_app_download\").withColumnRenamed(\"sum(paid_app_download)\", \"paid_app_download\").withColumnRenamed(\"sum(revenue)\", \"revenue\")\n    giq_df = giq_df.fillna({\"free_app_download\":0, \"paid_app_download\":0})\n    giq_df = giq_df.withColumn(\"download\", giq_df.free_app_download + giq_df.paid_app_download)\n\n    #compare\n    s1=giq_df.select([\"device_code\", \"country_code\", \"genre_id\", \"download\", \"revenue\"])\n    s2=est_unified_df.select([\"device_code\", \"country_code\", \"genre_id\", \"download\", \"revenue\"])\n\n    diff = s1.union(s2).subtract(s1.intersect(s2))\n    if diff.count()>0:\n        print \"{}: FAIL\".format(date)\n        print diff.show(2)\n    else:\n        print  \"{}: PASS\".format(date)\n    \n    \ndef get_date_list(start_date, end_date, freq=\"D\"):\n    date_list = [x.strftime('%Y-%m-%d') for x in list(pd.date_range(start=start_date, end=end_date, freq=freq))]\n    return date_list\n\n\ndate_list = get_date_list(\"2010-07-04/\", \"2020-02-08/\")\nfor date in date_list:\n    try:\n        compare(date)\n    except Exception, e:\n        print \"{}: ERROR\".format(date) \n\n"]},{"cell_type":"code","execution_count":0,"id":"20200216-122944_1611377973","metadata":{},"outputs":[],"source":["%md\n\n1. fill na > 0逻辑, download有, 但是 revenue没有. 所以会出现 download =0 , revenue=null的情况\n2. 正在跑\n"]},{"cell_type":"code","execution_count":0,"id":"20200216-121335_296724452","metadata":{},"outputs":[],"source":["\n\nsql = \"device_code='ios-phone' and country_code='NA' and genre_id=207\"\ns1.filter(sql).show()\ns2.filter(sql).show()\n"]},{"cell_type":"code","execution_count":0,"id":"20200216-094454_592749310","metadata":{},"outputs":[],"source":["\n\nimport pandas as pd\n\ntest_df1 = pd.DataFrame({'id': [1,2,3], 'download':[1,2,3]})\ntest_df2 = pd.DataFrame({'id': [1,1,2,3,4], 'id2':[11,111,22,33,44], 'nickname':['aa','aa','bb','cc','dd']})\n\n\nresult_df = test_df1.merge(test_df2, on='id', how='outer')\n\nprint result_df\n"]},{"cell_type":"code","execution_count":0,"id":"20200216-095511_571202517","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql import Row\nimport pyspark.sql.functions as F \n\n\ndf = spark.createDataFrame( [Row(1, [1,2,3])], ['id', 'genre_id'])\ndf.show()\ndf = df.withColumn('genre_id', F.explode('genre_id'))\ndf.show()\n"]},{"cell_type":"code","execution_count":0,"id":"20200215-023242_558555763","metadata":{},"outputs":[],"source":["%%sh\n\naws s3 ls s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.genre-est.v1/fact/granularity=daily/\n# aws s3 ls s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/granularity=daily/date=2019-12-27/\n\n#                           PRE app-tech.store.app-est.v1/\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200216-085248_996121247","metadata":{},"outputs":[],"source":["%%sh\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}