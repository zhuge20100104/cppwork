{"cells":[{"cell_type":"code","execution_count":0,"id":"20200430-134827_1618575167","metadata":{},"outputs":[],"source":["\nimport datetime\nstart='2010-07-04'\nend='2020-04-07'\nreal_date1 = datetime.date(*[int(x) for x in start.split('-')])\nreal_date2 = datetime.date(*[int(x) for x in end.split('-')])\ndate_range = real_date2 - real_date1\ndates = list()\nfor days in xrange(date_range.days):\n    dates.append(real_date1 + datetime.timedelta(days))\ndates.reverse()\n\nprint dates\n\ndevice_code=[\"ios-phone\",\"ios-tablet\",\"android-all\"]\n\n\ntest_data = [ (day, device) for day in dates for device in device_code]\n\nprint test_data"]},{"cell_type":"code","execution_count":0,"id":"20200430-115202_64869850","metadata":{},"outputs":[],"source":["\n\nimport psycopg2\nimport datetime\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nimport aaplproxy\nfrom aadatapipelinecore.core.urn import Urn\nfrom aaplproxy.da.local_sqlrunner import LocalSqlRunner\nfrom aadatapipelinecore.core.utils.module import application_settings\nfrom pyspark.sql import Row\n\ndevice_code=[\"ios-phone\",\"ios-tablet\",\"android-all\"]\n\ndef citus_row(test_data):\n    def get_data_in_citus(date , device_code):\n        citus_dsn_ = (\n            \"dbname='{db}' user='{user}' password='{password}' \"\n            \"host='{host}' port='{port}'\".format(\n                db=\"aa_store_db\",\n                user=\"citus_bdp_prod_app_int_qa\",\n                host=\"10.2.10.254\",\n                password=\"wZw8cfBuuklIskVG\",\n                port=5432\n            )\n        )\n        sql = '''SELECT \n                    CAST((SUM(est_free_app_download) + SUM(est_paid_app_download)) AS INT) AS total,\n                    CAST(SUM(est_organic_download) AS INT) as est_organic_download, \n                    CAST(SUM(est_paid_download) AS INT) as est_paid_download\n                    FROM store.store_est_category_fact_v6 \n                    WHERE date='{}' \n                    AND device_code='{}' \n                    AND granularity='daily' '''.format(date, device_code)\n        \n        db_data = query(citus_dsn_, sql)\n        return db_data\n\n    def query(dsn, sql):\n        with psycopg2.connect(dsn) as conn:\n            conn.autocommit = True\n            with conn.cursor() as cur:\n                cur.execute(sql)\n                result = cur.fetchall()\n                conn.commit()\n        return result\n    \n    result = get_data_in_citus(test_data[0], test_data[1])\n    # print result\n\n    return [Row(total=r[0], organic_download=r[1], paid_download=r[2], date=test_data[0], device=test_data[1]) for r in result]\n\n\ntest_rdd = sc.parallelize(map(citus_row, test_data), 2).cache()\n\nimport pyspark\ntest_rdd.unpersist()\nprint test_rdd.persist(pyspark.StorageLevel.MEMORY_AND_DISK)\ntest_rdd.getStorageLevel()\nprint(test_rdd.getStorageLevel())\nprint test_rdd.take(1)\nnew_rdd = test_rdd.flatMap(lambda x: x)\nnew_rdd.toDF().where(\"organic_download != total or paid_download!=0 \").show()\n\n\n# df_plploxy.createOrReplaceTempView(\"old\")\n# df_citus.createOrReplaceTempView(\"new\")\n\n# spark.sql(\"\")\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200505-031038_384903026","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql.types import StructType\nfrom pyspark.sql.types import StructField\nfrom pyspark.sql.types import StringType\nfrom pyspark.sql.types import IntegerType\nfrom pyspark.sql.types import DateType\n\nimport pyspark\ntest_rdd.unpersist()\ntest_rdd.persist(pyspark.StorageLevel.MEMORY_AND_DISK)\ntest_rdd.getStorageLevel()\nprint(test_rdd.getStorageLevel())\nprint test_rdd.take(1)\nnew_rdd = test_rdd.flatMap(lambda x: x)\nnew_rdd.toDF().where(\"organic_download != total or paid_download!=0 \").show()\n# new_rdd.where(\"organic_download != total \")\n# test_rdd.toDF().show(20,False)\n# test.toDF([\"date\",\"device\",\"organic_download\",\"paid_download\",\"total\"]).show()\n# schema=StructType([StructField(\"date\", DateType, True), StructField(\"device_code\", StringType, True), StructField(\"sum\", DoubleType, True), StructField(\"organic_download\", DoubleType, True), StructField(\"paid_download\", DoubleType, True)])\n# spark.createDataFrame(test_rdd, schema).show()"]},{"cell_type":"code","execution_count":0,"id":"20200505-032020_1874351081","metadata":{},"outputs":[],"source":["\ncoalesce_rdd = new_rdd.coalesce(1).cache()\ncoalesce_rdd.getNumPartitions()"]},{"cell_type":"code","execution_count":0,"id":"20200506-091357_1228077239","metadata":{},"outputs":[],"source":["\nimport datetime\nstart='2020-04-17'\nend='2020-04-18'\nreal_date1 = datetime.date(*[int(x) for x in start.split('-')])\nreal_date2 = datetime.date(*[int(x) for x in end.split('-')])\ndate_range = real_date2 - real_date1\ndates = list()\nfor days in xrange(date_range.days):\n    dates.append(real_date1 + datetime.timedelta(days))\ndates.reverse()\n\nprint dates\n\ndevice_code=[\"ios-phone\",\"ios-tablet\",\"android-all\"]\n\n\ntest_data = [ (day, device) for day in dates for device in device_code]\n\nprint test_data"]},{"cell_type":"code","execution_count":0,"id":"20200505-071953_678422637","metadata":{},"outputs":[],"source":["\n\nimport psycopg2\nimport datetime\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nimport aaplproxy\nfrom aadatapipelinecore.core.urn import Urn\nfrom aaplproxy.da.local_sqlrunner import LocalSqlRunner\nfrom aadatapipelinecore.core.utils.module import application_settings\nfrom pyspark.sql import Row\n\ndevice_code=[\"ios-phone\",\"ios-tablet\",\"android-all\"]\n\ndef citus_row(test_data):\n    def get_data_in_citus(date , device_code):\n        citus_dsn_ = (\n            \"dbname='{db}' user='{user}' password='{password}' \"\n            \"host='{host}' port='{port}'\".format(\n                db=\"aa_citus_db\",\n                user=\"citus_bdp_usage_qa\",\n                host=\"10.2.10.132\",\n                password=\"dNzWtSV3pKTx\",\n                port=5432\n            )\n        )\n        sql = '''SELECT \n                    CAST((SUM(est_free_app_download) + SUM(est_paid_app_download)) AS INT) AS total,\n                    CAST(SUM(est_organic_download) AS INT) as est_organic_download, \n                    CAST(SUM(est_paid_download) AS INT) as est_paid_download\n                    FROM store.store_est_category_fact_v6 \n                    WHERE date='{}' \n                    AND device_code='{}' \n                    AND granularity='daily' '''.format(date, device_code)\n        \n        db_data = query(citus_dsn_, sql)\n        return db_data\n\n    def query(dsn, sql):\n        with psycopg2.connect(dsn) as conn:\n            conn.autocommit = True\n            with conn.cursor() as cur:\n                cur.execute(sql)\n                result = cur.fetchall()\n                conn.commit()\n        return result\n    \n    result = get_data_in_citus(test_data[0], test_data[1])\n    # print result\n\n    return [Row(total=r[0], organic_download=r[1], paid_download=r[2], date=test_data[0], device=test_data[1]) for r in result]\n\n\ntest_rdd = sc.parallelize(map(citus_row, test_data), 2).cache()\n\nimport pyspark\ntest_rdd.unpersist()\nprint test_rdd.persist(pyspark.StorageLevel.MEMORY_AND_DISK)\ntest_rdd.getStorageLevel()\nprint(test_rdd.getStorageLevel())\nprint test_rdd.take(1)\nnew_rdd = test_rdd.flatMap(lambda x: x)\nnew_rdd.toDF().where(\"organic_download + paid_download!=total \").show()\n\n\n# df_plploxy.createOrReplaceTempView(\"old\")\n# df_citus.createOrReplaceTempView(\"new\")\n\n# spark.sql(\"\")\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200506-091459_596490589","metadata":{},"outputs":[],"source":["\n\nimport psycopg2\nimport datetime\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nimport aaplproxy\nfrom aadatapipelinecore.core.urn import Urn\nfrom aaplproxy.da.local_sqlrunner import LocalSqlRunner\nfrom aadatapipelinecore.core.utils.module import application_settings\nfrom pyspark.sql import Row\n\ndevice_code=[\"ios-phone\",\"ios-tablet\",\"android-all\"]\n\ndef citus_row(test_data):\n    def get_data_in_citus(date , device_code):\n        citus_dsn_ = (\n            \"dbname='{db}' user='{user}' password='{password}' \"\n            \"host='{host}' port='{port}'\".format(\n                db=\"aa_citus_db\",\n                user=\"citus_bdp_usage_qa\",\n                host=\"10.2.10.132\",\n                password=\"dNzWtSV3pKTx\",\n                port=5432\n            )\n        )\n        sql = '''SELECT \n                    CAST((SUM(est_free_app_download) + SUM(est_paid_app_download)) AS INT) AS total,\n                    CAST(SUM(est_organic_download) AS INT) as est_organic_download, \n                    CAST(SUM(est_paid_download) AS INT) as est_paid_download\n                    FROM store.store_est_fact_v6 \n                    WHERE date='{}' \n                    AND device_code='{}' \n                    AND granularity='daily' '''.format(date, device_code)\n        \n        db_data = query(citus_dsn_, sql)\n        return db_data\n\n    def query(dsn, sql):\n        with psycopg2.connect(dsn) as conn:\n            conn.autocommit = True\n            with conn.cursor() as cur:\n                cur.execute(sql)\n                result = cur.fetchall()\n                conn.commit()\n        return result\n    \n    result = get_data_in_citus(test_data[0], test_data[1])\n    # print result\n\n    return [Row(total=r[0], organic_download=r[1], paid_download=r[2], date=test_data[0], device=test_data[1]) for r in result]\n\n\ntest_rdd = sc.parallelize(map(citus_row, test_data), 2).cache()\n\nimport pyspark\ntest_rdd.unpersist()\nprint test_rdd.persist(pyspark.StorageLevel.MEMORY_AND_DISK)\ntest_rdd.getStorageLevel()\nprint(test_rdd.getStorageLevel())\nprint test_rdd.take(1)\nnew_rdd = test_rdd.flatMap(lambda x: x)\nnew_rdd.toDF().where(\"organic_download + paid_download!=total \").show()\n\n\n# df_plploxy.createOrReplaceTempView(\"old\")\n# df_citus.createOrReplaceTempView(\"new\")\n\n# spark.sql(\"\")\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200506-092528_532083986","metadata":{},"outputs":[],"source":["\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}