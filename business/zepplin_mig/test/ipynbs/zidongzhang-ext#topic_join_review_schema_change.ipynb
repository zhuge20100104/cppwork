{"cells":[{"cell_type":"code","execution_count":0,"id":"20200311-031643_424117576","metadata":{},"outputs":[],"source":["%md\n1. check count: distinct count group by process date (find the latest data), compared with topic data and  load to DB data:\ntopic data, please use delta lake to read\n`s3://b2c-prod-data-pipeline-unified-advancedreview/unified/advancedreview.topic.v1/fact/ `\nload to db data:\n`s3://b2c-prod-data-pipeline-unified-advancedreview/_obsolete/`\n            a.  PRE aa.adv_join_201908_20200116_1/\n            b.  PRE aa.adv_join_20200116_2020024_2/\n            c.  PRE aa.adv_join_20200220_202003_3/\n            d. `s3://b2c-prod-data-pipeline-unified-advancedreview/_obsolete/aa.adv_join_20200306_20200310/`\n2. Pick data in a, b, c , compared 10 review details of each folder:\n\t\t    a.  review data:    `s3://b2c-prod-data-pipeline-unified-review/unified/review_load_temp/review_agg_v3/`\n\t\t    b.  review data:    `s3://b2c-prod-data-pipeline-unified-review/unified/review.v1/fact/` + where (process date between 2020-01-16 and 2020-02-24 )\n            c.  review data:    `s3://b2c-prod-data-pipeline-unified-review/unified/review.v4/fact/` + where ( process date between 2020-02-20 and 2020-03-07 ) , use delta lake\n            d.  review data:   `s3://b2c-prod-data-pipeline-unified-review/unified/review.v4/fact/` + where ( process date between 2020-03-07 and 2020-03-10 ) , use delta lake\n3. Find not joined data topic:\nwrite not join data with review_id, topic, process date, event date, to\n`s3://b2c-prod-data-pipeline-qa/aa.review/adv_not_join/`"]},{"cell_type":"code","execution_count":0,"id":"20200311-032801_1262603502","metadata":{},"outputs":[],"source":["%%sh\naws s3 ls \"s3://b2c-prod-data-pipeline-unified-advancedreview/unified/advancedreview.topic.v1/fact/\" "]},{"cell_type":"code","execution_count":0,"id":"20200311-033120_1144225287","metadata":{},"outputs":[],"source":["%%sh\naws s3 ls \"s3://b2c-prod-data-pipeline-unified-advancedreview/_obsolete/\""]},{"cell_type":"code","execution_count":0,"id":"20200311-091527_1662505159","metadata":{},"outputs":[],"source":["%%sh\n"]},{"cell_type":"code","execution_count":0,"id":"20200311-052621_1968878714","metadata":{},"outputs":[],"source":["\ntopic_test_path = \"s3://b2c-prod-data-pipeline-unified-advancedreview/unified/advancedreview.topic.v1/fact/\"\ndf_topic_test = spark.read.format('delta').load(topic_test_path)\ndf_topic_test.show(4, True, True)"]},{"cell_type":"code","execution_count":0,"id":"20200311-052914_1365203567","metadata":{},"outputs":[],"source":["\nload_test_paths = [\"s3://b2c-prod-data-pipeline-unified-advancedreview/_obsolete/aa.adv_join_201908_20200116_1/event_month=*\", \\\n                   \"s3://b2c-prod-data-pipeline-unified-advancedreview/_obsolete/aa.adv_join_20200116_2020024_2/event_month=*\", \\\n                   \"s3://b2c-prod-data-pipeline-unified-advancedreview/_obsolete/aa.adv_join_20200220_202003_3/event_month=*\", \\\n                   \"s3://b2c-prod-data-pipeline-unified-advancedreview/_obsolete/aa.adv_join_20200306_20200310/event_month=*\"]\ndf_load_test = spark.read.parquet(*load_test_paths)\ndf_load_test.show(4, True, True)"]},{"cell_type":"code","execution_count":0,"id":"20200311-060516_1710143627","metadata":{},"outputs":[],"source":["\nprint(\"Before grouped topic data:\", df_topic_test.count())\ndf_topic_grouped = df_topic_test.groupby(\"review_id\").agg({\"process_date\": \"max\"})\ndf_topic_grouped_count = df_topic_grouped.count()\nprint(\"After grouped topic data:\", df_topic_grouped_count)\ndf_topic_selected = df_topic_grouped.select(\"review_id\")\n\ndf_load_selected = df_load_test.select(\"review_id\")\n\ndf_except = df_topic_selected.subtract(df_load_selected)"]},{"cell_type":"code","execution_count":0,"id":"20200311-075628_971834195","metadata":{},"outputs":[],"source":["\ndf_topic_test2 = df_topic_test.select(\"review_id\", \"process_date\", \"date\", \"topic_ids\").withColumnRenamed('review_id', 'key')\ndf_not_joined = df_topic_test2.join(df_except, df_topic_test2.key==df_except.review_id, 'right_outer').select('review_id', 'process_date', 'date', 'topic_ids')\n\ndf_not_joined.show(3)\n\na = df_load_test.where(\"review_id='5400356011'\")\na.show()"]},{"cell_type":"code","execution_count":0,"id":"20200311-113416_2037410240","metadata":{},"outputs":[],"source":["\ndf_not_joined.coalesce(1).write.mode(\"overwrite\").parquet(\"s3://b2c-prod-data-pipeline-qa/aa.review/adv_not_join\")"]},{"cell_type":"code","execution_count":0,"id":"20200311-113939_461685526","metadata":{},"outputs":[],"source":["\ndf_not_joined_test = spark.read.parquet(\"s3://b2c-prod-data-pipeline-qa/aa.review/adv_not_join/\")\ndf_not_joined_test.show(3)\ndf_not_joined.groupby(\"process_date\").count().show(100)"]},{"cell_type":"code","execution_count":0,"id":"20200312-093845_2120873416","metadata":{},"outputs":[],"source":["\ndf_dev_not_join = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-advancedreview/_obsolete/aa.adv_not_join_201907_20200310_not_fix/\")\nprint df_dev_not_join.count()\nprint spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-advancedreview/_obsolete/aa.adv_not_join_201907_20200310_fix/\").count()\nprint df_dev_not_join.printSchema()"]},{"cell_type":"code","execution_count":0,"id":"20200311-073406_1645734147","metadata":{},"outputs":[],"source":["\nprint(\"After subtracting\", df_except.count())\n\ndf_anti_except = df_load_selected.subtract(df_topic_selected)\nprint(\"anti subtracting\", df_anti_except.count())"]},{"cell_type":"code","execution_count":0,"id":"20200311-033438_854508361","metadata":{},"outputs":[],"source":["\ndf = spark.createDataFrame([('111', '2020-02-01'),('222', '2020-02-02'), ('333', '2020-02-03'), ('222', '2020-02-03')],[\"review_id\", \"date\"])\ndf.show()\n# df.groupby(\"review_id\").agg({\"date\": \"max\"}).show()\ndf2 = spark.createDataFrame([('111', '2020-02-01'), ('444', '2020-02-20')],[\"review_id\", \"date\"])\ndf2 = df2.select(\"review_id\")\ndf2 = df2.withColumnRenamed(\"review_id\", \"key\")\ndf2.show()\n\ndf3 = df.join(df2, df.review_id==df2.key, 'right').select(\"key\", \"date\")\ndf3.show()\n\n# print df[df.review_id.isin(['111'])].collect()\n# df3 = df.subtract(df2)\n# df3.show()\n\ndf.head(1)"]},{"cell_type":"code","execution_count":0,"id":"20200311-034159_2015950625","metadata":{},"outputs":[],"source":["%md\n1. check count: distinct count group by process date (find the latest data), compared with topic data and  load to DB data:\ntopic data, please use delta lake to read\n`s3://b2c-prod-data-pipeline-unified-advancedreview/unified/advancedreview.topic.v1/fact/ `\nload to db data:\n`s3://b2c-prod-data-pipeline-unified-advancedreview/_obsolete/`\n            a.  PRE aa.adv_join_201908_20200116_1/\n            b.  PRE aa.adv_join_20200116_2020024_2/\n            c.  PRE aa.adv_join_20200220_202003_3/\n2. Pick data in a, b, c , compared 10 review details of each folder:\n\t\t    a.  review data:    `s3://b2c-prod-data-pipeline-unified-review/unified/review_load_temp/review_agg_v3/`\n\t\t    b.  review data:    `s3://b2c-prod-data-pipeline-unified-review/unified/review.v1/fact/` + where (process date between 2020-01-16 and 2020-02-24 )\n            c.  review data:    `s3://b2c-prod-data-pipeline-unified-review/unified/review.v4/fact/` + where ( process date between 2020-02-20 and 2020-03-07 ) , use delta lake\n3. Find not joined data topic:\nwrite not join data with review_id, topic, process date, event date, to\n`s3://b2c-prod-data-pipeline-qa/aa.review/adv_not_join/`"]},{"cell_type":"code","execution_count":0,"id":"20200311-094554_474281143","metadata":{},"outputs":[],"source":["%md\n## Review Data ------------------------------------------------------------------------------------------"]},{"cell_type":"code","execution_count":0,"id":"20200311-091017_744618804","metadata":{},"outputs":[],"source":["%%sh\naws s3 ls s3://b2c-prod-data-pipeline-unified-review/unified/review_load_temp/review_agg_v3/event_month=2019-06/ --recursive --human --summarize | tail -5"]},{"cell_type":"code","execution_count":0,"id":"20200311-091435_526319965","metadata":{},"outputs":[],"source":["%%sh\naws s3 ls s3://b2c-prod-data-pipeline-unified-review/unified/review.v1/fact/process_granularity=daily/"]},{"cell_type":"code","execution_count":0,"id":"20200311-091619_2067071828","metadata":{},"outputs":[],"source":["%%sh\naws s3 ls s3://b2c-prod-data-pipeline-unified-review/unified/review.v4/fact/process_granularity=daily/"]},{"cell_type":"code","execution_count":0,"id":"20200311-091124_1951489162","metadata":{},"outputs":[],"source":["%md\n## Load to DB Data------------------------------------------------------------------------------------------"]},{"cell_type":"code","execution_count":0,"id":"20200311-093704_714104356","metadata":{},"outputs":[],"source":["%%sh\naws s3 ls s3://b2c-prod-data-pipeline-unified-advancedreview/_obsolete/aa.adv_join_201908_20200116_1/event_month=2019-06/ --recursive --human --summarize | tail -2\n"]},{"cell_type":"code","execution_count":0,"id":"20200311-093838_1626026305","metadata":{},"outputs":[],"source":["%%sh\naws s3 ls s3://b2c-prod-data-pipeline-unified-advancedreview/_obsolete/aa.adv_join_20200116_2020024_2/"]},{"cell_type":"code","execution_count":0,"id":"20200311-093946_543795188","metadata":{},"outputs":[],"source":["%%sh\naws s3 ls s3://b2c-prod-data-pipeline-unified-advancedreview/_obsolete/aa.adv_join_20200220_202003_3/"]},{"cell_type":"code","execution_count":0,"id":"20200311-091127_963922642","metadata":{},"outputs":[],"source":["\n# df_b = spark.read.parquet('s3://b2c-prod-data-pipeline-unified-review/unified/review.v1/fact/process_granularity=daily/process_date=2017-06-21/')\nspark.read.format(\"delta\").parquet(\"s3://b2c-prod-data-pipeline-unified-advancedreview/unified/advancedreview.topic.v1/fact/\").where(\"review_id='5549512716'\").show()\n# df_b.where(\"process_granularity='daily' and process_date='2017-06-10' and process_hour=23 and device_code='ios-all' and market_code='apple-store'\")\n# df_b.show(4, True, True)\n# row_10_load_data = df_load_test.take(10)\n# df_load_test.show(10, True, True)\n# review_id_list = [row['review_id'] for row in row_10_load_data]\n# for review_id in review_id_list:\n# a = df_b.where(\"review_id='4866938646'\")\n# print a\n# df_b.show(2, True, True)"]},{"cell_type":"code","execution_count":0,"id":"20200311-092522_150933151","metadata":{},"outputs":[],"source":["\na.show()"]},{"cell_type":"code","execution_count":0,"id":"20200311-103836_876573205","metadata":{},"outputs":[],"source":["\ndef detail_check(num, picked_data_path, delta1, source_data_path, delta2, condition=None):\n    def read_data(path, delta, condition):\n        '''\n        check data format (delta lake or not)\n        '''\n        if delta:\n            return spark.read.format('delta').load(path).where(condition)\n        return spark.read.parquet(path).where(condition)\n        \n    # Read data from s3 path\n    df_picked_data = read_data(picked_data_path, delta1, condition)\n    df_source_data = read_data(source_data_path, delta2, condition) \n    \n    # Review id list from picked data\n    row_picked_data = df_picked_data.take(10)\n    \n    print \"row_picked_data:\", row_picked_data\n    \n    review_id_list = [row['review_id'] for row in row_picked_data]\n    \n    print \"review_id_list:\", review_id_list\n    \n    # Search picked data in source data\n    row_source_data = []\n    for review_id in review_id_list:\n        print \"review_id = \", review_id\n        row_source_data.append(df_source_data.where(\"review_id='{}'\".format(review_id)).collect()[0])\n        print row_source_data\n    \n    return df_picked_data, df_source_data, row_picked_data, row_source_data\n\n\n\n\nload_data_path =  \"s3://b2c-prod-data-pipeline-unified-advancedreview/_obsolete/aa.adv_join_201908_20200116_1/\"\nreview_data_path = \"s3://b2c-prod-data-pipeline-unified-review/unified/review_load_temp/review_agg_v3/\"\ncondition = \"event_month='2019-06'\"\ndf_picked_data, df_source_data, row_picked_data, row_source_data = detail_check(10, load_data_path, False, review_data_path, False, condition)"]},{"cell_type":"code","execution_count":0,"id":"20200312-063310_1451209094","metadata":{},"outputs":[],"source":["\nload_data_path =  \"s3://b2c-prod-data-pipeline-unified-advancedreview/_obsolete/aa.adv_join_201908_20200116_1/\"\nreview_data_path = \"s3://b2c-prod-data-pipeline-unified-review/unified/review_load_temp/review_agg_v3/\"\ndf_review_data = spark.read.parquet(review_data_path).where(\"event_month='2019-10'\")\ndf_review_data.where(\"app_id='1084930849' and country_code='CA' and review_id='4866884041'\").show()"]},{"cell_type":"code","execution_count":0,"id":"20200312-022723_142214241","metadata":{},"outputs":[],"source":["\nprint [i['review_id'] for i in row_picked_data]\nprint [i['content'] for i in row_source_data]==[i['content'] for i in row_picked_data]\nprint \"Done\""]},{"cell_type":"code","execution_count":0,"id":"20200312-030907_1847022517","metadata":{},"outputs":[],"source":["\ndef detail_check(num, picked_data_path, delta1, condition1, source_data_path, delta2, condition2):\n    def read_data(path, delta, condition):\n        '''\n        check data format (delta lake or not)\n        '''\n        if delta:\n            df = spark.read.format('delta').load(path)\n        df = spark.read.parquet(path)\n        if condition:\n            return df.where(condition)\n        return df\n        \n    # Read data from s3 path\n    df_picked_data = read_data(picked_data_path, delta1, condition1)\n    df_source_data = read_data(source_data_path, delta2, condition2)\n    \n    # Review id list from picked data\n    row_picked_data = df_picked_data.take(10)\n    \n    print \"row_picked_data:\", row_picked_data\n    \n    review_id_list = [row['review_id'] for row in row_picked_data]\n    \n    print \"review_id_list:\", review_id_list\n    \n    # Search picked data in source data\n    row_source_data = []\n    for review_id in review_id_list:\n        print \"review_id = \", review_id\n        row_source_data.append(df_source_data.where(\"review_id='{}'\".format(review_id)).collect()[0])\n        print row_source_data\n    \n    return df_picked_data, df_source_data, row_picked_data, row_source_data\n    \n\nload_data_path =  \"s3://b2c-prod-data-pipeline-unified-advancedreview/_obsolete/aa.adv_join_20200116_2020024_2/\"\nreview_data_path = \"s3://b2c-prod-data-pipeline-unified-review/unified/review.v1/fact/process_granularity=daily/\"\ncondition1 = \"event_month='2020-01'\"\ncondition2 = \"process_date>='2020-01-01' and process_date<='2020-02-01'\"\ndf_picked_data_b, df_source_data_b, row_picked_data_b, row_source_data_b = detail_check(10, load_data_path, False, condition1, review_data_path, False, condition2)\n"]},{"cell_type":"code","execution_count":0,"id":"20200312-085706_2146721480","metadata":{},"outputs":[],"source":["\nprint [i['review_id'] for i in row_picked_data_b]\nprint [i['content'] for i in row_source_data_b]==[i['content'] for i in row_picked_data_b]\nprint \"Done\""]},{"cell_type":"code","execution_count":0,"id":"20200312-085750_522947912","metadata":{},"outputs":[],"source":["\ndef detail_check(num, picked_data_path, delta1, condition1, source_data_path, delta2, condition2):\n    def read_data(path, delta, condition):\n        '''\n        check data format (delta lake or not)\n        '''\n        if delta:\n            df = spark.read.format('delta').load(path)\n        df = spark.read.parquet(path)\n        if condition:\n            return df.where(condition)\n        return df\n        \n    # Read data from s3 path\n    df_picked_data = read_data(picked_data_path, delta1, condition1)\n    df_source_data = read_data(source_data_path, delta2, condition2)\n    \n    # Review id list from picked data\n    row_picked_data = df_picked_data.take(10)\n    \n    print \"row_picked_data:\", row_picked_data\n    \n    review_id_list = [row['review_id'] for row in row_picked_data]\n    \n    print \"review_id_list:\", review_id_list\n    \n    # Search picked data in source data\n    row_source_data = []\n    for review_id in review_id_list:\n        print \"review_id = \", review_id\n        row_source_data.append(df_source_data.where(\"review_id='{}'\".format(review_id)).collect())\n        print row_source_data[-1]\n    \n    return df_picked_data, df_source_data, row_picked_data, row_source_data\n    \n\nload_data_path =  \"s3://b2c-prod-data-pipeline-unified-advancedreview/_obsolete/aa.adv_join_20200220_202003_3/\"\nreview_data_path = \"s3://b2c-prod-data-pipeline-unified-review/unified/review.v4/fact/process_granularity=daily/\"\ncondition1 = \"event_month='2020-02'\"\ncondition2 = \"process_date>='2020-02-01' and process_date<='2020-03-01'\"\ndf_picked_data_c, df_source_data_c, row_picked_data_c, row_source_data_c = detail_check(10, load_data_path, False, condition1, review_data_path, False, condition2)\n"]},{"cell_type":"code","execution_count":0,"id":"20200312-091421_1318472556","metadata":{},"outputs":[],"source":["\na = spark.read.parquet(review_data_path).where(\"review_id='5501297572'\")\na.show()"]},{"cell_type":"code","execution_count":0,"id":"20200312-092626_1488308005","metadata":{},"outputs":[],"source":["\na.where(\"time='2020-02*'\").show()"]},{"cell_type":"code","execution_count":0,"id":"20200312-091329_987855434","metadata":{},"outputs":[],"source":["\nprint [i['review_id'] for i in row_picked_data_c]\nprint [i['content'] for i in row_source_data_c]==[i['content'] for i in row_picked_data_c]\nprint \"Done\""]},{"cell_type":"code","execution_count":0,"id":"20200312-034552_1749832951","metadata":{},"outputs":[],"source":["\nload_data_path =  \"s3://b2c-prod-data-pipeline-unified-advancedreview/_obsolete/aa.adv_join_20200116_2020024_2/\"\nreview_data_path = \"s3://b2c-prod-data-pipeline-unified-review/unified/review.v1/fact/process_granularity=daily/\"\ncondition = \"process_date>='2020-02-20' and process_date<='2020-03-07'\"\ndf_picked_data_c, df_source_data_c, row_picked_data_c, row_source_data_c = detail_check(10, load_data_path, False, review_data_path, True)\n"]},{"cell_type":"code","execution_count":0,"id":"20200312-034756_1477883274","metadata":{},"outputs":[],"source":["\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}