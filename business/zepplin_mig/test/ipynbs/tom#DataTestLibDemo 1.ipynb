{"cells":[{"cell_type":"code","execution_count":0,"id":"20211220-031640_233556143","metadata":{},"outputs":[],"source":["%%sh\naws s3 ls s3://aardvark-prod-pdx-mdm-to-int/usage_retention/batch=retention_batch_D7_routine/version=v1.0.0/range_type=MONTH/date=2021-10-31/\n"]},{"cell_type":"code","execution_count":0,"id":"20211220-033345_1347336023","metadata":{},"outputs":[],"source":["\n## Spark Parquet Loader Test Example\n## Load the data test lib to python runtime\nspark.sparkContext.addPyFile(\"s3://b2c-prod-dca-bdp-data/BDP-PROD-APP-INT-QA/bdp/user_data/application_name=aa_data_test_app/application_code/version=latest/code/bdp_resources/usr/lib/spark/python/dependencies.zip\")\n\n# import spark loader\nfrom data_lib.api import spark_loader\n\nloader = spark_loader(spark)\n\np_path = \"s3://aardvark-prod-pdx-mdm-to-int/usage_retention/batch=retention_batch_D7_routine/version=v1.0.0/range_type=MONTH/date=2021-10-31/\"\n\n## Build a temp view in memory called retention\ndf = loader.load_parquet_as_table(p_path, \"retention\")\n\nprint(df.count())\ndf_metrics_names = spark.sql(\"select distinct(metric_name) from retention\")\ndf_metrics_names.show(df_metrics_names.count())\n"]},{"cell_type":"code","execution_count":0,"id":"20211220-032955_953664368","metadata":{},"outputs":[],"source":["  \n## Convert narrow table to wide example\nfrom pyspark.sql.functions import *\nfrom data_lib.api import NarrowToWideParams, convert_narrow_table_to_wide\nfrom data_lib.api import spark_loader\n\nloader = spark_loader(spark)\np_path = \"s3://b2c-prod-data-pipeline-qa/fredric/retention_data_2021_10_31/\"\ndf = loader.load_parquet_as_table(p_path, \"retention_narrow\")\n\ndf.show(1, False)\n\nnarrow_to_wide_p = NarrowToWideParams(\"retention_narrow\", [\"app_id\", \"device_type\", \"country\", \"age\", \"gender\", \"platform\"], \"metric_name\", [\"RRD0\", \"RRD1\", \"RRD2\", \"RRD3\", \"RRD4\", \"RRD5\", \"RRD6\", \"RRD7\"], \"value\", None)\nwide_df = convert_narrow_table_to_wide(spark, narrow_to_wide_p)\n\n## Save wide df to a new path of QA s3\n# wide_df.write.parquet(\"s3://b2c-prod-data-pipeline-qa/fredric/retention_data_2021_10_31_wide/\")\n\nwide_df.show(5, False)\n\n"]},{"cell_type":"code","execution_count":0,"id":"20211220-034752_1590476511","metadata":{},"outputs":[],"source":["\n\nfrom pyspark.sql.functions import *\nfrom data_lib.api import spark_loader\nfrom data_lib.api.data_op import compare_columns_and_get_result_df\n\n## Load wide df & do some comparison\n\nloader = spark_loader(spark)\np_path = \"s3://b2c-prod-data-pipeline-qa/fredric/retention_data_2021_10_31_wide/\"\nwide_df = loader.load_parquet_as_table(p_path, \"retention_narrow\")\n\nprint(wide_df.count())\n\nsf_df = loader.load_sf_as_table(\"select * from AA_INTELLIGENCE_PRODUCTION.ADL_USAGE_PAID.FACT_USAGE_RETENTION_DAY_V1_CLUSTER_BY_DATE where date_key=20211031 \", \"retention_sf\")\nprint(sf_df.count())\n\njoined_df = wide_df.join(sf_df, [wide_df.app_id==sf_df.PRODUCT_KEY, wide_df.country==sf_df.COUNTRY_CODE,  wide_df.device_type==sf_df.DEVICE_KEY], \"inner\")\n\njoined_df = joined_df.withColumn(\"RRD1_SRC\", (col(\"EST_TOTAL_RETENTION_USERS_D0\") * col(\"RRD1\")).cast(\"int\")) \\\n    .withColumn(\"RRD2_SRC\",  (col(\"EST_TOTAL_RETENTION_USERS_D0\") * col(\"RRD2\")).cast(\"int\")) \\\n    .withColumn(\"RRD1_DST\", col(\"EST_TOTAL_RETENTION_USERS_D1\").cast(\"int\")) \\\n    .withColumn(\"RRD2_DST\", col(\"EST_TOTAL_RETENTION_USERS_D2\").cast(\"int\"))\n    \nres_df = compare_columns_and_get_result_df(joined_df, [\"RRD1_SRC\", \"RRD2_SRC\"], [\"RRD1_DST\", \"RRD2_DST\"])\n\nequals_df = res_df.filter(col(\"cal_result\") == True)\nnot_equals_df = res_df.filter(col(\"cal_result\") == False)\nprint(equals_df.count())\nprint(not_equals_df.count())\n\nnot_equals_df.show(1)\n"]},{"cell_type":"code","execution_count":0,"id":"20211220-035403_640032694","metadata":{},"outputs":[],"source":["\n\n## Extended\n## Apache Arrow Loader, a C++ based column-storaged library.\nfrom data_lib.api import arrow_loader\n\nloader = arrow_loader() \nquery = \"select * from AA_INTELLIGENCE_PRODUCTION.ADL_USAGE_PAID.FACT_USAGE_RETENTION_DAY_V1_CLUSTER_BY_DATE where date_key=20211031\"\ndf_table = loader.load_sf(query)\n\nis_greater_than_zero = True\nfor i in range(0, len(df_table)):\n    r_d1 = df_table[\"EST_TOTAL_RETENTION_USERS_D1\"][i].as_py()\n    if r_d1 is not None and  r_d1 < 0:\n        print(r_d1)\n        is_greater_than_zero = False\n        break\n\nassert is_greater_than_zero is True, \"Test retention_d1 greater than zero failed\"\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20211220-105154_449290418","metadata":{},"outputs":[],"source":["\n\n## Extended\n## Pandas loader \n\nfrom data_lib.api import pd_loader\n\nloader = pd_loader() \nquery = \"select * from AA_INTELLIGENCE_PRODUCTION.ADL_USAGE_PAID.FACT_USAGE_RETENTION_DAY_V1_CLUSTER_BY_DATE where date_key=20211031\"\ndf_table = loader.load_sf(query)\n\ni = 0\nis_greater_than_zero = True\nfor _, row in df_table.iterrows():\n    r_d1 = row[\"EST_TOTAL_RETENTION_USERS_D1\"]\n    if r_d1 is not None and  r_d1 < 0:\n        is_greater_than_zero = False\n        break\n\nassert is_greater_than_zero is True, \"Test retention_d1 greater than zero failed\"\n\n    \n"]},{"cell_type":"code","execution_count":0,"id":"20211220-115956_1269680208","metadata":{},"outputs":[],"source":["\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}