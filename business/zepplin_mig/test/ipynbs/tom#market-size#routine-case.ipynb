{"cells":[{"cell_type":"code","execution_count":0,"id":"20200216-084246_1070404385","metadata":{},"outputs":[],"source":["\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/code.zip\")\nimport pandas as pd\npd.set_option('expand_frame_repr', False)\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200218-123522_159859745","metadata":{},"outputs":[],"source":["\nfrom bdce.common.utils import update_application_code\nupdate_application_code(\n    spark, role=\"BDP-PROD-APP-INT-QA\", application_name=\"aa-int-qa-db-check\"\n)\nspark.sparkContext.addPyFile(\"/tmp/zeppelin_application_code/libs/python/dependencies.zip\")\n"]},{"cell_type":"code","execution_count":0,"id":"20200218-123609_589014058","metadata":{},"outputs":[],"source":["\n\nfrom applications.db_check_v1.db_check import send_message\nsend_message()"]},{"cell_type":"code","execution_count":0,"id":"20200215-035851_932187271","metadata":{},"outputs":[],"source":["\n\n# Copyright (c) 2018 App Annie Inc. All rights reserved.\n# pylint: disable=E1101,C0412\n\n# Copyright (c) 2018 App Annie Inc. All rights reserved.\n# pylint: disable=E1101,C0412\n\n\"\"\"\nDB Check modules\n\"\"\"\n\nimport datetime\nfrom applications.db_check_v1.common.base_test import PipelineTest\nfrom applications.db_check_v1.common.db_check_utils import query_df, _get_pre_date_from_refresh_routing_config, _get_date_from_refresh_routing_config\nfrom pyspark.sql.types import LongType, IntegerType, StringType, StructType, StructField\nfrom applications.db_check_v1.common.constants import COUNTRY_CODE_MAPPING_BY_MARKET_CODE as COUNTRY_CODE_MAPPING, \\\n    CATEGORY_ID_MAPPING_BY_MARLKET_AND_DEVICE_CODE as CATEGORY_ID_MAPPING\nfrom applications.db_check_v1.common.utils import get_week_start_end_date\nfrom applications.db_check_v1.cases.store.market_size_v1.constants import MARKET_SIZE_DSN\nimport pandas as pd\n\n\nfrom functools import wraps\n\n\ndef etl_skip(delta_days=1):\n    def inner_function(func):\n        @wraps(func)\n        def wrapper(self, *args, **kwargs):\n            pre_etl_date = _get_pre_date_from_refresh_routing_config( self.routing_config)\n            trigger_datetime = self.trigger_datetime or datetime.datetime.utcnow()\n            skipped_condition = trigger_datetime - pre_etl_date > datetime.timedelta(days=delta_days)\n            skipped_reason = \"The trigger time {} is not in the {} * 24hrs after the ETL completed time {}.\".format(\n                trigger_datetime, delta_days, pre_etl_date\n            )\n\n            @skipIf(skipped_condition, skipped_reason)\n            def inner_func(self, *args, **kwargs):\n                return func(self, *args, **kwargs)\n\n            inner_func(self, *args, **kwargs)\n        return wrapper\n    return inner_function\n\n\nclass MarketSizeRawData(object):\n    raw_s3_path = \"s3://b2c-prod-dca-store-estimates/store_estv2/MARKET_SIZE_ESTIMATES_FINAL/\" \\\n                  \"version=2.0.0/range_type=DAY/date={date}/\"\n    device_code_mapping = {\n        \"0google-play\": \"android-all\",\n        \"1ios\": \"ios-all\",\n        \"1ipad\": \"ios-tablet\",\n        \"1iphone\": \"ios-phone\",\n    }\n\n    metric_mapping = {\n        \"downloads\": \"est_market_size_download\",\n        \"revenue\": \"est_market_size_revenue\"\n    }\n\n    dimension_mapping = {\n        \"price_type\": \"app_price_type_id\",\n        \"purchase_type\": \"purchase_type_id\"\n    }\n\n    def __init__(self, spark):\n        self.spark = spark\n\n    def get(self, date):\n        df = self._get_raw_data_by_date(date)\n        df = self._parse_mapping(df)\n        df = self._parse_unified_format(df)\n        df = self._data_clean_up(df)\n        return df\n\n    def _data_clean_up(self, df):\n        # clean unknown mapping\n        category_id_list = list(set(CATEGORY_ID_MAPPING[\"apple-store\"][\"ios-all\"].values() +\n                                    CATEGORY_ID_MAPPING[\"google-play\"][\"android-all\"].values()))\n\n        country_code_list = list(set(COUNTRY_CODE_MAPPING[\"apple-store\"].values() +\n                                     COUNTRY_CODE_MAPPING[\"google-play\"].values()))\n\n        df = df[(df['category_id'].isin(category_id_list)) & (df['country_code'].isin(country_code_list))]\n        return df\n\n    def _parse_mapping(self, df):\n        # country_code mapping\n        df.loc[df[\"platform_id\"] == 0] = df.loc[df[\"platform_id\"] == 0].\\\n            replace({\"store_id\": COUNTRY_CODE_MAPPING[\"google-play\"]})\n        df.loc[df[\"platform_id\"] == 1] = df.loc[df[\"platform_id\"] == 1].\\\n            replace({\"store_id\": COUNTRY_CODE_MAPPING[\"apple-store\"]})\n        df = df.rename(columns={'store_id': 'country_code'})\n\n        # category_id mapping\n        df.loc[df[\"platform_id\"] == 0] = df.loc[df[\"platform_id\"] == 0].\\\n            replace({\"category_id\": CATEGORY_ID_MAPPING[\"google-play\"][\"android-all\"]})\n        df.loc[df[\"platform_id\"] == 1] = df.loc[df[\"platform_id\"] == 1].\\\n            replace({\"category_id\": CATEGORY_ID_MAPPING[\"apple-store\"][\"ios-all\"]})\n\n        # device_code mapping\n        df[\"device_code\"] = df[\"platform_id\"].astype(str) + df[\"device\"]\n        df = df.replace({\"device_code\": self.device_code_mapping})\n        return df\n\n    def _parse_unified_format(self, df):\n        df = df.rename(columns=self.dimension_mapping)\n        df = df.pivot_table(index=[\"app_price_type_id\", \"purchase_type_id\", \"category_id\",\n                                   \"device_code\", \"country_code\"], columns='data_type', values='estimate')\n        df.reset_index(inplace=True)\n        df.columns.name = None\n        df = df.rename(columns=self.metric_mapping)\n        return df\n\n    def _get_raw_data_by_date(self, date):\n        \"\"\"\n        +--------+----------+-----------+-----------+---------+----------+-------------+-----------+--------+\n        |store_id|      date|platform_id|     device|data_type|price_type|purchase_type|category_id|estimate|\n        +--------+----------+-----------+-----------+---------+----------+-------------+-----------+--------+\n        |      10|2020-01-10|          0|google-play|downloads|         1|           10|          1|11981138|\n        +--------+----------+-----------+-----------+---------+----------+-------------+-----------+--------+\n        \"\"\"\n        schema = StructType([\n            StructField(\"store_id\", IntegerType(), False),\n            StructField(\"date\", StringType(), False),\n            StructField(\"platform_id\", IntegerType(), False),\n            StructField(\"device\", StringType(), False),\n            StructField(\"data_type\", StringType(), False),\n            StructField(\"price_type\", IntegerType(), False),\n            StructField(\"purchase_type\", IntegerType(), False),\n            StructField(\"category_id\", IntegerType(), False),\n            StructField(\"estimate\", LongType(), False)\n        ])\n        raw_df = self.spark.read.parquet(self.raw_s3_path.format(date=date))\n        return raw_df.toPandas()\n\n    def get_rank_count_and_sum_by_date(self, date):\n        pass\n        # return raw_count, raw_sum\n\n\nclass MarketSizeUnifiedData(object):\n    unified_s3_path = \"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.market-size.v1/fact/\" \\\n                      \"granularity=daily/date={}/\"\n\n    def __init__(self, spark):\n        self.spark = spark\n\n    def get(self, date):\n        unified_df = self.spark.read.parquet(self.unified_s3_path.format(date)).toPandas()\n        unified_df = unified_df.drop([\"_identifier\"], axis=1)\n        return unified_df\n\n\nclass MarketSizeDBData(object):\n    def get(self, date):\n        sql = \"SELECT * FROM store.store_market_size_fact_v1  WHERE date='{}'\".format(date)\n        return query_df(MARKET_SIZE_DSN, sql)\n\n\nclass TestMarketSizeDaily(PipelineTest):\n    # Every Tuesday 16:00 UTC time will refresh the data of last Full Week.\n    routing_config = ('* 16 * * 2', 3)\n    \n    def __init__(self, methodName='runTest', trigger_datetime=None):\n        super(TestMarketSizeDaily, self).__init__(methodName, trigger_datetime)\n\n    def _compare_df(self, df1, df2):\n        for diff_type in [\"left\", \"right\"]:\n            diff_df = df1.merge(df2, indicator=True, how=diff_type)  # .loc[lambda x : x['_merge']!='both']\n            diff_df = diff_df.loc[diff_df[\"_merge\"] != \"both\"]\n            if len(diff_df) != 0:\n                print diff_type\n                print diff_df.country_code.unique()\n                print diff_df.category_id.unique()\n                print diff_df.device_code.unique()\n            self.assertEqual(len(diff_df), 0)\n\n    @etl_skip(delta_days=1)\n    def test_market_size_etl_accuracy_and_completeness(self):\n        # Every Tuesday 16:00 UTC time will refresh the data of last Full Week.\n        start_date, end_date = get_week_start_end_date(self.check_date_str)\n        date_list = get_date_list(start_date, end_date)\n        for date in date_list:\n            print date\n            raw_df = MarketSizeRawData(self.spark).get(date)\n            unified_df = MarketSizeUnifiedData(self.spark).get(date)\n            db_db = MarketSizeDBData().get(date)\n\n            self._compare_df(raw_df, unified_df)\n            self._compare_df(unified_df, db_db)\n        self.assertEqual(1, 0)\n\n    def test_market_size_etl_timelines(self):\n        # Every Tuesday 16:00 UTC time will refresh the data of last Full Week.\n        # E.g. 2020-02-11 17:00 the data of 2020-02-02 ~ 2020-02-08 will be ready\n        trigger_datetime = datetime.datetime.strptime(\"2020-02-11 17:00:00\", '%Y-%m-%d %H:%M:%S')\n        check_date_str_actual = self._get_check_date_from_routing_config(trigger_datetime).strftime(\"%Y-%m-%d\")\n        self.assertEqual(\"2020-02-08\", check_date_str_actual)\n\n\ndef get_date_list(start_date, end_date, freq=\"D\"):\n    date_list = [x.strftime('%Y-%m-%d') for x in list(pd.date_range(start=start_date, end=end_date, freq=freq))]\n    return date_list\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200217-035327_2018961537","metadata":{},"outputs":[],"source":["\n\n# raw_df = MarketSizeRawData(spark)._get_raw_data_by_date(\"2019-12-09\")\n\nprint raw_df\n\nraw_df[raw_df[store_id]==]\n"]},{"cell_type":"code","execution_count":0,"id":"20200226-015734_1276962845","metadata":{},"outputs":[],"source":["\n\n# Copyright (c) 2018 App Annie Inc. All rights reserved.\n# pylint: disable=E1101,C0412,C1801\n\n\"\"\"\nDB Check modules\n\"\"\"\n\nimport datetime\nfrom applications.db_check_v1.common.base_test import PipelineTest\nfrom applications.db_check_v1.common.db_check_utils import query_df, etl_skip\nfrom applications.db_check_v1.common.constants import COUNTRY_CODE_MAPPING_BY_MARKET_CODE as COUNTRY_CODE_MAPPING, \\\n    CATEGORY_ID_MAPPING_BY_MARLKET_AND_DEVICE_CODE as CATEGORY_ID_MAPPING\nfrom applications.db_check_v1.common.utils import get_week_start_end_date, get_date_list\nfrom applications.db_check_v1.cases.store.market_size_v1.constants import MARKET_SIZE_DSN\n\n\nclass MarketSizeRawData(object):\n    raw_s3_path = \"s3://b2c-prod-dca-store-estimates/store_estv2/MARKET_SIZE_ESTIMATES_FINAL/\" \\\n                  \"version=2.0.0/range_type=DAY/date={date}/\"\n    device_code_mapping = {\n        \"0google-play\": \"android-all\",\n        \"1ios\": \"ios-all\",\n        \"1ipad\": \"ios-tablet\",\n        \"1iphone\": \"ios-phone\",\n    }\n\n    metric_mapping = {\n        \"downloads\": \"est_market_size_download\",\n        \"revenue\": \"est_market_size_revenue\"\n    }\n\n    dimension_mapping = {\n        \"price_type\": \"app_price_type_id\",\n        \"purchase_type\": \"purchase_type_id\"\n    }\n\n    def __init__(self, spark):\n        self.spark = spark\n\n    def get(self, date):\n        df = self._get_raw_data_by_date(date)\n        df = self._parse_mapping(df)\n        df = self._parse_unified_format(df)\n        df = self._data_clean_up(df)\n        return df\n\n    def _data_clean_up(self, df):\n        # clean unknown mapping\n        category_id_list = list(set(CATEGORY_ID_MAPPING[\"apple-store\"][\"ios-all\"].values() +\n                                    CATEGORY_ID_MAPPING[\"google-play\"][\"android-all\"].values()))\n\n        country_code_list = list(set(COUNTRY_CODE_MAPPING[\"apple-store\"].values() +\n                                     COUNTRY_CODE_MAPPING[\"google-play\"].values()))\n\n        df = df[(df['category_id'].isin(category_id_list)) & (df['country_code'].isin(country_code_list))]\n        return df\n\n    def _parse_mapping(self, df):\n        # country_code mapping\n        df.loc[df[\"platform_id\"] == 0] = df.loc[df[\"platform_id\"] == 0].\\\n            replace({\"store_id\": COUNTRY_CODE_MAPPING[\"google-play\"]})\n        df.loc[df[\"platform_id\"] == 1] = df.loc[df[\"platform_id\"] == 1].\\\n            replace({\"store_id\": COUNTRY_CODE_MAPPING[\"apple-store\"]})\n        df = df.rename(columns={'store_id': 'country_code'})\n\n        # category_id mapping\n        df.loc[df[\"platform_id\"] == 0] = df.loc[df[\"platform_id\"] == 0].\\\n            replace({\"category_id\": CATEGORY_ID_MAPPING[\"google-play\"][\"android-all\"]})\n        df.loc[df[\"platform_id\"] == 1] = df.loc[df[\"platform_id\"] == 1].\\\n            replace({\"category_id\": CATEGORY_ID_MAPPING[\"apple-store\"][\"ios-all\"]})\n\n        # device_code mapping\n        df[\"device_code\"] = df[\"platform_id\"].astype(str) + df[\"device\"]\n        df = df.replace({\"device_code\": self.device_code_mapping})\n        return df\n\n    def _parse_unified_format(self, df):\n        df = df.rename(columns=self.dimension_mapping)\n        df = df.pivot_table(index=[\"app_price_type_id\", \"purchase_type_id\", \"category_id\",\n                                   \"device_code\", \"country_code\"], columns='data_type', values='estimate')\n        df.reset_index(inplace=True)\n        df.columns.name = None\n        df = df.rename(columns=self.metric_mapping)\n        return df\n\n    def _get_raw_data_by_date(self, date):\n        \"\"\"\n        +--------+----------+-----------+-----------+---------+----------+-------------+-----------+--------+\n        |store_id|      date|platform_id|     device|data_type|price_type|purchase_type|category_id|estimate|\n        +--------+----------+-----------+-----------+---------+----------+-------------+-----------+--------+\n        |      10|2020-01-10|          0|google-play|downloads|         1|           10|          1|11981138|\n        +--------+----------+-----------+-----------+---------+----------+-------------+-----------+--------+\n        \"\"\"\n        # schema = StructType([\n        #     StructField(\"store_id\", IntegerType(), False),\n        #     StructField(\"date\", StringType(), False),\n        #     StructField(\"platform_id\", IntegerType(), False),\n        #     StructField(\"device\", StringType(), False),\n        #     StructField(\"data_type\", StringType(), False),\n        #     StructField(\"price_type\", IntegerType(), False),\n        #     StructField(\"purchase_type\", IntegerType(), False),\n        #     StructField(\"category_id\", IntegerType(), False),\n        #     StructField(\"estimate\", LongType(), False)\n        # ])\n        raw_df = self.spark.read.parquet(self.raw_s3_path.format(date=date))\n        return raw_df.toPandas()\n\n    def get_rank_count_and_sum_by_date(self, date):\n        pass\n        # return raw_count, raw_sum\n\n\nclass MarketSizeUnifiedData(object):\n    unified_s3_path = \"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.market-size.v1/fact/\" \\\n                      \"granularity=daily/date={}/\"\n\n    def __init__(self, spark):\n        self.spark = spark\n\n    def get(self, date):\n        unified_df = self.spark.read.parquet(self.unified_s3_path.format(date)).toPandas()\n        unified_df = unified_df.drop([\"_identifier\"], axis=1)\n        return unified_df\n\n\nclass MarketSizeDBData(object):\n    def get(self, date):\n        sql = \"SELECT * FROM store.store_market_size_fact_v1 WHERE date='{}'\".format(date)\n        return query_df(MARKET_SIZE_DSN, sql)\n\n    def get_led(self):\n        sql = \"SELECT * FROM store.store_market_size_latest_date_v1\"\n        return query_df(MARKET_SIZE_DSN, sql)\n\n\nclass TestMarketSizeWeekly(PipelineTest):\n    # Every Tuesday 16:00 UTC time will refresh the data of last Full Week.\n    trigger_date_config = ('* 16 * * 2', 3)\n\n    def _compare_df(self, df1, df2, log=''):\n        for diff_type in [\"left\", \"right\"]:\n            diff_df = df1.merge(df2, indicator=True, how=diff_type)  # .loc[lambda x : x['_merge']!='both']\n            diff_df = diff_df.loc[diff_df[\"_merge\"] != \"both\"]\n            if len(diff_df) != 0:\n                print diff_type\n                print diff_df.country_code.unique()\n                print diff_df.category_id.unique()\n                print diff_df.device_code.unique()\n                print df1\n                print df2\n            self.assertEqual(len(diff_df), 0,\n                             msg=\"found mismatch when compare the raw, unified, db.\"\n                                 \" diff count is \\n {}, logs:{}\".format(len(diff_df), log))\n\n    @etl_skip()\n    def test_market_size_etl_accuracy_and_completeness(self):\n        # Every Tuesday 16:00 UTC time will refresh the data of last Full Week.\n        start_date, end_date = get_week_start_end_date(self.check_date_str)\n        date_list = get_date_list(start_date, end_date)\n        for date in date_list:\n            raw_df = MarketSizeRawData(self.spark).get(date)\n            unified_df = MarketSizeUnifiedData(self.spark).get(date)\n            db_df = MarketSizeDBData().get(date)\n\n            self._compare_df(raw_df, unified_df, log=\"raw / unified\")\n            self._compare_df(unified_df, db_df, log=\"unified / db\")\n\n    def test_market_size_etl_timelines(self):\n        # Every Tuesday 16:00 UTC time will refresh the data of last Full Week.\n        # E.g. 2020-02-11 17:00 the data of 2020-02-02 ~ 2020-02-08 will be ready\n        trigger_datetime = datetime.datetime.strptime(\"2020-02-11 17:00:00\", '%Y-%m-%d %H:%M:%S')\n        check_date_str_actual = self._get_check_date_from_routing_config(trigger_datetime).strftime(\"%Y-%m-%d\")\n        self.assertEqual(\"2020-02-08\", check_date_str_actual)\n\n    @etl_skip()\n    def test_market_size_led(self):\n        _, expected_led_date = get_week_start_end_date(self.check_date_str)\n        print self.check_date_str\n        print get_week_start_end_date(self.check_date_str)\n        led_df = MarketSizeDBData().get_led()\n        for device_code in [\"ios-all\", \"android-all\", \"ios-tablet\", \"ios-phone\"]:\n            actual_led_date = led_df.loc[led_df.device_code == device_code].date.values[0].strftime(\"%Y-%m-%d\")\n            print \"-{}-\".format(actual_led_date)\n            print dir(actual_led_date)\n\n            print \"-{}-\".format(expected_led_date)\n            print dir(expected_led_date)\n           \n            assert expected_led_date==actual_led_date\n            self.assertEqual(expected_led_date, actual_led_date,\n                             msg=\"current led for device : {} is {}, it should be {}\".format(\n                                 device_code, actual_led_date, expected_led_date))\n"]},{"cell_type":"code","execution_count":0,"id":"20200215-035445_246722786","metadata":{},"outputs":[],"source":["\n\nfrom applications.db_check_v1.cases.store.market_size_v1.test_market_size_v1 import TestMarketSizeWeekly\n\n#\nfrom applications.db_check_v1.cases.advanced_review.test_advainced_review import TestAdvancedReview\nfrom applications.db_check_v1.cases.aso.test_aso import TestASO, TestASOSOVDataDaily, \\\n    TestASOSOVDataWeekly, TestASOSOVDataMonthly, TestASOMetrics\nfrom applications.db_check_v1.cases.market.test_market import TestMarketDimensionDaily, \\\n    TestMarketLogsFactAndSeenDaily, TestMarketMonthlyCheck, TestMarketWeeklyCheck\nfrom applications.db_check_v1.cases.mobile_web.test_mobile_web import TestMobileWebDaily, \\\n    TestMobileWebWeekly, \\\n    TestMobileWebMonthly, TestMobileWebRetention\nfrom applications.db_check_v1.cases.sdk.test_sdk import TestSDKDaily, TestSDKWeekly, TestSDKMonthly\nfrom applications.db_check_v1.cases.store.app_rank_v1.test_app_rank_v1 import TestAppStoreRankDaily\nfrom applications.db_check_v1.cases.store.app_rank_v1.test_app_store_rank import TestAppStoreRank\nfrom applications.db_check_v1.cases.store.download_attribution.test_download_attribution import \\\n    TestDownloadAttribution\nfrom applications.db_check_v1.cases.store.market_size_v1.test_market_size_v1 import TestMarketSizeWeekly\nfrom applications.db_check_v1.cases.usage.test_city_level import TestCityLevelWeekly, TestCityLevelMonthly\nfrom applications.db_check_v1.common.html_report_test_runner import HTMLTestRunner\n#\n\nimport sys\nimport datetime\nimport traceback\nimport unittest\n\ndef debug(case_list):\n    std_out_origin= sys.stdout\n    std_err_origin= sys.stderr\n    try:\n        suite =  unittest.TestSuite()\n        for case in case_list:\n            suite.addTest(case)\n        runner = unittest.TextTestRunner(verbosity=2, buffer=True)\n        runner.run(suite)\n    except Exception as ex:\n        print dir(ex)\n        print ex.message\n        traceback.print_exception(type(ex), ex, ex.__traceback__)\n    finally:\n        sys.stdout = std_out_origin\n        sys.stderr = std_err_origin\n    \ncase_name_list = [\n    \"test_market_size_etl_accuracy_and_completeness\",\n    \"test_market_size_etl_timelines\",\n    \"test_market_size_led\"\n    ]\n\n# TestMarketDimensionDaily(trriger_date='2020-09-01')\ntest_case_list = [ ] # pass \ntest_case_list.append(unittest.TestLoader().loadTestsFromTestCase(TestMarketDimensionDaily))\ntest_case_list.append(unittest.TestLoader().loadTestsFromTestCase(TestMarketLogsFactAndSeenDaily))\ntest_case_list.append(unittest.TestLoader().loadTestsFromTestCase(TestMarketWeeklyCheck))\ntest_case_list.append(unittest.TestLoader().loadTestsFromTestCase(TestMarketMonthlyCheck))\n\n\ndebug(test_case_list)\n"]},{"cell_type":"code","execution_count":0,"id":"20200220-112708_849602439","metadata":{},"outputs":[],"source":["\n\ndate=\"2020-01-01\"\nest_unified_df = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.genre-est.v1/fact/granularity=daily/date={}/\".format(date))\nest_unified_df.show(5)"]},{"cell_type":"code","execution_count":0,"id":"20200215-035725_94453679","metadata":{},"outputs":[],"source":["%%sh\n\naws s3 ls s3://b2c-prod-dca-store-estimates/store_estv2/MARKET_SIZE_ESTIMATES_FINAL/version=2.0.0/range_type=DAY/date=2020-01-13/\n"]},{"cell_type":"code","execution_count":0,"id":"20200215-035810_1899635542","metadata":{},"outputs":[],"source":["%%sh\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}