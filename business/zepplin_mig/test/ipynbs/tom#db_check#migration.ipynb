{"cells":[{"cell_type":"code","execution_count":0,"id":"20191220-051305_424518930","metadata":{},"outputs":[],"source":["\nfrom bdce.common.utils import update_application_code\nupdate_application_code(\n    spark, role=\"BDP-PROD-APP-INT-QA\", application_name=\"aa-int-qa-db-check-debug\"\n)\n\n"]},{"cell_type":"code","execution_count":0,"id":"20191223-051818_2116599596","metadata":{},"outputs":[],"source":["\n# restart interpreter\n"]},{"cell_type":"code","execution_count":0,"id":"20191223-051800_1983013052","metadata":{},"outputs":[],"source":["\nspark.sparkContext.addPyFile(\"/tmp/zeppelin_application_code/libs/python/dependencies.zip\")\n\nfrom applications.db_check_v1.db_check import send_message\n\nsend_message()\n\n"]},{"cell_type":"code","execution_count":0,"id":"20191223-004340_467923193","metadata":{},"outputs":[],"source":["\n# Copyright (c) 2018 App Annie Inc. All rights reserved.\n\n\"\"\"\nDB Check modules\n\"\"\"\n\n# spark.sparkContext.addPyFile(\"/tmp/zeppelin_application_code/libs/python/dependencies.zip\")\n\nimport zlib\n\nimport pandas as pd\n\nfrom applications.db_check_v1.cases.store.app_rank_v1.base_test import PipelineTest\nfrom applications.db_check_v1.cases.store.app_rank_v1.constants import APP_STORE_RANK_METRICS\nfrom applications.db_check_v1.cases.store.app_rank_v1.reader import AppleTvRaw, AmazonRaw, AppleTvUnified, \\\n    AmazonUnified, AppleTvDB, AmazonDB, MacDB, MacUnified, MacRaw\n    \n    \nfrom applications.db_check_v1.cases.store.app_rank_v1.reader import AppStoreRankRawData\nfrom applications.db_check_v1.cases.store.app_rank_v1.constants import APP_STORE_RANK_METRICS, rank_bucket, \\\n    CATEGORY_ID_MAPPING, METRIC_MAPPING, COUNTRY_CODE_MAPPING, aa_dsn, aa_amazon_dsn, citus_dsn\n\n\nclass TestAppStoreRankDaily(PipelineTest):\n    routing_config = ('* 9 * * *', 1)\n\n    def test_mac_etl_process(self):\n        country_code = 'US'\n        category_id = 200000\n        raw_df = MacRaw(self.spark).parse_df_to_unified_format(\n            MacRaw(self.spark).get(self.check_date_str, country_code, category_id))\n        unified_df = MacUnified(self.spark).get(self.check_date_str, country_code, category_id)\n        db_df = MacDB(self.spark).get(self.check_date_str, country_code, category_id)\n        for metric in APP_STORE_RANK_METRICS:\n            _raw_df = raw_df[pd.notnull(raw_df[metric])].sort_values(metric)\n            _unified_df = unified_df[pd.notnull(unified_df[metric])].sort_values(metric)\n            _db_df = db_df[pd.notnull(db_df[metric])].sort_values(metric)\n            print _raw_df\n            print _unified_df\n            print _db_df\n            data_app = {\n                'raw': _raw_df.app_id.tolist(),\n                'unified': _unified_df.app_id.tolist(),\n                'db': _db_df.app_id.tolist()\n            }\n\n            data_rank = {\n                'raw': _raw_df[metric].tolist(),\n                'unified': _unified_df[metric].tolist(),\n                'db': _db_df[metric].tolist()\n            }\n\n            self.assertTrue(data_app['raw'] == data_app['unified'] == data_app['db'], msg=\"{}\".format(data_app))\n            self.assertTrue(data_rank['raw'] == data_rank['unified'] == data_rank['db'], msg=\"{}\".format(data_rank))\n\n    def test_mac_transform_completeness(self):\n        raw_count, raw_sum = MacRaw(self.spark).get_rank_count_and_sum_by_date(self.check_date_str)\n        unified_count, unified_sum = MacUnified(self.spark).get_rank_count_and_sum_by_date(self.check_date_str)\n\n        self.assertEqual(raw_count, unified_count)\n        self.assertEqual(raw_sum, unified_sum)\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20191223-004436_1038776699","metadata":{},"outputs":[],"source":["\n\nimport sys\nimport datetime\nimport traceback\nimport unittest\n\ndef debug(case):\n    std_out_origin= sys.stdout\n    std_err_origin= sys.stderr\n    try:\n        suite =  unittest.TestSuite()\n        suite.addTest(case)\n        runner = unittest.TextTestRunner(verbosity=2, buffer=True)\n        runner.run(suite)\n    except Exception as ex:\n        print ex.message\n        print traceback.format_exc()\n    finally:\n        sys.stdout = std_out_origin\n        sys.stderr = std_err_origin\n    \n\n# testcase = AppStoreRankDailyTest(\"test_amazon_completeness\", datetime.datetime.strptime(\"2019-06-07\", \"%Y-%m-%d\") )  # pass \n# testcase = AppStoreRankDailyTest(\"test_apple_tv_completeness\", datetime.datetime.strptime(\"2019-06-07\", \"%Y-%m-%d\") )  # pass\n# testcase = AppStoreRankDailyTest(\"test_amazon_etl_process\", datetime.datetime.strptime(\"2019-06-07\", \"%Y-%m-%d\") )  # pass\ntestcase = TestAppStoreRankDaily(\"test_mac_etl_process\", datetime.datetime.strptime(\"2019-06-07\", \"%Y-%m-%d\") )  # pass\ndebug(testcase)\n\n"]},{"cell_type":"code","execution_count":0,"id":"20191231-070502_1897884821","metadata":{},"outputs":[],"source":["\n\nimport zlib\n\n\nclass AppStoreRankRawData():\n    bucket_name = \"\"\n    bucket_path = \"\"\n    data_split_str = \"\"\n    rank_list_split_str = \"\"\n    rank_split_str = \"\"\n    accept_feeds = []\n    country_code_mapping = {}\n    category_id_mapping = {}\n    metric_mapping = {}\n    market_code = \"\"\n    filename_available = []\n\n    def __init__(self, spark):\n        self.spark = spark\n\n    def get(self, date, country_code, category_id):\n        df = self.get_raw_data_by_date(date)\n        return df.loc[(df.country_code == country_code) & (df.category_id == category_id)]\n\n    def parse_mapping(self, df):\n        if self.country_code_mapping:\n            if isinstance(self.country_code_mapping.keys()[0], int):\n                df[\"country_code\"] = pd.to_numeric(df[\"country_code\"])\n            df = df.replace({\"country_code\": self.country_code_mapping})\n\n        if self.category_id_mapping:\n            df[\"category_id\"] = pd.to_numeric(df[\"category_id\"])\n            df = df.replace({\"category_id\": self.category_id_mapping})\n\n        if self.metric_mapping:\n            df[\"metric\"] = pd.to_numeric(df[\"metric\"])\n            df = df.replace({\"metric\": self.metric_mapping})\n        return df\n\n    def parse_df_to_unified_format(self, df):\n        columns = [\"code\", \"category_id\", \"country_code\",\n                   \"free_download\", \"paid_download\", \"revenue\", \"new_free_download\", \"new_paid_download\" ]\n        data_list = []\n        for index,row in df.iterrows():\n            if len(row.app_rank_list) == 0:\n                continue\n            for index,app_id in enumerate(row.app_rank_list, start=1):\n                free_download = index if row.metric == 'free_download' else None\n                paid_download = index if row.metric == 'paid_download' else None\n                revenue = index if row.metric == 'revenue' else None\n                new_free_download = index if row.metric == 'new_free_download' else None\n                new_paid_download = index if row.metric == 'new_paid_download' else None\n                data_list.append([app_id, row.category_id, row.country_code,\n                                  free_download, paid_download, revenue, new_free_download, new_paid_download])\n        new_df = pd.DataFrame(data_list, columns=columns)\n        aggregate_dict = {metric: 'min' for metric in APP_STORE_RANK_METRICS}\n        new_df = new_df.groupby(new_df['code'], as_index=False).aggregate(aggregate_dict).\\\n            reindex(columns=new_df.columns)\n        # code to app_ids\n        code_app_id_mapping = self.get_code_app_id_mapping(new_df.code.tolist())\n        if code_app_id_mapping is not None:\n            new_df = new_df.merge(code_app_id_mapping, on='code', how=\"left\").rename(columns={'id':'app_id'})\n        else:\n            new_df.rename(columns={'code': 'app_id'})\n        return new_df\n\n    def get_unified_format(self, date):\n        df = self.get_raw_data_by_date(date)\n        return self.parse_df_to_unified_format(df)\n\n    def get_raw_data_by_date(self, date):\n        \"\"\"\n        :return: raw_data_frame\n        :rtype: list_of_dic\n        raw_data:\n        _________________________________________________________________________________\n        |    date    |   country_id   |  category_id  |   feed_id   |   rank (app_id)   |\n        |------------|----------------|---------------|-------------|-------------------|\n        | 2019-04-27 | 143441(bigint) |   6016 (int)  |   0 (int)   | 376510438(bigint) |\n        ---------------------------------------------------------------------------------\n        unified_data:\n        _____________________________________________________________________________________\n        |  country_code  |   category_id   |       app_id       | feed_name (free_download) |\n        |----------------|-----------------|--------------------|---------------------------|\n        |      'US'      | 100026 (bigint) | 376510438 (bigint) |    25 (int) (app_rank)    |\n        -------------------------------------------------------------------------------------\n        \"\"\"\n        path = \"{_bucket_path}/{_date}/23/\".format(_date=date, _bucket_path=self.bucket_path)\n        bucket = rank_bucket(self.bucket_name)\n        columns = ['date', 'country_code', 'category_id', 'metric', 'app_rank_list']\n\n        _raw_data_list = []\n        for filepath in bucket.list(path):\n            filename = filepath.replace(path, '')\n            if self.filename_available and filename not in self.filename_available:\n                continue\n            _raw_data = zlib.decompress(bucket.get(filepath))\n            for _line in _raw_data.splitlines():\n                line_data = _line.split(self.data_split_str)\n                app_rank_list = [rank_app for rank_app in line_data[4].split(self.rank_list_split_str) if\n                                 rank_app.strip() != '']\n                if self.rank_split_str:\n                    app_rank_list = [app_rank.split(self.rank_split_str)[1] for app_rank in app_rank_list]\n                line_data[4] = app_rank_list\n                _raw_data_list.append(line_data)\n        return self.parse_mapping(pd.DataFrame(_raw_data_list, columns=columns))\n\n\n    def get_code_app_id_mapping(self, code_ids):\n        return None\n\n    def get_rank_count_and_sum_by_date(self, date):\n        raw_df = self.get_raw_data_by_date(date)\n        raw_agg_df_list = []\n        for df_index, row in raw_df.iterrows():\n            if len(row.app_rank_list) == 0:\n                continue\n            _df = pd.DataFrame([[app_id, app_index] for app_index, app_id in enumerate(row.app_rank_list, start=1)],\n                              columns=[\"code\", \"rank\"])\n            aggregation_functions = {'rank': 'min'}\n            raw_agg_df = _df.groupby(_df['code'], as_index=False)\\\n                .aggregate(aggregation_functions)\\\n                .reindex(columns=_df.columns)\n            raw_agg_df_list.append(raw_agg_df)\n\n        raw_agg_df_all = pd.concat(raw_agg_df_list, ignore_index=True, sort=False)\n        app_id_mapping_df = self.get_code_app_id_mapping(list(set(raw_agg_df_all.code.tolist())))\n        if app_id_mapping_df is not None:\n            raw_agg_df_all = raw_agg_df_all.merge(app_id_mapping_df, on='code', how=\"left\")\n        raw_count = len(raw_agg_df_all[raw_agg_df_all.id.notnull()])\n        raw_sum = raw_agg_df_all[raw_agg_df_all.id.notnull()][\"rank\"].sum()\n        return raw_count, raw_sum\n\n\nclass MacRaw(AppStoreRankRawData):\n    bucket_name = \"prod_appannie_ios\"\n    bucket_path = \"mac/country-ranks\"\n    data_split_str = \"\\t\"\n    rank_list_split_str = \" \"\n\n    device_code = \"mac-os-mac\"\n    market_code = 'apple-store'\n\n    category_id_mapping = CATEGORY_ID_MAPPING['mac-os-mac']\n    metric_mapping = METRIC_MAPPING['mac-os-mac']\n    country_code_mapping = COUNTRY_CODE_MAPPING['ios']\n\n    filename_available = [str(id) for id in COUNTRY_CODE_MAPPING['ios']]\n\n\n# class IPhoneRaw(AppStoreRankRawData):\n#     bucket_name = \"prod_appannie_ios\"\n#     bucket_path = \"country-ranks\"\n#     data_split_str = \"\\t\"\n#     rank_list_split_str = \" \"\n#     accept_feeds = [0, 1, 2]\n#\n#\n# class IPadRaw(AppStoreRankRawData):\n#     bucket_name = \"prod_appannie_ios\"\n#     bucket_path = \"country-ranks\"\n#     data_split_str = \"\\t\"\n#     rank_list_split_str = \" \"\n\n# df_temp =  MacRaw(spark).get_raw_data_by_date(\"2019-11-09\")\nprint df_temp\nMacRaw(spark).get('2019-11-09', 'US', 200000)\n\n\n# self.parse_mapping(\n"]},{"cell_type":"code","execution_count":0,"id":"20191223-015359_279906055","metadata":{},"outputs":[],"source":["%%sh\n\n# aws s3 ls s3://prod_appannie_ios/mac/country-ranks/2019-06-07/23/\naws s3 ls s3://b2c-prod-data-pipeline-unified-store-free/unified/app-tech.store.app-rank.v1/fact/date=2019-06-05/device_code=mac-os-mac/"]},{"cell_type":"code","execution_count":0,"id":"20191223-041645_648207369","metadata":{},"outputs":[],"source":["\ndf = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-free/unified/app-tech.store.app-rank.v1/fact/date=2019-06-05/device_code=mac-os-mac/\").toPandas()\nprint df\n "]},{"cell_type":"code","execution_count":0,"id":"20191223-042330_906996804","metadata":{},"outputs":[],"source":["%%sh\n\nls -al /tmp/zeppelin_application_code/applications/db_check_v1/cases/store/app_rank_v1/\n\ncat  /tmp/zeppelin_application_code/applications/db_check_v1/cases/store/app_rank_v1/reader.py"]},{"cell_type":"code","execution_count":0,"id":"20191223-050132_2006025497","metadata":{},"outputs":[],"source":["%%sh \n\n\nls -al /var/log/pkg_install.log\n\ncat /var/log/pkg_install.log"]},{"cell_type":"code","execution_count":0,"id":"20201109-022559_925904871","metadata":{},"outputs":[],"source":["%%sh\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}