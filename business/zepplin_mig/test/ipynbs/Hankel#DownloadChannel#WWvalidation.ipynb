{"cells":[{"cell_type":"code","execution_count":0,"id":"20210527-113727_890376048","metadata":{},"outputs":[],"source":["\nprint(\"Start\")"]},{"cell_type":"code","execution_count":0,"id":"20191227-101546_278685021","metadata":{},"outputs":[],"source":["\nfrom pyspark.storagelevel import StorageLevel\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import BooleanType\nfrom datetime import datetime\n\n\n# Snowflake Production\nsfOptions = {\n  \"sfURL\" : \"appannie_aa_int_prod.us-east-1.snowflakecomputing.com\",\n  \"sfUser\" : \"app_bdp_data_validation_qa\",\n  \"sfPassword\" : \"0HN#s@Wa5$1R8jVj\",\n  \"sfDatabase\" : \"AA_INTELLIGENCE_PRODUCTION\",\n  \"sfSchema\" : \"ADL_STORE_PAID\",\n  \"sfWarehouse\" : \"wh_dod_read7\"\n}\nSNOWFLAKE_SOURCE_NAME = \"net.snowflake.spark.snowflake\"\n\n\nstart_date = '2021-04-01'\nend_date = '2021-06-20'\n\nprint(spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n    .options(**sfOptions) \\\n    .option(\"query\",  f\"select distinct date from FACT_STORE_PRODUCT_DOWNLOAD_CHANNEL_V1_CLUSTER_BY_DATE where country_code='WW' and date>='{start_date}' and date<='{end_date}';\") \\\n    .load().count())\n    \nprint(spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n    .options(**sfOptions) \\\n    .option(\"query\",  f\"select distinct date from FACT_STORE_PRODUCT_DOWNLOAD_CHANNEL_V1_CLUSTER_BY_DATE where country_code!='WW' and date>='{start_date}' and date<='{end_date}';\") \\\n    .load().count())"]},{"cell_type":"code","execution_count":0,"id":"20210630-044818_1554613195","metadata":{},"outputs":[],"source":["\n\nstart_date = '2021-04-01'\nend_date = '2021-06-20'\n\n# Sum of metrics for WW\nww_sum = spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n    .options(**sfOptions) \\\n    .option(\"query\",  f\"select sum(est_download) as v1, sum(est_paid_download) as v2, sum(est_organic_download) as v3, \\\n        sum(est_paid_search_download) as v4, sum(est_paid_in_app_ads_download) as v5, \\\n        sum(est_organic_search_download) as v6, sum(est_organic_featured_download) as v7\\\n        from FACT_STORE_PRODUCT_DOWNLOAD_CHANNEL_V1_CLUSTER_BY_DATE \\\n        where date>='{start_date}' and date<='{end_date}' and country_code='WW';\") \\\n    .load()\n    \nww_sum.show()\n        \n# Sum of metrics for other countries\no_sum = spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n    .options(**sfOptions) \\\n    .option(\"query\",  f\"select sum(est_download) as v1, sum(est_paid_download) as v2, sum(est_organic_download) as v3, \\\n        sum(est_paid_search_download) as v4, sum(est_paid_in_app_ads_download) as v5, \\\n        sum(est_organic_search_download) as v6, sum(est_organic_featured_download) as v7\\\n        from FACT_STORE_PRODUCT_DOWNLOAD_CHANNEL_V1_CLUSTER_BY_DATE \\\n        where date>='{start_date}' and date<='{end_date}'  and country_code!='WW';\") \\\n    .load()\n    \no_sum.show()"]},{"cell_type":"code","execution_count":0,"id":"20210527-153816_556721791","metadata":{},"outputs":[],"source":["\nfrom pyspark.storagelevel import StorageLevel\nfrom pyspark.sql.functions import *\nfrom datetime import date\nimport random\n\n\nstart = date(2021, 4, 1)\nend = date(2021, 6, 20)\n\nfor i in random.sample(range(start.toordinal(), end.toordinal()), 20):\n    current = str(date.fromordinal(i))\n    \n    # Sum of metrics for WW\n    ww_sum = spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n        .options(**sfOptions) \\\n        .option(\"query\",  f\"select sum(est_download) as v1, sum(est_paid_download) as v2, sum(est_organic_download) as v3, \\\n            sum(est_paid_search_download) as v4, sum(est_paid_in_app_ads_download) as v5, \\\n            sum(est_organic_search_download) as v6, sum(est_organic_featured_download) as v7\\\n            from FACT_STORE_PRODUCT_DOWNLOAD_CHANNEL_V1_CLUSTER_BY_DATE \\\n            where date='{current}' and country_code='WW';\") \\\n        .load()\n        \n    # Sum of metrics for other countries\n    o_sum = spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n        .options(**sfOptions) \\\n        .option(\"query\",  f\"select sum(est_download) as v1, sum(est_paid_download) as v2, sum(est_organic_download) as v3, \\\n            sum(est_paid_search_download) as v4, sum(est_paid_in_app_ads_download) as v5, \\\n            sum(est_organic_search_download) as v6, sum(est_organic_featured_download) as v7\\\n            from FACT_STORE_PRODUCT_DOWNLOAD_CHANNEL_V1_CLUSTER_BY_DATE \\\n            where date='{current}' and country_code!='WW';\") \\\n        .load()\n        \n    \n    ww = ww_sum.collect()[0]\n    o = o_sum.collect()[0]\n    if ww.V1 != ww.V1:\n        print(f\"Incorrect EST_DOWNLOAD Sum on {current}\")\n        \n    print(f\"{current}: {ww.V2-o.V2}, {ww.V3-o.V3}, {ww.V4-o.V4}, {ww.V5-o.V5}, {ww.V6-o.V6}, {ww.V7-o.V7}\")\n\nprint(\"Checked.\")\n"]},{"cell_type":"code","execution_count":0,"id":"20210528-065059_158160274","metadata":{},"outputs":[],"source":["\nfrom pyspark.storagelevel import StorageLevel\nfrom pyspark.sql.functions import *\nfrom datetime import date\nimport random\n\n\ndates = [date(2021, 4, 1), date(2021, 4, 24), date(2021, 5, 29)]\nproduct_keys = [20600012501710, 20600000013820, 20600010817872]\n\nfor i in range(len(dates)):\n    d = str(dates[i])\n    p = product_keys[i]\n    \n    # Sum of metrics for WW\n    ww_sum = spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n        .options(**sfOptions) \\\n        .option(\"query\",  f\"select sum(est_download), sum(est_paid_download), sum(est_organic_download), \\\n            sum(est_paid_search_download), sum(est_paid_in_app_ads_download), \\\n            sum(est_organic_search_download), sum(est_organic_featured_download) \\\n            from FACT_STORE_PRODUCT_DOWNLOAD_CHANNEL_V1_CLUSTER_BY_DATE \\\n            where date='{d}' and product_key='{p}' and country_code='WW';\") \\\n        .load()\n        \n    # Sum of metrics for other countries\n    o_sum = spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n        .options(**sfOptions) \\\n        .option(\"query\",  f\"select sum(est_download), sum(est_paid_download), sum(est_organic_download), \\\n            sum(est_paid_search_download), sum(est_paid_in_app_ads_download), \\\n            sum(est_organic_search_download), sum(est_organic_featured_download) \\\n            from FACT_STORE_PRODUCT_DOWNLOAD_CHANNEL_V1_CLUSTER_BY_DATE \\\n            where date='{d}' and product_key='{p}' and country_code!='WW';\") \\\n        .load()\n        \n    ww_sum.show()\n    o_sum.show()\n"]},{"cell_type":"code","execution_count":0,"id":"20210528-033835_1944833726","metadata":{},"outputs":[],"source":["\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}