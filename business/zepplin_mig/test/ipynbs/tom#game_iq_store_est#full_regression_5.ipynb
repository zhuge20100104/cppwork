{"cells":[{"cell_type":"code","execution_count":0,"id":"20200221-001751_1972235615","metadata":{},"outputs":[],"source":["\nspark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nimport pandas as pd\npd.set_option('expand_frame_repr', False)\nimport boto3\n\ns3 = boto3.resource('s3')\ns3object = s3.Object('b2c-prod-data-pipeline-qa', 'tom/gameiq/2020-03-13/regression5.txt')\nlog = [] \n\n"]},{"cell_type":"code","execution_count":0,"id":"20200220-113825_2126261453","metadata":{},"outputs":[],"source":["\n\nimport pandas as pd\nfrom pyspark.sql import functions as F\nfrom applications.db_check_v1.common.constants import COUNTRY_CODE_MAPPING_BY_MARKET_CODE as COUNTRY_CODE_MAPPING\nfrom conf.settings import *\nfrom applications.db_check_v1.common.db_check_utils import query_df\nimport pandas as pd\n\n\nDEVICE_CODE_MAPPING_BY_DEVICE_ID = {\n    'google-play':{\n        1000: \"android-all\",\n        1001: \"android-phone\",\n        1002: \"android-tablet\",\n    },\n    'apple-store': {\n        2000: \"ios-all\",\n        2001: \"ios-phone\",\n        2002: \"ios-tablet\"\n    }\n}\nDEVICE_CODE_MAPPING = DEVICE_CODE_MAPPING_BY_DEVICE_ID\n\ndaily_est_dsn =(\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_DAILY_EST_NAME,\n        user=PG_DAILY_EST_ACCESS_ID,\n        host=PG_DAILY_EST_HOSTS[0][0],\n        password=PG_DAILY_EST_SECRET_KEY,\n        port=PG_DAILY_EST_HOSTS[0][1]\n    )\n)\n\nmapping_df_unified = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-dna/unified/dna.genre_id_product_mapping.v1/dimension/\")\ntransformed_mapping_df = mapping_df_unified.select([\"product_id\", \"genre_id\"]).withColumn('genre_id', F.explode('genre_id'))\n\ndef compare(date):\n    #collect\n    store_est_unified_df = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.app-est.v1/fact/granularity=daily/date={}/\".format(date))\n    est_unified_df = spark.read.parquet(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/store.genre-est.v1/fact/granularity=daily/date={}/\".format(date))\n    \n    # #transform\n    transformed_store_est_unified_df = store_est_unified_df.select([\"app_id\", \"device_code\", \"country_code\", \"free_app_download\", \"paid_app_download\", \"revenue\"]).withColumnRenamed(\"app_id\", \"product_id\")\n    giq_df = transformed_store_est_unified_df.join(transformed_mapping_df, transformed_mapping_df.product_id == transformed_store_est_unified_df.product_id, how='inner').groupBy([\"device_code\", \"country_code\", \"genre_id\"]).agg({\n            \"free_app_download\": \"sum\",\n            \"paid_app_download\": \"sum\",\n            \"revenue\": \"sum\",\n        }).withColumnRenamed(\"sum(free_app_download)\", \"free_app_download\").withColumnRenamed(\"sum(paid_app_download)\", \"paid_app_download\").withColumnRenamed(\"sum(revenue)\", \"revenue\")\n    giq_df = giq_df.fillna({\"free_app_download\":0, \"paid_app_download\":0})\n    giq_df = giq_df.withColumn(\"download\", F.when(giq_df.free_app_download + giq_df.paid_app_download>0, giq_df.free_app_download + giq_df.paid_app_download).otherwise(F.lit(None)))\n\n    #compare\n    s1=giq_df.select([\"device_code\", \"country_code\", \"genre_id\", \"download\", \"revenue\"])\n    s2=est_unified_df.select([\"device_code\", \"country_code\", \"genre_id\", \"download\", \"revenue\"])\n\n    diff = s1.union(s2).subtract(s1.intersect(s2))\n    \n    ##########################\n    # DB & UNIFIED LAYER TEST\n\n    sql = \"\"\"\nselect device_id, store_id, date, genre_id, modifier_id, download, revenue from plproxy.execute_select_nestloop($proxy$ \n    select device_id, store_id, date, genre_id, modifier_id, download, revenue\n    from aa.genre_store_daily_estimate\n    where \n        date = '{}'\n$proxy$) tbl (device_id SMALLINT, store_id INT, date DATE , genre_id BIGINT, modifier_id BIGINT, download BIGINT, revenue BIGINT);\"\"\".format(date)\n\n    db_df = query_df(daily_est_dsn, sql)\n\n    db_df.loc[db_df['device_id'].isin(DEVICE_CODE_MAPPING['google-play'])] = db_df.loc[db_df['device_id'].isin(DEVICE_CODE_MAPPING['google-play'])].replace({\"device_id\": DEVICE_CODE_MAPPING['google-play']})\n    db_df.loc[db_df['device_id'].isin(DEVICE_CODE_MAPPING['apple-store'])] = db_df.loc[db_df['device_id'].isin(DEVICE_CODE_MAPPING['apple-store'])].replace({\"device_id\": DEVICE_CODE_MAPPING['apple-store']})\n\n    db_df = db_df.replace({\"store_id\": COUNTRY_CODE_MAPPING['google-play']})\n    db_df = db_df.replace({\"store_id\": COUNTRY_CODE_MAPPING['apple-store']})\n\n    db_df = db_df.rename(columns={'store_id': 'country_code'}).rename(columns={'device_id': 'device_code'}).rename(columns={'device_id': 'device_code'}).rename(columns={'device_id': 'device_code'})\n\n    est_unified_df = est_unified_df.toPandas()\n    est_unified_df[\"modifier_id\"] = 100000\n\n    diff_db = _compare_df(est_unified_df, db_df)\n    \n    if diff.count()>0:\n        return \"{}: FAIL UNIFIED\".format(date)\n        diff.show(2)\n    elif len(diff_db)>0:\n        return \"{}: FAIL DB\".format(date)\n        print diff_db\n    else:\n        return  \"{}: PASS\".format(date)\n    \n    \ndef get_date_list(start_date, end_date, freq=\"D\"):\n    date_list = [x.strftime('%Y-%m-%d') for x in list(pd.date_range(start=start_date, end=end_date, freq=freq))]\n    return date_list\n\ndef _compare_df(df1, df2):\n    for diff_type in [\"left\", \"right\"]:\n        diff_df = df1.merge(df2, indicator=True, how=diff_type)  # .loc[lambda x : x['_merge']!='both']\n        diff_df = diff_df.loc[diff_df[\"_merge\"] != \"both\"]\n        if len(diff_df) != 0:\n            print diff_type\n            return diff_df\n    return []\n\ndef write_log(strobj, s3obj):\n    s3obj.put(Body=str(strobj))\n\n# date_list = get_date_list(\"2010-07-04/\", \"2020-02-15/\")\ndate_list = get_date_list(\"2018-01-01/\", \"2020-02-29/\")\nfor date in date_list:\n    temp_log = \"\"\n    try:\n        temp_log = compare(date)\n    except Exception, e:\n        temp_log = \"{}: ERROR\".format(date) \n    log.append(temp_log)\n    print temp_log\n    write_log(log, s3object)\n"]},{"cell_type":"code","execution_count":0,"id":"20200223-012118_1365265199","metadata":{},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":0,"id":"20200220-114032_875785722","metadata":{},"outputs":[],"source":["\n\nimport boto3\n\ndef read_s3(key):\n    print '*'*100 \n    print key\n    s3 = boto3.resource('s3')\n    obj = s3.Object('b2c-prod-data-pipeline-qa', key)\n    body = obj.get()['Body'].read()\n    print body\n\nread_s3('tom/all/regression1.txt')\nread_s3('tom/all/regression2.txt')\nread_s3('tom/all/regression3.txt')\nread_s3('tom/all/regression4.txt')\nread_s3('tom/all/regression5.txt')\n\n"]},{"cell_type":"code","execution_count":0,"id":"20200223-012131_1092049496","metadata":{},"outputs":[],"source":["\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}