{"cells":[{"cell_type":"code","execution_count":0,"id":"20191122-025432_1819228276","metadata":{},"outputs":[],"source":["\n\nimport psycopg2\nimport datetime\nimport pandas as pd\n\ncitus_dsn_ = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=\"aa_citus_db\",\n        user=\"citus_bdp_usage_qa\",\n        host=\"10.2.10.132\",\n        password=\"dNzWtSV3pKTx\",\n        port=5432\n    )\n)\n\ndef query(dsn, sql):\n    with psycopg2.connect(dsn) as conn:\n        conn.autocommit = True\n        with conn.cursor() as cur:\n            cur.execute(sql)\n            result = cur.fetchall()\n            conn.commit()\n    return result\n\ndef get_date_list(begin_date, end_date, freq):\n    date_list = [x.strftime('%Y-%m-%d') for x in list(pd.date_range(start=begin_date, end=end_date, freq=freq))]\n    return date_list\n\nbegin_date = datetime.datetime.strptime(\"2019-01-01\", '%Y-%m-%d')\nend_date = datetime.datetime.strptime(\"2019-01-30\", '%Y-%m-%d')\nDATE_LIST = get_date_list(begin_date, end_date, \"D\")\n\n\n\nmetrics = [\"free_download\"]\n\n# print \"%table \\tdate\\tcount\"\nprint \"%table {}\\t{}\".format(\"date\", \"count\")\n\nfor date_str in DATE_LIST:\n    date_count = {}\n    for metric in metrics:\n        sql = 'SELECT date, device_code, country_code, category_id, count({metric}),max({metric}) FROM store.store_app_rank_fact_v1  WHERE date = \\'{date_str}\\' AND ( granularity = \\'hourly\\' ) AND ( hour = 23 ) AND ({metric} is not null)  GROUP BY country_code, date, device_code, country_code, category_id ORDER BY date ASC'.format(\n            metric=metric, date_str=date_str)\n\n        test_result = query(citus_dsn_, sql)\n        date_count[metric] = 0\n        for result in test_result:\n            date, device_code, country_code, category_id, count, max = result\n            if count != 0 and count != max:\n                date_count[metric] += 1\n                # print \",\".join([date.strftime(\"%Y-%m-%d\"), device_code, country_code, str(category_id), metric, str(count),str(max)])\n    total_count = sum([date_count[key] for key in date_count])\n    print \"\\t\".join([date_str, str(total_count)])\n\nprint \"end\""]},{"cell_type":"code","execution_count":0,"id":"20191122-030630_1355724520","metadata":{},"outputs":[],"source":["\n\ndf = spark.read.parquet(\"s3://b2c-prod-advanced-review/oss/ADVRVW_TOPIC_EFFECTIVE_PREDICTIONS/version=1.0.0/platform=2/process_date=2019-10-14/country=AU/language=en/part-00000-fab743d5-e8ff-4f23-86ff-92bacb3fdccd-c000.snappy.parquet\")\ndf.printSchema()\ndf.createOrReplaceTempView(\"review\")\nprint(\">>>>>>>>>>>>>>>\")\n# df.select('rating').rdd.map(lambda x:(x[0],1)).toDF().show()\n\nfrom pyspark.sql.functions import udf\nfrom pyspark.sql.types import IntegerType\nfrom pyspark.sql.types import ArrayType\ndef _append(x):\n    return [float(val)**2 for val in x]\nappend_udf = udf(lambda z: _append(z), ArrayType(IntegerType()))\n\ndef square_list(x):\n    x.append(0)\n    return [a for a in x]\n\nsquare_list_udf = udf(lambda y: square_list(y), ArrayType(IntegerType()))\n\n\ndf.select('topic_ids', square_list_udf('topic_ids')).show()\n\n\n# df.withColumn('review_vaa',append_udf('topic_ids')).show()\n\n\n\n# from pyspark.sql import functions as F\n\n# spark.sql(\"select * from review where rating =1\").show(10)\n\n\n\n\n"]},{"cell_type":"code","execution_count":0,"id":"20191122-025440_301321089","metadata":{},"outputs":[],"source":["\n\nprint \"%table {}\\t{}\".format(\"date\", \"count\")\n\nfor x in range(10):\n    print str(x) ,\"\\t\", str(2*x)\nprint \"end\"    "]},{"cell_type":"code","execution_count":0,"id":"20191125-015539_921117142","metadata":{},"outputs":[],"source":["%%sh\nls -al\n\n\nwhoami"]},{"cell_type":"code","execution_count":0,"id":"20191125-023814_1437452930","metadata":{},"outputs":[],"source":["\n\nwordscounts = [('cat',2),('cat',2),('elephant',1),('rat',2)]\nwordCountRDD = sc.parallelize(wordscounts)\nprint (wordCountRDD.collect())\n\ntotalCount = wordCountRDD.map(lambda (x,y):y).reduce(lambda x,y:x+y)\n\nprint(totalCount)\n\n\nprint(wordCountRDD.groupByKey().map(lambda (k,v):(k,sum(v))).collect())\n\n\n\nprint(wordCountRDD.groupByKey().map(lambda (k,v):(k,sum(v))).map(lambda (x,y):y).reduce(lambda x,y:x+y))"]},{"cell_type":"code","execution_count":0,"id":"20191125-094706_1232324160","metadata":{},"outputs":[],"source":["%%sh\n\naws s3 ls s3://b2c-prod-data-pipeline-qa/tom/gameiq/2020-03-13/\n"]},{"cell_type":"code","execution_count":0,"id":"20200313-052228_1934384076","metadata":{},"outputs":[],"source":["%%sh\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}