{"cells":[{"cell_type":"code","execution_count":0,"id":"20200625-102251_1457069342","metadata":{},"outputs":[],"source":["\nfrom bdce.common.utils import update_application_code\nupdate_application_code(spark, role=\"BDP-PROD-APP-INT-QA\", application_name=\"zidong-application-autopipeline\")\n\n# reload dependencies from temp\nspark.sparkContext.addPyFile(\"/tmp/zeppelin_application_code/libs/python/dependencies.zip\")\n# spark.sparkContext.addPyFile(\"/home/hadoop/bdp/application/libs/python/dependencies.zip\")\nimport aaplproxy"]},{"cell_type":"code","execution_count":0,"id":"20200625-101654_530219373","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql.functions import sum\nfrom pyspark.sql.functions import desc\nfrom aadatapipelinecore.core.urn import Urn\nimport psycopg2\nfrom pyspark.sql import Row\nfrom dateutil.relativedelta import relativedelta\nfrom aaplproxy.connection import ClusterConnection\nfrom conf import settings\nfrom aadatapipelinecore.core.loader.plproxy import build_db_settings\nimport datetime as d\nimport datetime\nfrom datetime import timedelta\n\n\ntest_result = []\nPG_AA_HOSTS = [('10.2.6.141', 5432)]\nPG_AA_NAME = 'aa_store_db'\nPG_AA_ACCESS_ID = 'citus_bdp_prod_app_int_qa'\nPG_AA_SECRET_KEY = 'wZw8cfBuuklIskVG'\n\naa_dsn = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_AA_NAME,\n        user=PG_AA_ACCESS_ID,\n        host=PG_AA_HOSTS[0][0],\n        password=PG_AA_SECRET_KEY,\n        port=PG_AA_HOSTS[0][1]\n    )\n)\n\nurn = Urn(\n    namespace=\"app-qa.db-check.v1\",\n    owner=\"app_qa\"\n)\ndaily_sql = \"\"\"select count(1), \n            sum(est_free_app_download), \n            sum(est_paid_app_download), \n            sum(est_revenue)\n            from \n    (select app_id, device_code, country_code,\n            sum(est_free_app_download) as est_free_app_download, \n            sum(est_paid_app_download) as est_paid_app_download,\n            sum(est_revenue) as est_revenue\n            from store.store_est_fact_v1\n            where date between '{}' and '{}'\n            group by\n            app_id,\n            device_code,\n            country_code) as t;\n\"\"\"\n\nsql = \"\"\"select count(1), \n        sum(est_free_app_download), \n        sum(est_paid_app_download), \n        sum(est_revenue)\n        from store.store_est_t_{}_fact_v1 \n        where date between '{}' and '{}' and granularity='{}';\"\"\"\n\n\ndef query(dsn, sql):\n    with psycopg2.connect(dsn) as conn:\n        conn.autocommit = True\n        with conn.cursor() as cur:\n            cur.execute(sql)\n            result = cur.fetchall()\n            conn.commit()\n    return result\n\n\ndef check_store_unified_db_completeness(graularity):\n    value = ['2018-05-06', '2018-05-12']\n    start = value[0]\n    end = value[1]\n    date = end\n    unified_result = query(aa_dsn, daily_sql.format(start, end))\n    db_result = query(aa_dsn, sql.format(graularity[0], date, date, graularity))\n    # print date\n    # print unified_result[0][0]\n    # print db_result\n    if unified_result[0][0] == db_result[0][0] and unified_result[0][1] == db_result[0][1] and unified_result[0][2] == db_result[0][2] and unified_result[0][3] == db_result[0][3]:\n        print \"Completeness Test PASS! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n    else:\n        test_result.append(date)\n        print \"Completeness Test FAIL!!!!! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n\n\n\nkey = 'weekly'\nvalue = ['2018-05-06', '2018-05-12']\ncheck_store_unified_db_completeness(key)"]},{"cell_type":"code","execution_count":0,"id":"20200625-102140_985349860","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql.functions import sum\nfrom pyspark.sql.functions import desc\nfrom aadatapipelinecore.core.urn import Urn\nimport psycopg2\nfrom pyspark.sql import Row\nfrom dateutil.relativedelta import relativedelta\nfrom aaplproxy.connection import ClusterConnection\nfrom conf import settings\nfrom aadatapipelinecore.core.loader.plproxy import build_db_settings\nimport datetime as d\nimport datetime\nfrom datetime import timedelta\n\n\ntest_result = []\nPG_AA_HOSTS = [('10.2.6.141', 5432)]\nPG_AA_NAME = 'aa_store_db'\nPG_AA_ACCESS_ID = 'citus_bdp_prod_app_int_qa'\nPG_AA_SECRET_KEY = 'wZw8cfBuuklIskVG'\n\naa_dsn = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_AA_NAME,\n        user=PG_AA_ACCESS_ID,\n        host=PG_AA_HOSTS[0][0],\n        password=PG_AA_SECRET_KEY,\n        port=PG_AA_HOSTS[0][1]\n    )\n)\n\nurn = Urn(\n    namespace=\"app-qa.db-check.v1\",\n    owner=\"app_qa\"\n)\ndaily_sql = \"\"\"select count(1), \n            sum(est_free_app_download), \n            sum(est_paid_app_download), \n            sum(est_revenue)\n            from \n    (select app_id, device_code, country_code,\n            sum(est_free_app_download) as est_free_app_download, \n            sum(est_paid_app_download) as est_paid_app_download,\n            sum(est_revenue) as est_revenue\n            from store.store_est_fact_v1\n            where date between '{}' and '{}'\n            group by\n            app_id,\n            device_code,\n            country_code) as t;\n\"\"\"\n\nsql = \"\"\"select count(1), \n        sum(est_free_app_download), \n        sum(est_paid_app_download), \n        sum(est_revenue)\n        from store.store_est_t_{}_fact_v1 \n        where date between '{}' and '{}' and granularity='{}';\"\"\"\n\n\ndef query(dsn, sql):\n    with psycopg2.connect(dsn) as conn:\n        conn.autocommit = True\n        with conn.cursor() as cur:\n            cur.execute(sql)\n            result = cur.fetchall()\n            conn.commit()\n    return result\n\n\ndef check_store_unified_db_completeness(value, graularity):\n    start = value[0]\n    end = value[1]\n    date = end\n    unified_result = query(aa_dsn, daily_sql.format(start, end))\n    db_result = query(aa_dsn, sql.format(graularity[0], date, date, graularity))\n    # print date\n    # print unified_result[0][0]\n    # print db_result\n    if unified_result[0][0] == db_result[0][0] and unified_result[0][1] == db_result[0][1] and unified_result[0][2] == db_result[0][2] and unified_result[0][3] == db_result[0][3]:\n        print \"Completeness Test PASS! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n    else:\n        test_result.append(date)\n        print \"Completeness Test FAIL!!!!! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n\n\n\nkey = 'monthly'\nvalue = ['2018-05-01', '2018-05-31']\ncheck_store_unified_db_completeness(value, key)"]},{"cell_type":"code","execution_count":0,"id":"20200625-102242_1856584384","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql.functions import sum\nfrom pyspark.sql.functions import desc\nfrom aadatapipelinecore.core.urn import Urn\nimport psycopg2\nfrom pyspark.sql import Row\nfrom dateutil.relativedelta import relativedelta\nfrom aaplproxy.connection import ClusterConnection\nfrom conf import settings\nfrom aadatapipelinecore.core.loader.plproxy import build_db_settings\nimport datetime as d\nimport datetime\nfrom datetime import timedelta\n\n\ntest_result = []\nPG_AA_HOSTS = [('10.2.6.141', 5432)]\nPG_AA_NAME = 'aa_store_db'\nPG_AA_ACCESS_ID = 'citus_bdp_prod_app_int_qa'\nPG_AA_SECRET_KEY = 'wZw8cfBuuklIskVG'\n\naa_dsn = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_AA_NAME,\n        user=PG_AA_ACCESS_ID,\n        host=PG_AA_HOSTS[0][0],\n        password=PG_AA_SECRET_KEY,\n        port=PG_AA_HOSTS[0][1]\n    )\n)\n\nurn = Urn(\n    namespace=\"app-qa.db-check.v1\",\n    owner=\"app_qa\"\n)\ndaily_sql = \"\"\"select count(1), \n            sum(est_free_app_download), \n            sum(est_paid_app_download), \n            sum(est_revenue)\n            from \n    (select app_id, device_code, country_code,\n            sum(est_free_app_download) as est_free_app_download, \n            sum(est_paid_app_download) as est_paid_app_download,\n            sum(est_revenue) as est_revenue\n            from store.store_est_fact_v1\n            where date between '{}' and '{}'\n            group by\n            app_id,\n            device_code,\n            country_code) as t;\n\"\"\"\n\nsql = \"\"\"select count(1), \n        sum(est_free_app_download), \n        sum(est_paid_app_download), \n        sum(est_revenue)\n        from store.store_est_t_{}_fact_v1 \n        where date between '{}' and '{}' and granularity='{}';\"\"\"\n\n\ndef query(dsn, sql):\n    with psycopg2.connect(dsn) as conn:\n        conn.autocommit = True\n        with conn.cursor() as cur:\n            cur.execute(sql)\n            result = cur.fetchall()\n            conn.commit()\n    return result\n\n\ndef check_store_unified_db_completeness(value, graularity):\n    start = value[0]\n    end = value[1]\n    date = end\n    unified_result = query(aa_dsn, daily_sql.format(start, end))\n    db_result = query(aa_dsn, sql.format(graularity[0], date, date, graularity))\n    # print date\n    # print unified_result[0][0]\n    # print db_result\n    if unified_result[0][0] == db_result[0][0] and unified_result[0][1] == db_result[0][1] and unified_result[0][2] == db_result[0][2] and unified_result[0][3] == db_result[0][3]:\n        print \"Completeness Test PASS! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n    else:\n        test_result.append(date)\n        print \"Completeness Test FAIL!!!!! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n\n\n\nkey = 'quarterly'\nvalue = ['2018-04-01', '2018-06-30']\ncheck_store_unified_db_completeness(value, key)"]},{"cell_type":"code","execution_count":0,"id":"20200625-102607_1179849361","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql.functions import sum\nfrom pyspark.sql.functions import desc\nfrom aadatapipelinecore.core.urn import Urn\nimport psycopg2\nfrom pyspark.sql import Row\nfrom dateutil.relativedelta import relativedelta\nfrom aaplproxy.connection import ClusterConnection\nfrom conf import settings\nfrom aadatapipelinecore.core.loader.plproxy import build_db_settings\nimport datetime as d\nimport datetime\nfrom datetime import timedelta\n\n\ntest_result = []\nPG_AA_HOSTS = [('10.2.6.141', 5432)]\nPG_AA_NAME = 'aa_store_db'\nPG_AA_ACCESS_ID = 'citus_bdp_prod_app_int_qa'\nPG_AA_SECRET_KEY = 'wZw8cfBuuklIskVG'\n\naa_dsn = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_AA_NAME,\n        user=PG_AA_ACCESS_ID,\n        host=PG_AA_HOSTS[0][0],\n        password=PG_AA_SECRET_KEY,\n        port=PG_AA_HOSTS[0][1]\n    )\n)\n\nurn = Urn(\n    namespace=\"app-qa.db-check.v1\",\n    owner=\"app_qa\"\n)\ndaily_sql = \"\"\"select count(1), \n            sum(est_free_app_download), \n            sum(est_paid_app_download), \n            sum(est_revenue)\n            from \n    (select app_id, device_code, country_code,\n            sum(est_free_app_download) as est_free_app_download, \n            sum(est_paid_app_download) as est_paid_app_download,\n            sum(est_revenue) as est_revenue\n            from store.store_est_fact_v1\n            where date between '{}' and '{}'\n            group by\n            app_id,\n            device_code,\n            country_code) as t;\n\"\"\"\n\nsql = \"\"\"select count(1), \n        sum(est_free_app_download), \n        sum(est_paid_app_download), \n        sum(est_revenue)\n        from store.store_est_t_{}_fact_v1 \n        where date between '{}' and '{}' and granularity='{}';\"\"\"\n\n\ndef query(dsn, sql):\n    with psycopg2.connect(dsn) as conn:\n        conn.autocommit = True\n        with conn.cursor() as cur:\n            cur.execute(sql)\n            result = cur.fetchall()\n            conn.commit()\n    return result\n\n\ndef check_store_unified_db_completeness(value, graularity):\n    start = value[0]\n    end = value[1]\n    date = end\n    unified_result = query(aa_dsn, daily_sql.format(start, end))\n    db_result = query(aa_dsn, sql.format(graularity[0], date, date, graularity))\n    # print date\n    # print unified_result[0][0]\n    # print db_result\n    if unified_result[0][0] == db_result[0][0] and unified_result[0][1] == db_result[0][1] and unified_result[0][2] == db_result[0][2] and unified_result[0][3] == db_result[0][3]:\n        print \"Completeness Test PASS! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n    else:\n        test_result.append(date)\n        print \"Completeness Test FAIL!!!!! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n\n\n\nkey = 'yearly'\nvalue = ['2018-01-01', '2018-12-31']\ncheck_store_unified_db_completeness(value, key)"]},{"cell_type":"code","execution_count":0,"id":"20200625-102625_150464052","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql.functions import sum\nfrom pyspark.sql.functions import desc\nfrom aadatapipelinecore.core.urn import Urn\nimport psycopg2\nfrom pyspark.sql import Row\nfrom dateutil.relativedelta import relativedelta\nfrom aaplproxy.connection import ClusterConnection\nfrom conf import settings\nfrom aadatapipelinecore.core.loader.plproxy import build_db_settings\nimport datetime as d\nimport datetime\nfrom datetime import timedelta\n\n\ntest_result = []\nPG_AA_HOSTS = [('10.2.6.141', 5432)]\nPG_AA_NAME = 'aa_store_db'\nPG_AA_ACCESS_ID = 'citus_bdp_prod_app_int_qa'\nPG_AA_SECRET_KEY = 'wZw8cfBuuklIskVG'\n\naa_dsn = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_AA_NAME,\n        user=PG_AA_ACCESS_ID,\n        host=PG_AA_HOSTS[0][0],\n        password=PG_AA_SECRET_KEY,\n        port=PG_AA_HOSTS[0][1]\n    )\n)\n\nurn = Urn(\n    namespace=\"app-qa.db-check.v1\",\n    owner=\"app_qa\"\n)\ndaily_sql = \"\"\"select count(1), \n            sum(est_free_app_download), \n            sum(est_paid_app_download), \n            sum(est_revenue)\n            from \n    (select app_id, device_code, country_code,\n            sum(est_free_app_download) as est_free_app_download, \n            sum(est_paid_app_download) as est_paid_app_download,\n            sum(est_revenue) as est_revenue\n            from store.store_est_fact_v1\n            where date between '{}' and '{}'\n            group by\n            app_id,\n            device_code,\n            country_code) as t;\n\"\"\"\n\nsql = \"\"\"select count(1), \n        sum(est_free_app_download), \n        sum(est_paid_app_download), \n        sum(est_revenue)\n        from store.store_est_t_{}_fact_v1 \n        where date between '{}' and '{}' and granularity='{}';\"\"\"\n\n\ndef query(dsn, sql):\n    with psycopg2.connect(dsn) as conn:\n        conn.autocommit = True\n        with conn.cursor() as cur:\n            cur.execute(sql)\n            result = cur.fetchall()\n            conn.commit()\n    return result\n\n\ndef check_store_unified_db_completeness(value, graularity):\n    start = value[0]\n    end = value[1]\n    date = end\n    unified_result = query(aa_dsn, daily_sql.format(start, end))\n    db_result = query(aa_dsn, sql.format(graularity[0], date, date, graularity))\n    # print date\n    # print unified_result[0][0]\n    # print db_result\n    if unified_result[0][0] == db_result[0][0] and unified_result[0][1] == db_result[0][1] and unified_result[0][2] == db_result[0][2] and unified_result[0][3] == db_result[0][3]:\n        print \"Completeness Test PASS! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n    else:\n        test_result.append(date)\n        print \"Completeness Test FAIL!!!!! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n\n\n\nkey = 'weekly'\nvalue = ['2020-01-26', '2020-02-01']\ncheck_store_unified_db_completeness(value, key)"]},{"cell_type":"code","execution_count":0,"id":"20200625-102745_1858029206","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql.functions import sum\nfrom pyspark.sql.functions import desc\nfrom aadatapipelinecore.core.urn import Urn\nimport psycopg2\nfrom pyspark.sql import Row\nfrom dateutil.relativedelta import relativedelta\nfrom aaplproxy.connection import ClusterConnection\nfrom conf import settings\nfrom aadatapipelinecore.core.loader.plproxy import build_db_settings\nimport datetime as d\nimport datetime\nfrom datetime import timedelta\n\n\ntest_result = []\nPG_AA_HOSTS = [('10.2.6.141', 5432)]\nPG_AA_NAME = 'aa_store_db'\nPG_AA_ACCESS_ID = 'citus_bdp_prod_app_int_qa'\nPG_AA_SECRET_KEY = 'wZw8cfBuuklIskVG'\n\naa_dsn = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_AA_NAME,\n        user=PG_AA_ACCESS_ID,\n        host=PG_AA_HOSTS[0][0],\n        password=PG_AA_SECRET_KEY,\n        port=PG_AA_HOSTS[0][1]\n    )\n)\n\nurn = Urn(\n    namespace=\"app-qa.db-check.v1\",\n    owner=\"app_qa\"\n)\ndaily_sql = \"\"\"select count(1), \n            sum(est_free_app_download), \n            sum(est_paid_app_download), \n            sum(est_revenue)\n            from \n    (select app_id, device_code, country_code,\n            sum(est_free_app_download) as est_free_app_download, \n            sum(est_paid_app_download) as est_paid_app_download,\n            sum(est_revenue) as est_revenue\n            from store.store_est_fact_v1\n            where date between '{}' and '{}'\n            group by\n            app_id,\n            device_code,\n            country_code) as t;\n\"\"\"\n\nsql = \"\"\"select count(1), \n        sum(est_free_app_download), \n        sum(est_paid_app_download), \n        sum(est_revenue)\n        from store.store_est_t_{}_fact_v1 \n        where date between '{}' and '{}' and granularity='{}';\"\"\"\n\n\ndef query(dsn, sql):\n    with psycopg2.connect(dsn) as conn:\n        conn.autocommit = True\n        with conn.cursor() as cur:\n            cur.execute(sql)\n            result = cur.fetchall()\n            conn.commit()\n    return result\n\n\ndef check_store_unified_db_completeness(value, graularity):\n    start = value[0]\n    end = value[1]\n    date = end\n    unified_result = query(aa_dsn, daily_sql.format(start, end))\n    db_result = query(aa_dsn, sql.format(graularity[0], date, date, graularity))\n    # print date\n    # print unified_result[0][0]\n    # print db_result\n    if unified_result[0][0] == db_result[0][0] and unified_result[0][1] == db_result[0][1] and unified_result[0][2] == db_result[0][2] and unified_result[0][3] == db_result[0][3]:\n        print \"Completeness Test PASS! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n    else:\n        test_result.append(date)\n        print \"Completeness Test FAIL!!!!! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n\n\n\nkey = 'monthly'\nvalue = ['2020-02-01', '2020-02-29']\ncheck_store_unified_db_completeness(value, key)"]},{"cell_type":"code","execution_count":0,"id":"20200625-102825_2058782389","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql.functions import sum\nfrom pyspark.sql.functions import desc\nfrom aadatapipelinecore.core.urn import Urn\nimport psycopg2\nfrom pyspark.sql import Row\nfrom dateutil.relativedelta import relativedelta\nfrom aaplproxy.connection import ClusterConnection\nfrom conf import settings\nfrom aadatapipelinecore.core.loader.plproxy import build_db_settings\nimport datetime as d\nimport datetime\nfrom datetime import timedelta\n\n\ntest_result = []\nPG_AA_HOSTS = [('10.2.6.141', 5432)]\nPG_AA_NAME = 'aa_store_db'\nPG_AA_ACCESS_ID = 'citus_bdp_prod_app_int_qa'\nPG_AA_SECRET_KEY = 'wZw8cfBuuklIskVG'\n\naa_dsn = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_AA_NAME,\n        user=PG_AA_ACCESS_ID,\n        host=PG_AA_HOSTS[0][0],\n        password=PG_AA_SECRET_KEY,\n        port=PG_AA_HOSTS[0][1]\n    )\n)\n\nurn = Urn(\n    namespace=\"app-qa.db-check.v1\",\n    owner=\"app_qa\"\n)\ndaily_sql = \"\"\"select count(1), \n            sum(est_free_app_download), \n            sum(est_paid_app_download), \n            sum(est_revenue)\n            from \n    (select app_id, device_code, country_code,\n            sum(est_free_app_download) as est_free_app_download, \n            sum(est_paid_app_download) as est_paid_app_download,\n            sum(est_revenue) as est_revenue\n            from store.store_est_fact_v1\n            where date between '{}' and '{}'\n            group by\n            app_id,\n            device_code,\n            country_code) as t;\n\"\"\"\n\nsql = \"\"\"select count(1), \n        sum(est_free_app_download), \n        sum(est_paid_app_download), \n        sum(est_revenue)\n        from store.store_est_t_{}_fact_v1 \n        where date between '{}' and '{}' and granularity='{}';\"\"\"\n\n\ndef query(dsn, sql):\n    with psycopg2.connect(dsn) as conn:\n        conn.autocommit = True\n        with conn.cursor() as cur:\n            cur.execute(sql)\n            result = cur.fetchall()\n            conn.commit()\n    return result\n\n\ndef check_store_unified_db_completeness(value, graularity):\n    start = value[0]\n    end = value[1]\n    date = end\n    unified_result = query(aa_dsn, daily_sql.format(start, end))\n    db_result = query(aa_dsn, sql.format(graularity[0], date, date, graularity))\n    # print date\n    # print unified_result[0][0]\n    # print db_result\n    if unified_result[0][0] == db_result[0][0] and unified_result[0][1] == db_result[0][1] and unified_result[0][2] == db_result[0][2] and unified_result[0][3] == db_result[0][3]:\n        print \"Completeness Test PASS! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n    else:\n        test_result.append(date)\n        print \"Completeness Test FAIL!!!!! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n\n\n\nkey = ''\nvalue = ['2020-01-01', '2020-03-31']\ncheck_store_unified_db_completeness(value, key)"]},{"cell_type":"code","execution_count":0,"id":"20200625-103509_783927423","metadata":{},"outputs":[],"source":["%%sh\nPGPASSWORD='wZw8cfBuuklIskVG' psql -h 10.2.6.141  -U citus_bdp_prod_app_int_qa -d aa_store_db -p 5432 << EOF \nset search_path=store;\nselect count(1), \n        sum(est_free_app_download), \n        sum(est_paid_app_download), \n        sum(est_revenue)\n        from store.store_est_t_q_fact_v1 \n        where date between '2019-03-31' and '2019-03-31' and granularity='quarterly';\nEOF\n"]},{"cell_type":"code","execution_count":0,"id":"20200625-102854_1948636720","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql.functions import sum\nfrom pyspark.sql.functions import desc\nfrom aadatapipelinecore.core.urn import Urn\nimport psycopg2\nfrom pyspark.sql import Row\nfrom dateutil.relativedelta import relativedelta\nfrom aaplproxy.connection import ClusterConnection\nfrom conf import settings\nfrom aadatapipelinecore.core.loader.plproxy import build_db_settings\nimport datetime as d\nimport datetime\nfrom datetime import timedelta\n\n\ntest_result = []\nPG_AA_HOSTS = [('10.2.6.141', 5432)]\nPG_AA_NAME = 'aa_store_db'\nPG_AA_ACCESS_ID = 'citus_bdp_prod_app_int_qa'\nPG_AA_SECRET_KEY = 'wZw8cfBuuklIskVG'\n\naa_dsn = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_AA_NAME,\n        user=PG_AA_ACCESS_ID,\n        host=PG_AA_HOSTS[0][0],\n        password=PG_AA_SECRET_KEY,\n        port=PG_AA_HOSTS[0][1]\n    )\n)\n\nurn = Urn(\n    namespace=\"app-qa.db-check.v1\",\n    owner=\"app_qa\"\n)\ndaily_sql = \"\"\"select count(1), \n            sum(est_free_app_download), \n            sum(est_paid_app_download), \n            sum(est_revenue)\n            from \n    (select app_id, device_code, country_code,\n            sum(est_free_app_download) as est_free_app_download, \n            sum(est_paid_app_download) as est_paid_app_download,\n            sum(est_revenue) as est_revenue\n            from store.store_est_fact_v1\n            where date between '{}' and '{}'\n            group by\n            app_id,\n            device_code,\n            country_code) as t;\n\"\"\"\n\nsql = \"\"\"select count(1), \n        sum(est_free_app_download), \n        sum(est_paid_app_download), \n        sum(est_revenue)\n        from store.store_est_t_{}_fact_v1 \n        where date between '{}' and '{}' and granularity='{}';\"\"\"\n\n\ndef query(dsn, sql):\n    with psycopg2.connect(dsn) as conn:\n        conn.autocommit = True\n        with conn.cursor() as cur:\n            cur.execute(sql)\n            result = cur.fetchall()\n            conn.commit()\n    return result\n\n\ndef check_store_unified_db_completeness(value, graularity):\n    start = value[0]\n    end = value[1]\n    date = end\n    unified_result = query(aa_dsn, daily_sql.format(start, end))\n    db_result = query(aa_dsn, sql.format(graularity[0], date, date, graularity))\n    # print date\n    # print unified_result[0][0]\n    # print db_result\n    if unified_result[0][0] == db_result[0][0] and unified_result[0][1] == db_result[0][1] and unified_result[0][2] == db_result[0][2] and unified_result[0][3] == db_result[0][3]:\n        print \"Completeness Test PASS! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n    else:\n        test_result.append(date)\n        print \"Completeness Test FAIL!!!!! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n\n\n\nkey = 'weekly'\nvalue = ['2020-02-02', '2020-02-08']\ncheck_store_unified_db_completeness(value, key)"]},{"cell_type":"code","execution_count":0,"id":"20200625-103111_1578446067","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql.functions import sum\nfrom pyspark.sql.functions import desc\nfrom aadatapipelinecore.core.urn import Urn\nimport psycopg2\nfrom pyspark.sql import Row\nfrom dateutil.relativedelta import relativedelta\nfrom aaplproxy.connection import ClusterConnection\nfrom conf import settings\nfrom aadatapipelinecore.core.loader.plproxy import build_db_settings\nimport datetime as d\nimport datetime\nfrom datetime import timedelta\n\n\ntest_result = []\nPG_AA_HOSTS = [('10.2.6.141', 5432)]\nPG_AA_NAME = 'aa_store_db'\nPG_AA_ACCESS_ID = 'citus_bdp_prod_app_int_qa'\nPG_AA_SECRET_KEY = 'wZw8cfBuuklIskVG'\n\naa_dsn = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_AA_NAME,\n        user=PG_AA_ACCESS_ID,\n        host=PG_AA_HOSTS[0][0],\n        password=PG_AA_SECRET_KEY,\n        port=PG_AA_HOSTS[0][1]\n    )\n)\n\nurn = Urn(\n    namespace=\"app-qa.db-check.v1\",\n    owner=\"app_qa\"\n)\ndaily_sql = \"\"\"select count(1), \n            sum(est_free_app_download), \n            sum(est_paid_app_download), \n            sum(est_revenue)\n            from \n    (select app_id, device_code, country_code,\n            sum(est_free_app_download) as est_free_app_download, \n            sum(est_paid_app_download) as est_paid_app_download,\n            sum(est_revenue) as est_revenue\n            from store.store_est_fact_v1\n            where date between '{}' and '{}'\n            group by\n            app_id,\n            device_code,\n            country_code) as t;\n\"\"\"\n\nsql = \"\"\"select count(1), \n        sum(est_free_app_download), \n        sum(est_paid_app_download), \n        sum(est_revenue)\n        from store.store_est_t_{}_fact_v1 \n        where date between '{}' and '{}' and granularity='{}';\"\"\"\n\n\ndef query(dsn, sql):\n    with psycopg2.connect(dsn) as conn:\n        conn.autocommit = True\n        with conn.cursor() as cur:\n            cur.execute(sql)\n            result = cur.fetchall()\n            conn.commit()\n    return result\n\n\ndef check_store_unified_db_completeness(value, graularity):\n    start = value[0]\n    end = value[1]\n    date = end\n    unified_result = query(aa_dsn, daily_sql.format(start, end))\n    db_result = query(aa_dsn, sql.format(graularity[0], date, date, graularity))\n    # print date\n    # print unified_result[0][0]\n    # print db_result\n    if unified_result[0][0] == db_result[0][0] and unified_result[0][1] == db_result[0][1] and unified_result[0][2] == db_result[0][2] and unified_result[0][3] == db_result[0][3]:\n        print \"Completeness Test PASS! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n    else:\n        test_result.append(date)\n        print \"Completeness Test FAIL!!!!! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n\n\n\nkey = 'weekly'\nvalue = ['2019-12-29', '2020-01-04']\ncheck_store_unified_db_completeness(value, key)"]},{"cell_type":"code","execution_count":0,"id":"20200625-103149_492607823","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql.functions import sum\nfrom pyspark.sql.functions import desc\nfrom aadatapipelinecore.core.urn import Urn\nimport psycopg2\nfrom pyspark.sql import Row\nfrom dateutil.relativedelta import relativedelta\nfrom aaplproxy.connection import ClusterConnection\nfrom conf import settings\nfrom aadatapipelinecore.core.loader.plproxy import build_db_settings\nimport datetime as d\nimport datetime\nfrom datetime import timedelta\n\n\ntest_result = []\nPG_AA_HOSTS = [('10.2.6.141', 5432)]\nPG_AA_NAME = 'aa_store_db'\nPG_AA_ACCESS_ID = 'citus_bdp_prod_app_int_qa'\nPG_AA_SECRET_KEY = 'wZw8cfBuuklIskVG'\n\naa_dsn = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_AA_NAME,\n        user=PG_AA_ACCESS_ID,\n        host=PG_AA_HOSTS[0][0],\n        password=PG_AA_SECRET_KEY,\n        port=PG_AA_HOSTS[0][1]\n    )\n)\n\nurn = Urn(\n    namespace=\"app-qa.db-check.v1\",\n    owner=\"app_qa\"\n)\ndaily_sql = \"\"\"select count(1), \n            sum(est_free_app_download), \n            sum(est_paid_app_download), \n            sum(est_revenue)\n            from \n    (select app_id, device_code, country_code,\n            sum(est_free_app_download) as est_free_app_download, \n            sum(est_paid_app_download) as est_paid_app_download,\n            sum(est_revenue) as est_revenue\n            from store.store_est_fact_v1\n            where date between '{}' and '{}'\n            group by\n            app_id,\n            device_code,\n            country_code) as t;\n\"\"\"\n\nsql = \"\"\"select count(1), \n        sum(est_free_app_download), \n        sum(est_paid_app_download), \n        sum(est_revenue)\n        from store.store_est_t_{}_fact_v1 \n        where date between '{}' and '{}' and granularity='{}';\"\"\"\n\n\ndef query(dsn, sql):\n    with psycopg2.connect(dsn) as conn:\n        conn.autocommit = True\n        with conn.cursor() as cur:\n            cur.execute(sql)\n            result = cur.fetchall()\n            conn.commit()\n    return result\n\n\ndef check_store_unified_db_completeness(value, graularity):\n    start = value[0]\n    end = value[1]\n    date = end\n    unified_result = query(aa_dsn, daily_sql.format(start, end))\n    db_result = query(aa_dsn, sql.format(graularity[0], date, date, graularity))\n    # print date\n    # print unified_result[0][0]\n    # print db_result\n    if unified_result[0][0] == db_result[0][0] and unified_result[0][1] == db_result[0][1] and unified_result[0][2] == db_result[0][2] and unified_result[0][3] == db_result[0][3]:\n        print \"Completeness Test PASS! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n    else:\n        test_result.append(date)\n        print \"Completeness Test FAIL!!!!! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n\n\n\nkey = 'monthly'\nvalue = ['2020-01-01', '2020-01-31']\ncheck_store_unified_db_completeness(value, key)"]},{"cell_type":"code","execution_count":0,"id":"20200625-103214_170249119","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql.functions import sum\nfrom pyspark.sql.functions import desc\nfrom aadatapipelinecore.core.urn import Urn\nimport psycopg2\nfrom pyspark.sql import Row\nfrom dateutil.relativedelta import relativedelta\nfrom aaplproxy.connection import ClusterConnection\nfrom conf import settings\nfrom aadatapipelinecore.core.loader.plproxy import build_db_settings\nimport datetime as d\nimport datetime\nfrom datetime import timedelta\n\n\ntest_result = []\nPG_AA_HOSTS = [('10.2.6.141', 5432)]\nPG_AA_NAME = 'aa_store_db'\nPG_AA_ACCESS_ID = 'citus_bdp_prod_app_int_qa'\nPG_AA_SECRET_KEY = 'wZw8cfBuuklIskVG'\n\naa_dsn = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_AA_NAME,\n        user=PG_AA_ACCESS_ID,\n        host=PG_AA_HOSTS[0][0],\n        password=PG_AA_SECRET_KEY,\n        port=PG_AA_HOSTS[0][1]\n    )\n)\n\nurn = Urn(\n    namespace=\"app-qa.db-check.v1\",\n    owner=\"app_qa\"\n)\ndaily_sql = \"\"\"select count(1), \n            sum(est_free_app_download), \n            sum(est_paid_app_download), \n            sum(est_revenue)\n            from \n    (select app_id, device_code, country_code,\n            sum(est_free_app_download) as est_free_app_download, \n            sum(est_paid_app_download) as est_paid_app_download,\n            sum(est_revenue) as est_revenue\n            from store.store_est_fact_v1\n            where date between '{}' and '{}'\n            group by\n            app_id,\n            device_code,\n            country_code) as t;\n\"\"\"\n\nsql = \"\"\"select count(1), \n        sum(est_free_app_download), \n        sum(est_paid_app_download), \n        sum(est_revenue)\n        from store.store_est_t_{}_fact_v1 \n        where date between '{}' and '{}' and granularity='{}';\"\"\"\n\n\ndef query(dsn, sql):\n    with psycopg2.connect(dsn) as conn:\n        conn.autocommit = True\n        with conn.cursor() as cur:\n            cur.execute(sql)\n            result = cur.fetchall()\n            conn.commit()\n    return result\n\n\ndef check_store_unified_db_completeness(value, graularity):\n    start = value[0]\n    end = value[1]\n    date = end\n    unified_result = query(aa_dsn, daily_sql.format(start, end))\n    quarterly_est_bucket= \"store.app-est.v3\"\n    category_df = spark.read.format(\"delta\").load(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/\" \\\n    \"{}/fact/\".format(quarterly_est_bucket)).where(\"granularity='{}' and date between '{}' and '{}'\".format(graularity, end, end))\n    category_df.createOrReplaceTempView(\"category_daily_df\")\n    db_result = spark.sql(\"select count(1), sum(free_app_download), sum(paid_app_download), sum(revenue) from category_daily_df\").collect()\n    if unified_result[0][0] == db_result[0][0] and unified_result[0][1] == db_result[0][1] and unified_result[0][2] == db_result[0][2] and unified_result[0][3] == db_result[0][3]:\n        print \"Completeness Test PASS! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n    else:\n        test_result.append(date)\n        print \"Completeness Test FAIL!!!!! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n\n\n\nkey = 'weekly'\nvalue = ['2020-03-01', '2020-03-07']\ncheck_store_unified_db_completeness(value, key)"]},{"cell_type":"code","execution_count":0,"id":"20200625-115033_1980423616","metadata":{},"outputs":[],"source":["\nfrom pyspark.sql.functions import sum\nfrom pyspark.sql.functions import desc\nfrom aadatapipelinecore.core.urn import Urn\nimport psycopg2\nfrom pyspark.sql import Row\nfrom dateutil.relativedelta import relativedelta\nfrom aaplproxy.connection import ClusterConnection\nfrom conf import settings\nfrom aadatapipelinecore.core.loader.plproxy import build_db_settings\nimport datetime as d\nimport datetime\nfrom datetime import timedelta\n\n\ntest_result = []\nPG_AA_HOSTS = [('10.2.6.141', 5432)]\nPG_AA_NAME = 'aa_store_db'\nPG_AA_ACCESS_ID = 'citus_bdp_prod_app_int_qa'\nPG_AA_SECRET_KEY = 'wZw8cfBuuklIskVG'\n\naa_dsn = (\n    \"dbname='{db}' user='{user}' password='{password}' \"\n    \"host='{host}' port='{port}'\".format(\n        db=PG_AA_NAME,\n        user=PG_AA_ACCESS_ID,\n        host=PG_AA_HOSTS[0][0],\n        password=PG_AA_SECRET_KEY,\n        port=PG_AA_HOSTS[0][1]\n    )\n)\n\nurn = Urn(\n    namespace=\"app-qa.db-check.v1\",\n    owner=\"app_qa\"\n)\ndaily_sql = \"\"\"select count(1), \n            sum(est_free_app_download), \n            sum(est_paid_app_download), \n            sum(est_revenue)\n            from \n    (select app_id, device_code, country_code,\n            sum(est_free_app_download) as est_free_app_download, \n            sum(est_paid_app_download) as est_paid_app_download,\n            sum(est_revenue) as est_revenue\n            from store.store_est_fact_v1\n            where date between '{}' and '{}'\n            group by\n            app_id,\n            device_code,\n            country_code) as t;\n\"\"\"\n\nsql = \"\"\"select count(1), \n        sum(est_free_app_download), \n        sum(est_paid_app_download), \n        sum(est_revenue)\n        from store.store_est_t_{}_fact_v1 \n        where date between '{}' and '{}' and granularity='{}';\"\"\"\n\n\ndef query(dsn, sql):\n    with psycopg2.connect(dsn) as conn:\n        conn.autocommit = True\n        with conn.cursor() as cur:\n            cur.execute(sql)\n            result = cur.fetchall()\n            conn.commit()\n    return result\n\n\ndef check_store_unified_db_completeness(value, graularity):\n    start = value[0]\n    end = value[1]\n    date = end\n    unified_result = query(aa_dsn, daily_sql.format(start, end))\n    quarterly_est_bucket= \"store.app-est.v3\"\n    category_df = spark.read.format(\"delta\").load(\"s3://b2c-prod-data-pipeline-unified-store-paid/unified/\" \\\n    \"{}/fact/\".format(quarterly_est_bucket)).where(\"granularity='{}' and date between '{}' and '{}'\".format(graularity, end, end))\n    category_df.createOrReplaceTempView(\"category_daily_df\")\n    db_result = spark.sql(\"select count(1), sum(free_app_download), sum(paid_app_download), sum(revenue) from category_daily_df\").collect()\n    if unified_result[0][0] == db_result[0][0] and unified_result[0][1] == db_result[0][1] and unified_result[0][2] == db_result[0][2] and unified_result[0][3] == db_result[0][3]:\n        print \"Completeness Test PASS! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n    else:\n        test_result.append(date)\n        print \"Completeness Test FAIL!!!!! date: {}, unified: {}, db: {}\".format(date, unified_result[0], db_result[0])\n\n\n\nkey = 'monthly'\nvalue = ['2020-03-01', '2020-03-31']\ncheck_store_unified_db_completeness(value, key)"]},{"cell_type":"code","execution_count":0,"id":"20200625-112711_1119600420","metadata":{},"outputs":[],"source":["%%sh\nPGPASSWORD='wZw8cfBuuklIskVG' psql -h 10.2.6.141  -U citus_bdp_prod_app_int_qa -d aa_store_db -p 5432 << EOF \nset search_path=store;\nselect count(1), \n        sum(est_free_app_download), \n        sum(est_paid_app_download), \n        sum(est_revenue)\n        from store.store_est_category_t_w_fact_v1 \n        where date between '2015-11-07' and '2015-11-07' and granularity='weekly';\nEOF"]},{"cell_type":"code","execution_count":0,"id":"20200625-113013_751227946","metadata":{},"outputs":[],"source":["%%sh\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}