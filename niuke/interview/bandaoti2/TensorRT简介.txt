引用文章地址：
https://blog.csdn.net/qq_40305597/article/details/121344844

TensorRT  简介

这张图是一个完整的现代深度学习应用，在硬件的应用方面，三个比较大的常用的领域是：
视觉相关，包含医疗、自动驾驶、摄像头的处理等等；
另外是语音和自然语言处理相关，包含语义理解和语音识别。
为了实现这些功能，会使用各种各样的框架，包括Caffe、TensorFlow、PyTorch等等。
框架不同，每个人的使用习惯也不同，但最终都是完成一件事情：深度学习模型的训练，
以及深度模型的推理。这样一个工具。完成这两个任务最核心的内容还是计算。
今天主要核心介绍的就是TensorRT以及相关的DeepStream SDK，他们如何来加速深度学习推理计算。

3. TensorRT 工作流程

第一件事是权重精度的校正。比如现在通常用的是FP32的数据类型，如果在做HPC的时候，
就可能都会用double类型的float，我们为什么要double类型？因为精度需要非常大的动态范围。
但是深度学习在做训练的时候可能并不需要那么大的动态范围，它非常小，可能连FP32都用不了，
这个时候就可以用一个更小的动态数据类型。现在TensorRT提出一个FP16半精度的数据类型，
还有int8以及最新出的int4的一些数据类型。
用这个工具可以帮助把一个较大范围的数据映射到一个较小的范围之内。这样的话在做计算的时候，
转换数据的速度非常快，因为数据类型的原因，它所占用的资源也非常少，这个时候的计算速度就会变得很快。

第二件事是网络层的合并，包括一些张量的重新规划。

第三件事是内核调用。内核调用跟GPU底层相关，NVIDIA所有的工具基本上都是基于CUDA这个生态所建立，
CUDA里核心的内容是两个方面。
一个方面是内存中各种显存的调用，多流的执行。
并行计算最有一个难点是数据传输之间那部分很难消掉，
硬件卡住的部分无法并行，而CUDA里边多流的执行把这些数据在传输的过程中进行计算，这样就把传输的部分给隐藏了。

另外一个方面是怎么调用CUDA核，怎么分配，
每个block里边分配多少个线程，每个grid里边有多少个block。
这些内容都对GPU要求或者对CUDA的计算功底要求比较高，需要花更多时间，
也需要对硬件底层更了解。
而TensorRT里边调用了一些方法，以一个最合理的方式去调用、操作这些数据。
Grid  --> Block  -> Thread




TensorRT的主要工作流程分为以下六步：

Export the model（导出模型）：将训练后的深度神经网络模型导出为ONNX/WTS文件。

Select Batch size：推断时，当优先考虑延迟时选择小的Batch，优先考虑吞吐量时选较大的Batch，
    Batch越大所需要的处理时间越长，但每个样本的平均时间越小。

Select Precision：推理一般需要比训练少的数字精度，较低的精度可以在不牺牲精度下提供更快的计算速度，
    更低的内存消耗，TensorRT支持TF32,FP32,FP10,INT8精度。

Convert the model：将模型从WTS/ONNX转为TensorRT引擎。

Deploy the model：两种类型的Runtime，C++和python绑定的独立的Runtime，
    以及与Tensorflow的原生集成的Runtime。


4.TensorRT 优化方式

4.1TensorRT 优化方式

使用TensorRT的必要步骤为：
    首先根据模型创建TensorRT的网络定义；
    然后调用TensorRT构建器以从网络创建优化的runtime引擎；
    序列化和反序列化引擎可以在runtime快速重新创建；
    最后向引擎提供数据以执行推理。T
    
    ensorRT优化方式主要有以下几点：

第一：重建网络结构，将一些可以组合的网络层进行层间融合或张量融合优化，这种优化方式也是最重要的优化方式。
    YOLOv5包含较多的网络层，部署推理目标检测模型的每层张量的计算都需要GPU来进行，GPU调用内部CUDA核心资源时，
    每层输入输出张量节点运算时都消耗较多时间在读写操作，内存带宽和GPU资源消耗都较多，
    层之间进行水平或垂直合并可以减少层数，提高了显存和带宽利用率。CUDA在多数据流传输时测量和计算数据信息，
    读写、输入输出启用/关闭并流过每一层消耗了大部分逻辑推理时间，层间合并/张量合并降低了使用CUDA的频率，
    零碎数据整合为整体传输，减少了向CPU 传输的次数，减少运行时间。

    比如卷积神经网络框架一般包含一个卷积层、一个偏置层和一个激活层，所以需要调用三次cuDNN对应的API，
    这三层网络就是可以合并到一起的；再比如YOLOv5的网络比较深也比较宽，并行运行若干个卷积层，这些卷积层也是可以合并的，
    合并一般分为网络结构的垂直集成和水平组合，
    例如将GoogleNetInception中三个卷积层、BN 质量层和 Relu 非线性激活层合并为一个网络层（CBR层），即垂直集成；
    水平组合即将输入为相同张量和执行相同操作的层融合一起，例如将GoogleNetInception中三个相连的1×1的CBR为一个大的1×1的CBR。

第二：去除concat层，降低传输吞吐量，不单独输入contcat，将输入直接传送至下一网络层，
    TensorRT可以不需要concat的操作而直接实现cancat，所以concat这层没有必要可以去除。
    例如可以将计算结果1×3×24×24和1×5×24×24 concat到一起变成一个1×8×24×24的矩阵。

第三：TensorRT预先写好了较多的GPU实现，Kernel根据不同的batch size大小和问题的复杂程度自动选择最合适的算法。

第四：不同的batch size做相应的tuning。

第五：精度优化，训练改进烟火检测模型时使用全精度FP32位数据，部署推理无需反向传播更新相应的计算节点的张量值，
    虽然引入了噪声，误差噪声影响各层的激活值输出，但对结果影响甚微，
    所以TensorRT推理时可以选用半精度浮点型INT8或FP16部署神经网络来加速推断，极大地提高了系统的吞吐量，降低了系统延迟时间，提高了准确率。
    TensorRT推理在模型层面和语言层面均可以获得加速，本文采用的TensorRT加速的YOLOv5模型更简单、推理更迅速、准确度更高，
    Jetson Nano内含嵌入式GPU支持 TensorRT，本论文采取的TensorRT加速的方案即为目前最成熟且优化的方式。
